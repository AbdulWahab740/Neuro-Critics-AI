{"pmid": "40748497", "pmcid": "12304841", "title": "Contribution of an Ambidirectional Cohort Study on the Epidemiology of 186 Autism Spectrum Disorder Cases in an Algerian Population", "publication_year": "N/A", "abstract": "Autism spectrum disorder (ASD) affects more than 80,000 children under the age of 18 in Algeria, making it a major public health problem. It is characterized by communication abnormalities, restricted and stereotyped behaviours and resistance to change. To date, scientific publications on autism in Algeria are very rare. This study proposes to report the clinical and paraclinical profiles of ASD children or young adults in an Algerian population, as well as the prenatal, perinatal and postnatal factors associated with ASD. We conducted an ambidirectional cohort study (retrospective and prospective) on 186 persons (143 boys and 43 girls) with a diagnosis of ASD who ranged in chronological age from 3 to 25 years (mean = 7 years 8 months; standard deviation = 3 years 9 months). Data were collected from medical records and patients interviews. The ASD diagnosis was carried out according to the Diagnostic and Statistical Manual of Mental Disorders, 4th Edition, revised, to the Diagnostic and Statistical Manual of Mental Disorders‐5th Ed (DSM‐5) criteria, the Childhood Autism Rating Scale (CARS), Autism Diagnostic Interview‐Revised and Autism Diagnostic Observation Schedule. Insomnia (36.6%) and attention‐deficit/hyperactivity disorder (13%) were the main comorbidities associated with autism. Most of the children (63.4%) were treated following the Treatment and Education of Autistic and Related Communication Handicapped Children. The rate of prenatal, perinatal and postnatal risk factors was registered among the ASD population. The clinical features and comorbidities of autism present among the study group were similar to findings in individuals with ASD in other parts of the world.", "full_text": "Autism spectrum disorder (ASD) is a group of complex developmental disorders characterized by deficits in social communication and restricted repetitive patterns of behaviour. The severity of these symptoms varies for each patient. ASD begins in early childhood and affects around 1% of the worldwide population (Myers et al.\nThe current situation of ASD and its prevalence in African countries remain poorly investigated and require further research. In North Africa, and particularly in Algeria, there is a significant lack of accurate data on the prevalence of autism. This absence of information limits the ability of health authorities and healthcare professionals to implement adapted policies for screening, diagnosis and care.\nThe prevalence of ASD among children with developmental disorders in Egypt and Tunisia was documented as 33.6% and 11.5%, respectively (Bakare and Munir\nIn Algeria, very few studies have been conducted on ASD. The prevalence of ASD during the period of 1997–2003 was rated at 38% of the total diagnoses among developmental disorders established in daytime hospitalization of Algiers (OuldTaleb\nIn 2018, Bekkou reported the epidemiological profile of ASD in the eastern region of Algeria (Bekkou et al.\nThe aim of the current study is (1) to describe the clinical and paraclinical profiles of ASD individuals in an Algerian population and (2) to investigate the association between prenatal and perinatal factors and the development of ASD in this population.\nThe present study is an ambidirectional cohort study conducted on a clinical population of children, adolescents and two adults with ASD and their parents.\nRetrospective study data were collected from autistic persons' medical records from 2013 to 2018.\nProspective data were collected from medical records and parents' interviews, from January 2019 until January 2021.\nA total of 186 individuals s diagnosed with ASD were enrolled from four different facilities in Algiers. Two are health facilities: Child and Adolescent Psychiatry Hospital of Drid Hocine (Algiers) and Neurology Service of the Specialized Hospital Establishment Pr Abdelkader Boukhroufa, Algiers. The two remaining establishments were the specialized educational and teaching institution ‘El RAFAHIYA LI TAWEHOUD’ for children in special need and the Association of the Williams–Beuren syndrome, Algiers.\nThe diagnosis of autism for all the persons included in the study was established by highly trained physicians (psychiatrists, paediatricians and neurologists) and non‐physicians (psychologists and speech therapists) using the DSM‐IV‐TR or DSM‐V (Diagnostic and Statistical Manual of Mental Disorders Fourth Edition Revised and Fifth Edition) clinical criteria. In addition to the clinical diagnosis, different diagnostic tools were used for distinguishing ASD from other developmental disorders and rating the autism symptom severity. Professionals either used a single diagnosis tool or a combination of two. Some others used a screening tool along with a diagnosis before making the final diagnosis.\nScreening tools used were the Modified‐Checklist for Autism in Toddlers (M‐CHAT) (Baron‐Cohen et al.\nASD affected individuals recruited were treated following different psychological approaches:\nTherapy of exchange and development (TED) (Lelord et al.\nApplied behaviour analysis (ABA) (Lovaas\nTreatment and Education of Autistic and Related Communication Handicapped Children (TEACCH) (Schopler\nThe Picture Exchange Communication System (PECS) (Bondy and Frost\nAll individuals included in the study had a diagnosis of ASD according to clinical criteria of the Diagnostic and Statistical Manual of Mental Disorders using the DSM‐IV‐TR or DSM‐V, depending on the diagnostic period. The children included in the study were aged at least 3 years.\nOne of the methodological challenges of this study lies in the use of the DSM‐IV‐TR and DSM‐5 criteria. To avoid inconsistencies in diagnoses, we applied a systematic conversion of old diagnoses (DSM‐IV‐TR) into DSM‐5 equivalents using recommendations established by previous studies (Volkmar and McPartland\nThis approach allows for the harmonization of diagnostic classifications and ensures continuity between patients diagnosed before and after 2018. Moreover, we considered the specific differences introduced by the DSM‐5, particularly the removal of subcategories and the new conceptualization of the disorder in severity levels. Among the 80 retrospective cases, 67 (83.8%) met DSM‐5 diagnostic criteria directly based on standardized tools and available clinical data. The remaining 13 cases (16.3%) initially showed partial compatibility but were reviewed in detail by clinicians to assess whether they fulfilled DSM‐5 core domains, including social communication deficits and restricted repetitive behaviours. Following this clinical reassessment, all 13 cases were confirmed as meeting DSM‐5 criteria for ASD and were therefore included in the final analysis.\nThe use of multiple diagnostic tools in this study aims to ensure a comprehensive and accurate assessment of ASD. Each tool used (M‐CHAT, CARS, ECA, ABC, ADOS, ADI‐R and BSE) targets specific aspects of the disorder, allowing for a finer analysis of patient profiles. This combined approach is consistent with international recommendations that advocate for the use of multiple instruments to increase the validity and reliability of diagnoses (Lord et al.\nSeveral of the tools used in this study were adapted and validated for Arabic‐speaking populations, including in Algeria. The M‐CHAT‐R/F, CARS‐2 and ECA were administered in their Modern Standard Arabic (MSA) or French versions, depending on the caregiver's language preference (Mneimneh et al.\nThe ADOS and ADI‐R, on the other hand, are internationally standardized behavioural tools recognized for their language independence, making them suitable for different populations (Lord et al.\nThe diagnostic tools selected in this study were chosen to complement each other rather than overlap. Each tool evaluates a specific dimension of ASD:\nThe M‐CHAT is an early screening tool for young children.\nThe CARS and ECA allow for an in‐depth behavioural assessment of ASD.\nThe ADOS and ADI‐R are global references for precise clinical diagnosis.\nThe ABC and BSE provide additional elements to better characterize cognitive and behavioural profiles.\nWe excluded children with severe or profound intellectual disability in whom a definitive diagnosis of autism could not be made.\nWe conducted a retrospective study based on collecting information from medical records of children who had visited the facilities cited before the year of 2018. A prospective study was conducted on other children during the period of 2019–2021, in which information was collected from both medical records and an interview with the parents or caregivers of the children (see Figure\nDiagram representing the study design followed for the study.\nBased on several examples from the literature, we established a questionnaire addressed to the parents and caregivers comprising three sections (Data\nThe second section of the questionnaire included two parts: The first part concerned clinical information: age of first diagnosis, ASD screening and assessment tool, ASD severity along with the presence of genetic pathologies or syndromes linked to syndromic ASD and behaviour therapy taken. In the second part, we looked at the presence of comorbidities associated with autism, such as neurological disorders (sleep disorder, epilepsy and visual disorders), developmental or intellectual disability, psychiatric disorders such as attention‐deficit/hyperactivity disorder (ADHD) and digestive disorders. Furthermore, electroencephalography (EEG), brain imaging and m agnetic resonance imaging (MRI) were also registered.\nIn order to investigate the perinatal and prenatal factors, we devoted the third part of the questionnaire to collect information on the medical condition of the mother regarding pregnancy: thyroid disorders, polycystic ovary syndrome, high blood pressure, diabetes, medical drug consumption, maternal age at labour and complications during and after delivery of the child with an ASD.\nQuestionnaires were filled with information from the children's medical records for the retrospective study and from medical records and parent's interview for the prospective study.\nThe statistical analysis was done using Statistical Package for Social Sciences software for Windows, Release 22.0 (IBM Corp. Released 2013. IBM SPSS Statistics for Windows, Version 22.0. USA). A one‐way analysis of variance (ANOVA) was used to determine whether there was a relation of dependence between the maternal age and the severity of the disorder using R software.\nThis work has been carried out with respect to confidentiality and anonymity during the processing of the children's data. Informal consent from parents or legal guardians of participants for the prospective study was obtained after the nature of the procedures had been fully explained. All participants have provided written consent and the present study was approved by the local ethics committee: ‘Algerian National Committee for the Evaluation and Programming of University Research’.\nEighty medical records were registered from the retrospective study, and 106 persons were enrolled in the prospective study. The number of cases registered each year is represented in Figure\nNumber of cases registered each year in the retrospective (a) and prospective (b) studies.\nAge of children or young adults from the retrospective study ranged from 3 years to 25 years old, with a mean (± standard deviation) of 7.3 ± 3.2 years. The mean age of 7.5 ± 4.7 years for the females was not statistically different from that of 7.2 ± 2.6 years for the males according to students T test (\nAge of participants, statistical parameters.\nThe mean age for the children or young adults in the prospective study was 8.1 ± 4.4 years with a range of 3–22 years. The mean age of 8.5 ± 4.8 years for the females was not different from that of the males: 8.0 ± 4.2 years (\nDistribution of ages in the retrospective (a) and prospective (b) studies.\nRetrospective study registered 61 males (76.3%) and 19 females (23.8%).\nMale predominance was also observed in the prospective study with 82 males (77.4%) and 24 females (22.6%). Overall, there were 143 males and 43 females, giving a male/female ratio of 3.3 (143/43). Statistical analysis showed no significant difference between both studies.\nParticipants included in the present study were from all Algerian provinces (Table\nNumber of ASD cases according to their origin, from retrospective and prospective study. Chi‐square test 2 × 3 (fusion of 2 last cells:\nRetrospective\n\nProspective\n\nIn the retrospective study, consanguinity was reported for six different children (7.5%) with third‐degree consanguineous parents. Among the 106 ASD children of the prospective study, a total of 15 (14.2%) had third‐degree relation parents and two (1.9%) distantly related parents. Statistical analysis showed no significant difference between both studies (chi‐square,\nWe defined psychiatric history as the presence of a psychiatric diagnosis among children's parents or their maternal/paternal aunts and uncles.\nIn the retrospective study we report that 12 children (15%) had an affected relative. Nine children had a history of psychiatric disorders from the paternal side and 3 children from the maternal side. Autism was reported in 5 of these cases (4 children from paternal and one from maternal side), and the remaining 7 children were reported as being affected by intellectual disability from the maternal and paternal side (5 children from paternal and two from maternal side).\nOut of the prospective cases, 10 children (9.4%) had at least a family member diagnosed with a mental disorder, 5 of whom were paternal relatives and 5 were maternal relatives, all with intellectual disability, and two children had a father diagnosed with depression.\nWe defined the age of diagnosis for children as the chronological age of the child, the year of their entry into the facility for an ASD diagnosis.\nIn the retrospective study, no child was diagnosed as having autism before the age of 3 years. About 30% of children were diagnosed before the age of 4 years, making the mean age of ASD diagnosis for the retrospective study 5.6 ± 2.1 years. The oldest child at diagnosis was aged 13 years (see Table\nAge at diagnosis, statistical parameters.\nFrom the prospective study, about 70% of children were diagnosed before the age of 4 years; the mean age of diagnosis was 4.0 ± 2.5 years. This mean is significantly different from that of the retrospective study (Student's\nMost practitioners administered CARS for diagnosing and rating ASD in the retrospective study, in 60% (\nMost children from the prospective study were administered the combination of three tools: CARS, M‐CHAT and BSE; this combination has been used for the diagnosis and the rating of 40% of children (\nOne child was diagnosed clinically by DSM IV‐RT, and this child had Asperger syndrome.\nDSM‐V was used in all retrospective cases (\nThe screening tools M‐CHAT and the combination of ADI‐R/ADOS were the least used screening tools with a rate of 5.7% (\nThe ASD scaling tests allowed us to divide the studied population into three groups according to the ASD symptoms severity: mild autism, moderate autism and severe autism.\nAccording to retrospective results, 27 children (33.8%) (21 males [26.3%] and 6 females [7.5%]) out of 80 were ranked as having mild autism, 27 (33.8%) (20 males [25%] and 7 females [8.8%]) as having moderate autism, and 26 (32.5%) (20 males (25%) and 6 females (7.5%)) as having severe autism.\nIn the prospective study, 25 children (23.6%) (21males (19.8%) and 4 females (3.8%)) out of 106 were ranked as having mild autism, 41 (38.6%) (27 males (25.5%) and 14 females (13.2%)) as having moderate autism, and 40 (37.7%) (34 males [32%] and 6 females [5.6%]) as having severe autism. For ASD rating, in both studies, there was no significant difference (\nAutism severity distribution in the retrospective (a) and prospective (b) studies.\nAmong 80 medical records, only one case was reported having syndromic autism, that is, phenylketonuria.\nFour different pathologies were identified in the ASD children enrolled in the prospective study. One child had phenylketonuria, one had San Filippo syndrome, another had Prader–Willi syndrome, and one child had tuberous sclerosis complex. None of the children from both studies had fragile X syndrome.\nThe diagnosis of comorbidities was reported with children's parents, clinical neuropsychiatric observation, DSM‐IV‐R and DSM‐V criteria. Psycho‐Educational Profile Third Edition was used in some cases to evaluate the general cognitive development of children and detect any intellectual deficiency.\nIn the retrospective study, insomnia and intestinal disorders (constipation) were the main comorbidities registered among the studied cases, with a rate of 28.8% for insomnia and 8.8% for intestinal disorders. ADHD and epilepsy were present in 12 and 5 children, respectively, 15% and 6.3%. Visual disorders and intellectual disability were the least registered comorbidities, with a presence rate of 2.5% and 1.3% each, respectively.\nIn the prospective study, insomnia (\nNot all children were subject to an intellectual quotient. Four children had mental retardation among 20 evaluated.\nComorbidities rates reported in both studies are represented in Table\nComorbidities registered in the retrospective and prospective study. Chi‐square test,\nRetrospective\n\nProspective\n\n\nTable\nTherapy approaches used in both studies. Chi‐square test (fusion of the last 5 cells):\nIn the retrospective study, EEG was performed for 51 children; 8 children's EEG was pathological, evoking irregular rhythms and/or the presence of epileptic patterns. MRI was clear for 23 children and evoked abnormalities for 3 different children: porencephaly, demyelinating lesions and hydrocephalus. The remaining 54 children had no MRI done.\nOnly 14 children had undergone a brain x‐ray scanner, and no abnormalities were detected.\nIn the prospective study, EEG was performed for 71 cases. EEG was pathological in 16 children, evoking abnormalities in favour of irregular rhythm and/or the presence of epileptic patterns.\nMRI was clear for 48 children. Eight children had one of the following abnormalities: enlargement of grooves in the frontotemporal region, cerebellar hypoplasia, demyelinating lesions and leucoencephalopathy. Regarding brain scans, 26 children had no abnormalities detected; the remaining 80 children had never done a brain scanning test.\nOnly one child out of 80 in the retrospective records had a karyotyping, and no abnormalities were found.\nIn the prospective study, 15 children had a karyotyping done and only one of them, who was a male of 10 years old, presented the Robertsonian translocation 45,XY,der(13;14)(q10;q10). Fragile X test was performed for five children, and no mutation was detected in the\nMaternal age at birth of the affected child was registered in 175 medical records.\nThere was a slight decrease in the mothers' average age with the degree of autism severity. However, ANOVA analysis revealed that this change was not significant in both studies (\nNo cases of diabetes were reported in the retrospective study. The only medication consumed by mothers during pregnancy was paracetamol, consumed by one mother.\nIn the prospective study, gestational hypertension was present in only 2 (2.0%) mothers. Lastly, 4 (4.0%) mothers had gestational diabetes (Table\nParacetamol along with antibiotic (amoxicillin) was consumed in 3 cases only. All mothers reported that these two treatments were for tonsillitis.\nCaesarean delivery, gestational age lower than 36 weeks, fetal distress and postpartum haemorrhage were the complications registered. Caesarean delivery was the main prenatal risk recorded at 19.7% in both studies (Table\nPerinatal factors reported from both studies.\nRetrospective\n\nProspective\n\nAbbreviation: PCOS, polycystic ovary syndrome.\nThe present study represents a first attempt to report the clinical and paraclinical profiles of an Algerian population with ASD, as well as some prenatal, perinatal and postnatal factors associated with autism spectrum disorder.\nOur study used the developmental systems approach to analyse the factors influencing autism in the Algerian population. The theoretical framework of the developmental systems approach (Volkmar and McPartland\nWe conducted an ambidirectional cohort study by collecting data from both a retrospective study based on medical record treatment and a prospective study based on medical records and parents' caregivers' interviews. The studied variables were designed according to the clinical aspects and probable risk factors of ASD from existing literature. Overall, all the variables desired for the cohort studies were found, which reflects the interest of experts in collecting information regarding autistic children in the facilities where the study was conducted.\nWe acknowledge that the use of multiple diagnostic tools with different levels of validation and standardization can influence results. However, to minimize these biases, we selected instruments that are either internationally recognized for their robustness (ADOS‐2 and ADI‐R) or validated and adapted into Arabic (M‐CHAT‐R/F, CARS‐2 and ECA). Furthermore, rigorous training of clinicians in administering these tests ensured consistent and reliable application in our study context (Huerta and Lord\nLinguistic diversity in Algeria—particularly the coexistence of Arabic (Darja and Modern Standard Arabic), French and Berber—did present practical challenges during assessments. These included variations in caregiver comprehension of test items and child responses influenced by code switching or uneven language exposure. To address this, we adapted our approach by allowing flexible administration in the caregiver's dominant language (typically Arabic or French) and by clarifying items orally when needed. Although standardized tools do not fully account for this multilingual context, clinical judgement and cultural familiarity helped ensure reliable interpretation of responses.\nMost of the results were similar in the two studies. Only three parameters were statistically different between the two studies: the age of diagnosis, the frequencies of comorbidities and the therapies. Globally, these differences result rather from an evolution of the practices than from methodological biases.\nThe decrease of the diagnosis age from 5.6 to 4.4 years between the two studies results certainly from an improved awareness of the medical community to ASD during this period. None of the cases reported in our study was diagnosed as having autism before the age of 3 years. It should be noted that, although the majority of parents of children with ASD have reported the age of onset to be prior to 24 months, they did not reach for a medical diagnosis before the age of 3 years. Parental concern emanates when restricted behaviour and language problems turn into a handicap that refrains the development of the child.\nDiagnostic strategies registered in the current study were multidisciplinary; this goes in line with the universal recommendations (Mukherjee\nStudies have shown that CARS is a reliable and stable indicator of autism in any child over 2 years of age as well as in adolescents (Geier et al.\nThe most common comorbidities in ASD children in the two studies were intellectual disability, insomnia and ADHD. Comorbidities found in our study, particularly intellectual disability and strabismus, corroborate with those associated with autism in previous studies (Lai et al.\nThe significant difference between the two studies was markedly due to a decrease in the ‘no comorbidity’ group decreasing from 37.5% to 3%, this indicating, similarly to the diagnosis of ASD, an effort to improve the clinical evaluation. These comorbidities can modulate the severity of autistic symptoms and impact the effectiveness of therapeutic interventions. For example, the presence of an anxiety disorder can reinforce social avoidance behaviours, whereas untreated ADHD can exacerbate attention and learning difficulties (Simonoff et al.\nThe main difference between the two studies was the absence of the TED approach in the prospective study and the increase of ‘no approach’ rising from 1.3% to 16%. In the prospective study, practitioners (psychologists and speech therapists) stopped using the TED approach; we have no clear explanation for this situation. It may be explained either by a feeling by practitioners or parents of lesser efficiency of TED or just by a change in practice due to different practitioners. Concerning the increase of the ‘no therapeutics’ group, we cannot exclude that this results from incomplete data collection. There is currently no consensus regarding which interventions are most effective for ASD treatment. TEACCH is a relatively common treatment option for individuals with autism (Green et al.\nA male predominance was observed in both studies; the male/female ratio was reported to be 3.2 and 3.4 for both studies, which matched the global estimation of the male/female ratio (Fombonne et al.\nIn our study, we observed ASD children or young adults from different regions of Algeria. The capital Algiers was the native province of the majority of ASD cases enrolled, which has probably to do with the availability of specialized structures in the capital. Lack of specialized facilities in other provinces represents a major issue for parents with affected children. It is also worth mentioning that this lack of autism specialized structures in other parts of the country obliges the parents to change their addresses to the capital Algiers for more appropriate intervention for their children.\nContrary to expectations, our study did not reveal a significant link between consanguinity and ASD. Several hypotheses can explain this observation: (1) a potential protective effect of other genetic or environmental factors in the studied population, (2) a sample that may not be large enough to detect this effect or (3) the need for more in‐depth genetic analysis to explore complex interactions between genes and environment. Further research incorporating genomic analyses would be necessary to better understand these dynamics (Al‐Salehi and Al‐Hifthy\nOur findings corroborate with those of Abdel Meguid, where consanguinity was not found to be a possible risk factor for ASD among an Egyptian population (Abdel Meguid et al.\nAge of parents is considered a risk factor for the occurrence of ASD and the degree of severity. In 2010, the state‐of‐the‐art synthesis concluded that the frequency of autistic children increases weakly with the age of the father and mother (risk multiplied by 1.3 for mother over 35 and per 1.4 for father over 40). In our study, we note that there was a slight decrease in the mothers' average age with the degree of autism severity, although it did not reach significance.\nUnfortunately, genetic analyses cannot be done in Algeria as a routine test due to the lack of specialized genetic laboratories on one hand and the high price of genetic tests on the other hand.\nSeveral studies have investigated the relationship between prenatal, perinatal and postnatal factors and autism (Kolevzon et al.\nOur study gives an insight into the clinical and paraclinical profiles of an autistic population in Algeria. Our findings do not necessarily reflect the actual situation of ASD on the national territory. The retrospective study is a valuable method because we found mainly the same results in the retrospective study as in the prospective study. Several differences may be due to the evolution of the recruitment of children.\nClinical features and comorbidities of autism present among the study group were similar to findings in individuals with autism in other parts of the world.\nUnfortunately, there is a huge lack of multi‐disciplinary centres in Algeria that can provide high‐quality intervention for autistic individuals. Experts in different fields who have experience in working with autistic children should assemble to establish a diagnosis and treatment consensus and better management of ASD individuals.\nSignificant efforts should be aimed at raising awareness among parents and caregivers for early diagnosis and therefore early and better intervention.\nThe findings of this study highlight the need to strengthen awareness and training actions to improve the early recognition of ASD in Algeria. In particular, we recommend:\nThe implementation of specialized training for healthcare professionals on the diagnosis and management of ASD.\nThe development of early intervention programmes based on behavioural and educational approaches adapted to the local context.\nThe promotion of awareness campaigns among the general public to reduce stigma and encourage families to seek early consultation.\nThe development of public policies dedicated to the social and educational inclusion of children with ASD (Dawson et al.\nOurida Loumi had full access to all the data in the study and drafted the manuscript. Ourida Loumi and Christian R. Andres designed, contributed and performed the study by statistical analysis, reviewing the literature, writing and revising the manuscript and agreeing to publish the article. All authors have agreed to the published version of the manuscript.\nThe authors declare no conflicts of interest.\n", "content_for_embedding": "Autism spectrum disorder (ASD) is a group of complex developmental disorders characterized by deficits in social communication and restricted repetitive patterns of behaviour. The severity of these symptoms varies for each patient. ASD begins in early childhood and affects around 1% of the worldwide population (Myers et al.\nThe current situation of ASD and its prevalence in African countries remain poorly investigated and require further research. In North Africa, and particularly in Algeria, there is a significant lack of accurate data on the prevalence of autism. This absence of information limits the ability of health authorities and healthcare professionals to implement adapted policies for screening, diagnosis and care.\nThe prevalence of ASD among children with developmental disorders in Egypt and Tunisia was documented as 33.6% and 11.5%, respectively (Bakare and Munir\nIn Algeria, very few studies have been conducted on ASD. The prevalence of ASD during the period of 1997–2003 was rated at 38% of the total diagnoses among developmental disorders established in daytime hospitalization of Algiers (OuldTaleb\nIn 2018, Bekkou reported the epidemiological profile of ASD in the eastern region of Algeria (Bekkou et al.\nThe aim of the current study is (1) to describe the clinical and paraclinical profiles of ASD individuals in an Algerian population and (2) to investigate the association between prenatal and perinatal factors and the development of ASD in this population.\nThe present study is an ambidirectional cohort study conducted on a clinical population of children, adolescents and two adults with ASD and their parents.\nRetrospective study data were collected from autistic persons' medical records from 2013 to 2018.\nProspective data were collected from medical records and parents' interviews, from January 2019 until January 2021.\nA total of 186 individuals s diagnosed with ASD were enrolled from four different facilities in Algiers. Two are health facilities: Child and Adolescent Psychiatry Hospital of Drid Hocine (Algiers) and Neurology Service of the Specialized Hospital Establishment Pr Abdelkader Boukhroufa, Algiers. The two remaining establishments were the specialized educational and teaching institution ‘El RAFAHIYA LI TAWEHOUD’ for children in special need and the Association of the Williams–Beuren syndrome, Algiers.\nThe diagnosis of autism for all the persons included in the study was established by highly trained physicians (psychiatrists, paediatricians and neurologists) and non‐physicians (psychologists and speech therapists) using the DSM‐IV‐TR or DSM‐V (Diagnostic and Statistical Manual of Mental Disorders Fourth Edition Revised and Fifth Edition) clinical criteria. In addition to the clinical diagnosis, different diagnostic tools were used for distinguishing ASD from other developmental disorders and rating the autism symptom severity. Professionals either used a single diagnosis tool or a combination of two. Some others used a screening tool along with a diagnosis before making the final diagnosis.\nScreening tools used were the Modified‐Checklist for Autism in Toddlers (M‐CHAT) (Baron‐Cohen et al.\nASD affected individuals recruited were treated following different psychological approaches:\nTherapy of exchange and development (TED) (Lelord et al.\nApplied behaviour analysis (ABA) (Lovaas\nTreatment and Education of Autistic and Related Communication Handicapped Children (TEACCH) (Schopler\nThe Picture Exchange Communication System (PECS) (Bondy and Frost\nAll individuals included in the study had a diagnosis of ASD according to clinical criteria of the Diagnostic and Statistical Manual of Mental Disorders using the DSM‐IV‐TR or DSM‐V, depending on the diagnostic period. The children included in the study were aged at least 3 years.\nOne of the methodological challenges of this study lies in the use of the DSM‐IV‐TR and DSM‐5 criteria. To avoid inconsistencies in diagnoses, we applied a systematic conversion of old diagnoses (DSM‐IV‐TR) into DSM‐5 equivalents using recommendations established by previous studies (Volkmar and McPartland\nThis approach allows for the harmonization of diagnostic classifications and ensures continuity between patients diagnosed before and after 2018. Moreover, we considered the specific differences introduced by the DSM‐5, particularly the removal of subcategories and the new conceptualization of the disorder in severity levels. Among the 80 retrospective cases, 67 (83.8%) met DSM‐5 diagnostic criteria directly based on standardized tools and available clinical data. The remaining 13 cases (16.3%) initially showed partial compatibility but were reviewed in detail by clinicians to assess whether they fulfilled DSM‐5 core domains, including social communication deficits and restricted repetitive behaviours. Following this clinical reassessment, all 13 cases were confirmed as meeting DSM‐5 criteria for ASD and were therefore included in the final analysis.\nThe use of multiple diagnostic tools in this study aims to ensure a comprehensive and accurate assessment of ASD. Each tool used (M‐CHAT, CARS, ECA, ABC, ADOS, ADI‐R and BSE) targets specific aspects of the disorder, allowing for a finer analysis of patient profiles. This combined approach is consistent with international recommendations that advocate for the use of multiple instruments to increase the validity and reliability of diagnoses (Lord et al.\nSeveral of the tools used in this study were adapted and validated for Arabic‐speaking populations, including in Algeria. The M‐CHAT‐R/F, CARS‐2 and ECA were administered in their Modern Standard Arabic (MSA) or French versions, depending on the caregiver's language preference (Mneimneh et al.\nThe ADOS and ADI‐R, on the other hand, are internationally standardized behavioural tools recognized for their language independence, making them suitable for different populations (Lord et al.\nThe diagnostic tools selected in this study were chosen to complement each other rather than overlap. Each tool evaluates a specific dimension of ASD:\nThe M‐CHAT is an early screening tool for young children.\nThe CARS and ECA allow for an in‐depth behavioural assessment of ASD.\nThe ADOS and ADI‐R are global references for precise clinical diagnosis.\nThe ABC and BSE provide additional elements to better characterize cognitive and behavioural profiles.\nWe excluded children with severe or profound intellectual disability in whom a definitive diagnosis of autism could not be made.\nWe conducted a retrospective study based on collecting information from medical records of children who had visited the facilities cited before the year of 2018. A prospective study was conducted on other children during the period of 2019–2021, in which information was collected from both medical records and an interview with the parents or caregivers of the children (see Figure\nDiagram representing the study design followed for the study.\nBased on several examples from the literature, we established a questionnaire addressed to the parents and caregivers comprising three sections (Data\nThe second section of the questionnaire included two parts: The first part concerned clinical information: age of first diagnosis, ASD screening and assessment tool, ASD severity along with the presence of genetic pathologies or syndromes linked to syndromic ASD and behaviour therapy taken. In the second part, we looked at the presence of comorbidities associated with autism, such as neurological disorders (sleep disorder, epilepsy and visual disorders), developmental or intellectual disability, psychiatric disorders such as attention‐deficit/hyperactivity disorder (ADHD) and digestive disorders. Furthermore, electroencephalography (EEG), brain imaging and m agnetic resonance imaging (MRI) were also registered.\nIn order to investigate the perinatal and prenatal factors, we devoted the third part of the questionnaire to collect information on the medical condition of the mother regarding pregnancy: thyroid disorders, polycystic ovary syndrome, high blood pressure, diabetes, medical drug consumption, maternal age at labour and complications during and after delivery of the child with an ASD.\nQuestionnaires were filled with information from the children's medical records for the retrospective study and from medical records and parent's interview for the prospective study.\nThe statistical analysis was done using Statistical Package for Social Sciences software for Windows, Release 22.0 (IBM Corp. Released 2013. IBM SPSS Statistics for Windows, Version 22.0. USA). A one‐way analysis of variance (ANOVA) was used to determine whether there was a relation of dependence between the maternal age and the severity of the disorder using R software.\nThis work has been carried out with respect to confidentiality and anonymity during the processing of the children's data. Informal consent from parents or legal guardians of participants for the prospective study was obtained after the nature of the procedures had been fully explained. All participants have provided written consent and the present study was approved by the local ethics committee: ‘Algerian National Committee for the Evaluation and Programming of University Research’.\nEighty medical records were registered from the retrospective study, and 106 persons were enrolled in the prospective study. The number of cases registered each year is represented in Figure\nNumber of cases registered each year in the retrospective (a) and prospective (b) studies.\nAge of children or young adults from the retrospective study ranged from 3 years to 25 years old, with a mean (± standard deviation) of 7.3 ± 3.2 years. The mean age of 7.5 ± 4.7 years for the females was not statistically different from that of 7.2 ± 2.6 years for the males according to students T test (\nAge of participants, statistical parameters.\nThe mean age for the children or young adults in the prospective study was 8.1 ± 4.4 years with a range of 3–22 years. The mean age of 8.5 ± 4.8 years for the females was not different from that of the males: 8.0 ± 4.2 years (\nDistribution of ages in the retrospective (a) and prospective (b) studies.\nRetrospective study registered 61 males (76.3%) and 19 females (23.8%).\nMale predominance was also observed in the prospective study with 82 males (77.4%) and 24 females (22.6%). Overall, there were 143 males and 43 females, giving a male/female ratio of 3.3 (143/43). Statistical analysis showed no significant difference between both studies.\nParticipants included in the present study were from all Algerian provinces (Table\nNumber of ASD cases according to their origin, from retrospective and prospective study. Chi‐square test 2 × 3 (fusion of 2 last cells:\nRetrospective\n\nProspective\n\nIn the retrospective study, consanguinity was reported for six different children (7.5%) with third‐degree consanguineous parents. Among the 106 ASD children of the prospective study, a total of 15 (14.2%) had third‐degree relation parents and two (1.9%) distantly related parents. Statistical analysis showed no significant difference between both studies (chi‐square,\nWe defined psychiatric history as the presence of a psychiatric diagnosis among children's parents or their maternal/paternal aunts and uncles.\nIn the retrospective study we report that 12 children (15%) had an affected relative. Nine children had a history of psychiatric disorders from the paternal side and 3 children from the maternal side. Autism was reported in 5 of these cases (4 children from paternal and one from maternal side), and the remaining 7 children were reported as being affected by intellectual disability from the maternal and paternal side (5 children from paternal and two from maternal side).\nOut of the prospective cases, 10 children (9.4%) had at least a family member diagnosed with a mental disorder, 5 of whom were paternal relatives and 5 were maternal relatives, all with intellectual disability, and two children had a father diagnosed with depression.\nWe defined the age of diagnosis for children as the chronological age of the child, the year of their entry into the facility for an ASD diagnosis.\nIn the retrospective study, no child was diagnosed as having autism before the age of 3 years. About 30% of children were diagnosed before the age of 4 years, making the mean age of ASD diagnosis for the retrospective study 5.6 ± 2.1 years. The oldest child at diagnosis was aged 13 years (see Table\nAge at diagnosis, statistical parameters.\nFrom the prospective study, about 70% of children were diagnosed before the age of 4 years; the mean age of diagnosis was 4.0 ± 2.5 years. This mean is significantly different from that of the retrospective study (Student's\nMost practitioners administered CARS for diagnosing and rating ASD in the retrospective study, in 60% (\nMost children from the prospective study were administered the combination of three tools: CARS, M‐CHAT and BSE; this combination has been used for the diagnosis and the rating of 40% of children (\nOne child was diagnosed clinically by DSM IV‐RT, and this child had Asperger syndrome.\nDSM‐V was used in all retrospective cases (\nThe screening tools M‐CHAT and the combination of ADI‐R/ADOS were the least used screening tools with a rate of 5.7% (\nThe ASD scaling tests allowed us to divide the studied population into three groups according to the ASD symptoms severity: mild autism, moderate autism and severe autism.\nAccording to retrospective results, 27 children (33.8%) (21 males [26.3%] and 6 females [7.5%]) out of 80 were ranked as having mild autism, 27 (33.8%) (20 males [25%] and 7 females [8.8%]) as having moderate autism, and 26 (32.5%) (20 males (25%) and 6 females (7.5%)) as having severe autism.\nIn the prospective study, 25 children (23.6%) (21males (19.8%) and 4 females (3.8%)) out of 106 were ranked as having mild autism, 41 (38.6%) (27 males (25.5%) and 14 females (13.2%)) as having moderate autism, and 40 (37.7%) (34 males [32%] and 6 females [5.6%]) as having severe autism. For ASD rating, in both studies, there was no significant difference (\nAutism severity distribution in the retrospective (a) and prospective (b) studies.\nAmong 80 medical records, only one case was reported having syndromic autism, that is, phenylketonuria.\nFour different pathologies were identified in the ASD children enrolled in the prospective study. One child had phenylketonuria, one had San Filippo syndrome, another had Prader–Willi syndrome, and one child had tuberous sclerosis complex. None of the children from both studies had fragile X syndrome.\nThe diagnosis of comorbidities was reported with children's parents, clinical neuropsychiatric observation, DSM‐IV‐R and DSM‐V criteria. Psycho‐Educational Profile Third Edition was used in some cases to evaluate the general cognitive development of children and detect any intellectual deficiency.\nIn the retrospective study, insomnia and intestinal disorders (constipation) were the main comorbidities registered among the studied cases, with a rate of 28.8% for insomnia and 8.8% for intestinal disorders. ADHD and epilepsy were present in 12 and 5 children, respectively, 15% and 6.3%. Visual disorders and intellectual disability were the least registered comorbidities, with a presence rate of 2.5% and 1.3% each, respectively.\nIn the prospective study, insomnia (\nNot all children were subject to an intellectual quotient. Four children had mental retardation among 20 evaluated.\nComorbidities rates reported in both studies are represented in Table\nComorbidities registered in the retrospective and prospective study. Chi‐square test,\nRetrospective\n\nProspective\n\n\nTable\nTherapy approaches used in both studies. Chi‐square test (fusion of the last 5 cells):\nIn the retrospective study, EEG was performed for 51 children; 8 children's EEG was pathological, evoking irregular rhythms and/or the presence of epileptic patterns. MRI was clear for 23 children and evoked abnormalities for 3 different children: porencephaly, demyelinating lesions and hydrocephalus. The remaining 54 children had no MRI done.\nOnly 14 children had undergone a brain x‐ray scanner, and no abnormalities were detected.\nIn the prospective study, EEG was performed for 71 cases. EEG was pathological in 16 children, evoking abnormalities in favour of irregular rhythm and/or the presence of epileptic patterns.\nMRI was clear for 48 children. Eight children had one of the following abnormalities: enlargement of grooves in the frontotemporal region, cerebellar hypoplasia, demyelinating lesions and leucoencephalopathy. Regarding brain scans, 26 children had no abnormalities detected; the remaining 80 children had never done a brain scanning test.\nOnly one child out of 80 in the retrospective records had a karyotyping, and no abnormalities were found.\nIn the prospective study, 15 children had a karyotyping done and only one of them, who was a male of 10 years old, presented the Robertsonian translocation 45,XY,der(13;14)(q10;q10). Fragile X test was performed for five children, and no mutation was detected in the\nMaternal age at birth of the affected child was registered in 175 medical records.\nThere was a slight decrease in the mothers' average age with the degree of autism severity. However, ANOVA analysis revealed that this change was not significant in both studies (\nNo cases of diabetes were reported in the retrospective study. The only medication consumed by mothers during pregnancy was paracetamol, consumed by one mother.\nIn the prospective study, gestational hypertension was present in only 2 (2.0%) mothers. Lastly, 4 (4.0%) mothers had gestational diabetes (Table\nParacetamol along with antibiotic (amoxicillin) was consumed in 3 cases only. All mothers reported that these two treatments were for tonsillitis.\nCaesarean delivery, gestational age lower than 36 weeks, fetal distress and postpartum haemorrhage were the complications registered. Caesarean delivery was the main prenatal risk recorded at 19.7% in both studies (Table\nPerinatal factors reported from both studies.\nRetrospective\n\nProspective\n\nAbbreviation: PCOS, polycystic ovary syndrome.\nThe present study represents a first attempt to report the clinical and paraclinical profiles of an Algerian population with ASD, as well as some prenatal, perinatal and postnatal factors associated with autism spectrum disorder.\nOur study used the developmental systems approach to analyse the factors influencing autism in the Algerian population. The theoretical framework of the developmental systems approach (Volkmar and McPartland\nWe conducted an ambidirectional cohort study by collecting data from both a retrospective study based on medical record treatment and a prospective study based on medical records and parents' caregivers' interviews. The studied variables were designed according to the clinical aspects and probable risk factors of ASD from existing literature. Overall, all the variables desired for the cohort studies were found, which reflects the interest of experts in collecting information regarding autistic children in the facilities where the study was conducted.\nWe acknowledge that the use of multiple diagnostic tools with different levels of validation and standardization can influence results. However, to minimize these biases, we selected instruments that are either internationally recognized for their robustness (ADOS‐2 and ADI‐R) or validated and adapted into Arabic (M‐CHAT‐R/F, CARS‐2 and ECA). Furthermore, rigorous training of clinicians in administering these tests ensured consistent and reliable application in our study context (Huerta and Lord\nLinguistic diversity in Algeria—particularly the coexistence of Arabic (Darja and Modern Standard Arabic), French and Berber—did present practical challenges during assessments. These included variations in caregiver comprehension of test items and child responses influenced by code switching or uneven language exposure. To address this, we adapted our approach by allowing flexible administration in the caregiver's dominant language (typically Arabic or French) and by clarifying items orally when needed. Although standardized tools do not fully account for this multilingual context, clinical judgement and cultural familiarity helped ensure reliable interpretation of responses.\nMost of the results were similar in the two studies. Only three parameters were statistically different between the two studies: the age of diagnosis, the frequencies of comorbidities and the therapies. Globally, these differences result rather from an evolution of the practices than from methodological biases.\nThe decrease of the diagnosis age from 5.6 to 4.4 years between the two studies results certainly from an improved awareness of the medical community to ASD during this period. None of the cases reported in our study was diagnosed as having autism before the age of 3 years. It should be noted that, although the majority of parents of children with ASD have reported the age of onset to be prior to 24 months, they did not reach for a medical diagnosis before the age of 3 years. Parental concern emanates when restricted behaviour and language problems turn into a handicap that refrains the development of the child.\nDiagnostic strategies registered in the current study were multidisciplinary; this goes in line with the universal recommendations (Mukherjee\nStudies have shown that CARS is a reliable and stable indicator of autism in any child over 2 years of age as well as in adolescents (Geier et al.\nThe most common comorbidities in ASD children in the two studies were intellectual disability, insomnia and ADHD. Comorbidities found in our study, particularly intellectual disability and strabismus, corroborate with those associated with autism in previous studies (Lai et al.\nThe significant difference between the two studies was markedly due to a decrease in the ‘no comorbidity’ group decreasing from 37.5% to 3%, this indicating, similarly to the diagnosis of ASD, an effort to improve the clinical evaluation. These comorbidities can modulate the severity of autistic symptoms and impact the effectiveness of therapeutic interventions. For example, the presence of an anxiety disorder can reinforce social avoidance behaviours, whereas untreated ADHD can exacerbate attention and learning difficulties (Simonoff et al.\nThe main difference between the two studies was the absence of the TED approach in the prospective study and the increase of ‘no approach’ rising from 1.3% to 16%. In the prospective study, practitioners (psychologists and speech therapists) stopped using the TED approach; we have no clear explanation for this situation. It may be explained either by a feeling by practitioners or parents of lesser efficiency of TED or just by a change in practice due to different practitioners. Concerning the increase of the ‘no therapeutics’ group, we cannot exclude that this results from incomplete data collection. There is currently no consensus regarding which interventions are most effective for ASD treatment. TEACCH is a relatively common treatment option for individuals with autism (Green et al.\nA male predominance was observed in both studies; the male/female ratio was reported to be 3.2 and 3.4 for both studies, which matched the global estimation of the male/female ratio (Fombonne et al.\nIn our study, we observed ASD children or young adults from different regions of Algeria. The capital Algiers was the native province of the majority of ASD cases enrolled, which has probably to do with the availability of specialized structures in the capital. Lack of specialized facilities in other provinces represents a major issue for parents with affected children. It is also worth mentioning that this lack of autism specialized structures in other parts of the country obliges the parents to change their addresses to the capital Algiers for more appropriate intervention for their children.\nContrary to expectations, our study did not reveal a significant link between consanguinity and ASD. Several hypotheses can explain this observation: (1) a potential protective effect of other genetic or environmental factors in the studied population, (2) a sample that may not be large enough to detect this effect or (3) the need for more in‐depth genetic analysis to explore complex interactions between genes and environment. Further research incorporating genomic analyses would be necessary to better understand these dynamics (Al‐Salehi and Al‐Hifthy\nOur findings corroborate with those of Abdel Meguid, where consanguinity was not found to be a possible risk factor for ASD among an Egyptian population (Abdel Meguid et al.\nAge of parents is considered a risk factor for the occurrence of ASD and the degree of severity. In 2010, the state‐of‐the‐art synthesis concluded that the frequency of autistic children increases weakly with the age of the father and mother (risk multiplied by 1.3 for mother over 35 and per 1.4 for father over 40). In our study, we note that there was a slight decrease in the mothers' average age with the degree of autism severity, although it did not reach significance.\nUnfortunately, genetic analyses cannot be done in Algeria as a routine test due to the lack of specialized genetic laboratories on one hand and the high price of genetic tests on the other hand.\nSeveral studies have investigated the relationship between prenatal, perinatal and postnatal factors and autism (Kolevzon et al.\nOur study gives an insight into the clinical and paraclinical profiles of an autistic population in Algeria. Our findings do not necessarily reflect the actual situation of ASD on the national territory. The retrospective study is a valuable method because we found mainly the same results in the retrospective study as in the prospective study. Several differences may be due to the evolution of the recruitment of children.\nClinical features and comorbidities of autism present among the study group were similar to findings in individuals with autism in other parts of the world.\nUnfortunately, there is a huge lack of multi‐disciplinary centres in Algeria that can provide high‐quality intervention for autistic individuals. Experts in different fields who have experience in working with autistic children should assemble to establish a diagnosis and treatment consensus and better management of ASD individuals.\nSignificant efforts should be aimed at raising awareness among parents and caregivers for early diagnosis and therefore early and better intervention.\nThe findings of this study highlight the need to strengthen awareness and training actions to improve the early recognition of ASD in Algeria. In particular, we recommend:\nThe implementation of specialized training for healthcare professionals on the diagnosis and management of ASD.\nThe development of early intervention programmes based on behavioural and educational approaches adapted to the local context.\nThe promotion of awareness campaigns among the general public to reduce stigma and encourage families to seek early consultation.\nThe development of public policies dedicated to the social and educational inclusion of children with ASD (Dawson et al.\nOurida Loumi had full access to all the data in the study and drafted the manuscript. Ourida Loumi and Christian R. Andres designed, contributed and performed the study by statistical analysis, reviewing the literature, writing and revising the manuscript and agreeing to publish the article. All authors have agreed to the published version of the manuscript.\nThe authors declare no conflicts of interest.\n", "topic": "Neurodevelopmental_disorder"}
{"pmid": "40698457", "pmcid": "12302815", "title": "ADHD and Suicide Risk: The Overlooked Roles of Comorbid Disorders and Stimulant Medications", "publication_year": "2025", "abstract": "Does Attention Deficit Hyperactivity Disorder (ADHD) increase the risk of suicidality among children? This article critically examines a notable study by", "full_text": "Does Attention Deficit Hyperactivity Disorder (ADHD) – the most common neurodevelopmental diagnosis in children (\n“The results revealed that elevated hyperactivity scores, surpassing the ADHD diagnosis threshold, were significantly associated with increased rates of suicidal behavior. Hyperactivity demonstrated a stronger association with lifetime suicide attempts compared to inattention. Moreover, children's self-reported ADHD symptoms exhibited a stronger correlation with suicide attempts than parental reports. This study highlights the critical role of hyperactivity in understanding suicidal behaviors among children with ADHD. It underscores the importance of considering hyperactivity-related symptoms in assessment and treatment approaches for suicidal behavior in this population.”\nIn this article, I discuss the study by\nDespite the significance of these concerns, my formal commentary on this study was rejected by the\nThe analysis of the study by Shahnovsky et al. begins with a close inspection of its methodology, followed by an analysis of its findings later in this article. As implied above, the study focused on testing direct links between characteristics of ADHD (inattention and hyperactivity) and suicide risk (suicide attempts and suicide behaviors). Such an approach, which emphasizes simple, unidimensional relationships between two variables, is accep in pioneering studies exploring phenomena that have not been previously investigated. However, when building on existing literature, it is essential to consider factors that are already well-documented.\nIn the case of the relationship between ADHD and suicidality, two key variables extensively discussed in the literature are the presence of comorbid disorders and the use of common medications prescribed for ADHD (\nPrevious studies linking ADHD to suicidality have consistently noted that, in most cases, the risk of suicide is better explained by the presence of other psychiatric disorders (\nIn the case of ADHD, this conflation – attributing suicidality to the disorder’s core characteristics (e.g., hyperactivity) – is well illustrated in a systematic review by Balaz and Kereszteny (Balazs & Kereszteny, 2017). In this review, the relationship between ADHD and suicide risk was frequently mediated by other psychiatric conditions. In fact, the authors of this review previously reported that the correlation between ADHD symptoms and suicide risk was entirely mediated by symptoms of other disorders (\nThis issue seems to concern Shanhovsky et al. as well. In the limitations section of their article, they acknowledge that “\nThis discrepancy between the two studies raises critical questions about the validity of attributing suicidality directly to ADHD. Why did the authors not integrate their own findings from the earlier study, which was based on overlapping data and essentially highlighted the importance of accounting for comorbidities? Additionally, how should we interpret the current findings of a positive relationship between hyperactivity and suicide risk when, in their previous study, the authors found\nA further, and perhaps more troubling, methodological gap in the study by Shanhovsky et al. concerns the potential contribution of psychiatric medications in general, and the first-line pharmacological treatment for ADHD in particular, to the observed suicide risk. Could the reported increased risk in this study be not a consequence of the diagnosis itself, but rather an unintended effect of the stimulant medications commonly prescribed as its treatment of choice (\nIndeed, the limitation section of the article by Shahnovsky et al. acknowledges that they “\nMoreover, the discussion of antidepressants in the limitations section may be less relevant for children aged 7–12, compared with the potential contribution of stimulants – the first-line treatment for ADHD – which was not mentioned in this section. As documented in the authors’ “separate study,” antidepressants were used by 58.6% of adolescents but only 15% of children. By contrast, stimulants were used by 22.5% of children and 13.5% of adolescents. This suggests that stimulants are more pertinent to the current study, which focuses on the link between hyperactivity and suicidality in young children.\nNot only was this straightforward possibility left unexamined, but the authors also state in their introduction: “It is now well established that significant associations exist between ADHD and suicidal behavior and that stimulant medications may help attenuate this link” (bold added). Before addressing the specific source they cite to support this claim, it is important to consider the broader context of the literature, which is, at best, inconclusive – and at worst, suggestive of a negative impact, as will be demonstrated in the following section. For instance, a 2020 meta-analysis examining a range of functional outcomes of ADHD medications identified two studies on suicidality (\nThe sole source cited by the authors to substantiate their claim regarding the protective effects of ADHD medications on suicidality is a study by\nI admit that I can understand the confusion regarding this source, as Shoval et al. also reported an interaction effect, which they interpreted as suggesting that “in children with substantial externalizing symptoms, ADHD medication use may be associated with less suicidality.” However, this interpretation does not negate the negative main effect of the medications on suicidality, and it is likely inaccurate.\nThis interpretation hinges on the observation that the association between externalizing symptoms and suicidality remained significant only among children who did not receive ADHD medications (\nThe study by Shoval et al. is, of course, not the only one to find a connection between ADHD medications and an increased risk of suicidality. For example, a large-scale study conducted in the Netherlands found that adults aged 18–40 who started using methylphenidate were twice as likely to attempt suicide compared to a control group with similar demographics (\nNotably, the risk associated with the medications, according to this UK study, was particularly high among young children (11–14) – a group similar in age to the very young children (7–12) examined in the study by Shanhovsky et al. While the absolute risk of death by suicide in this age group was very low (as suicide deaths are extremely rare at such young ages), the relative differences within this low-risk group were striking. In the UK study, young children who used stimulant medications were nearly 162 times more likely to die by suicide compared to those who did not (\nThis troubling figure may stem from the relatively common occurrence of suicidal thoughts triggered by these medications. Indeed, even small-scale experimental studies have reported suicidal ideation or behaviors as adverse outcomes of these treatments (e.g.,\nMoreover, ADHD medications, such as methylphenidate, may also contribute to suicidal ideation through their well-documented depression-related effects (\nHaving addressed the critical methodological gaps in the study by Shahnovsky et al., it is equally important to examine its actual findings and evaluate the extent to which they support the broader narrative linking ADHD symptoms to suicide risk. Below is a summary of the findings reported in the study:\nChildren's self-reported hyperactivity was significantly related to lifetime suicide attempts.\nChildren's self-reported inattention was not significantly related to lifetime suicide attempts.\nChildren's self-reported inattention and hyperactivity were not significantly related to suicide behaviors (though the authors note they approached significance).\nParental reports of both hyperactivity and inattention were not significantly related to lifetime suicide attempts.\nParental reports of both hyperactivity and inattention were not significantly related to suicide behaviors.\nAs this summary shows, ADHD symptoms were largely unrelated to suicide risk. The only significant finding, which linked hyperactivity (but not inattention) to past suicide attempts (but not suicidal behaviors), was based solely on children’s self-reported responses. This raises a critical question: how can children as young as 7 years old – or even those at the upper end of the age range, 12 years old – reliably evaluate their own levels of hyperactivity or inattention, let alone compare these to standardized clinical thresholds?\nSupporting this reliability concern, the study's concordance test between parent and child reports revealed a “very low level of agreement… suggesting almost no concordance between the children's and parents' reports on ADHD symptoms.” This striking disparity underscores the potential distortion in children’s self-perceptions and further calls into question the reliability of the sole significant result.\nFurthermore, even if the authors' entire set of hypotheses had been statistically confirmed, it is important to recognize that basic symptom measures of hyperactivity and inattention (without the use of broader, standardized assessments) provide an incomplete and potentially misleading picture. This concern is particularly relevant in the case of hyperactivity, which can arise from a wide range of neurodevelopmental, emotional, or situational factors unrelated to ADHD itself.\nTaken together, these predominantly non-significant findings, which rely on unreliable self-reports of very young children, challenge the narrative presented in the study’s abstract (see the opening of this article) and cast serious doubt on the validity of hyperactivity as a critical risk factor for suicidality. In my view, the pattern of results suggests that other variables, likely unrelated to ADHD symptoms as discussed throughout this article, may offer a far more robust and accurate explanation for understanding suicide risk in children.\nAltogether, the actual findings of the study, combined with its omission of critical variables known to increase suicide risk (i.e., comorbid disorders and ADHD medications) and its misinterpretation of previous research (which has essentially documented a troubling link between ADHD medications and suicide risk) (\nThese methodological and interpretative gaps not only limit the study's utility but also risk perpetuating harmful misconceptions. Clinicians might act on its conclusions and prescribe ADHD medications to suppress the supposedly dangerous hyperactivity – medications that were not accounted for in the study and that are well-documented to increase depression and suicide risk (as shown throughout the current article).\nTo avoid such potential harm, and to advance the field of suicidology in children, future research would benefit from a more nuanced and comprehensive approach. Assessments that include both comorbid conditions and negative effects of medications are essential to disentangle the complex relationship between ADHD, its treatments, and suicidality. In my view, addressing these gaps could bring us closer to identifying precise risk factors and developing safe interventions.\nThis recommendation is particularly critical given the growing recognition of the limited validity − and potential risks − of the biomedical framing of ADHD (\nAgainst this broader backdrop, the study by Shahnovsky et al. represents an important opportunity for reflection and constructive dialogue. Despite the critical observations raised throughout this article, please allow me to conclude by commending the authors once again for addressing such a crucial and challenging topic. Their lifelong dedication to advancing suicide prevention is deeply appreciated, and it is in this spirit that I offer these reflections. I hope that this discussion fosters a constructive dialogue that contributes to refining research practices and deepening our understanding of the tragic phenomenon of childhood suicide.\nThis supplementary material provides background on the editorial barriers encountered when attempting to publish the current article in the journal where the original study by\nUpon the publication of the study by Shahnovsky et al., which identified hyperactivity as a significant predictor of suicide attempts, I contacted EJIHPE to request an exception to the journal’s policy that prohibits commentaries and letters critiquing published articles. I argued that such a policy contradicts fundamental scientific norms and impedes open academic discourse. Additionally, I outlined several key concerns – detailed in the main article – regarding the study by Shahnovsky et al.\nFollowing this exchange, I was granted permission and explicitly encouraged to submit a formal commentary. However, despite this initial approval, my submission was later rejected on the grounds that the journal does not accept commentaries. The rejection was accompanied by two justifications:\nThat the study’s objective was “\nThat the study’s limitations section had already addressed most of my concerns.\nBelieving this rationale to be flawed, I appealed the decision, clearly demonstrating that the limitations section did not sufficiently address the key methodological issues I raised and that it even contained certain misrepresentations (as can be seen in the main article). Despite this, my appeal was denied without further justification.\nGiven these circumstances, I felt it was my ethical duty to publish my commentary elsewhere to ensure an open scholarly discussion of the study’s findings and their implications.", "content_for_embedding": "Does Attention Deficit Hyperactivity Disorder (ADHD) – the most common neurodevelopmental diagnosis in children (\n“The results revealed that elevated hyperactivity scores, surpassing the ADHD diagnosis threshold, were significantly associated with increased rates of suicidal behavior. Hyperactivity demonstrated a stronger association with lifetime suicide attempts compared to inattention. Moreover, children's self-reported ADHD symptoms exhibited a stronger correlation with suicide attempts than parental reports. This study highlights the critical role of hyperactivity in understanding suicidal behaviors among children with ADHD. It underscores the importance of considering hyperactivity-related symptoms in assessment and treatment approaches for suicidal behavior in this population.”\nIn this article, I discuss the study by\nDespite the significance of these concerns, my formal commentary on this study was rejected by the\nThe analysis of the study by Shahnovsky et al. begins with a close inspection of its methodology, followed by an analysis of its findings later in this article. As implied above, the study focused on testing direct links between characteristics of ADHD (inattention and hyperactivity) and suicide risk (suicide attempts and suicide behaviors). Such an approach, which emphasizes simple, unidimensional relationships between two variables, is accep in pioneering studies exploring phenomena that have not been previously investigated. However, when building on existing literature, it is essential to consider factors that are already well-documented.\nIn the case of the relationship between ADHD and suicidality, two key variables extensively discussed in the literature are the presence of comorbid disorders and the use of common medications prescribed for ADHD (\nPrevious studies linking ADHD to suicidality have consistently noted that, in most cases, the risk of suicide is better explained by the presence of other psychiatric disorders (\nIn the case of ADHD, this conflation – attributing suicidality to the disorder’s core characteristics (e.g., hyperactivity) – is well illustrated in a systematic review by Balaz and Kereszteny (Balazs & Kereszteny, 2017). In this review, the relationship between ADHD and suicide risk was frequently mediated by other psychiatric conditions. In fact, the authors of this review previously reported that the correlation between ADHD symptoms and suicide risk was entirely mediated by symptoms of other disorders (\nThis issue seems to concern Shanhovsky et al. as well. In the limitations section of their article, they acknowledge that “\nThis discrepancy between the two studies raises critical questions about the validity of attributing suicidality directly to ADHD. Why did the authors not integrate their own findings from the earlier study, which was based on overlapping data and essentially highlighted the importance of accounting for comorbidities? Additionally, how should we interpret the current findings of a positive relationship between hyperactivity and suicide risk when, in their previous study, the authors found\nA further, and perhaps more troubling, methodological gap in the study by Shanhovsky et al. concerns the potential contribution of psychiatric medications in general, and the first-line pharmacological treatment for ADHD in particular, to the observed suicide risk. Could the reported increased risk in this study be not a consequence of the diagnosis itself, but rather an unintended effect of the stimulant medications commonly prescribed as its treatment of choice (\nIndeed, the limitation section of the article by Shahnovsky et al. acknowledges that they “\nMoreover, the discussion of antidepressants in the limitations section may be less relevant for children aged 7–12, compared with the potential contribution of stimulants – the first-line treatment for ADHD – which was not mentioned in this section. As documented in the authors’ “separate study,” antidepressants were used by 58.6% of adolescents but only 15% of children. By contrast, stimulants were used by 22.5% of children and 13.5% of adolescents. This suggests that stimulants are more pertinent to the current study, which focuses on the link between hyperactivity and suicidality in young children.\nNot only was this straightforward possibility left unexamined, but the authors also state in their introduction: “It is now well established that significant associations exist between ADHD and suicidal behavior and that stimulant medications may help attenuate this link” (bold added). Before addressing the specific source they cite to support this claim, it is important to consider the broader context of the literature, which is, at best, inconclusive – and at worst, suggestive of a negative impact, as will be demonstrated in the following section. For instance, a 2020 meta-analysis examining a range of functional outcomes of ADHD medications identified two studies on suicidality (\nThe sole source cited by the authors to substantiate their claim regarding the protective effects of ADHD medications on suicidality is a study by\nI admit that I can understand the confusion regarding this source, as Shoval et al. also reported an interaction effect, which they interpreted as suggesting that “in children with substantial externalizing symptoms, ADHD medication use may be associated with less suicidality.” However, this interpretation does not negate the negative main effect of the medications on suicidality, and it is likely inaccurate.\nThis interpretation hinges on the observation that the association between externalizing symptoms and suicidality remained significant only among children who did not receive ADHD medications (\nThe study by Shoval et al. is, of course, not the only one to find a connection between ADHD medications and an increased risk of suicidality. For example, a large-scale study conducted in the Netherlands found that adults aged 18–40 who started using methylphenidate were twice as likely to attempt suicide compared to a control group with similar demographics (\nNotably, the risk associated with the medications, according to this UK study, was particularly high among young children (11–14) – a group similar in age to the very young children (7–12) examined in the study by Shanhovsky et al. While the absolute risk of death by suicide in this age group was very low (as suicide deaths are extremely rare at such young ages), the relative differences within this low-risk group were striking. In the UK study, young children who used stimulant medications were nearly 162 times more likely to die by suicide compared to those who did not (\nThis troubling figure may stem from the relatively common occurrence of suicidal thoughts triggered by these medications. Indeed, even small-scale experimental studies have reported suicidal ideation or behaviors as adverse outcomes of these treatments (e.g.,\nMoreover, ADHD medications, such as methylphenidate, may also contribute to suicidal ideation through their well-documented depression-related effects (\nHaving addressed the critical methodological gaps in the study by Shahnovsky et al., it is equally important to examine its actual findings and evaluate the extent to which they support the broader narrative linking ADHD symptoms to suicide risk. Below is a summary of the findings reported in the study:\nChildren's self-reported hyperactivity was significantly related to lifetime suicide attempts.\nChildren's self-reported inattention was not significantly related to lifetime suicide attempts.\nChildren's self-reported inattention and hyperactivity were not significantly related to suicide behaviors (though the authors note they approached significance).\nParental reports of both hyperactivity and inattention were not significantly related to lifetime suicide attempts.\nParental reports of both hyperactivity and inattention were not significantly related to suicide behaviors.\nAs this summary shows, ADHD symptoms were largely unrelated to suicide risk. The only significant finding, which linked hyperactivity (but not inattention) to past suicide attempts (but not suicidal behaviors), was based solely on children’s self-reported responses. This raises a critical question: how can children as young as 7 years old – or even those at the upper end of the age range, 12 years old – reliably evaluate their own levels of hyperactivity or inattention, let alone compare these to standardized clinical thresholds?\nSupporting this reliability concern, the study's concordance test between parent and child reports revealed a “very low level of agreement… suggesting almost no concordance between the children's and parents' reports on ADHD symptoms.” This striking disparity underscores the potential distortion in children’s self-perceptions and further calls into question the reliability of the sole significant result.\nFurthermore, even if the authors' entire set of hypotheses had been statistically confirmed, it is important to recognize that basic symptom measures of hyperactivity and inattention (without the use of broader, standardized assessments) provide an incomplete and potentially misleading picture. This concern is particularly relevant in the case of hyperactivity, which can arise from a wide range of neurodevelopmental, emotional, or situational factors unrelated to ADHD itself.\nTaken together, these predominantly non-significant findings, which rely on unreliable self-reports of very young children, challenge the narrative presented in the study’s abstract (see the opening of this article) and cast serious doubt on the validity of hyperactivity as a critical risk factor for suicidality. In my view, the pattern of results suggests that other variables, likely unrelated to ADHD symptoms as discussed throughout this article, may offer a far more robust and accurate explanation for understanding suicide risk in children.\nAltogether, the actual findings of the study, combined with its omission of critical variables known to increase suicide risk (i.e., comorbid disorders and ADHD medications) and its misinterpretation of previous research (which has essentially documented a troubling link between ADHD medications and suicide risk) (\nThese methodological and interpretative gaps not only limit the study's utility but also risk perpetuating harmful misconceptions. Clinicians might act on its conclusions and prescribe ADHD medications to suppress the supposedly dangerous hyperactivity – medications that were not accounted for in the study and that are well-documented to increase depression and suicide risk (as shown throughout the current article).\nTo avoid such potential harm, and to advance the field of suicidology in children, future research would benefit from a more nuanced and comprehensive approach. Assessments that include both comorbid conditions and negative effects of medications are essential to disentangle the complex relationship between ADHD, its treatments, and suicidality. In my view, addressing these gaps could bring us closer to identifying precise risk factors and developing safe interventions.\nThis recommendation is particularly critical given the growing recognition of the limited validity − and potential risks − of the biomedical framing of ADHD (\nAgainst this broader backdrop, the study by Shahnovsky et al. represents an important opportunity for reflection and constructive dialogue. Despite the critical observations raised throughout this article, please allow me to conclude by commending the authors once again for addressing such a crucial and challenging topic. Their lifelong dedication to advancing suicide prevention is deeply appreciated, and it is in this spirit that I offer these reflections. I hope that this discussion fosters a constructive dialogue that contributes to refining research practices and deepening our understanding of the tragic phenomenon of childhood suicide.\nThis supplementary material provides background on the editorial barriers encountered when attempting to publish the current article in the journal where the original study by\nUpon the publication of the study by Shahnovsky et al., which identified hyperactivity as a significant predictor of suicide attempts, I contacted EJIHPE to request an exception to the journal’s policy that prohibits commentaries and letters critiquing published articles. I argued that such a policy contradicts fundamental scientific norms and impedes open academic discourse. Additionally, I outlined several key concerns – detailed in the main article – regarding the study by Shahnovsky et al.\nFollowing this exchange, I was granted permission and explicitly encouraged to submit a formal commentary. However, despite this initial approval, my submission was later rejected on the grounds that the journal does not accept commentaries. The rejection was accompanied by two justifications:\nThat the study’s objective was “\nThat the study’s limitations section had already addressed most of my concerns.\nBelieving this rationale to be flawed, I appealed the decision, clearly demonstrating that the limitations section did not sufficiently address the key methodological issues I raised and that it even contained certain misrepresentations (as can be seen in the main article). Despite this, my appeal was denied without further justification.\nGiven these circumstances, I felt it was my ethical duty to publish my commentary elsewhere to ensure an open scholarly discussion of the study’s findings and their implications.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "40304384", "pmcid": "12303962", "title": "Altered functional network topology and connectivity in female nurses with shift work sleep disorder", "publication_year": "N/A", "abstract": "", "full_text": "Shift work, prevalent among healthcare workers like nurses, significantly disrupts the endogenous circadian rhythm and acts as a major risk factor for sleep disorders (\nWith rapid advancements in neuroimaging technology, recent studies have indicated that SWSD in nurses is closely associated with alterations in brain function, such as abnormal activity in the default mode network (DMN) and attention-related circuits (\nTo address this knowledge gap, we employed graph theory analysis of resting-state fMRI data to conduct a systematic investigation into the brain functional network topology of female nurses with SWSD. Our study was guided by three primary hypotheses: (1) that female nurses with SWSD would exhibit disrupted brain network organization, manifesting as reduced global and local efficiency compared to HCs; (2) that SWSD would be associated with altered functional connectivity, especially weakened connections within and between key networks like the DMN, visual network (VN), and limbic network (LN); and (3) that these neuroimaging-derived network metrics would correlate with clinical measures of sleep disturbance. By elucidating the neurobiological underpinnings of SWSD, this study aimed to advance our understanding of its pathophysiology and inform the development of novel strategies for prevention and intervention. A flowchart detailing the research process is presented in\nThis study recruited female nurses from the Yancheng School of Clinical Medicine, Nanjing Medical University from May to July 2024. To minimize the acute effects of recent shift work and to capture the chronic neurobiological alterations associated with SWSD, all participants were scanned on a scheduled day off between 6:00 PM and 9:00 PM. Prior to the scan, participants were instructed to lie still in a supine position with their eyes closed, remain awake, and avoid systematic thinking, allowing their minds to wander freely. Foam padding was used to minimize head motion. The resting-state scan was part of a broader imaging protocol, and the scanning conditions were kept consistent for all participants. Inclusion criteria for the SWSD group (\nThe required sample size was determined by an\nPrior to MRI scanning, general demographic information and clinical data were collected, including age, years of education, Beck Anxiety Inventory (BAI) scores, Beck Depression Inventory-II (BDI-II) scores, PSQI scores, and Insomnia Severity Index (ISI) scores.\nRs-fMRI and structural 3D T1-weighted images were acquired using a 3.0 Tesla MRI scanner equipped with a 24-channel head coil (Discovery 750w, GE, United States) at the Yancheng School of Clinical Medicine of Nanjing Medical University (Imaging parameters are provided in the\nResting-state fMRI preprocessing: The rs-fMRI data were preprocessed using SPM12 and Data Processing and Analysis for Brain Imaging (DPABI) implemented in MATLAB (R2018b) (\nGraph theoretical analysis of brain network characteristics was performed using the GRETNA software (\nFC networks were constructed using the graph theoretical network analysis toolbox (GRETNA) (\nDifferences in FC between brain regions were analyzed using the connection module of the GRETNA software. Group differences in functional connections were identified using a two-sample\nSPSS 27.0 software was used for statistical analysis. First, normality tests were conducted for age, years of education, PSQI scores, ISI scores, TIV, BAI scores, and BDI-II scores. For normally distributed measurement data, independent sample\nTwo-sample\nDemographic and clinical characteristics of the HCs (\nDemographic and clinical features of all participants.\nBAI, Beck Anxiety Inventory; BDI, Beck Depression Inventory; FC, functional connectivity; F, female; HCs, healthy controls; ISI, Insomnia Severity Index; L, left; M, male; PSQI, Pittsburgh Sleep Quality Index; R, right; SWSD, shift work sleep disorder; TIV, total intracranial volume. Bold values indicate statistical significance (\nGlobal network metrics for the SWSD group and HCs were calculated and compared, utilizing the AUC for each global property (\nGroup comparisons of AUC values of global network properties.\nAUC, area under the curve; C\nAlterations in global network metrics. Compared with HCs, the C\nCompared with the HCs, the NCP of the bilateral calcarine cortex, bilateral lingual gyrus, right cuneus and left superior occipital gyrus was significantly decreased in the SWSD group (all\nNodes showing significant differences in NCP between nurses with SWSD and HCs. The blue circles represent a higher NCP in HCs than in nurses with SWSD (all\nNodes showing significant differences in NLE between nurses with SWSD and HCs. The blue circles represent a higher NLE in HCs than in nurses with SWSD (all\nCompared to HCs, the SWSD group showed significantly altered FC (all\nAltered functional network connectivity.\nANG, angular gyrus; CAL, calcarine cortex; CAU, caudate nucleus; CUN, cuneus; DMN, default mode network; FFG, fusiform gyrus; FPN, frontoparietal network; IPL, inferior parietal lobule; ITG, inferior temporal gyrus; LN, limbic network; LING, lingual gyrus; MFG, middle frontal gyrus; MOG, middle occipital gyrus; OLF, olfactory cortex; ORBsup, superior orbitofrontal gyrus; PCUN, precuneus; PreCG, precentral gyrus; REC, rectus gyrus; SFGmed, superior frontal gyrus, medial part; SMN, somatomotor network; SN, subcortical network; SOG, superior occipital gyrus; VN, visual network; VAN, ventral attention network.\nAlterations in brain functional network connectivity between nurses with SWSD and HCs. Nodes represent specific brain regions grouped by functional networks, including SMN, DMN, VN, VAN, FPN, SN, and LN. Edges indicate significant changes in functional connectivity between nurses with SWSD and HCs, with edge colors reflecting the direction and magnitude of\nAs illustrated in\nCorrelation analysis.\nUsing graph theoretical analysis, this study investigated alterations in brain functional network topology and subnetwork connectivity in nurses with SWSD relative to HCs. These network alterations were subsequently correlated with clinical sleep variables, specifically the PSQI and ISI. The principal findings were as follows: (1) global network metrics, including E\nThe intricate structural and functional organization of the brain arises from the topological configurations of neuronal clusters (\nPrevious extensive research indicates that various sleep disorders exhibit alterations in global brain network topology, including obstructive sleep apnea (OSA) (\nRegarding nodal network metrics, our analysis revealed a significant decrease in NCP in the bilateral calcarine cortex, the bilateral lingual gyrus, and the left superior occipital gyrus compared to HCs. Concurrently, NLE was also significantly reduced in this group, specifically in the bilateral calcarine cortex, bilateral lingual gyrus, right cuneus, and right caudate nucleus. These aforementioned visual network regions (bilateral calcarine cortex, bilateral lingual gyrus, left superior occipital gyrus, and right cuneus) are key components of the visual system (\nBeyond alterations in topological properties, this study also revealed a complex subnetwork of altered FC within and between large-scale brain networks (SMN, SN, VN, LN, FPN, DMN), characterized by both abnormally strong and weak connections. In SWSD, abnormally strong connections may reflect the brain’s compensatory efforts to counteract inefficiencies or a dysregulated hyperconnective state, while weakened connections likely indicate reduced information transfer efficiency or impaired integration between regions (\nBeyond these intra-network disruptions, sleep disorders also profoundly affect FC between distinct brain networks. These disorders disrupt VN interactions with the DMN (\nThe clinical relevance of these network alterations is underscored by our correlation analyses. First, a negative correlation was observed between PSQI scores and NLE in the right cuneus. The cuneus, a core region of the occipital visual cortex, is involved in primary visual information processing, visuospatial processing, and visual attention (\nAlthough this study provided valuable insights into the neural underpinnings of SWSD in nurses, there are several limitations that should be considered. First, our study did not incorporate subjective measures to assess daytime sleepiness (e.g., the Epworth sleepiness scale) or circadian chronotype (e.g., the morningness–eveningness questionnaire). These clinical scales would have allowed us to directly correlate behavioral and circadian phenotypes with the observed alterations in brain networks, thereby enhancing the clinical relevance of our findings. Future studies should incorporate these assessments to build a more comprehensive brain-behavior model of SWSD. Second, the cross-sectional design of our study limits causal inference. It remains unclear whether the observed brain changes are a cause or a consequence of SWSD. A longitudinal study would be invaluable, not only to elucidate the direction of causality but also to map the temporal dynamics of these network alterations. Such a design would enable us to determine, for instance, whether these changes are exacerbated by continued shift work, fluctuate with schedule modifications, or can be ameliorated through intervention. Third, the study focused exclusively on female nurses aged 20–40 years, which may limit the generalizability of the findings to other populations, such as male nurses or nurses in different age groups. Importantly, this precludes the exploration of how SWSD-related brain changes may vary across the lifespan. Future studies should include more diverse samples, particularly across a wider age range and in other populations (e.g., male shift workers), to assess the generalizability of these findings. Fourth, the assessment of sleep disorders and psychological status relied on self-report questionnaires (PSQI, ISI, BAI, and BDI-II), which are subject to recall bias and subjective interpretation, although these are standard instruments in the field. Objective measures of sleep, such as actigraphy or polysomnography, could provide more robust data in future research. Fifth, the focus of the present study is on the topological properties and functional network connectivity in nurses with SWSD. However, this approach cannot resolve the directionality of influence between brain regions. To address this limitation, future investigations should employ methods designed to assess effective connectivity, such as Multivariate granger causality. By utilizing a larger sample and multivariate Granger causality analysis, such studies could elucidate the dynamics of directed functional influence and information flow within and between networks, providing a more comprehensive understanding of how SWSD reconfigures the brain’s communication architecture. Sixth, a further limitation is our inability to perform a stratified analysis by shift work duration. Although we collected these data, the resulting subgroups (e.g., 1–5 years,\nIn conclusion, this study demonstrates that SWSD in female nurses is characterized by significant alterations in brain functional network topology. Key among these are widespread reductions in both global and nodal network efficiency, particularly within visual processing regions and the caudate nucleus, alongside a complex pattern of disrupted (primarily weakened) FC across multiple brain networks. Crucially, these neuroimaging changes correlated significantly with clinical measures of insomnia severity and sleep quality. Identifying these topological and FC alterations advances our understanding of the pathophysiological mechanisms underlying SWSD and provides novel insights for potential prevention and intervention strategies.", "content_for_embedding": "Shift work, prevalent among healthcare workers like nurses, significantly disrupts the endogenous circadian rhythm and acts as a major risk factor for sleep disorders (\nWith rapid advancements in neuroimaging technology, recent studies have indicated that SWSD in nurses is closely associated with alterations in brain function, such as abnormal activity in the default mode network (DMN) and attention-related circuits (\nTo address this knowledge gap, we employed graph theory analysis of resting-state fMRI data to conduct a systematic investigation into the brain functional network topology of female nurses with SWSD. Our study was guided by three primary hypotheses: (1) that female nurses with SWSD would exhibit disrupted brain network organization, manifesting as reduced global and local efficiency compared to HCs; (2) that SWSD would be associated with altered functional connectivity, especially weakened connections within and between key networks like the DMN, visual network (VN), and limbic network (LN); and (3) that these neuroimaging-derived network metrics would correlate with clinical measures of sleep disturbance. By elucidating the neurobiological underpinnings of SWSD, this study aimed to advance our understanding of its pathophysiology and inform the development of novel strategies for prevention and intervention. A flowchart detailing the research process is presented in\nThis study recruited female nurses from the Yancheng School of Clinical Medicine, Nanjing Medical University from May to July 2024. To minimize the acute effects of recent shift work and to capture the chronic neurobiological alterations associated with SWSD, all participants were scanned on a scheduled day off between 6:00 PM and 9:00 PM. Prior to the scan, participants were instructed to lie still in a supine position with their eyes closed, remain awake, and avoid systematic thinking, allowing their minds to wander freely. Foam padding was used to minimize head motion. The resting-state scan was part of a broader imaging protocol, and the scanning conditions were kept consistent for all participants. Inclusion criteria for the SWSD group (\nThe required sample size was determined by an\nPrior to MRI scanning, general demographic information and clinical data were collected, including age, years of education, Beck Anxiety Inventory (BAI) scores, Beck Depression Inventory-II (BDI-II) scores, PSQI scores, and Insomnia Severity Index (ISI) scores.\nRs-fMRI and structural 3D T1-weighted images were acquired using a 3.0 Tesla MRI scanner equipped with a 24-channel head coil (Discovery 750w, GE, United States) at the Yancheng School of Clinical Medicine of Nanjing Medical University (Imaging parameters are provided in the\nResting-state fMRI preprocessing: The rs-fMRI data were preprocessed using SPM12 and Data Processing and Analysis for Brain Imaging (DPABI) implemented in MATLAB (R2018b) (\nGraph theoretical analysis of brain network characteristics was performed using the GRETNA software (\nFC networks were constructed using the graph theoretical network analysis toolbox (GRETNA) (\nDifferences in FC between brain regions were analyzed using the connection module of the GRETNA software. Group differences in functional connections were identified using a two-sample\nSPSS 27.0 software was used for statistical analysis. First, normality tests were conducted for age, years of education, PSQI scores, ISI scores, TIV, BAI scores, and BDI-II scores. For normally distributed measurement data, independent sample\nTwo-sample\nDemographic and clinical characteristics of the HCs (\nDemographic and clinical features of all participants.\nBAI, Beck Anxiety Inventory; BDI, Beck Depression Inventory; FC, functional connectivity; F, female; HCs, healthy controls; ISI, Insomnia Severity Index; L, left; M, male; PSQI, Pittsburgh Sleep Quality Index; R, right; SWSD, shift work sleep disorder; TIV, total intracranial volume. Bold values indicate statistical significance (\nGlobal network metrics for the SWSD group and HCs were calculated and compared, utilizing the AUC for each global property (\nGroup comparisons of AUC values of global network properties.\nAUC, area under the curve; C\nAlterations in global network metrics. Compared with HCs, the C\nCompared with the HCs, the NCP of the bilateral calcarine cortex, bilateral lingual gyrus, right cuneus and left superior occipital gyrus was significantly decreased in the SWSD group (all\nNodes showing significant differences in NCP between nurses with SWSD and HCs. The blue circles represent a higher NCP in HCs than in nurses with SWSD (all\nNodes showing significant differences in NLE between nurses with SWSD and HCs. The blue circles represent a higher NLE in HCs than in nurses with SWSD (all\nCompared to HCs, the SWSD group showed significantly altered FC (all\nAltered functional network connectivity.\nANG, angular gyrus; CAL, calcarine cortex; CAU, caudate nucleus; CUN, cuneus; DMN, default mode network; FFG, fusiform gyrus; FPN, frontoparietal network; IPL, inferior parietal lobule; ITG, inferior temporal gyrus; LN, limbic network; LING, lingual gyrus; MFG, middle frontal gyrus; MOG, middle occipital gyrus; OLF, olfactory cortex; ORBsup, superior orbitofrontal gyrus; PCUN, precuneus; PreCG, precentral gyrus; REC, rectus gyrus; SFGmed, superior frontal gyrus, medial part; SMN, somatomotor network; SN, subcortical network; SOG, superior occipital gyrus; VN, visual network; VAN, ventral attention network.\nAlterations in brain functional network connectivity between nurses with SWSD and HCs. Nodes represent specific brain regions grouped by functional networks, including SMN, DMN, VN, VAN, FPN, SN, and LN. Edges indicate significant changes in functional connectivity between nurses with SWSD and HCs, with edge colors reflecting the direction and magnitude of\nAs illustrated in\nCorrelation analysis.\nUsing graph theoretical analysis, this study investigated alterations in brain functional network topology and subnetwork connectivity in nurses with SWSD relative to HCs. These network alterations were subsequently correlated with clinical sleep variables, specifically the PSQI and ISI. The principal findings were as follows: (1) global network metrics, including E\nThe intricate structural and functional organization of the brain arises from the topological configurations of neuronal clusters (\nPrevious extensive research indicates that various sleep disorders exhibit alterations in global brain network topology, including obstructive sleep apnea (OSA) (\nRegarding nodal network metrics, our analysis revealed a significant decrease in NCP in the bilateral calcarine cortex, the bilateral lingual gyrus, and the left superior occipital gyrus compared to HCs. Concurrently, NLE was also significantly reduced in this group, specifically in the bilateral calcarine cortex, bilateral lingual gyrus, right cuneus, and right caudate nucleus. These aforementioned visual network regions (bilateral calcarine cortex, bilateral lingual gyrus, left superior occipital gyrus, and right cuneus) are key components of the visual system (\nBeyond alterations in topological properties, this study also revealed a complex subnetwork of altered FC within and between large-scale brain networks (SMN, SN, VN, LN, FPN, DMN), characterized by both abnormally strong and weak connections. In SWSD, abnormally strong connections may reflect the brain’s compensatory efforts to counteract inefficiencies or a dysregulated hyperconnective state, while weakened connections likely indicate reduced information transfer efficiency or impaired integration between regions (\nBeyond these intra-network disruptions, sleep disorders also profoundly affect FC between distinct brain networks. These disorders disrupt VN interactions with the DMN (\nThe clinical relevance of these network alterations is underscored by our correlation analyses. First, a negative correlation was observed between PSQI scores and NLE in the right cuneus. The cuneus, a core region of the occipital visual cortex, is involved in primary visual information processing, visuospatial processing, and visual attention (\nAlthough this study provided valuable insights into the neural underpinnings of SWSD in nurses, there are several limitations that should be considered. First, our study did not incorporate subjective measures to assess daytime sleepiness (e.g., the Epworth sleepiness scale) or circadian chronotype (e.g., the morningness–eveningness questionnaire). These clinical scales would have allowed us to directly correlate behavioral and circadian phenotypes with the observed alterations in brain networks, thereby enhancing the clinical relevance of our findings. Future studies should incorporate these assessments to build a more comprehensive brain-behavior model of SWSD. Second, the cross-sectional design of our study limits causal inference. It remains unclear whether the observed brain changes are a cause or a consequence of SWSD. A longitudinal study would be invaluable, not only to elucidate the direction of causality but also to map the temporal dynamics of these network alterations. Such a design would enable us to determine, for instance, whether these changes are exacerbated by continued shift work, fluctuate with schedule modifications, or can be ameliorated through intervention. Third, the study focused exclusively on female nurses aged 20–40 years, which may limit the generalizability of the findings to other populations, such as male nurses or nurses in different age groups. Importantly, this precludes the exploration of how SWSD-related brain changes may vary across the lifespan. Future studies should include more diverse samples, particularly across a wider age range and in other populations (e.g., male shift workers), to assess the generalizability of these findings. Fourth, the assessment of sleep disorders and psychological status relied on self-report questionnaires (PSQI, ISI, BAI, and BDI-II), which are subject to recall bias and subjective interpretation, although these are standard instruments in the field. Objective measures of sleep, such as actigraphy or polysomnography, could provide more robust data in future research. Fifth, the focus of the present study is on the topological properties and functional network connectivity in nurses with SWSD. However, this approach cannot resolve the directionality of influence between brain regions. To address this limitation, future investigations should employ methods designed to assess effective connectivity, such as Multivariate granger causality. By utilizing a larger sample and multivariate Granger causality analysis, such studies could elucidate the dynamics of directed functional influence and information flow within and between networks, providing a more comprehensive understanding of how SWSD reconfigures the brain’s communication architecture. Sixth, a further limitation is our inability to perform a stratified analysis by shift work duration. Although we collected these data, the resulting subgroups (e.g., 1–5 years,\nIn conclusion, this study demonstrates that SWSD in female nurses is characterized by significant alterations in brain functional network topology. Key among these are widespread reductions in both global and nodal network efficiency, particularly within visual processing regions and the caudate nucleus, alongside a complex pattern of disrupted (primarily weakened) FC across multiple brain networks. Crucially, these neuroimaging changes correlated significantly with clinical measures of insomnia severity and sleep quality. Identifying these topological and FC alterations advances our understanding of the pathophysiological mechanisms underlying SWSD and provides novel insights for potential prevention and intervention strategies.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "40156638", "pmcid": "12302699", "title": "Communication quality between parents and siblings of children with chronic disorders", "publication_year": "N/A", "abstract": "", "full_text": "The experience of growing up with a sibling who has a chronic disorder is relatively common, with prevalence rates estimated between 7 % and 17 % [\nSuch risks may stem from a variety of factors. First, siblings can lack knowledge about and misunderstand the diagnosis, which can provoke anxiety, self-blame, and concern about acquiring the same disorder ([\nParents of children with chronic disorders experience higher levels of stress compared to parents of typically developing children due to the physical, financial, and psychosocial demands of caring for a child with a chronic disorder [\nParent-child communication in families of children with chronic disorders is, on average, poorer quality than in other families, with higher levels of hostile, intrusive and withdrawn communication than controls [\nOne way to meet the needs of siblings and parents of children with chronic disorders is to organize support groups where the participants can connect with others in similar situations, share experiences, express feelings, and receive support from peers and clinicians [\nThe SIBS intervention consists of five sessions (\nA Randomized Controlled Group Intervention Trial for Siblings of Children with Chronic disorders [\nAn open trial study of SIBS found positive effects on communication quality between siblings and parents [\nBetween the open trial and RCT, changes were made to training for SIBS group leaders to emphasise the parental response of validating more strongly, as validation was underrepresented in an examination of parent-child conversations during the open trial [\nHow do parents and siblings of children with chronic disorders communicate in an intervention setting?\nWhich topics do children and parents talk about in an intervention setting?\nTo what extent do parents listen, explore, and validate when responding to their sibling child?\nDue to the explorative and qualitative nature of the study, we addressed the research questions openly, without a priori hypotheses.\nParticipants were recruited to join the SIBS-RCT through health care services from three municipalities, five hospitals, a national specialist disorder center for rare disorders, and a range of patient user organizations ([\nFor the present study, we drew a sub-sample from the SIBS-RCT consisting of 20 siblings and 19 parents (one parent attended separate 1:1 sessions with twin siblings). The dyads included 12 girls and 8 boys and 12 mothers and 7 fathers. Siblings' ages ranged from 8 to 13 years (M = 9). Parents' average education level was high, with 47 % reporting ≥4 years of post-high school education, 37 % reporting 1–4 years of post-high school education, and 16 % completing only high school. A range of chronic disorder diagnoses was represented across participating families, including attention deficit hyperactivity disorder (ADHD), autism spectrum disorder (ASD), Tourette syndrome, eating disorders, cerebral palsy, epilepsy, and intellectual disabilities. Ethnic diversity was low in our sample, as all participants were of European descent.\nData for our study consists of 20 audio recordings of parent-child dialogues from Session 3 of the SIBS intervention. In Session 3, the focus is on the siblings' questions and thoughts about the disorder, allowing the parents to practice communication skills taught in a previous session. The siblings have prepared questions from Session 2 that they bring into Session 3 and present to their parents, and parents practice responding to these questions by listening, exploring, and validating. At some point during this 1:1 conversation, a group leader enters the room and provides the parent with feedback. Each intervention session had at least two group leaders (one for sibling group and one for parent group) who acted as group leaders, facilitators, and supervisors across the group and 1:1 parts of the intervention. In the complete RCT, there were 28 such group leaders. However, because Session 3 of the intervention was audio recorded rather than video recorded, it is unclear how many individual group leaders were involved in the 1:1 conversations in our sample.\nWe considered Session 3 appropriate for conducting an in-depth analysis of how parents respond to siblings' cues and concerns because it is the first interaction between the siblings and parents after the parents receive communication training in Sessions 1 and 2.\nThe conversation recordings last around 20 min (m = 24 min) and were transcribed verbatim. From the transcriptions, we noted topics mentioned by siblings, then grouped similar topics into overarching themes. We counted the frequency of each theme, and ranked the themes from most to least frequently mentioned, with the aim of identifying topics of interest to siblings. We continued analyzing new dyads until no new themes were identified and thus the data was considered saturated ([\nParent-sibling communication quality was analyzed using the Verona Coding Definition of Emotional Sequences (VR-CoDES) [\nVR-CoDES response category and SIBS target behaviours.\nThe VR-CoDES presents a consensus-based definition of a person's implicit signals or hints (cues) and explicitly expressed emotional distress (concerns) [\nExamples of negative expressions from siblings and parent responses.\nVR-CoDES is intended to be applied to responses that occur directly after a cue or concern is expressed [\nIn this study, coding of parent-child dialogues was carried out by identifying cues, concerns, and repeated cues from participating children, and categorizing parent responses as provide versus reduce space, and as explicit versus non-explicit. Additionally, provide space responses were coded under the subcategories of listening, exploring, or validating responses. Explicit delayed responses from parents and repeated cues were also coded (\nOverview over coding scheme.\nFinally, two members of the research team who were also clinicians noted their clinical observations and impressions from the dyads throughout analysis, in response to concerns that the VRCoDES were missing important aspects of parent-child communication in SIBS [\nSiblings raised the following themes in conversation with their parents (listed most to least frequent):\nIllness: how the sibling got the diagnosis, symptoms and prognosis. Example:\nDifferential treatment. Example:\nHeritability and worries about getting the diagnosis. Example:\nViolence, temper tantrums and acting out of the child with a chronic disorder. Example:\nSibling relationship. Example:\nLonging for more time together as a family. Example:\nNeed for attention, feelings of loneliness. Example:\nImpact on social life. Example:\nSiblings made a total of 177 expressions of negative affect, with cues accounting for 53.1 % (\nA total of 186 parent responses to siblings' cues and concerns were coded. There was a larger proportion of providing space responses (74 %,\nOf provide space responses, 80 % were explicit (n = 109). The most common explicit provide space response type was exploring (67 %,\nNon-explicit provide space responses accounted for 20 % (\nOverall, the proportion of reduced space responses was lower than for provide space responses (26 %,\n\nParent: “Honestly, why do you think she hits when you get close?”\nSibling: “Because she is happy.”\nParent: “Because she is happy? So, it is actually a good thing?”\nSibling: “No!”\nParent: “Yes, it actually is. I think you didn't quite understand what I meant.”\nSibling: “Yes, but not for me.”\nA lower proportion of the reduce space responses were non-explicit (23 %). These types of responses also tended to provide information, advice, and reassurance. For example, a father asked: “What bothers you the most?” The son answered with a concern: “That he hits me.” The father responded: “Mmm, but we are trying to fix that.”\nProvide space responses were further analyzed into listening, exploring and validating, the target behaviours of the SIBS intervention. Exploration, for example asking the child follow-up or clarification questions, was the most frequently used approach (59 %,\nWe are not allowed to watch TV as much as he is, and we are not allowed to watch TV at the dinner table, and we don't always have someone who has time to put us to bed, but he always has someone who puts him to bed, because he's trying… to get all the attention and spend most of his time with you.\nThe mother responded with a warm tone in her voice, saying: “Yes” after a pause.\nThroughout the analyses, we observed a number of instances where the VR-CoDES did not capture important aspects of parent-child communication, including cases of parents practicing the SIBS target behaviours. For example, some parents reduced space, but used a warm tone and asked exploratory questions, which encouraged the sibling to share more. The following conversation between father and daughter illustrates a sibling continuing to share more even though her father used a response that was coded as reduce space according to the VR-CoDES:\nSibling: “But I don't feel like explaining every single time I have visitors.”\nParent: “Do you have visitors that often?”\nSibling: “No, I'm not allowed because [sibling] is home.”\nParent: “What do you think about that?”\nSibling: “That it is very unfair.”\nIn other cases, the VR-CoDES guidelines prevented instances of parental exploring, validating and listening to be missed in the analysis. For example, following VR-CoDES guidelines, the same cue or concern should not be coded twice, and parental responses should not be coded unless they directly follow an expressed cue or concern. In the conversation below, the parent validates the sibling's thoughts, but this was not captured in the analysis because no cue or concern was presented first:\nSibling: I haven't thought much about it.\nParent: No. There is no right or wrong answer here.\nSibling: Only right answers.\nParent: No, yes. There are only right answers, you could say; that's a better way to put it. Good. Good thinking. Only right answers.\nParents also showed listening behaviour that was not captured by the VR-CoDES, prompting with minimal words such as “yes” and “hmm” while siblings were speaking, instead of showing these behaviours after siblings had finished stating a cue or concern. Finally, sometimes the VR-CoDES led to the recording of a parental response as positive (i.e. one of the target SIBS behaviours) but the tone of the conversation was not positive.\nFor example, in one of the dyads, a daughter reacted to her father's exploration via questionning:\nParent: “I'm just asking you questions.”\nSibling: “No, it's like an interview.”\nThe aim of this study was to examine how siblings and parents of children with chronic disorders communicate in an intervention setting. We found that siblings raised a variety of topics with their parents, and that their expressions of negative emotion were split approximately evenly between cues and concerns. Parents mainly responded by providing space; within these responses, exploration was the most common type of SIBS intervention target behaviour, followed by validation and listening.\nThe topics raised by siblings were similar to those found in previous literature. The most frequently occurring topic was the diagnosis, including worries about contagion or heritability of the disorder. This reflects previous findings that siblings often receive limited information about their sibling's condition and are concerned about their own health in relation to the condition ([\nThe participating siblings expressed themselves with a more even ratio of cues and concerns (53 % cues and 47 % concerns) than expected from previous applications of VR-CoDES on child data. For example, [\nWithin their responses to siblings' cues and concerns, we found that parents mainly provided space (74 % of responses), encouraging them to share more about their experiences, situations, and feelings. These results are consistent with findings from Haukeland et al. [\nValidating responses accounted for a third (33 %) of the provide space responses in our analyses, making validation the second most used SIBS target behaviour. This finding differs notably from the Haukeland et al. [\nListening responses accounted for only 8 % of the provide space responses in our analysis, making it the least-used approach. This low rate of listening responses is also inconsistent with Haukeland et al.'s [\nThe current study used quantitative analysis combined with qualitative observations of parent-sibling conversations to examine how siblings express themselves in an intervention setting and how parents respond to these expressions. The intervention setting means that our findings do not necessarily reflect how parents and siblings communicate on a day-to-day basis, as parents had received psychoeducation, practiced communication techniques, and accessed the prepared questions from the siblings in advance of the sessions we analyzed.\nHowever, our findings do offer insight into how parents and siblings communicate during the SIBS intervention—an important step towards creating an effective, evidence-based intervention for siblings of children with chronic disorders. One of our most important findings was that parental validation responses increased since a previous study of the SIBS intervention [\nThe use of VR-CoDES was a key strength of our study, providing a manual-based, quantitative measure of emotional expression and response which allowed for a relatively objective assessment of parent-sibling communication quality and made comparison with results from previous studies possible. However, the VR-CoDES also failed to capture some important aspects of parent-child communication, including active listening behaviours that occurred throughout a child's speech, or parental input that did not follow a cue or concern. Moreover, the VR-CoDES do not cover non-verbal responses and our use of audio recordings did not allow for this to be noted. Parents may have expressed non-verbal validation, attentiveness, or other empathic signals such as supportive facial expressions, hugs, or nodding of their heads that was not captured in our analysis ([\nAn additional limitation is that participant parents were, on average, better educated than the general population. Parents with higher levels of education are known to make less use of negative disciplinary practices, have greater knowledge about child development, and engage in more conversations with their children compared to parents with lower levels of education ([\nSimilarly, our sample included families with a child with a range of chronic disorders including ASD, ADHD, Tourette syndrome, eating disorders, cerebral palsy, epilepsy, and intellectual disabilities, but it is unclear whether our findings would generalize to families with other diagnoses. The presence of somatic illnesses such as cancer, for example, could potentially cause siblings to bring up different themes in conversation, which could in turn provoke different types of responses from parents. Larger study samples representing a wider range of diagnoses could begin to address these questions. Future studies could also explore ways in which the SIBS communication skills could be provided to families in different ways, such as via an online format (see, for example, [\nThe current study contributes valuable qualitative insight to a sibling intervention setting. Most parent-sibling dyads communicated with warmth and care, even when using reducing space responses, which facilitated a space for siblings to share their emotions and experiences even if these aspects of communication were not always captured by the VR-CoDES. These results are promising, as one of the key aims of the SIBS intervention is to improve family communication quality by enhancing parental listening, exploration, and validation. Overall, the findings from this study contribute to the further development of the SIBS intervention and to a broader understanding of parent-child communication in families with a child with a chronic disorder.\nThe SIBS-RCT was approved by The Regional Committee for Medical and Health Research Ethics South East (REK - 2018/2461) ([\nThe Norwegian Research Council, project no. 321027.\nWe have no known conflict of interest to disclose.", "content_for_embedding": "The experience of growing up with a sibling who has a chronic disorder is relatively common, with prevalence rates estimated between 7 % and 17 % [\nSuch risks may stem from a variety of factors. First, siblings can lack knowledge about and misunderstand the diagnosis, which can provoke anxiety, self-blame, and concern about acquiring the same disorder ([\nParents of children with chronic disorders experience higher levels of stress compared to parents of typically developing children due to the physical, financial, and psychosocial demands of caring for a child with a chronic disorder [\nParent-child communication in families of children with chronic disorders is, on average, poorer quality than in other families, with higher levels of hostile, intrusive and withdrawn communication than controls [\nOne way to meet the needs of siblings and parents of children with chronic disorders is to organize support groups where the participants can connect with others in similar situations, share experiences, express feelings, and receive support from peers and clinicians [\nThe SIBS intervention consists of five sessions (\nA Randomized Controlled Group Intervention Trial for Siblings of Children with Chronic disorders [\nAn open trial study of SIBS found positive effects on communication quality between siblings and parents [\nBetween the open trial and RCT, changes were made to training for SIBS group leaders to emphasise the parental response of validating more strongly, as validation was underrepresented in an examination of parent-child conversations during the open trial [\nHow do parents and siblings of children with chronic disorders communicate in an intervention setting?\nWhich topics do children and parents talk about in an intervention setting?\nTo what extent do parents listen, explore, and validate when responding to their sibling child?\nDue to the explorative and qualitative nature of the study, we addressed the research questions openly, without a priori hypotheses.\nParticipants were recruited to join the SIBS-RCT through health care services from three municipalities, five hospitals, a national specialist disorder center for rare disorders, and a range of patient user organizations ([\nFor the present study, we drew a sub-sample from the SIBS-RCT consisting of 20 siblings and 19 parents (one parent attended separate 1:1 sessions with twin siblings). The dyads included 12 girls and 8 boys and 12 mothers and 7 fathers. Siblings' ages ranged from 8 to 13 years (M = 9). Parents' average education level was high, with 47 % reporting ≥4 years of post-high school education, 37 % reporting 1–4 years of post-high school education, and 16 % completing only high school. A range of chronic disorder diagnoses was represented across participating families, including attention deficit hyperactivity disorder (ADHD), autism spectrum disorder (ASD), Tourette syndrome, eating disorders, cerebral palsy, epilepsy, and intellectual disabilities. Ethnic diversity was low in our sample, as all participants were of European descent.\nData for our study consists of 20 audio recordings of parent-child dialogues from Session 3 of the SIBS intervention. In Session 3, the focus is on the siblings' questions and thoughts about the disorder, allowing the parents to practice communication skills taught in a previous session. The siblings have prepared questions from Session 2 that they bring into Session 3 and present to their parents, and parents practice responding to these questions by listening, exploring, and validating. At some point during this 1:1 conversation, a group leader enters the room and provides the parent with feedback. Each intervention session had at least two group leaders (one for sibling group and one for parent group) who acted as group leaders, facilitators, and supervisors across the group and 1:1 parts of the intervention. In the complete RCT, there were 28 such group leaders. However, because Session 3 of the intervention was audio recorded rather than video recorded, it is unclear how many individual group leaders were involved in the 1:1 conversations in our sample.\nWe considered Session 3 appropriate for conducting an in-depth analysis of how parents respond to siblings' cues and concerns because it is the first interaction between the siblings and parents after the parents receive communication training in Sessions 1 and 2.\nThe conversation recordings last around 20 min (m = 24 min) and were transcribed verbatim. From the transcriptions, we noted topics mentioned by siblings, then grouped similar topics into overarching themes. We counted the frequency of each theme, and ranked the themes from most to least frequently mentioned, with the aim of identifying topics of interest to siblings. We continued analyzing new dyads until no new themes were identified and thus the data was considered saturated ([\nParent-sibling communication quality was analyzed using the Verona Coding Definition of Emotional Sequences (VR-CoDES) [\nVR-CoDES response category and SIBS target behaviours.\nThe VR-CoDES presents a consensus-based definition of a person's implicit signals or hints (cues) and explicitly expressed emotional distress (concerns) [\nExamples of negative expressions from siblings and parent responses.\nVR-CoDES is intended to be applied to responses that occur directly after a cue or concern is expressed [\nIn this study, coding of parent-child dialogues was carried out by identifying cues, concerns, and repeated cues from participating children, and categorizing parent responses as provide versus reduce space, and as explicit versus non-explicit. Additionally, provide space responses were coded under the subcategories of listening, exploring, or validating responses. Explicit delayed responses from parents and repeated cues were also coded (\nOverview over coding scheme.\nFinally, two members of the research team who were also clinicians noted their clinical observations and impressions from the dyads throughout analysis, in response to concerns that the VRCoDES were missing important aspects of parent-child communication in SIBS [\nSiblings raised the following themes in conversation with their parents (listed most to least frequent):\nIllness: how the sibling got the diagnosis, symptoms and prognosis. Example:\nDifferential treatment. Example:\nHeritability and worries about getting the diagnosis. Example:\nViolence, temper tantrums and acting out of the child with a chronic disorder. Example:\nSibling relationship. Example:\nLonging for more time together as a family. Example:\nNeed for attention, feelings of loneliness. Example:\nImpact on social life. Example:\nSiblings made a total of 177 expressions of negative affect, with cues accounting for 53.1 % (\nA total of 186 parent responses to siblings' cues and concerns were coded. There was a larger proportion of providing space responses (74 %,\nOf provide space responses, 80 % were explicit (n = 109). The most common explicit provide space response type was exploring (67 %,\nNon-explicit provide space responses accounted for 20 % (\nOverall, the proportion of reduced space responses was lower than for provide space responses (26 %,\n\nParent: “Honestly, why do you think she hits when you get close?”\nSibling: “Because she is happy.”\nParent: “Because she is happy? So, it is actually a good thing?”\nSibling: “No!”\nParent: “Yes, it actually is. I think you didn't quite understand what I meant.”\nSibling: “Yes, but not for me.”\nA lower proportion of the reduce space responses were non-explicit (23 %). These types of responses also tended to provide information, advice, and reassurance. For example, a father asked: “What bothers you the most?” The son answered with a concern: “That he hits me.” The father responded: “Mmm, but we are trying to fix that.”\nProvide space responses were further analyzed into listening, exploring and validating, the target behaviours of the SIBS intervention. Exploration, for example asking the child follow-up or clarification questions, was the most frequently used approach (59 %,\nWe are not allowed to watch TV as much as he is, and we are not allowed to watch TV at the dinner table, and we don't always have someone who has time to put us to bed, but he always has someone who puts him to bed, because he's trying… to get all the attention and spend most of his time with you.\nThe mother responded with a warm tone in her voice, saying: “Yes” after a pause.\nThroughout the analyses, we observed a number of instances where the VR-CoDES did not capture important aspects of parent-child communication, including cases of parents practicing the SIBS target behaviours. For example, some parents reduced space, but used a warm tone and asked exploratory questions, which encouraged the sibling to share more. The following conversation between father and daughter illustrates a sibling continuing to share more even though her father used a response that was coded as reduce space according to the VR-CoDES:\nSibling: “But I don't feel like explaining every single time I have visitors.”\nParent: “Do you have visitors that often?”\nSibling: “No, I'm not allowed because [sibling] is home.”\nParent: “What do you think about that?”\nSibling: “That it is very unfair.”\nIn other cases, the VR-CoDES guidelines prevented instances of parental exploring, validating and listening to be missed in the analysis. For example, following VR-CoDES guidelines, the same cue or concern should not be coded twice, and parental responses should not be coded unless they directly follow an expressed cue or concern. In the conversation below, the parent validates the sibling's thoughts, but this was not captured in the analysis because no cue or concern was presented first:\nSibling: I haven't thought much about it.\nParent: No. There is no right or wrong answer here.\nSibling: Only right answers.\nParent: No, yes. There are only right answers, you could say; that's a better way to put it. Good. Good thinking. Only right answers.\nParents also showed listening behaviour that was not captured by the VR-CoDES, prompting with minimal words such as “yes” and “hmm” while siblings were speaking, instead of showing these behaviours after siblings had finished stating a cue or concern. Finally, sometimes the VR-CoDES led to the recording of a parental response as positive (i.e. one of the target SIBS behaviours) but the tone of the conversation was not positive.\nFor example, in one of the dyads, a daughter reacted to her father's exploration via questionning:\nParent: “I'm just asking you questions.”\nSibling: “No, it's like an interview.”\nThe aim of this study was to examine how siblings and parents of children with chronic disorders communicate in an intervention setting. We found that siblings raised a variety of topics with their parents, and that their expressions of negative emotion were split approximately evenly between cues and concerns. Parents mainly responded by providing space; within these responses, exploration was the most common type of SIBS intervention target behaviour, followed by validation and listening.\nThe topics raised by siblings were similar to those found in previous literature. The most frequently occurring topic was the diagnosis, including worries about contagion or heritability of the disorder. This reflects previous findings that siblings often receive limited information about their sibling's condition and are concerned about their own health in relation to the condition ([\nThe participating siblings expressed themselves with a more even ratio of cues and concerns (53 % cues and 47 % concerns) than expected from previous applications of VR-CoDES on child data. For example, [\nWithin their responses to siblings' cues and concerns, we found that parents mainly provided space (74 % of responses), encouraging them to share more about their experiences, situations, and feelings. These results are consistent with findings from Haukeland et al. [\nValidating responses accounted for a third (33 %) of the provide space responses in our analyses, making validation the second most used SIBS target behaviour. This finding differs notably from the Haukeland et al. [\nListening responses accounted for only 8 % of the provide space responses in our analysis, making it the least-used approach. This low rate of listening responses is also inconsistent with Haukeland et al.'s [\nThe current study used quantitative analysis combined with qualitative observations of parent-sibling conversations to examine how siblings express themselves in an intervention setting and how parents respond to these expressions. The intervention setting means that our findings do not necessarily reflect how parents and siblings communicate on a day-to-day basis, as parents had received psychoeducation, practiced communication techniques, and accessed the prepared questions from the siblings in advance of the sessions we analyzed.\nHowever, our findings do offer insight into how parents and siblings communicate during the SIBS intervention—an important step towards creating an effective, evidence-based intervention for siblings of children with chronic disorders. One of our most important findings was that parental validation responses increased since a previous study of the SIBS intervention [\nThe use of VR-CoDES was a key strength of our study, providing a manual-based, quantitative measure of emotional expression and response which allowed for a relatively objective assessment of parent-sibling communication quality and made comparison with results from previous studies possible. However, the VR-CoDES also failed to capture some important aspects of parent-child communication, including active listening behaviours that occurred throughout a child's speech, or parental input that did not follow a cue or concern. Moreover, the VR-CoDES do not cover non-verbal responses and our use of audio recordings did not allow for this to be noted. Parents may have expressed non-verbal validation, attentiveness, or other empathic signals such as supportive facial expressions, hugs, or nodding of their heads that was not captured in our analysis ([\nAn additional limitation is that participant parents were, on average, better educated than the general population. Parents with higher levels of education are known to make less use of negative disciplinary practices, have greater knowledge about child development, and engage in more conversations with their children compared to parents with lower levels of education ([\nSimilarly, our sample included families with a child with a range of chronic disorders including ASD, ADHD, Tourette syndrome, eating disorders, cerebral palsy, epilepsy, and intellectual disabilities, but it is unclear whether our findings would generalize to families with other diagnoses. The presence of somatic illnesses such as cancer, for example, could potentially cause siblings to bring up different themes in conversation, which could in turn provoke different types of responses from parents. Larger study samples representing a wider range of diagnoses could begin to address these questions. Future studies could also explore ways in which the SIBS communication skills could be provided to families in different ways, such as via an online format (see, for example, [\nThe current study contributes valuable qualitative insight to a sibling intervention setting. Most parent-sibling dyads communicated with warmth and care, even when using reducing space responses, which facilitated a space for siblings to share their emotions and experiences even if these aspects of communication were not always captured by the VR-CoDES. These results are promising, as one of the key aims of the SIBS intervention is to improve family communication quality by enhancing parental listening, exploration, and validation. Overall, the findings from this study contribute to the further development of the SIBS intervention and to a broader understanding of parent-child communication in families with a child with a chronic disorder.\nThe SIBS-RCT was approved by The Regional Committee for Medical and Health Research Ethics South East (REK - 2018/2461) ([\nThe Norwegian Research Council, project no. 321027.\nWe have no known conflict of interest to disclose.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "40080884", "pmcid": "12303493", "title": "The effectiveness of cognitive behavioral therapy in patients with motor neuron disease: A systematic review", "publication_year": "N/A", "abstract": "", "full_text": "Motor neuron diseases (MND) represent a heterogeneous group of neurodegenerative disorders characterized by selective degeneration of the upper motor neurons (pyramidal cells in the cerebral cortex) and lower motor neurons (anterior horn cells in the spinal cord and brainstem motor nuclei).\nCognitive-behavioral therapy, a psychotherapeutic approach integrating cognitive and behavioral principles, targets emotional regulation by modifying maladaptive thought patterns and behaviors.\nThis systematic review was conducted following the Cochrane Handbook guidelines\nThe eligibility criteria were randomized controlled trials (RCTs) with individual/cluster allocation and parallel-group designs, including multi-arm trials. Non-RCT studies, conference abstracts, and non-peer reviewed publications were excluded. Selection followed the Population, Intervention, Comparator, Outcome (PICO) framework without restrictions on sample size, study duration, publication date, or language.\nPatients suffering from MND.\nThe intervention group underwent CBT incorporating mindfulness-based interventions, ACT, and multimodal delivery formats (in-person, digital, and self-administered modalities). Patients in the control group received standard care.\nAccording to the criteria established by the authors, the outcome measures focused on evaluating the effectiveness of CBT in patients with MND. These measures primarily encompass the quality of life, psychological flexibility, anxiety and depression symptoms, caregiver burden, and physical health status.\nThe PubMed, Web of Science, Cochrane Library, and Embase databases were searched to identify relevant studies that met the inclusion criteria. Detailed search strategies are provided in Appendix 1, Supplemental Digital Content,\nThe review process is illustrated. PRISMA (Systematic Reviews and Meta-Analyses) flow diagram.\nTwo independent reviewers (H.Y. and T. Y. H.) performed blinded quality assessment using the Cochrane Risk of Bias Tool (version 5.1.0),\nThe systematic search yielded 1452 records, with 5 randomized controlled trials\nLiterature bias risk table.\nFive eligible trials\nBasic characteristics of included studies.\nN/A: unable to obtain.\nRCTs = randomized controlled trials.\nSpecific characteristics of the included study interventions.\n① ALSSQOL-R: ALS-specific quality of life scale; ② ALS-FRS-R: ALS functional rating scale; ③ ZBI: Zarit Caregiver Burden Inventory; ④ MQOL-R: McGill Quality of Life questionnaire; ⑤ HADS: Hospital Anxiety and Depression Scale; ⑥ AAQ-II: Acceptance and Action Questionnaire-II; ⑦ EQ-5D-5L: Five-level, Five-dimension Health Questionnaire; ⑧ EQ-VAS: EuroQoL visual analogue scale; ⑨ STTS-R: Satisfaction with Therapy and Therapists scale; ⑩ SF-36-MCS: Short Form Health Survey; ⑪ ALSAQ-40-EF: The Emotional functioning subscale of the Amyotrophic Lateral Sclerosis Assessment Questionnaire; ⑫ CSI: caregiver stress index.\nACT = acceptance and commitment therapy, MBCT = mindfulness-based cognitive therapy.\nAll 5 studies\nAll 5 trials\nA trial\nThree trials\nFour studies\nThree trials\nThis systematic review demonstrated that CBT demonstrates therapeutic efficacy in enhancing psychological flexibility, quality of life, and affective symptom management, although it demonstrates limited efficacy in mitigating caregiver burden and physical health deterioration. These findings align with the established CBT mechanisms observed in populations with chronic disease,\nThe reviewed CBT variants comprised 3 distinct therapeutic frameworks: MBCT emphasizing present-moment awareness, and nonjudgmental acceptance.\nThis synthesis demonstrates that all 3 CBT modalities, traditional CBT, MBCT, and ACT, are effective in enhancing the quality of life of patients with MND. Comparative analysis revealed that traditional CBT exhibits superior therapeutic performance in ameliorating affective symptoms compared to ACT. Progressive functional deterioration (e.g., dysphagia and respiratory compromise) inherently limits engagement in structured psychotherapeutic protocols, as evidenced by existing pathophysiological studies.\nThe reviewed cognitive behavioral interventions demonstrated modality-specific implementation frameworks and outcomes. Traditional CBT, administered by certified psychologists through structured six-module protocols (diagnosis acceptance, emotional regulation, autonomy maintenance, social support mobilization, future-oriented coping, and activity preservation) delivered in weekly 60-minute sessions, effectively enhanced QoL while mitigating caregiver burden in patients.\nEmpirical evidence establishes psychological flexibility as a critical determinant of life, with meta-analytic data demonstrating robust correlations between adaptive cognitive-emotional regulation capacities and enhanced life satisfaction/mental health outcomes (\nThis systematic review substantiates the therapeutic efficacy of CBT in ameliorating the core clinical manifestations of MND, including deficits in quality of life, psychological rigidity, and affective disturbances, although the longitudinal therapeutic sustainability remains inadequately characterized. Current evidence is constrained by methodological limitations including suboptimal intervention protocols and ill-defined temporal parameters. To address these gaps, future research imperatives include (1) confirmatory randomized controlled trials with standardized CBT dosing regimens, (2) development of precision psychiatry frameworks integrating multimodal therapeutic approaches tailored to disease-stage-specific pathophenotypes, and (3) implementation of AI-driven adaptive algorithms that enable real-time protocol optimization to prevent therapeutic overexposure while maintaining intervention fidelity.\nThis systematic review was subjected to several methodological constraints. First, while implementing a comprehensive search strategy, the exclusion of non-English publications and gray literature from database inception through February 2025 may introduce selection bias. Second, the limited sample size (n = 5 trials) heightened vulnerability to single-study dominance effects, compounded by inherent challenges in conducting longitudinal neuropsychological interventions given the epidemiological characteristics of MND, notably low incidence rates (0.79/100,000), and rapid disease progression that truncates therapeutic windows. Furthermore, CBT’s mechanism of action of CBT typically necessitates longitudinal protocols spanning weeks to months for measurable neurobehavioral modulation, a requirement that is frequently unattainable in MND populations. Finally, inadequate statistical power owing to small cohort sizes and insufficient accounting for phenotypic heterogeneity underscores the need for future large-scale multicenter trials incorporating stratified subgroup analyses.\nEmerging evidence substantiates the therapeutic efficacy of CBT in enhancing psychological flexibility, QoL, and affective symptom management in patients with MND, although it has a limited impact on caregiver burden indices and general health metrics. As a non-pharmacological intervention within an incurable neurodegenerative context, where care prioritizes symptom palliation and QoL optimization, CBT provides a critical modality for addressing psychosocial sequelae by targeting disease-related cognitive distortions. This systematic review highlights CBT’s viability as an adjunctive psychosocial support mechanism; however, methodological limitations, including restricted sample sizes (n = 5 studies), heterogeneous outcome measures, and unstandardized assessment protocols, preclude quantitative synthesis. Research imperatives include large-scale RCTs employing standardized assessment batteries, with particular emphasis on phenotype-stratified analyses (bulbar vs spinal onset variants), and dual-perspective evaluations incorporating patient–caregiver dyad assessments to comprehensively characterize intervention value.", "content_for_embedding": "Motor neuron diseases (MND) represent a heterogeneous group of neurodegenerative disorders characterized by selective degeneration of the upper motor neurons (pyramidal cells in the cerebral cortex) and lower motor neurons (anterior horn cells in the spinal cord and brainstem motor nuclei).\nCognitive-behavioral therapy, a psychotherapeutic approach integrating cognitive and behavioral principles, targets emotional regulation by modifying maladaptive thought patterns and behaviors.\nThis systematic review was conducted following the Cochrane Handbook guidelines\nThe eligibility criteria were randomized controlled trials (RCTs) with individual/cluster allocation and parallel-group designs, including multi-arm trials. Non-RCT studies, conference abstracts, and non-peer reviewed publications were excluded. Selection followed the Population, Intervention, Comparator, Outcome (PICO) framework without restrictions on sample size, study duration, publication date, or language.\nPatients suffering from MND.\nThe intervention group underwent CBT incorporating mindfulness-based interventions, ACT, and multimodal delivery formats (in-person, digital, and self-administered modalities). Patients in the control group received standard care.\nAccording to the criteria established by the authors, the outcome measures focused on evaluating the effectiveness of CBT in patients with MND. These measures primarily encompass the quality of life, psychological flexibility, anxiety and depression symptoms, caregiver burden, and physical health status.\nThe PubMed, Web of Science, Cochrane Library, and Embase databases were searched to identify relevant studies that met the inclusion criteria. Detailed search strategies are provided in Appendix 1, Supplemental Digital Content,\nThe review process is illustrated. PRISMA (Systematic Reviews and Meta-Analyses) flow diagram.\nTwo independent reviewers (H.Y. and T. Y. H.) performed blinded quality assessment using the Cochrane Risk of Bias Tool (version 5.1.0),\nThe systematic search yielded 1452 records, with 5 randomized controlled trials\nLiterature bias risk table.\nFive eligible trials\nBasic characteristics of included studies.\nN/A: unable to obtain.\nRCTs = randomized controlled trials.\nSpecific characteristics of the included study interventions.\n① ALSSQOL-R: ALS-specific quality of life scale; ② ALS-FRS-R: ALS functional rating scale; ③ ZBI: Zarit Caregiver Burden Inventory; ④ MQOL-R: McGill Quality of Life questionnaire; ⑤ HADS: Hospital Anxiety and Depression Scale; ⑥ AAQ-II: Acceptance and Action Questionnaire-II; ⑦ EQ-5D-5L: Five-level, Five-dimension Health Questionnaire; ⑧ EQ-VAS: EuroQoL visual analogue scale; ⑨ STTS-R: Satisfaction with Therapy and Therapists scale; ⑩ SF-36-MCS: Short Form Health Survey; ⑪ ALSAQ-40-EF: The Emotional functioning subscale of the Amyotrophic Lateral Sclerosis Assessment Questionnaire; ⑫ CSI: caregiver stress index.\nACT = acceptance and commitment therapy, MBCT = mindfulness-based cognitive therapy.\nAll 5 studies\nAll 5 trials\nA trial\nThree trials\nFour studies\nThree trials\nThis systematic review demonstrated that CBT demonstrates therapeutic efficacy in enhancing psychological flexibility, quality of life, and affective symptom management, although it demonstrates limited efficacy in mitigating caregiver burden and physical health deterioration. These findings align with the established CBT mechanisms observed in populations with chronic disease,\nThe reviewed CBT variants comprised 3 distinct therapeutic frameworks: MBCT emphasizing present-moment awareness, and nonjudgmental acceptance.\nThis synthesis demonstrates that all 3 CBT modalities, traditional CBT, MBCT, and ACT, are effective in enhancing the quality of life of patients with MND. Comparative analysis revealed that traditional CBT exhibits superior therapeutic performance in ameliorating affective symptoms compared to ACT. Progressive functional deterioration (e.g., dysphagia and respiratory compromise) inherently limits engagement in structured psychotherapeutic protocols, as evidenced by existing pathophysiological studies.\nThe reviewed cognitive behavioral interventions demonstrated modality-specific implementation frameworks and outcomes. Traditional CBT, administered by certified psychologists through structured six-module protocols (diagnosis acceptance, emotional regulation, autonomy maintenance, social support mobilization, future-oriented coping, and activity preservation) delivered in weekly 60-minute sessions, effectively enhanced QoL while mitigating caregiver burden in patients.\nEmpirical evidence establishes psychological flexibility as a critical determinant of life, with meta-analytic data demonstrating robust correlations between adaptive cognitive-emotional regulation capacities and enhanced life satisfaction/mental health outcomes (\nThis systematic review substantiates the therapeutic efficacy of CBT in ameliorating the core clinical manifestations of MND, including deficits in quality of life, psychological rigidity, and affective disturbances, although the longitudinal therapeutic sustainability remains inadequately characterized. Current evidence is constrained by methodological limitations including suboptimal intervention protocols and ill-defined temporal parameters. To address these gaps, future research imperatives include (1) confirmatory randomized controlled trials with standardized CBT dosing regimens, (2) development of precision psychiatry frameworks integrating multimodal therapeutic approaches tailored to disease-stage-specific pathophenotypes, and (3) implementation of AI-driven adaptive algorithms that enable real-time protocol optimization to prevent therapeutic overexposure while maintaining intervention fidelity.\nThis systematic review was subjected to several methodological constraints. First, while implementing a comprehensive search strategy, the exclusion of non-English publications and gray literature from database inception through February 2025 may introduce selection bias. Second, the limited sample size (n = 5 trials) heightened vulnerability to single-study dominance effects, compounded by inherent challenges in conducting longitudinal neuropsychological interventions given the epidemiological characteristics of MND, notably low incidence rates (0.79/100,000), and rapid disease progression that truncates therapeutic windows. Furthermore, CBT’s mechanism of action of CBT typically necessitates longitudinal protocols spanning weeks to months for measurable neurobehavioral modulation, a requirement that is frequently unattainable in MND populations. Finally, inadequate statistical power owing to small cohort sizes and insufficient accounting for phenotypic heterogeneity underscores the need for future large-scale multicenter trials incorporating stratified subgroup analyses.\nEmerging evidence substantiates the therapeutic efficacy of CBT in enhancing psychological flexibility, QoL, and affective symptom management in patients with MND, although it has a limited impact on caregiver burden indices and general health metrics. As a non-pharmacological intervention within an incurable neurodegenerative context, where care prioritizes symptom palliation and QoL optimization, CBT provides a critical modality for addressing psychosocial sequelae by targeting disease-related cognitive distortions. This systematic review highlights CBT’s viability as an adjunctive psychosocial support mechanism; however, methodological limitations, including restricted sample sizes (n = 5 studies), heterogeneous outcome measures, and unstandardized assessment protocols, preclude quantitative synthesis. Research imperatives include large-scale RCTs employing standardized assessment batteries, with particular emphasis on phenotype-stratified analyses (bulbar vs spinal onset variants), and dual-perspective evaluations incorporating patient–caregiver dyad assessments to comprehensively characterize intervention value.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "40034618", "pmcid": "12299740", "title": "Combined Cataract and Vitrectomy Surgery in Pediatric Patients", "publication_year": "N/A", "abstract": "", "full_text": "The use of combined cataract surgery (or lensectomy) and vitrectomy in pediatric patients is not well-documented in the current medical literature. Although numerous studies have evaluated pars plana vitrectomy (PPV) techniques and outcomes in children, few have specifically addressed the combined approach of cataract extraction or lensectomy with vitrectomy in this population.\nCataract surgery has advanced considerably over the past few decades, particularly with the widespread adoption of phacoemulsification in adult patients. However, pediatric cataract surgery poses unique anatomical and physiological challenges that require different surgical strategies [\nIn complex pediatric ocular conditions, combining cataract extraction or lensectomy (either with or without intraocular lens (IOL) implantation) with vitrectomy is commonly employed, as it may offer significant clinical advantages (\nSeveral pediatric conditions may necessitate this combined surgical approach, particularly in advanced stages [\nThis review aims to summarize the existing literature on the use of combined cataract surgery (or lensectomy) and vitrectomy in pediatric patients, highlighting its indications, advantages, limitations, and clinical outcomes across various pediatric ocular pathologies.\nA literature search was performed using the PubMed (\nProspective and retrospective clinical studies, case series, and relevant review articles were considered. Inclusion criteria were studies published in English that addressed combined lensectomy and vitrectomy (combined LV) techniques in pediatric patients for the management of pediatric cataracts, ectopia lentis, ROP, RD, and PFV. Exclusion criteria included studies focused solely on adult patients, animal models, or those not evaluating lensectomy and vitrectomy procedures.\nDue to the heterogeneity of study designs, surgical techniques, and outcome measures across the included literature, a systematic review or meta-analysis was not feasible. Instead, findings were qualitatively summarized to identify trends in surgical decision-making, procedural approaches, and clinical outcomes. Comparative tables were constructed to summarize surgical indications for combined LV, IOL strategies, outcomes, and associated complications.\nThe initial literature search yielded a total of 160 articles. After screening titles and abstracts and applying the inclusion and exclusion criteria, 43 articles were deemed relevant and included in this narrative review. Among these, there were 23 retrospective studies, 10 narrative reviews, 4 prospective studies, 3 case reports, 2 systematic reviews, and 1 case series. No randomized controlled trials were identified.\nMost studies focused on surgical techniques, visual and anatomical outcomes, and postoperative complications. The majority of clinical studies were conducted at single institutions, with varying sample sizes and follow-up durations.\nPediatric cataracts remain a leading cause of treatable visual impairment in children worldwide [\nThe importance of technique selection and age-specific surgical planning is highlighted in a retrospective study by Li et al. (2023), which evaluated long-term visual outcomes and complications following lensectomy with anterior vitrectomy and primary IOL implantation in children with bilateral congenital cataracts [\nVAO is the preferred term over posterior capsule opacification (PCO) in pediatric patients, as visual obscuration can occur despite the creation of a primary posterior capsulorhexis [\nAnterior vitrectomy in pediatric cataract surgery plays a pivotal role in reducing postoperative complications, particularly VAO [\nPostoperative glaucoma is another major complication following cataract surgery in infancy and remains a leading cause of long-term vision loss in this population [\nSurgical decision-making in pediatric cataract cases should consider patient age, lens density, and the presence of posterior segment pathology [\nEctopia lentis in pediatric patients can result from trauma or may occur secondary to systemic conditions such as Marfan syndrome and other connective tissue disorders [\nSSFIOLs have been proposed as an effective means of correcting aphakia in pediatric patients lacking adequate capsular support [\nIris-sutures intraocular lenses are another viable surgical option to ensure adequate lens position [\nIn ectopia lentis, the choice of combined LV is primarily driven by the extent of lens instability, degree of capsular support, and age-appropriate IOL considerations [\nROP remains a leading cause of childhood blindness worldwide, especially in low-birthweight and preterm infants [\nSurgical management in advanced cases typically involves vitrectomy or combined LV [\nSen et al. (2023) compared LSV and combined LV in a cohort of Stage 4 and 5 ROP eyes, demonstrating that LSV resulted in better visual outcomes and fewer postoperative complications [\nIn particularly severe cases, such as Stage 5C ROP (total retinal detachment along with anterior segment anomalies) with corneal opacification, a staged lensectomy and vitrectomy approach has been proposed [\nModified surgical techniques have also evolved to minimize complications and improve access. Chandra et al. (2019) described a hybrid clear corneal micro-incision lensectomy and vitrectomy approach using 25G instruments in 50 eyes with Stage 5 ROP [\nDespite surgical advances, long-term complications such as glaucoma remain a concern [\nAnatomic reattachment does not always correlate with functional vision [\nCollectively, the literature emphasizes that the surgical approach should be individualized based on disease stage, anterior segment clarity, and extent of fibrovascular proliferation [\nRhegmatogenous retinal detachment (RRD) is a major vision-threatening condition [\nSurgical repair of RRD using PPV has an anatomic success rate of approximately 80% [\nLSV is preferred in pediatric patients, especially for cases involving TRD or opaque media [\nDespite the advantages of LSV, complex retinal detachment cases in children may require combined LV [\nIn pediatric RD, LSV is favored when visualization is adequate [\nPFV, previously called persistent hyperplastic primary vitreous (PHPV), is a rare but significant developmental anomaly arising from the failure of regression of the hyaloid vasculature, often leading to a spectrum of anterior and posterior ocular pathologies, including cataract, retrolental fibrovascular membranes, and RD [\nSeveral studies have evaluated the safety and efficacy of combined LV for PFV, highlighting both the technical challenges and the potential for functional rehabilitation [\nSimilarly, Khurana et al. (2021) reported favorable outcomes in a prospective cohort of 20 children undergoing phacoaspiration with or without IOL implantation, combined with dissection and cauterization of the PFV stalk [\nEven though anatomic restoration is vital, it does not always lead to visual improvement [\nAge and lens status are pivotal in surgical decision-making [\nSurgical approach also influences outcomes. In a 20-year retrospective study, Bata et al. (2019) found that a limbal approach resulted in better visual acuity and lower complication rates compared to the pars plana approach [\nInnovative surgical tools, such as endoscopic-assisted vitrectomy, are expanding the therapeutic armamentarium [\nAlthough visual prognosis in PFV is variable and often guarded, especially in eyes with posterior involvement or structural anomalies, surgical intervention can still yield meaningful functional and anatomical benefits in select cases [\nCombined LV is frequently used in the surgical management of PFV, especially in cases involving both anterior and posterior segments, or when significant lens opacity or retrolental traction is present [\nA comparative overview of the clinical indications, anatomical and visual outcomes, and complications of combined LV across common pediatric pathologies is provided in\nGiven the variety of IOL implantation techniques available for pediatric patients undergoing combined LV surgery,\nLimitations of this review include the low frequency and clinical complexity of the ocular conditions discussed, which limit the availability of robust data on this topic. Most of the included studies are retrospective and show variability in patient populations, surgical techniques, outcome measures, and follow-up durations. Additionally, many are single-center studies with small sample sizes, which may affect the generalizability of findings. Despite these limitations, this review provides a structured summary of the current literature on combined LV in pediatric patients, organized by clinical indication. It offers practical insight into when and why combined LV may be appropriate in children and highlights areas where future research is needed.\nThis review underscores the importance of a tailored, case-by-case surgical approach when managing pediatric patients requiring cataract extraction, lensectomy, and/or vitrectomy. While LSV is often preferred to preserve accommodation, combined LV procedures are frequently necessary in the presence of complex anterior-posterior segment pathology.\nOutcomes following combined LV in children remain highly variable and are influenced by multiple factors, including patient age, underlying ocular anatomy, disease severity, and surgical technique. Although anatomic success is commonly achievable, functional visual outcomes are often limited. Moreover, combined LV is associated with a higher risk of postoperative complications such as glaucoma, VAO, and IOL dislocation, underscoring the need for long-term follow-up and comprehensive visual rehabilitation strategies.\nFuture studies and harmonized multicenter registries are essential to refine surgical indications and improve outcomes in this complex pediatric population. Although randomized clinical trials provide the highest level of evidence, their design and implementation in this context are challenging due to the rarity of combined LV procedures in children, the heterogeneity of underlying conditions, and the need for long-term follow-up to assess visual outcomes. However, we believe that outcome variability can be partially addressed through collaborative, prospective data collection. Rather than advocating for a universal protocol, future efforts should focus on establishing clinical principles based on shared outcome predictors such as patient age, ocular anatomy, and surgical indication. We propose the implementation of retrospective analyses using large databases such as the IRIS Registry or the Vestrum Health database. These resources could enable meaningful evaluations of surgical outcomes and complications in pediatric patients, supporting more consistent and informed decision-making while preserving individualized patient care.", "content_for_embedding": "The use of combined cataract surgery (or lensectomy) and vitrectomy in pediatric patients is not well-documented in the current medical literature. Although numerous studies have evaluated pars plana vitrectomy (PPV) techniques and outcomes in children, few have specifically addressed the combined approach of cataract extraction or lensectomy with vitrectomy in this population.\nCataract surgery has advanced considerably over the past few decades, particularly with the widespread adoption of phacoemulsification in adult patients. However, pediatric cataract surgery poses unique anatomical and physiological challenges that require different surgical strategies [\nIn complex pediatric ocular conditions, combining cataract extraction or lensectomy (either with or without intraocular lens (IOL) implantation) with vitrectomy is commonly employed, as it may offer significant clinical advantages (\nSeveral pediatric conditions may necessitate this combined surgical approach, particularly in advanced stages [\nThis review aims to summarize the existing literature on the use of combined cataract surgery (or lensectomy) and vitrectomy in pediatric patients, highlighting its indications, advantages, limitations, and clinical outcomes across various pediatric ocular pathologies.\nA literature search was performed using the PubMed (\nProspective and retrospective clinical studies, case series, and relevant review articles were considered. Inclusion criteria were studies published in English that addressed combined lensectomy and vitrectomy (combined LV) techniques in pediatric patients for the management of pediatric cataracts, ectopia lentis, ROP, RD, and PFV. Exclusion criteria included studies focused solely on adult patients, animal models, or those not evaluating lensectomy and vitrectomy procedures.\nDue to the heterogeneity of study designs, surgical techniques, and outcome measures across the included literature, a systematic review or meta-analysis was not feasible. Instead, findings were qualitatively summarized to identify trends in surgical decision-making, procedural approaches, and clinical outcomes. Comparative tables were constructed to summarize surgical indications for combined LV, IOL strategies, outcomes, and associated complications.\nThe initial literature search yielded a total of 160 articles. After screening titles and abstracts and applying the inclusion and exclusion criteria, 43 articles were deemed relevant and included in this narrative review. Among these, there were 23 retrospective studies, 10 narrative reviews, 4 prospective studies, 3 case reports, 2 systematic reviews, and 1 case series. No randomized controlled trials were identified.\nMost studies focused on surgical techniques, visual and anatomical outcomes, and postoperative complications. The majority of clinical studies were conducted at single institutions, with varying sample sizes and follow-up durations.\nPediatric cataracts remain a leading cause of treatable visual impairment in children worldwide [\nThe importance of technique selection and age-specific surgical planning is highlighted in a retrospective study by Li et al. (2023), which evaluated long-term visual outcomes and complications following lensectomy with anterior vitrectomy and primary IOL implantation in children with bilateral congenital cataracts [\nVAO is the preferred term over posterior capsule opacification (PCO) in pediatric patients, as visual obscuration can occur despite the creation of a primary posterior capsulorhexis [\nAnterior vitrectomy in pediatric cataract surgery plays a pivotal role in reducing postoperative complications, particularly VAO [\nPostoperative glaucoma is another major complication following cataract surgery in infancy and remains a leading cause of long-term vision loss in this population [\nSurgical decision-making in pediatric cataract cases should consider patient age, lens density, and the presence of posterior segment pathology [\nEctopia lentis in pediatric patients can result from trauma or may occur secondary to systemic conditions such as Marfan syndrome and other connective tissue disorders [\nSSFIOLs have been proposed as an effective means of correcting aphakia in pediatric patients lacking adequate capsular support [\nIris-sutures intraocular lenses are another viable surgical option to ensure adequate lens position [\nIn ectopia lentis, the choice of combined LV is primarily driven by the extent of lens instability, degree of capsular support, and age-appropriate IOL considerations [\nROP remains a leading cause of childhood blindness worldwide, especially in low-birthweight and preterm infants [\nSurgical management in advanced cases typically involves vitrectomy or combined LV [\nSen et al. (2023) compared LSV and combined LV in a cohort of Stage 4 and 5 ROP eyes, demonstrating that LSV resulted in better visual outcomes and fewer postoperative complications [\nIn particularly severe cases, such as Stage 5C ROP (total retinal detachment along with anterior segment anomalies) with corneal opacification, a staged lensectomy and vitrectomy approach has been proposed [\nModified surgical techniques have also evolved to minimize complications and improve access. Chandra et al. (2019) described a hybrid clear corneal micro-incision lensectomy and vitrectomy approach using 25G instruments in 50 eyes with Stage 5 ROP [\nDespite surgical advances, long-term complications such as glaucoma remain a concern [\nAnatomic reattachment does not always correlate with functional vision [\nCollectively, the literature emphasizes that the surgical approach should be individualized based on disease stage, anterior segment clarity, and extent of fibrovascular proliferation [\nRhegmatogenous retinal detachment (RRD) is a major vision-threatening condition [\nSurgical repair of RRD using PPV has an anatomic success rate of approximately 80% [\nLSV is preferred in pediatric patients, especially for cases involving TRD or opaque media [\nDespite the advantages of LSV, complex retinal detachment cases in children may require combined LV [\nIn pediatric RD, LSV is favored when visualization is adequate [\nPFV, previously called persistent hyperplastic primary vitreous (PHPV), is a rare but significant developmental anomaly arising from the failure of regression of the hyaloid vasculature, often leading to a spectrum of anterior and posterior ocular pathologies, including cataract, retrolental fibrovascular membranes, and RD [\nSeveral studies have evaluated the safety and efficacy of combined LV for PFV, highlighting both the technical challenges and the potential for functional rehabilitation [\nSimilarly, Khurana et al. (2021) reported favorable outcomes in a prospective cohort of 20 children undergoing phacoaspiration with or without IOL implantation, combined with dissection and cauterization of the PFV stalk [\nEven though anatomic restoration is vital, it does not always lead to visual improvement [\nAge and lens status are pivotal in surgical decision-making [\nSurgical approach also influences outcomes. In a 20-year retrospective study, Bata et al. (2019) found that a limbal approach resulted in better visual acuity and lower complication rates compared to the pars plana approach [\nInnovative surgical tools, such as endoscopic-assisted vitrectomy, are expanding the therapeutic armamentarium [\nAlthough visual prognosis in PFV is variable and often guarded, especially in eyes with posterior involvement or structural anomalies, surgical intervention can still yield meaningful functional and anatomical benefits in select cases [\nCombined LV is frequently used in the surgical management of PFV, especially in cases involving both anterior and posterior segments, or when significant lens opacity or retrolental traction is present [\nA comparative overview of the clinical indications, anatomical and visual outcomes, and complications of combined LV across common pediatric pathologies is provided in\nGiven the variety of IOL implantation techniques available for pediatric patients undergoing combined LV surgery,\nLimitations of this review include the low frequency and clinical complexity of the ocular conditions discussed, which limit the availability of robust data on this topic. Most of the included studies are retrospective and show variability in patient populations, surgical techniques, outcome measures, and follow-up durations. Additionally, many are single-center studies with small sample sizes, which may affect the generalizability of findings. Despite these limitations, this review provides a structured summary of the current literature on combined LV in pediatric patients, organized by clinical indication. It offers practical insight into when and why combined LV may be appropriate in children and highlights areas where future research is needed.\nThis review underscores the importance of a tailored, case-by-case surgical approach when managing pediatric patients requiring cataract extraction, lensectomy, and/or vitrectomy. While LSV is often preferred to preserve accommodation, combined LV procedures are frequently necessary in the presence of complex anterior-posterior segment pathology.\nOutcomes following combined LV in children remain highly variable and are influenced by multiple factors, including patient age, underlying ocular anatomy, disease severity, and surgical technique. Although anatomic success is commonly achievable, functional visual outcomes are often limited. Moreover, combined LV is associated with a higher risk of postoperative complications such as glaucoma, VAO, and IOL dislocation, underscoring the need for long-term follow-up and comprehensive visual rehabilitation strategies.\nFuture studies and harmonized multicenter registries are essential to refine surgical indications and improve outcomes in this complex pediatric population. Although randomized clinical trials provide the highest level of evidence, their design and implementation in this context are challenging due to the rarity of combined LV procedures in children, the heterogeneity of underlying conditions, and the need for long-term follow-up to assess visual outcomes. However, we believe that outcome variability can be partially addressed through collaborative, prospective data collection. Rather than advocating for a universal protocol, future efforts should focus on establishing clinical principles based on shared outcome predictors such as patient age, ocular anatomy, and surgical indication. We propose the implementation of retrospective analyses using large databases such as the IRIS Registry or the Vestrum Health database. These resources could enable meaningful evaluations of surgical outcomes and complications in pediatric patients, supporting more consistent and informed decision-making while preserving individualized patient care.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "39898095", "pmcid": "12309892", "title": "Long-term, age-associated activity quantification in the DE50-MD dog model of Duchenne muscular dystrophy", "publication_year": "N/A", "abstract": "Animal models with a clinically relevant phenotype remain important for robust evaluation of novel therapeutics for the fatal X-linked genetic disorder Duchenne muscular dystrophy (DMD). Demonstration of functional improvement is crucial for both patients and regulatory authorities. Here, we investigate non-invasive methods to quantify activity changes in DE50-MD dogs. Using collar-based Axivity-AX3 tri-axial accelerometers, we measured activity in affected DE50-MD male dogs (3-8 per age point) and littermate wild-type (WT) male controls (3-13 per age point) at monthly intervals from 3 to 18 months of age. Acceleration vector magnitudes were used to derive a series of activity measures over 24 h. Mixed model analyses were used to examine differences between affected and WT groups at different ages. Activity indicators for DE50-MD dogs were significantly higher for percent time spent at rest (", "full_text": "The X-linked disorder, Duchenne muscular dystrophy (DMD), affects approximately 1 in 3500-6000 live male births worldwide (\nThere are various animal models of DMD, including the mdx mouse (\nFunctional assessments are crucial for monitoring disease progression in patients with DMD and for monitoring treatment trials. They provide important information on the effects of musculoskeletal changes on overall mobility as well as assessing quality of life, both of which are critical for patients and their families; they are also important for regulatory bodies. There are several commonly used functional outcome measures in DMD-affected boys including the 6-min walk test (6 MWT) (\nPhysical activity declines in boys with DMD as their disease progresses (\nAn increasingly popular method of quantifying movement patterns in humans is the use of wearable, tri-axial accelerometers (\nThe use of wearable sensors for tracking changes in longer-term activity (over days to weeks) in boys with DMD has increased (\nThere was no significant difference in activity intensity between the 1st and 2nd 24-h periods across all ages for DE50-MD (\nActivity metrics are summarised in\nWhile the number of low-intensity active bouts decreased in both groups with age, the mean duration of low-intensity active bouts increased in WT controls with age but decreased in DE50-MD dogs (interaction\nThe percent time spent at rest (\nThe threshold above which the most-active (x) minutes of a dog accumulated over a 24-h period, i.e.\nPrincipal component analysis (PCA) revealed two principal components (PC1 and PC2) of interest with respective eigenvalues of 10.53 and 2.02 that cumulatively explained 89.67% of the total variance (75.21% and 14.46%, respectively) (\nWe aimed to determine which of the metrics examined in this study would be most applicable to assessment of activity patterns in pre-clinical trials. We calculated prospective required sample sizes (\nSample size calculations for all statistically significant metrics at selected ages\nCalculations (power 0.8, alpha 0.05) completed for all activity metrics that showed statistically significant differences between groups by effect size. Numbers represent the number of animals required per genotype to detect the desired treatment effect at this statistical power in future trials using each metric. Notice that the total bout count of high-intensity activity and M30\nTo our knowledge, this is the first study investigating long-term changes in activity patterns by using accelerometry to assess physical activity in a dog model of DMD. Previous functional measures have included gait kinematics (\nThe ability to distinguish between intensity levels of activity when quantifying treatment effects is likely to provide insight into how improvements in function affect quality of life. For example, an increase in percent time spent at lower intensity activity only and no change in higher intensity activity could be a valuable outcome, as well as providing a more granular understanding of how the mechanism of action of a certain drug is reflected in functional outcomes. Our overall goal was to determine the most useful quantitative metrics to distinguish between activity patterns of the DE50-MD and WT control animals for future preclinical trials of therapeutics. These data reveal the prominent activity differences between DE50-MD and WT dogs across all ages studied. Time spent resting and metrics quantifying higher intensity activity appear to be key factors. Importantly, we predict these metrics will be helpful as objective functional outcome measures, using low animal numbers, in future treatment trials (see\nMeasures of activity intensity (in ms\nThe proportion of time spent at rest quantifies time spent under the pre-determined ‘active/inactive’ threshold for acceleration (<0.154\nReductions were observed in all metrics across both high and low intensities; however, the most prominent differences were seen at higher intensity levels, particularly the proportion of time spent at high-intensity activity and the total number of high-intensity bouts of activity over a 24-h period. These metrics decreased over time, particularly in the DE50-MD group, following the pattern of expected disease progression in human patients, where individuals undergo progressive paresis with stiffer muscles (\nIn addition to more-traditional acceleration threshold metrics derived to be specific to a certain experimental population, we assessed the time-based threshold metrics M2\nSample size assessments were performed to help determine the most useful activity biomarkers to take forward to pre-clinical trials in the DE50-MD dog model. The number of high-intensity active bouts over a 24-h period and the M30\nThis study was carried out with dogs that had remained undisturbed in their habituated housing. This provides a longer-term assessment of the capacity of the animals for movement, in contrast to related studies involving shorter duration (\nIn summary, quantitative, objective assessment of the activity patterns of DE50-MD dogs and WT controls have been provided, demonstrating the ability to distinguish between these groups across a wide age range. We report a set of activity metrics derived from tri-axial accelerometer data which can contribute towards characterising the functional performance of the DE50-MD model for DMD as well as discriminating between genotypes. These results support the hypothesis that these activity metrics, collected via long-term activity monitoring, can successfully discriminate between genotypes and will be useful in assessing treatment outcomes in future pre-clinical trials. The fact that these assessments are easily obtained, are non-invasive and independent of bias has distinct practical, welfare and scientific advantages. Similar approaches might be applicable in other canine models of DMD and, indeed, more generally, in other animal disease models associated with locomotor or neuromuscular dysfunction.\nCarrier DE50-MD female dogs were mated naturally with wild-type (WT) beagle males (RCC strain). Adult dogs were housed (12-h light/dark cycle; 15-24°C) in large kennels within groups, until pregnant females were close to whelping, upon which they were housed in single kennels. Puppies were weaned at age 10-12 weeks, then grouped in their litters until aged ∼4-5 months. Adults were housed in groups of two to four animals, according to social hierarchy. Kennel size ranged between 6.2 and 6.6 m\nData were collected using Axivity AX3 activity monitors (Axivity, UK) that had previously been validated for use in dogs (\nWeekday monitoring was for 48 h continuously (weekdays 12pm–12pm) at a sample frequency of 200-400 Hz starting at 12pm. When sample frequencies >200 Hz were used, data were computationally resampled to 200 Hz to ensure homogeneity. Dogs remained in their kennels (with their kennel mates) during the test period and were subject to their ‘normal’ daily routine (feeding, cleaning, etc.). To best characterise each time point, the 48-h time interval, beginning at 12pm on the first day of monitoring, was split into 2×24-h periods, enabling aggregate metrics to be calculated per 24 h. The mean of these metrics across the two, 24-h periods was calculated and used in subsequent analyses. Variability between the two 24-h periods was assessed and is described in further detail below. In some cases (15/214 recordings), it was not possible to capture 48 h of continuous activity due to sensor destruction (chewing) or malfunction. In these cases, aggregate metrics were calculated for the first 24-h period.\nAll signal processing was performed using MATLAB R2020b. A 6th order Butterworth band-pass filter was used in both directions to obtain zero phase lag. Cut-off frequencies of 0.28 Hz and 32.76 Hz were used, based on pilot observations (\nThis metric characterises overall, whole-body acceleration over 24 h and is calculated by computing the integral of the 24-h vector magnitude curve minus gravity. As this calculation takes place after band-pass filtering, the signal due to gravity has already been removed by the high pass component of the filter. Daily activity intensity is the velocity quantity (in ms\nMetrics M2\nThe metric ‘percent time spent at rest’ quantifies the proportion of time spent at rest over a fixed period derived from our previously labelled accelerometer and video data and Receiver Operating Characteristic (ROC) analyses (\nThis metric quantifies the proportion of time spent at a higher intensity activity level, defined as the threshold that best discriminates between DE50-MD and WT control dogs. This threshold was derived by computing the percentage of time spent above an acceleration threshold, in a similar way as described in (\nThis metric quantifies the proportion of time spent at a lower intensity activity, which was defined as being between the two thresholds described above (above 0.154\nStatistical analyses were conducted with SPSS Statistics (IBM SPSS Statistics 25) and GraphPad Prism 9 (GraphPad Software Inc. 1994-2021). To assess the validity of averaging the activity metrics across the two 24-h periods of data, we compared daily activity intensity data from the first 24-h period with the second 24-h period for all dogs at all time points. Comparison across the first and second 24-h period was performed using paired two-tailed\nA principal component analysis (PCA) was performed (GraphPad Prism 9) to summarise variation in activity metrics among the DE50-MD and WT controls across all ages. This allowed us to explore which activity metrics varied most across all dogs and assess whether these patterns differed between groups. The first component (PC1), which captured the largest proportion of variance, was then examined statistically using a linear mixed-effects model (LMM), assessing the effect of age, genotype and their interaction, followed by Fisher's least significant difference post-hoc comparisons. Individual dog was included as a random effect to account for repeated measures. Individual activity metrics were assessed using the same LMM analysis as described above (SPSS Statistics).\nSample sizes were calculated to assess the metrics that would be most appropriate for assessing treatment outcomes in possible future pre-clinical treatment trials (power 0.8, alpha 0.05). Effect sizes of 20%, 25%, 50%, 75% and 100% were investigated (i.e. the degree to which any therapy could induce a change from the value of DE50-MD towards that of WT animals). Sample size calculations were completed using GLIMMPSE v1 (", "content_for_embedding": "The X-linked disorder, Duchenne muscular dystrophy (DMD), affects approximately 1 in 3500-6000 live male births worldwide (\nThere are various animal models of DMD, including the mdx mouse (\nFunctional assessments are crucial for monitoring disease progression in patients with DMD and for monitoring treatment trials. They provide important information on the effects of musculoskeletal changes on overall mobility as well as assessing quality of life, both of which are critical for patients and their families; they are also important for regulatory bodies. There are several commonly used functional outcome measures in DMD-affected boys including the 6-min walk test (6 MWT) (\nPhysical activity declines in boys with DMD as their disease progresses (\nAn increasingly popular method of quantifying movement patterns in humans is the use of wearable, tri-axial accelerometers (\nThe use of wearable sensors for tracking changes in longer-term activity (over days to weeks) in boys with DMD has increased (\nThere was no significant difference in activity intensity between the 1st and 2nd 24-h periods across all ages for DE50-MD (\nActivity metrics are summarised in\nWhile the number of low-intensity active bouts decreased in both groups with age, the mean duration of low-intensity active bouts increased in WT controls with age but decreased in DE50-MD dogs (interaction\nThe percent time spent at rest (\nThe threshold above which the most-active (x) minutes of a dog accumulated over a 24-h period, i.e.\nPrincipal component analysis (PCA) revealed two principal components (PC1 and PC2) of interest with respective eigenvalues of 10.53 and 2.02 that cumulatively explained 89.67% of the total variance (75.21% and 14.46%, respectively) (\nWe aimed to determine which of the metrics examined in this study would be most applicable to assessment of activity patterns in pre-clinical trials. We calculated prospective required sample sizes (\nSample size calculations for all statistically significant metrics at selected ages\nCalculations (power 0.8, alpha 0.05) completed for all activity metrics that showed statistically significant differences between groups by effect size. Numbers represent the number of animals required per genotype to detect the desired treatment effect at this statistical power in future trials using each metric. Notice that the total bout count of high-intensity activity and M30\nTo our knowledge, this is the first study investigating long-term changes in activity patterns by using accelerometry to assess physical activity in a dog model of DMD. Previous functional measures have included gait kinematics (\nThe ability to distinguish between intensity levels of activity when quantifying treatment effects is likely to provide insight into how improvements in function affect quality of life. For example, an increase in percent time spent at lower intensity activity only and no change in higher intensity activity could be a valuable outcome, as well as providing a more granular understanding of how the mechanism of action of a certain drug is reflected in functional outcomes. Our overall goal was to determine the most useful quantitative metrics to distinguish between activity patterns of the DE50-MD and WT control animals for future preclinical trials of therapeutics. These data reveal the prominent activity differences between DE50-MD and WT dogs across all ages studied. Time spent resting and metrics quantifying higher intensity activity appear to be key factors. Importantly, we predict these metrics will be helpful as objective functional outcome measures, using low animal numbers, in future treatment trials (see\nMeasures of activity intensity (in ms\nThe proportion of time spent at rest quantifies time spent under the pre-determined ‘active/inactive’ threshold for acceleration (<0.154\nReductions were observed in all metrics across both high and low intensities; however, the most prominent differences were seen at higher intensity levels, particularly the proportion of time spent at high-intensity activity and the total number of high-intensity bouts of activity over a 24-h period. These metrics decreased over time, particularly in the DE50-MD group, following the pattern of expected disease progression in human patients, where individuals undergo progressive paresis with stiffer muscles (\nIn addition to more-traditional acceleration threshold metrics derived to be specific to a certain experimental population, we assessed the time-based threshold metrics M2\nSample size assessments were performed to help determine the most useful activity biomarkers to take forward to pre-clinical trials in the DE50-MD dog model. The number of high-intensity active bouts over a 24-h period and the M30\nThis study was carried out with dogs that had remained undisturbed in their habituated housing. This provides a longer-term assessment of the capacity of the animals for movement, in contrast to related studies involving shorter duration (\nIn summary, quantitative, objective assessment of the activity patterns of DE50-MD dogs and WT controls have been provided, demonstrating the ability to distinguish between these groups across a wide age range. We report a set of activity metrics derived from tri-axial accelerometer data which can contribute towards characterising the functional performance of the DE50-MD model for DMD as well as discriminating between genotypes. These results support the hypothesis that these activity metrics, collected via long-term activity monitoring, can successfully discriminate between genotypes and will be useful in assessing treatment outcomes in future pre-clinical trials. The fact that these assessments are easily obtained, are non-invasive and independent of bias has distinct practical, welfare and scientific advantages. Similar approaches might be applicable in other canine models of DMD and, indeed, more generally, in other animal disease models associated with locomotor or neuromuscular dysfunction.\nCarrier DE50-MD female dogs were mated naturally with wild-type (WT) beagle males (RCC strain). Adult dogs were housed (12-h light/dark cycle; 15-24°C) in large kennels within groups, until pregnant females were close to whelping, upon which they were housed in single kennels. Puppies were weaned at age 10-12 weeks, then grouped in their litters until aged ∼4-5 months. Adults were housed in groups of two to four animals, according to social hierarchy. Kennel size ranged between 6.2 and 6.6 m\nData were collected using Axivity AX3 activity monitors (Axivity, UK) that had previously been validated for use in dogs (\nWeekday monitoring was for 48 h continuously (weekdays 12pm–12pm) at a sample frequency of 200-400 Hz starting at 12pm. When sample frequencies >200 Hz were used, data were computationally resampled to 200 Hz to ensure homogeneity. Dogs remained in their kennels (with their kennel mates) during the test period and were subject to their ‘normal’ daily routine (feeding, cleaning, etc.). To best characterise each time point, the 48-h time interval, beginning at 12pm on the first day of monitoring, was split into 2×24-h periods, enabling aggregate metrics to be calculated per 24 h. The mean of these metrics across the two, 24-h periods was calculated and used in subsequent analyses. Variability between the two 24-h periods was assessed and is described in further detail below. In some cases (15/214 recordings), it was not possible to capture 48 h of continuous activity due to sensor destruction (chewing) or malfunction. In these cases, aggregate metrics were calculated for the first 24-h period.\nAll signal processing was performed using MATLAB R2020b. A 6th order Butterworth band-pass filter was used in both directions to obtain zero phase lag. Cut-off frequencies of 0.28 Hz and 32.76 Hz were used, based on pilot observations (\nThis metric characterises overall, whole-body acceleration over 24 h and is calculated by computing the integral of the 24-h vector magnitude curve minus gravity. As this calculation takes place after band-pass filtering, the signal due to gravity has already been removed by the high pass component of the filter. Daily activity intensity is the velocity quantity (in ms\nMetrics M2\nThe metric ‘percent time spent at rest’ quantifies the proportion of time spent at rest over a fixed period derived from our previously labelled accelerometer and video data and Receiver Operating Characteristic (ROC) analyses (\nThis metric quantifies the proportion of time spent at a higher intensity activity level, defined as the threshold that best discriminates between DE50-MD and WT control dogs. This threshold was derived by computing the percentage of time spent above an acceleration threshold, in a similar way as described in (\nThis metric quantifies the proportion of time spent at a lower intensity activity, which was defined as being between the two thresholds described above (above 0.154\nStatistical analyses were conducted with SPSS Statistics (IBM SPSS Statistics 25) and GraphPad Prism 9 (GraphPad Software Inc. 1994-2021). To assess the validity of averaging the activity metrics across the two 24-h periods of data, we compared daily activity intensity data from the first 24-h period with the second 24-h period for all dogs at all time points. Comparison across the first and second 24-h period was performed using paired two-tailed\nA principal component analysis (PCA) was performed (GraphPad Prism 9) to summarise variation in activity metrics among the DE50-MD and WT controls across all ages. This allowed us to explore which activity metrics varied most across all dogs and assess whether these patterns differed between groups. The first component (PC1), which captured the largest proportion of variance, was then examined statistically using a linear mixed-effects model (LMM), assessing the effect of age, genotype and their interaction, followed by Fisher's least significant difference post-hoc comparisons. Individual dog was included as a random effect to account for repeated measures. Individual activity metrics were assessed using the same LMM analysis as described above (SPSS Statistics).\nSample sizes were calculated to assess the metrics that would be most appropriate for assessing treatment outcomes in possible future pre-clinical treatment trials (power 0.8, alpha 0.05). Effect sizes of 20%, 25%, 50%, 75% and 100% were investigated (i.e. the degree to which any therapy could induce a change from the value of DE50-MD towards that of WT animals). Sample size calculations were completed using GLIMMPSE v1 (", "topic": "Neurodevelopmental_disorder"}
{"pmid": "39761048", "pmcid": "12308699", "title": "Identity work among girls with ADHD: struggling with ", "publication_year": "N/A", "abstract": "The number of individuals diagnosed with ADHD is rapidly increasing in Sweden, with approximately two-thirds of diagnosed children being boys. However, among older adolescents, ADHD now appears to be more common among girls. Despite this, girls remain an understudied group. The purpose of this study was to explore how girls with ADHD described their identity work amid the tension between norms of socially appropriate female behavior (conceptualized as the", "full_text": "Attention-Deficit/Hyperactivity Disorder (ADHD) is a common neurodevelopmental disorder, globally affecting approximately 5–7% of children and adolescents (\nIn Sweden, approximately two-thirds of children with ADHD are boys (\nThus, the purpose of this article is to explore how girls with ADHD—a group that is understudied—describe their identity work amid the tension between generalized norms of socially appropriate behavior for females (conceptualized in this article as a role and the\nThe core symptoms of ADHD can manifest in different ways, but primarily involve difficulties with impulse control, attention, and hyperactivity (\nADHD is associated with a higher risk of comorbidity with other psychiatric diagnoses, such as dyslexia, anxiety, and depression. ADHD treatment typically includes various forms of psychotherapy, as well as central nervous system (CNS) stimulant medication. In Sweden, 75 percent of children diagnosed with ADHD begin medication treatment after receiving their diagnosis (\nHistorically, ADHD has been considered a diagnosis primarily affecting boys (\nADHD is associated with temperamental traits (\nThere is limited research on how people with ADHD perceive, describe, and construct their identities. The diagnosis may be seen as something external, to distance oneself from\nA Swedish phenomenological study found that adolescents diagnosed with ADHD perceived their diagnosis as something that could accommodate their ADHD-related traits, which were described as both positive and negative (\nADHD is often identified in institutional environments such as schools (\nIn Sweden, educational regulations state that all students, regardless of disability or formal diagnosis, should be able to attend school and have the right to support (Swedish Educational Act 2010:800, Chapter 3, §5). A formal diagnosis, such as ADHD, often leads to better access to special aids (\nStimulant medication is often regarded as an aid in schooling children with ADHD as it has been found to enhance concentration in learning environments (\nAttending Swedish schools comes with specific behavioral expectations. Schools instill respect for authority, tolerance, and structure. Students are expected not only to complete their schoolwork and achieve passing grades but also to focus and concentrate, remain quiet, sit still for extended periods, and develop sufficient social competence to maintain friendships. In this way, school imposes behavioral demands that actively shape students. Individuals with ADHD often experience academic challenges and high rates of school absenteeism (\nIdentity work can be studied through people’s narratives about who they are and how they define themselves (\nTo analytically understand this identity work (\nThe dramaturgical perspective, as presented by\nMoreover, people behave more formally in the frontstage, adhering to societal norms and expectations, while the backstage region allows for informal behavior, trusting that no audience is present.\nPeople perform differently depending on the context—such as in the workplace, at a family dinner, or at a grocery store—because social expectations differ in each situation, and we take on different roles in each. In different contexts, we manage and adjust our behavior to influence how others perceive us. Goffman called this behavior “impression management” (\nA well-known study that extended Goffman’s original concept of impression management and critically examined its impact on individuals’ emotional lives and well-being is Hochschild’s seminal research on flight attendants (\nSocial camouflage is a term closely related to\nThe generalized other shapes the part of the self, called the\nThe concepts of the generalized other,\nThis study is part of a larger research project on ADHD and identity formation among adolescents with an ADHD diagnosis and those without a diagnosis but with symptoms. The research project has been approved by the Swedish Ethical Review Authority (reference number 2023-06162-01).\nSince the aim of this study was to explore and describe girls’ experiences of their\nThis study was conducted as part of a larger research project on ADHD and identity (see, for example,\nTen interviews were deemed sufficient to achieve saturation in terms of experiences and diversity of perspectives. All participants were in upper secondary school or high school. Thus, the age span of the participants was 15–18 years. The participants lived in the greater Stockholm area at the time of the interviews.\nThe interviews were conducted by master’s students under the supervision of the project investigators, Author 1 (JG) and Author 3 (MF). The interview guide used in this project consisted primarily of open-ended questions, which provided ample room for subjectivity, interpretation, and flexibility. The interview guide specifically explored experiences related to home, school, and free time by asking questions and allowed for follow-up questions.\nThe interview guide is included in\nThe interviews were collected during the spring of 2024 and were analyzed later that same year by Author 2 (ME), in collaboration with and under the supervision of Author 1 (JG). The use of interview data collected by our master’s students has both advantages and disadvantages. A clear disadvantage is that the material is “static,” meaning no follow-up questions can be asked. However, an advantage is that entirely new perspectives can be applied to the material, potentially uncovering novel insights. Since we had no direct contact with the participants, we presumably approached the material without developing participant-related preconceptions. All researchers inevitably bring their own perspectives and biases to an analysis, but in this case, such influences were likely minimized.\nA thematic inductive coding was employed to analyse the interview transcripts based on the process described by\nThe first step in the thematic analysis was to become familiar with the interview data. Author 2 (ME) read through the interview transcripts thoroughly multiple times, taking notes on segments that were relevant, followed by an initial coding of the material. This process sorted out the parts related to the focus of this study, i.e., identity work and school, and gathered them in a separate document.\nThe second step in the process was to look for themes within the codes, create themes, and review whether they fit. This was an iterative process, going back and forth to check the trustworthiness of the developing themes. The rationale behind this process is that themes should reflect the included codes, and vice versa. However, the rich nuances of the codes are somewhat lost in the overarching themes. Nevertheless, to present the coding in a meaningful way, the codes needed to be organized into broader themes.\nThe coding generated four overarching themes central to the participants’ identity work.\n\n\n\n\nTo ensure the rigour and credibility of the inductive process, the coding was conducted collaboratively by Author 2 (ME) and Author 1 (JG) during the autumn of 2024. The joint coding sessions allowed for continuous dialogue and reflexive discussions, contributing to a more nuanced and trustworthy interpretation of the data. JG held overall supervisory responsibility for the coding process, in close collaboration with Author 3 (MF), which further strengthened the consistency and coherence of the analysis. To enhance the transparency and replicability of the study, the coding scheme and detailed description of the coding process are provided in\nOnce the themes had been systematically distilled, the analytical concepts of\nAn abductive approach constitutes a methodological stance that combines elements of both induction and deduction but fundamentally seeks to generate new understandings through a dynamic, iterative movement between empirical data and theory. The abductive process aims to produce the most plausible and creative explanations for observed phenomena. In abductive analysis, researchers often begin with preliminary empirical material or a partially developed analysis. When this material is brought into dialogue with theoretical concepts, the process may lead to the refinement of existing concepts, the development of new ones, or the emergence of entirely novel perspectives (\nThe results of the abductive interpretative phase are presented in this section. They are organized around four themes that were identified through inductive thematic coding as central to the participants’ identity work, as illustrated in\nThe identity work themes identified among the participants.\nTo ensure the anonymity of the participants’, identifying information has been omitted, and fictitious names have been assigned to each participant.\nA common theme was that the participants felt they had to adjust their behavior in different situations—mostly in the school setting but also in groups with new people—where it was unclear whether their behavior was appreciated. Multiple interviewees expressed that they had to hide their true selves and “hold back energy” to be socially accepted or to avoid being perceived as annoying by their peers. This is exemplified by quotes from Ester and Jasmine later in this section. However, this adjustment could also work in the opposite direction: participants who identified as introverts sometimes adapted their behavior in school to appear more outgoing and social, especially when there was a lot of “fooling around” in class.\nTrying to fit into a group and adjusting one’s behavior to some extent is likely something all adolescents experience, as it is part of growing up and finding one’s place in the world. However, the experience for adolescents with ADHD may differ because they often learn that their traits or dispositions are considered inappropriate. Since ADHD entails hyperactivity and impulsivity, many participants expressed that they had to suppress those aspects of themselves. This process also involved observing others’ behavior and imitating it to some extent in order to fit into the group.\nHanna recounted:\n\nHanna continued to explain that if she relaxed in a social situation, she might say something inappropriate. Therefore, she remained tense and felt like she was “walking on eggshells” in contexts that did not feel entirely safe or familiar. She described this as very tiring, leading to a build-up of emotions that would later be expressed in a safer context.\nHanna explained:\n\nAnother participant, Sara, had a similar experience of school being very draining. She was assessed for ADHD primarily because she was so exhausted.\nSara testified:\n\nCamouflaging symptoms and constantly being on edge in social situations was described as necessary for functioning socially (\nThe safer context—often the home—functioned as the back region, where one did not have to perform or adjust their behavior but could simply be their original self, known as the\nEster described a similar experience:\n\nEster explained that this had both negative and positive outcomes. The negative was that it was tough and required a lot of energy. The positive was that it prevented others from feeling uncomfortable due to hyperactivity and impulsivity.\nThe pros and cons of masking were also described by another participant, Anna. She explained that she tended to talk about topics she knew others were interested in while holding back her own interests and actively trying to fit in.\nAnna recounted:\n\nCamouflaging (\nThus, one could experience a sense of belonging and community, but at the cost of losing originality of the self. The ability to camouflage could also be considered an asset—part of a double-edged sword.\nAnother participant, Jasmine, described how she felt in certain social situations at school:\n\nMultiple participants explained how they had taken on the role of “the class clown” and were often perceived as funny by their peers. Hanna explained that when she was younger, she used to feel left out and different at school. She assumed that others perceived her in a negative way, which led her to act out. As she grew older, she learned to use her hyperactive and impulsive traits, as well as her lack of a filter, to her advantage—turning them into useful tools in social situations.\nHanna explained:\n\nThe older version of Hanna, the person she had become, had learned to balance the social expectations of\nHanna testified:\n\nThus, a disposition that may be seen as undesirable in social contexts—such as in school, or before one has learned to control it socially—can actually be used to one’s advantage. Instead of being perceived as annoying and weird which deeply impacts the looking-glass self-perception, it can also make a person appear funny and spontaneous. This is a form of impression management (\nMost participants perceived their diagnosis as a significant part of their identity—who they were—which influenced how they functioned and processed information. The interview data revealed no signs of stigmatization regarding having ADHD per se; on the contrary, the participants stated that many people had an understanding of the condition. It was perceived as common and normalized by others. However, behaviors associated with ADHD were discouraged by certain individuals or in specific environments, such as in a school setting or at home.\nAlma described how she identified with aspects of her ADHD and how difficult it felt when someone implicitly or explicitly suggested that the behaviors needed to be better controlled, for instance, with medication.\nAlma testified:\n\nReceiving comments about the undesired characteristics that constituted the participants’\nOther participants explained that they struggled to identify with ADHD due to the strong stereotypes that exist about the condition. They did not see themselves in the way the diagnosis was portrayed by some people.\nHanna recounted:\n\nHanna problematized how ADHD manifested differently in boys and girls and how the common perception of ADHD was based on the stereotypical “boy ADHD,” which assumed that individuals with the condition were disruptive. She also pointed out that her ADHD went unnoticed for a long time, as the adults in her life simply saw her as “defiant.” Hanna understood this in relation to gender roles—girls were expected to behave in a certain way, and guilt was often imposed on them. Meanwhile, boys’ behavior was more accepted to a certain extent, giving them a better chance of having their struggles recognized and being diagnosed with ADHD early on. While awaiting proper attention and struggling with a different set of symptoms, girls were instead unable to see themselves as having ADHD due to the one-sided and widespread dissemination of a gender-coded boy stereotype.\nHanna explained:\n\nAccording to previous research (\nTone described how the doctors discussed ADHD, informed her about the associated risks, and explained the possible side effects of the medication. She was told that she had a higher risk of depression and substance abuse, among other things. Receiving all this information placed her in a social category that was difficult to fully accept. In this case, the diagnosis was frustrating and disappointing, prompting identity work focused on concerns about the future.\nTone recounted:\n\nReceiving the diagnosis also meant a new definition of the situation and of who one was. Tone and other participants were labeled into a new group. At the same time, this involved new information for the\nHanna described how she was often perceived as “stuck up” by others, and that she had no filter, which were not considered traditional feminine qualities. Going against society’s norms and expectations of how a girl should be also added an extra burden to the identity work. She simply wished that she could better match these socially ascribed traits.\nHanna recounted:\n\nEster experienced her ADHD symptoms as obstacles, particularly in school, where she struggled with concentration. However, she also emphasized that she was proud of her diagnosis and that the traits associated with it are a significant part of her identity.\nEster testified:\n\nEster acknowledged the challenging aspects of her ADHD but still recognized that it was a fundamental part of who she was. Navigating and managing identity work in relation to ADHD was difficult. Many participants were proud of their diagnosis and the traits that came with it. However, it also led to confusion and frustration when others disapproved of it or when ADHD was understood in a stereotypical way that was hard to relate to. Additionally, society constantly signaled that such behavior was undesirable. As a result, the societal\nSchool was often challenging for the participants, especially when proper accommodations were not provided. All of them experienced difficulties in school to varying degrees. A distinction could be made between issues related to schoolwork (academic issues) and those concerning social interactions with teachers and classmates (social issues).\nParticipants reported difficulties with concentration and focus on school assignments, as well as challenges with executive functioning when starting a project. They had to manage an inconsistent ability to be productive—some days, they struggled to accomplish anything, while on other days, they could write several pages or complete multiple assignments.\nThe social challenges often stemmed from feeling left out, misunderstood, or overwhelmed by large classes, which intensified the identity work.\nAnother common issue was that typical ADHD symptoms—such as hyperactivity and impulsivity—often conflicted with the social norms and expectations of school. A specific\nAll participants in this study had been diagnosed with ADHD, and in almost every case, the initiative for a clinical assessment came from the school. However, the participants were not assessed until late adolescence because there were no visible problems in school or with their grades. Yet, it was often in school that it became clear they had ADHD or that ADHD first became an obstacle.\nThis means that, depending on the severity of the ADHD, it may not pose difficulties outside the school context.\nChrissy recounted:\n\nTone testified:\n\nUsing\nPrevious research on adolescents’ school experiences suggests that while the early years of schooling were relatively manageable, secondary and upper secondary school proved more challenging (\nChrissy thought her behavior was normal in the earlier years of school. Back then, she lived in a non-academic town. She described a behavioral and academic change later in middle school.\nChrissy recounted:\n\nIn fifth grade, she switched to a more academic and high-achieving school, where students were expected to sit still and listen. She described how the classroom became chaotic because of her behavior. A school\nJasmine testified to having similar experiences:\n\nFor Tone, school and the role of a student had almost always been associated with anxiety. She explained how she never felt comfortable in school, partly because she saw others perform in the classroom in ways that she was unable to.\nTone recounted:\n\nAs the quote shows, adults were assigning a definite label to her, which created worry about the future. Using\nThe level of accommodations and support available to individuals with ADHD varies between schools. Ester described her school experience as a square, while she felt like a triangle, as she did not feel like she fit in. Moreover, she explained that although she actually liked school, the lack of accommodations and support generated negative feelings towards it.\nElla described how she usually has a good self-image, but that it had been damaged by how she was treated by teachers and friends at school, which speaks to a different\nApplying\nThe participants took some form of central stimulant medication. The attitude toward the medication varied, but the main reason for taking it was to increase focus and concentration in school. Thus, performing on the school stage served as the primary motive. Based on the analysis, the medication seemed to create two distinct identities and was often described as almost creating two different versions of themselves.\nChrissy testified:\n\nChrissy also explained how the medication helped with concentration in school and improved her grades. However, she stressed how it felt to take the medication since she did not feel like herself when she was on it. Teachers and parents wanted her to continue taking the medication so she could succeed in school, but her friends did not like the person she became while on the medication.\nChrissy recounted:\n\nThis created a conflict between two roles or identities. The medication created a\nSara had a somewhat different experience over time. The primary purpose of the medication was to improve her grades in school.\nSara recounted:\n\nSara’s case speaks to the possibility, depending on the severity of the symptoms, of learning the role of a student and developing skills that can eventually be maintained without medication.\nEster, on the other hand, explained how she was trying different medications with varying doses to find the right one. The medication was helping her, but the most recent one stopped working in the middle of the last class. This may point to the possibility of change, even evolution, as articulated by Sara, and suggests that other factors may be at play over the many years spent in the school context among children and adolescents.\nThe analysis clearly illustrates that the\nThe participants were subjected to imposed identity norms and behaviors by institutions such as the school (\nSimilarly, it was also challenging to combat what the participants perceived as a prevailing gender stereotype of ADHD, which had various implications for them—ranging from a delayed recognition of their difficulties to postponed diagnoses and encounters with widespread stereotypical thinking about the condition (\nSchool was described as anxiety-inducing and challenging by most of the participants, who experienced various difficulties both academically and socially (\nIn other words, there was challenges related to the personal experience of academic and social worth—when one struggles to fit in and function both academically and socially—especially in a school context that fully gravitates toward performance, results, and grading (\nThe idea of medication stemmed from society’s high regard for the ability to perform and deliver results in school (\nSchool was generally the agent that initiated an ADHD assessment (\nRegardless of performance and results, school was the biggest obstacle and challenge for the participants. Some even stopped attending school in upper secondary education. This resonates with previous research, which shows that students with ADHD are more likely to be long-term absent from school (\nAccording to school regulations in Sweden, all students, regardless of diagnosis, have the right to special support and accommodations in school if needed (\nIn the end, school was experienced as a highly structured and rigid environment with little tolerance for behavior that deviated from norms and expectations. Additionally, there was an accelerating curve of increasing demands, as school was perceived to become more challenging after elementary school, reaching its peak difficulty in upper secondary school. This aligns with previous research that has shown the same pattern (\nThus, the role of medication served as an imposed means to fulfill the failed role of a student. Many participants described how medication helped them, particularly with executive function difficulties. It contributed to better grades, made it easier to start projects, and improved focus in class, for example. Medication was often described in terms of “helping with grades,” “getting the job done,” and the importance of it lasting throughout the entire school day. Most participants started medicating soon after receiving their diagnosis (cf.\nNot all participants reported issues related to their medication, and it is important to note that the role of medication is neither inherently good nor bad but rather complex (\nCentral stimulant medication also comes with several side effects, both physical and emotional, which distinguishes it from other types of medication as it significantly affects one’s personality and behavior (\nMoreover, identity-altering medication is not necessarily the sole solution from a school perspective for adolescents with ADHD. This can also be viewed from an organizational and resource perspective (\nFrom both a pedagogical and a cost perspective (rather than relying on expensive assessments, medication, and specially designed support functions), significantly smaller class sizes with qualified educators could be another approach to supporting the growing group of students with ADHD (\nAnother approach could be to reconsider early national tests, which start in year 3, and the grading system, which currently begins in sixth grade in Sweden. Taken together, these factors contribute to high expectations and demands being placed on children at a very early stage. Research is inconclusive regarding these changes to the school system and has not fully considered their impact on identity work and formation in children and adolescents.\nImpression management (\nRevisiting the studies by\nPrevious research on social camouflaging has shown that it is linked to poor mental health (\nAnother approach, linking the challenges to the current organization of the school, could be to create more educational stages at the school. Instead of a large stage with a standard role, organizing more, but smaller stages would create new and better conditions for students. This approach would benefit both girls and boys with ADHD, reducing tension, turbulence, and conflict in identity work while improving conditions for mental health and well-being.\nThe interaction between the school system and the increased prevalence of ADHD diagnoses among children and adolescents is something that requires much more research. From a sociological perspective, it is not only medicine that has solutions for how the best possible conditions for students with ADHD are created. On the contrary, it is important to look beyond a medical paradigm to identify more sustainable paths from a long-term self-identity perspective (\nThe theoretical perspectives used in this study have been highly valuable from an analytical standpoint, helping to understand the roles, or\nThis study used a limited sample of 10 interview transcripts from participating girls with ADHD. Since this was a qualitative study, the aim was not to generalize the findings to the broader population, but rather to explore and gain a deeper understanding of the identity work of girls with ADHD, as this remains an understudied group. However, an obvious limitation of this approach was that no comparisons could be made between boys and girls. Such comparisons are intended to be conducted in the later stages of the project. Another limitation was that we analyzed previously collected material, which was “silent,” meaning no follow-up questions could be posed.\nMore research is warranted on the rising prevalence of ADHD among adolescents, taking into account the complex interaction between schools, parents, healthcare, and the individual. Additionally, the organization and resources of schools are important areas of research. Fundamental changes in schools—such as grading systems, higher expectations, large class sizes, a lack of pedagogical resources, and increased competition in higher education and the labor market—are likely to influence the focus on behavior, achievements, and performance. This, in turn, may lead to children being labeled early on within the ADHD spectrum, shaping their identity.\nA longitudinal research design would have been a desirable approach. While such studies are undeniably resource-intensive, they hold the potential to generate unique insights into identity work both prior to diagnosis and at various stages following it. This would offer a process-oriented understanding of ADHD, the development of targeted interventions, and the evolving nature of identity work over time.", "content_for_embedding": "Attention-Deficit/Hyperactivity Disorder (ADHD) is a common neurodevelopmental disorder, globally affecting approximately 5–7% of children and adolescents (\nIn Sweden, approximately two-thirds of children with ADHD are boys (\nThus, the purpose of this article is to explore how girls with ADHD—a group that is understudied—describe their identity work amid the tension between generalized norms of socially appropriate behavior for females (conceptualized in this article as a role and the\nThe core symptoms of ADHD can manifest in different ways, but primarily involve difficulties with impulse control, attention, and hyperactivity (\nADHD is associated with a higher risk of comorbidity with other psychiatric diagnoses, such as dyslexia, anxiety, and depression. ADHD treatment typically includes various forms of psychotherapy, as well as central nervous system (CNS) stimulant medication. In Sweden, 75 percent of children diagnosed with ADHD begin medication treatment after receiving their diagnosis (\nHistorically, ADHD has been considered a diagnosis primarily affecting boys (\nADHD is associated with temperamental traits (\nThere is limited research on how people with ADHD perceive, describe, and construct their identities. The diagnosis may be seen as something external, to distance oneself from\nA Swedish phenomenological study found that adolescents diagnosed with ADHD perceived their diagnosis as something that could accommodate their ADHD-related traits, which were described as both positive and negative (\nADHD is often identified in institutional environments such as schools (\nIn Sweden, educational regulations state that all students, regardless of disability or formal diagnosis, should be able to attend school and have the right to support (Swedish Educational Act 2010:800, Chapter 3, §5). A formal diagnosis, such as ADHD, often leads to better access to special aids (\nStimulant medication is often regarded as an aid in schooling children with ADHD as it has been found to enhance concentration in learning environments (\nAttending Swedish schools comes with specific behavioral expectations. Schools instill respect for authority, tolerance, and structure. Students are expected not only to complete their schoolwork and achieve passing grades but also to focus and concentrate, remain quiet, sit still for extended periods, and develop sufficient social competence to maintain friendships. In this way, school imposes behavioral demands that actively shape students. Individuals with ADHD often experience academic challenges and high rates of school absenteeism (\nIdentity work can be studied through people’s narratives about who they are and how they define themselves (\nTo analytically understand this identity work (\nThe dramaturgical perspective, as presented by\nMoreover, people behave more formally in the frontstage, adhering to societal norms and expectations, while the backstage region allows for informal behavior, trusting that no audience is present.\nPeople perform differently depending on the context—such as in the workplace, at a family dinner, or at a grocery store—because social expectations differ in each situation, and we take on different roles in each. In different contexts, we manage and adjust our behavior to influence how others perceive us. Goffman called this behavior “impression management” (\nA well-known study that extended Goffman’s original concept of impression management and critically examined its impact on individuals’ emotional lives and well-being is Hochschild’s seminal research on flight attendants (\nSocial camouflage is a term closely related to\nThe generalized other shapes the part of the self, called the\nThe concepts of the generalized other,\nThis study is part of a larger research project on ADHD and identity formation among adolescents with an ADHD diagnosis and those without a diagnosis but with symptoms. The research project has been approved by the Swedish Ethical Review Authority (reference number 2023-06162-01).\nSince the aim of this study was to explore and describe girls’ experiences of their\nThis study was conducted as part of a larger research project on ADHD and identity (see, for example,\nTen interviews were deemed sufficient to achieve saturation in terms of experiences and diversity of perspectives. All participants were in upper secondary school or high school. Thus, the age span of the participants was 15–18 years. The participants lived in the greater Stockholm area at the time of the interviews.\nThe interviews were conducted by master’s students under the supervision of the project investigators, Author 1 (JG) and Author 3 (MF). The interview guide used in this project consisted primarily of open-ended questions, which provided ample room for subjectivity, interpretation, and flexibility. The interview guide specifically explored experiences related to home, school, and free time by asking questions and allowed for follow-up questions.\nThe interview guide is included in\nThe interviews were collected during the spring of 2024 and were analyzed later that same year by Author 2 (ME), in collaboration with and under the supervision of Author 1 (JG). The use of interview data collected by our master’s students has both advantages and disadvantages. A clear disadvantage is that the material is “static,” meaning no follow-up questions can be asked. However, an advantage is that entirely new perspectives can be applied to the material, potentially uncovering novel insights. Since we had no direct contact with the participants, we presumably approached the material without developing participant-related preconceptions. All researchers inevitably bring their own perspectives and biases to an analysis, but in this case, such influences were likely minimized.\nA thematic inductive coding was employed to analyse the interview transcripts based on the process described by\nThe first step in the thematic analysis was to become familiar with the interview data. Author 2 (ME) read through the interview transcripts thoroughly multiple times, taking notes on segments that were relevant, followed by an initial coding of the material. This process sorted out the parts related to the focus of this study, i.e., identity work and school, and gathered them in a separate document.\nThe second step in the process was to look for themes within the codes, create themes, and review whether they fit. This was an iterative process, going back and forth to check the trustworthiness of the developing themes. The rationale behind this process is that themes should reflect the included codes, and vice versa. However, the rich nuances of the codes are somewhat lost in the overarching themes. Nevertheless, to present the coding in a meaningful way, the codes needed to be organized into broader themes.\nThe coding generated four overarching themes central to the participants’ identity work.\n\n\n\n\nTo ensure the rigour and credibility of the inductive process, the coding was conducted collaboratively by Author 2 (ME) and Author 1 (JG) during the autumn of 2024. The joint coding sessions allowed for continuous dialogue and reflexive discussions, contributing to a more nuanced and trustworthy interpretation of the data. JG held overall supervisory responsibility for the coding process, in close collaboration with Author 3 (MF), which further strengthened the consistency and coherence of the analysis. To enhance the transparency and replicability of the study, the coding scheme and detailed description of the coding process are provided in\nOnce the themes had been systematically distilled, the analytical concepts of\nAn abductive approach constitutes a methodological stance that combines elements of both induction and deduction but fundamentally seeks to generate new understandings through a dynamic, iterative movement between empirical data and theory. The abductive process aims to produce the most plausible and creative explanations for observed phenomena. In abductive analysis, researchers often begin with preliminary empirical material or a partially developed analysis. When this material is brought into dialogue with theoretical concepts, the process may lead to the refinement of existing concepts, the development of new ones, or the emergence of entirely novel perspectives (\nThe results of the abductive interpretative phase are presented in this section. They are organized around four themes that were identified through inductive thematic coding as central to the participants’ identity work, as illustrated in\nThe identity work themes identified among the participants.\nTo ensure the anonymity of the participants’, identifying information has been omitted, and fictitious names have been assigned to each participant.\nA common theme was that the participants felt they had to adjust their behavior in different situations—mostly in the school setting but also in groups with new people—where it was unclear whether their behavior was appreciated. Multiple interviewees expressed that they had to hide their true selves and “hold back energy” to be socially accepted or to avoid being perceived as annoying by their peers. This is exemplified by quotes from Ester and Jasmine later in this section. However, this adjustment could also work in the opposite direction: participants who identified as introverts sometimes adapted their behavior in school to appear more outgoing and social, especially when there was a lot of “fooling around” in class.\nTrying to fit into a group and adjusting one’s behavior to some extent is likely something all adolescents experience, as it is part of growing up and finding one’s place in the world. However, the experience for adolescents with ADHD may differ because they often learn that their traits or dispositions are considered inappropriate. Since ADHD entails hyperactivity and impulsivity, many participants expressed that they had to suppress those aspects of themselves. This process also involved observing others’ behavior and imitating it to some extent in order to fit into the group.\nHanna recounted:\n\nHanna continued to explain that if she relaxed in a social situation, she might say something inappropriate. Therefore, she remained tense and felt like she was “walking on eggshells” in contexts that did not feel entirely safe or familiar. She described this as very tiring, leading to a build-up of emotions that would later be expressed in a safer context.\nHanna explained:\n\nAnother participant, Sara, had a similar experience of school being very draining. She was assessed for ADHD primarily because she was so exhausted.\nSara testified:\n\nCamouflaging symptoms and constantly being on edge in social situations was described as necessary for functioning socially (\nThe safer context—often the home—functioned as the back region, where one did not have to perform or adjust their behavior but could simply be their original self, known as the\nEster described a similar experience:\n\nEster explained that this had both negative and positive outcomes. The negative was that it was tough and required a lot of energy. The positive was that it prevented others from feeling uncomfortable due to hyperactivity and impulsivity.\nThe pros and cons of masking were also described by another participant, Anna. She explained that she tended to talk about topics she knew others were interested in while holding back her own interests and actively trying to fit in.\nAnna recounted:\n\nCamouflaging (\nThus, one could experience a sense of belonging and community, but at the cost of losing originality of the self. The ability to camouflage could also be considered an asset—part of a double-edged sword.\nAnother participant, Jasmine, described how she felt in certain social situations at school:\n\nMultiple participants explained how they had taken on the role of “the class clown” and were often perceived as funny by their peers. Hanna explained that when she was younger, she used to feel left out and different at school. She assumed that others perceived her in a negative way, which led her to act out. As she grew older, she learned to use her hyperactive and impulsive traits, as well as her lack of a filter, to her advantage—turning them into useful tools in social situations.\nHanna explained:\n\nThe older version of Hanna, the person she had become, had learned to balance the social expectations of\nHanna testified:\n\nThus, a disposition that may be seen as undesirable in social contexts—such as in school, or before one has learned to control it socially—can actually be used to one’s advantage. Instead of being perceived as annoying and weird which deeply impacts the looking-glass self-perception, it can also make a person appear funny and spontaneous. This is a form of impression management (\nMost participants perceived their diagnosis as a significant part of their identity—who they were—which influenced how they functioned and processed information. The interview data revealed no signs of stigmatization regarding having ADHD per se; on the contrary, the participants stated that many people had an understanding of the condition. It was perceived as common and normalized by others. However, behaviors associated with ADHD were discouraged by certain individuals or in specific environments, such as in a school setting or at home.\nAlma described how she identified with aspects of her ADHD and how difficult it felt when someone implicitly or explicitly suggested that the behaviors needed to be better controlled, for instance, with medication.\nAlma testified:\n\nReceiving comments about the undesired characteristics that constituted the participants’\nOther participants explained that they struggled to identify with ADHD due to the strong stereotypes that exist about the condition. They did not see themselves in the way the diagnosis was portrayed by some people.\nHanna recounted:\n\nHanna problematized how ADHD manifested differently in boys and girls and how the common perception of ADHD was based on the stereotypical “boy ADHD,” which assumed that individuals with the condition were disruptive. She also pointed out that her ADHD went unnoticed for a long time, as the adults in her life simply saw her as “defiant.” Hanna understood this in relation to gender roles—girls were expected to behave in a certain way, and guilt was often imposed on them. Meanwhile, boys’ behavior was more accepted to a certain extent, giving them a better chance of having their struggles recognized and being diagnosed with ADHD early on. While awaiting proper attention and struggling with a different set of symptoms, girls were instead unable to see themselves as having ADHD due to the one-sided and widespread dissemination of a gender-coded boy stereotype.\nHanna explained:\n\nAccording to previous research (\nTone described how the doctors discussed ADHD, informed her about the associated risks, and explained the possible side effects of the medication. She was told that she had a higher risk of depression and substance abuse, among other things. Receiving all this information placed her in a social category that was difficult to fully accept. In this case, the diagnosis was frustrating and disappointing, prompting identity work focused on concerns about the future.\nTone recounted:\n\nReceiving the diagnosis also meant a new definition of the situation and of who one was. Tone and other participants were labeled into a new group. At the same time, this involved new information for the\nHanna described how she was often perceived as “stuck up” by others, and that she had no filter, which were not considered traditional feminine qualities. Going against society’s norms and expectations of how a girl should be also added an extra burden to the identity work. She simply wished that she could better match these socially ascribed traits.\nHanna recounted:\n\nEster experienced her ADHD symptoms as obstacles, particularly in school, where she struggled with concentration. However, she also emphasized that she was proud of her diagnosis and that the traits associated with it are a significant part of her identity.\nEster testified:\n\nEster acknowledged the challenging aspects of her ADHD but still recognized that it was a fundamental part of who she was. Navigating and managing identity work in relation to ADHD was difficult. Many participants were proud of their diagnosis and the traits that came with it. However, it also led to confusion and frustration when others disapproved of it or when ADHD was understood in a stereotypical way that was hard to relate to. Additionally, society constantly signaled that such behavior was undesirable. As a result, the societal\nSchool was often challenging for the participants, especially when proper accommodations were not provided. All of them experienced difficulties in school to varying degrees. A distinction could be made between issues related to schoolwork (academic issues) and those concerning social interactions with teachers and classmates (social issues).\nParticipants reported difficulties with concentration and focus on school assignments, as well as challenges with executive functioning when starting a project. They had to manage an inconsistent ability to be productive—some days, they struggled to accomplish anything, while on other days, they could write several pages or complete multiple assignments.\nThe social challenges often stemmed from feeling left out, misunderstood, or overwhelmed by large classes, which intensified the identity work.\nAnother common issue was that typical ADHD symptoms—such as hyperactivity and impulsivity—often conflicted with the social norms and expectations of school. A specific\nAll participants in this study had been diagnosed with ADHD, and in almost every case, the initiative for a clinical assessment came from the school. However, the participants were not assessed until late adolescence because there were no visible problems in school or with their grades. Yet, it was often in school that it became clear they had ADHD or that ADHD first became an obstacle.\nThis means that, depending on the severity of the ADHD, it may not pose difficulties outside the school context.\nChrissy recounted:\n\nTone testified:\n\nUsing\nPrevious research on adolescents’ school experiences suggests that while the early years of schooling were relatively manageable, secondary and upper secondary school proved more challenging (\nChrissy thought her behavior was normal in the earlier years of school. Back then, she lived in a non-academic town. She described a behavioral and academic change later in middle school.\nChrissy recounted:\n\nIn fifth grade, she switched to a more academic and high-achieving school, where students were expected to sit still and listen. She described how the classroom became chaotic because of her behavior. A school\nJasmine testified to having similar experiences:\n\nFor Tone, school and the role of a student had almost always been associated with anxiety. She explained how she never felt comfortable in school, partly because she saw others perform in the classroom in ways that she was unable to.\nTone recounted:\n\nAs the quote shows, adults were assigning a definite label to her, which created worry about the future. Using\nThe level of accommodations and support available to individuals with ADHD varies between schools. Ester described her school experience as a square, while she felt like a triangle, as she did not feel like she fit in. Moreover, she explained that although she actually liked school, the lack of accommodations and support generated negative feelings towards it.\nElla described how she usually has a good self-image, but that it had been damaged by how she was treated by teachers and friends at school, which speaks to a different\nApplying\nThe participants took some form of central stimulant medication. The attitude toward the medication varied, but the main reason for taking it was to increase focus and concentration in school. Thus, performing on the school stage served as the primary motive. Based on the analysis, the medication seemed to create two distinct identities and was often described as almost creating two different versions of themselves.\nChrissy testified:\n\nChrissy also explained how the medication helped with concentration in school and improved her grades. However, she stressed how it felt to take the medication since she did not feel like herself when she was on it. Teachers and parents wanted her to continue taking the medication so she could succeed in school, but her friends did not like the person she became while on the medication.\nChrissy recounted:\n\nThis created a conflict between two roles or identities. The medication created a\nSara had a somewhat different experience over time. The primary purpose of the medication was to improve her grades in school.\nSara recounted:\n\nSara’s case speaks to the possibility, depending on the severity of the symptoms, of learning the role of a student and developing skills that can eventually be maintained without medication.\nEster, on the other hand, explained how she was trying different medications with varying doses to find the right one. The medication was helping her, but the most recent one stopped working in the middle of the last class. This may point to the possibility of change, even evolution, as articulated by Sara, and suggests that other factors may be at play over the many years spent in the school context among children and adolescents.\nThe analysis clearly illustrates that the\nThe participants were subjected to imposed identity norms and behaviors by institutions such as the school (\nSimilarly, it was also challenging to combat what the participants perceived as a prevailing gender stereotype of ADHD, which had various implications for them—ranging from a delayed recognition of their difficulties to postponed diagnoses and encounters with widespread stereotypical thinking about the condition (\nSchool was described as anxiety-inducing and challenging by most of the participants, who experienced various difficulties both academically and socially (\nIn other words, there was challenges related to the personal experience of academic and social worth—when one struggles to fit in and function both academically and socially—especially in a school context that fully gravitates toward performance, results, and grading (\nThe idea of medication stemmed from society’s high regard for the ability to perform and deliver results in school (\nSchool was generally the agent that initiated an ADHD assessment (\nRegardless of performance and results, school was the biggest obstacle and challenge for the participants. Some even stopped attending school in upper secondary education. This resonates with previous research, which shows that students with ADHD are more likely to be long-term absent from school (\nAccording to school regulations in Sweden, all students, regardless of diagnosis, have the right to special support and accommodations in school if needed (\nIn the end, school was experienced as a highly structured and rigid environment with little tolerance for behavior that deviated from norms and expectations. Additionally, there was an accelerating curve of increasing demands, as school was perceived to become more challenging after elementary school, reaching its peak difficulty in upper secondary school. This aligns with previous research that has shown the same pattern (\nThus, the role of medication served as an imposed means to fulfill the failed role of a student. Many participants described how medication helped them, particularly with executive function difficulties. It contributed to better grades, made it easier to start projects, and improved focus in class, for example. Medication was often described in terms of “helping with grades,” “getting the job done,” and the importance of it lasting throughout the entire school day. Most participants started medicating soon after receiving their diagnosis (cf.\nNot all participants reported issues related to their medication, and it is important to note that the role of medication is neither inherently good nor bad but rather complex (\nCentral stimulant medication also comes with several side effects, both physical and emotional, which distinguishes it from other types of medication as it significantly affects one’s personality and behavior (\nMoreover, identity-altering medication is not necessarily the sole solution from a school perspective for adolescents with ADHD. This can also be viewed from an organizational and resource perspective (\nFrom both a pedagogical and a cost perspective (rather than relying on expensive assessments, medication, and specially designed support functions), significantly smaller class sizes with qualified educators could be another approach to supporting the growing group of students with ADHD (\nAnother approach could be to reconsider early national tests, which start in year 3, and the grading system, which currently begins in sixth grade in Sweden. Taken together, these factors contribute to high expectations and demands being placed on children at a very early stage. Research is inconclusive regarding these changes to the school system and has not fully considered their impact on identity work and formation in children and adolescents.\nImpression management (\nRevisiting the studies by\nPrevious research on social camouflaging has shown that it is linked to poor mental health (\nAnother approach, linking the challenges to the current organization of the school, could be to create more educational stages at the school. Instead of a large stage with a standard role, organizing more, but smaller stages would create new and better conditions for students. This approach would benefit both girls and boys with ADHD, reducing tension, turbulence, and conflict in identity work while improving conditions for mental health and well-being.\nThe interaction between the school system and the increased prevalence of ADHD diagnoses among children and adolescents is something that requires much more research. From a sociological perspective, it is not only medicine that has solutions for how the best possible conditions for students with ADHD are created. On the contrary, it is important to look beyond a medical paradigm to identify more sustainable paths from a long-term self-identity perspective (\nThe theoretical perspectives used in this study have been highly valuable from an analytical standpoint, helping to understand the roles, or\nThis study used a limited sample of 10 interview transcripts from participating girls with ADHD. Since this was a qualitative study, the aim was not to generalize the findings to the broader population, but rather to explore and gain a deeper understanding of the identity work of girls with ADHD, as this remains an understudied group. However, an obvious limitation of this approach was that no comparisons could be made between boys and girls. Such comparisons are intended to be conducted in the later stages of the project. Another limitation was that we analyzed previously collected material, which was “silent,” meaning no follow-up questions could be posed.\nMore research is warranted on the rising prevalence of ADHD among adolescents, taking into account the complex interaction between schools, parents, healthcare, and the individual. Additionally, the organization and resources of schools are important areas of research. Fundamental changes in schools—such as grading systems, higher expectations, large class sizes, a lack of pedagogical resources, and increased competition in higher education and the labor market—are likely to influence the focus on behavior, achievements, and performance. This, in turn, may lead to children being labeled early on within the ADHD spectrum, shaping their identity.\nA longitudinal research design would have been a desirable approach. While such studies are undeniably resource-intensive, they hold the potential to generate unique insights into identity work both prior to diagnosis and at various stages following it. This would offer a process-oriented understanding of ADHD, the development of targeted interventions, and the evolving nature of identity work over time.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "39715963", "pmcid": "12310149", "title": "Predicting Engagement With Conversational Agents in Mental Health Therapy by Examining the Role of Epistemic Trust, Personality, and Fear of Intimacy: Cross-Sectional Web-Based Survey Study", "publication_year": "N/A", "abstract": "", "full_text": "In the past few years, the way clinical professionals, patients, and the general population relate to emotional suffering has notably changed. A crucial role in this shift can be attributed to the rise of artificial intelligence (AI) and conversational agents (CAs). These are advanced manifestations of large language models, which are capable of analyzing and extracting knowledge from human conversations, using it to adaptively prompt a real-time answer and consequently creating multiturn human-computer dialogues. The unique ability of CAs to interact with human beings, understand their communication styles, and engage in human-like conversational responses gained notable attention. This is due primarily to their potential applications in the fields of enhancing mental well-being and providing social support [\nHowever, beyond these technical features, it is imperative to understand the psychological determinants that may drive individuals to rely solely, or primarily, on CA-based therapy, bypassing human interaction. This understanding is crucial for the ethical provision of mental health care, as for some (eg, people with a poor mental capacity or severe mental illness), the prevalent use of CAs may be counterproductive, for example, by eliciting dependence and overreliance on the relationship built with the CA [\nSeveral psychological factors may influence a person’s willingness to communicate exclusively with autonomous agents in order to deal with life-related painful emotions and memories. Among those, 4 factors appear to be of major importance, as pointed out by several reviews on this topic: epistemic trust, fear of intimacy, attachment strategies, and personality domains (for more details on these reviews and meta-analyses, see sections below).\nPerceptions of AI capabilities and trust in its effectiveness may play a significant role in shaping individuals’ attitudes toward CA-based therapy. Over the past decade, there has been an incremental growth in the number of reviews [\nAs Alvarado [\nAs a concept, epistemic trust has a long history that precedes the rise of AI. For instance, Fonagy et al [\nIn this study, epistemic trust was conceptualized as the individual’s predisposition to perceive the information delivered by a CA as accurate, relevant, generalizable, and safe, and therefore, the CA as a trustworthy communicator. This is in line with different definitions of epistemic trust (eg, [\nResearch efforts aimed at understanding attitudes toward AI have primarily concentrated on personality traits underpinning our preferences and behaviors [\nSimilarly, Fonagy and colleagues [\nAlthough research in this field is still in its infancy, recent findings [\nIntimacy involves the capacity to commit oneself to particular affiliations and relationships, and to possess the “ethical courage” necessary to uphold these commitments [\nCurrently, technology often plays a paradoxical role in fostering a sense of “virtual intimacy” while leading to potential social isolation [\nIndividuals grappling with the fear of intimacy typically exhibit characteristics rooted in 2 distinct avoidance-based attachment strategies, which correspond to 2 different models of the self: fearful and dismissing [\nIn the past few years, an increasing reliance on CAs in mental health therapy has emerged [\nConsidering this, this study aimed to address a gap in the literature by examining how key psychological factors—specifically epistemic trust, personality traits, avoidance-based attachment styles, and fear of intimacy—influenced individuals’ willingness to engage with CAs for mental health support. The goal was to contribute to a deeper understanding of the psychological underpinnings that shape preferences for CA-based therapy, with broader implications for the ethical implementation of AI in mental health care. To achieve this, we employed an ordinal logistic regression model to assess the predictive role of these factors in shaping individuals’ dispositions toward AI-mediated therapeutic interventions.\nData were collected through an online survey distributed to students attending the MSc course “Psychology of Communication” at the Department of Philosophy, Communication and Performing Arts of Rome3 University (Italy). The study was advertised by posting an e-copy of the study flyer on the academic page and Microsoft Teams channel of the MSc course, reaching out to a pool of 876 students. Participants accessed the survey through a Google Forms link, where they were presented with a Participation Information Sheet (PIS) outlining study details, that is, a concise overview of the study’s objectives, participation requirements, data handling procedures, and contact information for the principal investigator, followed by a consent form.\nThe participants were asked to confirm their agreement to participate by clicking “I agree” on the consent form. Selecting this option to express informed consent redirected participants to another form containing the assessment measures used as part of this study. Participants remained anonymous and could withdraw from the study at any time before data analysis by contacting the principal investigator through email as described in the PIS. The online survey used in this study was designed and implemented in accordance with the CHERRIES (Checklist for Reporting Results of Internet E-Surveys [\nCHERRIES: Checklist for Reporting Results of Internet E-Surveys.\nIRB: institutional review board.\nAIPsi: Italian Psychoanalytical Association.\nPIS: Participation Information Sheet.\nPPOM: partial proportional odds model.\nSociodemographic information (eg, age, gender, years of education, and marital status) was collected. To assess the preference for CA-based therapy over human being-based clinical interventions, participants were asked to answer the following question: “On a scale from 1 to 5, how willing are you to participate in psychotherapy sessions solely facilitated by artificial intelligence (AI), without any interaction with a human psychologist?” (scores range from 1=not at all to 5=extremely).\nThe Italian adaptation [\nThe Italian translation of the Relationship Questionnaire [\nThe Italian version [\nOriginally developed to assess the comfort of revealing intimate personal details to helping professions, the Fear of Intimacy With Helping Professionals Scale (FIS-HP [\nTo determine sample size, we computed an a priori power analysis for logistic regression using G*Power (version 3.1.9.2; Heinrich-Heine-Universität Düsseldorf) [\nGiven the polytomous and ordinal nature of the dependent variable (ie, willingness to address mental health conditions only via CA-based interventions, assessed using 5 categories that may be ordered according to the level of magnitude), we performed an ordinal logistic regressive model using the polr function in the MASS package of R (R Core Team, 2025), following the procedure described by Liang and Zhan [\nProbabilities of the ordinal response variable were transformed into log-odds via logit function, as shown in\nEquation 1: Logistic transformation of cumulative probabilities.\nIn logistic regression, log-odds indicate the likelihood of being at or below a certain category level relative to being above it. A positive logit value suggests a higher likelihood of being in or below a particular category, while a negative value indicates a higher likelihood of being above that category. To express odds in terms of predicted probabilities, which are often easier to interpret, we used the transformation formula:\nEquation 2: Conversion from log-odds to predicted probabilities.\nWhere P(Y≥j) represents the predicted probability of the dependent variable Y being in or below category level\nEquation 3: Predicted probability for dummy variable (gender).\nWe used the POM, considering the effects of independent variables (IVs) on the dependent variable as equal across all categories. For instance, the OR of each IV is the same for each cut-off – (1) P[Y=1] versus P[Y≥2], (2) P[Y≤2] versus P[Y≥3], (3) P[Y≤3] versus P[Y≥4], and (4) P[Y≤4] versus P[Y≥5]. POM is the most frequently used logistic regression model for analyzing ordinal response variables [\nTo test the proportional odds assumption (or parallel line assumption), we conducted the Brant test via the Brant R package [\nOut of 876 students, 736 students (84.01% respondents) aged 18 to 85 years completed the survey. As outliers increase data variability and decrease statistical power, 1 participant (male, age 85 y) was manually removed. The final sample consisted of 735 participants (191 males, 25.98%; 543 females, 73.88%; and 1 missing) with a mean age of 27.69 (SD 12.31) years. The single case with missing gender data was handled using multiple imputation, ensuring that no data were excluded from the analyses due to this missing value. Although the age range of the sample was broad (18‐85 y), the distribution was moderately right-skewed, with a median age of 24 (IQR 19‐31) years, reflecting the student population from which the sample was drawn. The majority (n=561, 76.36%) were single or in a nonserious relationship, and the remaining 414 (56.3%) were married or in a stable union. On average, participants had 13.84 (SD 3.50) years of education. A total of 76 individuals (10.30%) reported a previous mental health condition, such as anxiety or depression; 127 (17.3%) reported frequent substance use (≥3 times/week) without meeting the criteria for abuse or dependence.\nThe results of the Brant test show that the overall test fails, and the parallel line assumption is not satisfied (\nAfter partially lifting the restriction, both PNOM and PPOM were models found to fit data correctly and may be useful to explain them. To identify the best solution for this purpose, we compared NPOM and PPOM by using residual deviance, which may be considered a measure of discrepancy of a generalized linear model from real observed data [\nOR: odds ratio.\nETCMQ: Epistemic Trust, Credulity and Mistrust Questionnaire.\nPID5−BF: Personality Inventory for DSM-5—Brief Form—Adult.\nRQ: Relationship Questionnaire.\nFIS-HP: Fear of Intimacy with Helping Professionals Scale\nLogit link values represent log-odds coefficients from the ordinal logistic regression model, indicating the effect of each predictor on the likelihood of expressing greater willingness to engage in conversational agent–based therapy (measured on a 5-point ordinal scale). Positive coefficients indicate a higher probability of choosing more favorable response categories (e.g., “somewhat willing” or “extremely willing”), while negative coefficients reflect a tendency toward lower willingness.\nETCMQ: Epistemic Trust, Credulity and Mistrust Questionnaire.\nPID5−BF: Personality Inventory for DSM-5—Brief Form—Adult.\nRQ: Relationship Questionnaire.\nFIS-HP: Fear of Intimacy with Helping Professionals Scale\nETCMQ: Epistemic Trust, Credulity and Mistrust Questionnaire.\nPID-5BF: Personality Inventory for DSM-5—Brief Form—Adult.\nRQ: Relationship Questionnaire.\nFIS-HP: Fear of Intimacy with Helping Professionals Scale\nOverall, our data showed that epistemic trust emerged as a strong predictor of willingness to rely on CA-based therapy. Higher levels of epistemic trust significantly increased the likelihood of choosing AI-mediated therapy (OR 1.745, 95% CI 1.10‐1.41;\nThis study examined the psychological and demographic factors influencing individuals’ preferences for conversational agent (CA)-based therapy over traditional human-mediated interventions. Using robust statistical approaches, we identified significant predictors, including epistemic trust, attachment styles, personality traits, fear of intimacy, and demographic factors such as gender and education. More specifically, greater epistemic trust significantly increased individuals’ willingness to engage with CA-based mental health therapy, highlighting its central role as a precondition for trusting AI-mediated support. Higher levels of fear of intimacy, particularly fear of sharing personal information, also predicted a preference for CA-based support, suggesting that individuals who feel emotionally vulnerable or threatened by interpersonal closeness may gravitate toward less socially demanding therapeutic tools. Personality traits such as detachment and psychoticism were also associated with greater willingness to use AI-mediated therapy, reflecting a preference for emotionally distant or unconventional interaction styles. Attachment styles showed more nuanced effects: individuals with avoidant attachment (both dismissing and fearful) were less inclined to engage in traditional human-based therapy, indirectly favoring CA-based interventions. Demographic predictors such as being single and having a higher level of education further contributed to increased willingness to use CA-based mental health support. These findings align with broader trends in the literature. Recent studies demonstrate that user trust in AI mental health tools is influenced not only by personal traits but also by perceptions of safety, anonymity, and emotional support [\nThe results underscored the centrality of epistemic trust in shaping individuals’ willingness to engage with CA-based therapy. Higher epistemic trust significantly predicted a greater preference for CAs (OR 1.745; 95% CI 1.31–2.32;\nAttachment styles, particularly avoidant patterns, emerged as significant predictors of CA-based therapy preference. Individuals with dismissing and fearful attachment styles were less likely to engage with traditional human therapists, likely due to discomfort with emotional intimacy and vulnerability. These findings align with Bartholomew and Horowitz’s [\nPersonality traits, particularly negative affectivity, detachment, and psychoticism, were significant predictors of willingness to engage with CA-based therapy. These traits reflect tendencies toward emotional dysregulation, social withdrawal, and unconventional thinking, which may drive preferences for less interpersonal forms of therapy. The findings align with Marengo et al [\nDemographic factors, including gender, education, and relationship status, also played a role in shaping preferences for CA-based therapy. While gender differences were not statistically significant, the trend suggested that men were slightly more inclined toward AI therapy than women. This aligns with previous findings suggesting that men are generally more open to adopting new technologies [\nThe findings have several practical and ethical implications. First, they highlight the need for CA-based therapies to be designed with sensitivity to individual differences, particularly attachment styles and personality traits. For instance, individuals with high detachment may benefit from interventions that gradually build emotional engagement, while those with high epistemic trust may prioritize transparency and reliability in AI responses. Based on these findings, we recommend that developers incorporate adaptive interaction styles into CA systems, such as pacing strategies, tailored disclosure prompts, and emotionally neutral yet supportive communication styles, to accommodate users who struggle with emotional closeness or fear of judgment. Second, our results underscore the importance of addressing the potential risks associated with CA-based therapy. While these technologies offer valuable alternatives, particularly for individuals who struggle with traditional therapy, they also carry risks of overreliance and reduced critical thinking [\nThis study offered a novel contribution to the emerging field of digital mental health by focusing not only on the technological acceptability of CAs, but also on the psychological determinants that underpin individual preferences for AI-mediated therapy. While previous research has highlighted user satisfaction, perceived usefulness, or the technical capabilities of CAs, relatively little attention has been paid to why certain individuals are more psychologically predisposed to prefer AI over human interaction in therapeutic contexts. By integrating constructs such as epistemic trust, fear of intimacy, attachment style, and maladaptive personality traits, this study provides a more comprehensive and person-centered model of CA engagement. This approach fills a critical gap in the literature and offers clinically relevant insights for tailoring CA-based interventions to the psychological needs and vulnerabilities of different user profiles. Nonetheless, while providing valuable insights, this study is not without limitations. The sample was drawn from a specific population (university students), which may limit the generalizability of the findings. More specifically, the participants were all enrolled in a psychology degree program, which likely reflects a cohort that is highly educated, psychologically literate, and potentially more open to digital therapeutic tools than the general population. This homogeneity may have biased responses toward higher levels of epistemic trust and engagement with AI, which could inflate associations between psychological variables and preference for CA-based therapy. As noted in broader critiques of online survey methodology (eg, Andrade [\nThis study contributes to the growing literature on AI-mediated mental health interventions by identifying key psychological and demographic predictors of preferences for CA-based therapy. The findings emphasize the importance of epistemic trust, attachment styles, personality traits, and demographic factors in shaping attitudes toward AI in mental health care. While these technologies offer promising alternatives to traditional therapy, their integration must be approached with caution to ensure ethical and effective mental health support. Future research should continue to explore the dynamic interactions between individual differences and technological features, paving the way for personalized and equitable mental health interventions.", "content_for_embedding": "In the past few years, the way clinical professionals, patients, and the general population relate to emotional suffering has notably changed. A crucial role in this shift can be attributed to the rise of artificial intelligence (AI) and conversational agents (CAs). These are advanced manifestations of large language models, which are capable of analyzing and extracting knowledge from human conversations, using it to adaptively prompt a real-time answer and consequently creating multiturn human-computer dialogues. The unique ability of CAs to interact with human beings, understand their communication styles, and engage in human-like conversational responses gained notable attention. This is due primarily to their potential applications in the fields of enhancing mental well-being and providing social support [\nHowever, beyond these technical features, it is imperative to understand the psychological determinants that may drive individuals to rely solely, or primarily, on CA-based therapy, bypassing human interaction. This understanding is crucial for the ethical provision of mental health care, as for some (eg, people with a poor mental capacity or severe mental illness), the prevalent use of CAs may be counterproductive, for example, by eliciting dependence and overreliance on the relationship built with the CA [\nSeveral psychological factors may influence a person’s willingness to communicate exclusively with autonomous agents in order to deal with life-related painful emotions and memories. Among those, 4 factors appear to be of major importance, as pointed out by several reviews on this topic: epistemic trust, fear of intimacy, attachment strategies, and personality domains (for more details on these reviews and meta-analyses, see sections below).\nPerceptions of AI capabilities and trust in its effectiveness may play a significant role in shaping individuals’ attitudes toward CA-based therapy. Over the past decade, there has been an incremental growth in the number of reviews [\nAs Alvarado [\nAs a concept, epistemic trust has a long history that precedes the rise of AI. For instance, Fonagy et al [\nIn this study, epistemic trust was conceptualized as the individual’s predisposition to perceive the information delivered by a CA as accurate, relevant, generalizable, and safe, and therefore, the CA as a trustworthy communicator. This is in line with different definitions of epistemic trust (eg, [\nResearch efforts aimed at understanding attitudes toward AI have primarily concentrated on personality traits underpinning our preferences and behaviors [\nSimilarly, Fonagy and colleagues [\nAlthough research in this field is still in its infancy, recent findings [\nIntimacy involves the capacity to commit oneself to particular affiliations and relationships, and to possess the “ethical courage” necessary to uphold these commitments [\nCurrently, technology often plays a paradoxical role in fostering a sense of “virtual intimacy” while leading to potential social isolation [\nIndividuals grappling with the fear of intimacy typically exhibit characteristics rooted in 2 distinct avoidance-based attachment strategies, which correspond to 2 different models of the self: fearful and dismissing [\nIn the past few years, an increasing reliance on CAs in mental health therapy has emerged [\nConsidering this, this study aimed to address a gap in the literature by examining how key psychological factors—specifically epistemic trust, personality traits, avoidance-based attachment styles, and fear of intimacy—influenced individuals’ willingness to engage with CAs for mental health support. The goal was to contribute to a deeper understanding of the psychological underpinnings that shape preferences for CA-based therapy, with broader implications for the ethical implementation of AI in mental health care. To achieve this, we employed an ordinal logistic regression model to assess the predictive role of these factors in shaping individuals’ dispositions toward AI-mediated therapeutic interventions.\nData were collected through an online survey distributed to students attending the MSc course “Psychology of Communication” at the Department of Philosophy, Communication and Performing Arts of Rome3 University (Italy). The study was advertised by posting an e-copy of the study flyer on the academic page and Microsoft Teams channel of the MSc course, reaching out to a pool of 876 students. Participants accessed the survey through a Google Forms link, where they were presented with a Participation Information Sheet (PIS) outlining study details, that is, a concise overview of the study’s objectives, participation requirements, data handling procedures, and contact information for the principal investigator, followed by a consent form.\nThe participants were asked to confirm their agreement to participate by clicking “I agree” on the consent form. Selecting this option to express informed consent redirected participants to another form containing the assessment measures used as part of this study. Participants remained anonymous and could withdraw from the study at any time before data analysis by contacting the principal investigator through email as described in the PIS. The online survey used in this study was designed and implemented in accordance with the CHERRIES (Checklist for Reporting Results of Internet E-Surveys [\nCHERRIES: Checklist for Reporting Results of Internet E-Surveys.\nIRB: institutional review board.\nAIPsi: Italian Psychoanalytical Association.\nPIS: Participation Information Sheet.\nPPOM: partial proportional odds model.\nSociodemographic information (eg, age, gender, years of education, and marital status) was collected. To assess the preference for CA-based therapy over human being-based clinical interventions, participants were asked to answer the following question: “On a scale from 1 to 5, how willing are you to participate in psychotherapy sessions solely facilitated by artificial intelligence (AI), without any interaction with a human psychologist?” (scores range from 1=not at all to 5=extremely).\nThe Italian adaptation [\nThe Italian translation of the Relationship Questionnaire [\nThe Italian version [\nOriginally developed to assess the comfort of revealing intimate personal details to helping professions, the Fear of Intimacy With Helping Professionals Scale (FIS-HP [\nTo determine sample size, we computed an a priori power analysis for logistic regression using G*Power (version 3.1.9.2; Heinrich-Heine-Universität Düsseldorf) [\nGiven the polytomous and ordinal nature of the dependent variable (ie, willingness to address mental health conditions only via CA-based interventions, assessed using 5 categories that may be ordered according to the level of magnitude), we performed an ordinal logistic regressive model using the polr function in the MASS package of R (R Core Team, 2025), following the procedure described by Liang and Zhan [\nProbabilities of the ordinal response variable were transformed into log-odds via logit function, as shown in\nEquation 1: Logistic transformation of cumulative probabilities.\nIn logistic regression, log-odds indicate the likelihood of being at or below a certain category level relative to being above it. A positive logit value suggests a higher likelihood of being in or below a particular category, while a negative value indicates a higher likelihood of being above that category. To express odds in terms of predicted probabilities, which are often easier to interpret, we used the transformation formula:\nEquation 2: Conversion from log-odds to predicted probabilities.\nWhere P(Y≥j) represents the predicted probability of the dependent variable Y being in or below category level\nEquation 3: Predicted probability for dummy variable (gender).\nWe used the POM, considering the effects of independent variables (IVs) on the dependent variable as equal across all categories. For instance, the OR of each IV is the same for each cut-off – (1) P[Y=1] versus P[Y≥2], (2) P[Y≤2] versus P[Y≥3], (3) P[Y≤3] versus P[Y≥4], and (4) P[Y≤4] versus P[Y≥5]. POM is the most frequently used logistic regression model for analyzing ordinal response variables [\nTo test the proportional odds assumption (or parallel line assumption), we conducted the Brant test via the Brant R package [\nOut of 876 students, 736 students (84.01% respondents) aged 18 to 85 years completed the survey. As outliers increase data variability and decrease statistical power, 1 participant (male, age 85 y) was manually removed. The final sample consisted of 735 participants (191 males, 25.98%; 543 females, 73.88%; and 1 missing) with a mean age of 27.69 (SD 12.31) years. The single case with missing gender data was handled using multiple imputation, ensuring that no data were excluded from the analyses due to this missing value. Although the age range of the sample was broad (18‐85 y), the distribution was moderately right-skewed, with a median age of 24 (IQR 19‐31) years, reflecting the student population from which the sample was drawn. The majority (n=561, 76.36%) were single or in a nonserious relationship, and the remaining 414 (56.3%) were married or in a stable union. On average, participants had 13.84 (SD 3.50) years of education. A total of 76 individuals (10.30%) reported a previous mental health condition, such as anxiety or depression; 127 (17.3%) reported frequent substance use (≥3 times/week) without meeting the criteria for abuse or dependence.\nThe results of the Brant test show that the overall test fails, and the parallel line assumption is not satisfied (\nAfter partially lifting the restriction, both PNOM and PPOM were models found to fit data correctly and may be useful to explain them. To identify the best solution for this purpose, we compared NPOM and PPOM by using residual deviance, which may be considered a measure of discrepancy of a generalized linear model from real observed data [\nOR: odds ratio.\nETCMQ: Epistemic Trust, Credulity and Mistrust Questionnaire.\nPID5−BF: Personality Inventory for DSM-5—Brief Form—Adult.\nRQ: Relationship Questionnaire.\nFIS-HP: Fear of Intimacy with Helping Professionals Scale\nLogit link values represent log-odds coefficients from the ordinal logistic regression model, indicating the effect of each predictor on the likelihood of expressing greater willingness to engage in conversational agent–based therapy (measured on a 5-point ordinal scale). Positive coefficients indicate a higher probability of choosing more favorable response categories (e.g., “somewhat willing” or “extremely willing”), while negative coefficients reflect a tendency toward lower willingness.\nETCMQ: Epistemic Trust, Credulity and Mistrust Questionnaire.\nPID5−BF: Personality Inventory for DSM-5—Brief Form—Adult.\nRQ: Relationship Questionnaire.\nFIS-HP: Fear of Intimacy with Helping Professionals Scale\nETCMQ: Epistemic Trust, Credulity and Mistrust Questionnaire.\nPID-5BF: Personality Inventory for DSM-5—Brief Form—Adult.\nRQ: Relationship Questionnaire.\nFIS-HP: Fear of Intimacy with Helping Professionals Scale\nOverall, our data showed that epistemic trust emerged as a strong predictor of willingness to rely on CA-based therapy. Higher levels of epistemic trust significantly increased the likelihood of choosing AI-mediated therapy (OR 1.745, 95% CI 1.10‐1.41;\nThis study examined the psychological and demographic factors influencing individuals’ preferences for conversational agent (CA)-based therapy over traditional human-mediated interventions. Using robust statistical approaches, we identified significant predictors, including epistemic trust, attachment styles, personality traits, fear of intimacy, and demographic factors such as gender and education. More specifically, greater epistemic trust significantly increased individuals’ willingness to engage with CA-based mental health therapy, highlighting its central role as a precondition for trusting AI-mediated support. Higher levels of fear of intimacy, particularly fear of sharing personal information, also predicted a preference for CA-based support, suggesting that individuals who feel emotionally vulnerable or threatened by interpersonal closeness may gravitate toward less socially demanding therapeutic tools. Personality traits such as detachment and psychoticism were also associated with greater willingness to use AI-mediated therapy, reflecting a preference for emotionally distant or unconventional interaction styles. Attachment styles showed more nuanced effects: individuals with avoidant attachment (both dismissing and fearful) were less inclined to engage in traditional human-based therapy, indirectly favoring CA-based interventions. Demographic predictors such as being single and having a higher level of education further contributed to increased willingness to use CA-based mental health support. These findings align with broader trends in the literature. Recent studies demonstrate that user trust in AI mental health tools is influenced not only by personal traits but also by perceptions of safety, anonymity, and emotional support [\nThe results underscored the centrality of epistemic trust in shaping individuals’ willingness to engage with CA-based therapy. Higher epistemic trust significantly predicted a greater preference for CAs (OR 1.745; 95% CI 1.31–2.32;\nAttachment styles, particularly avoidant patterns, emerged as significant predictors of CA-based therapy preference. Individuals with dismissing and fearful attachment styles were less likely to engage with traditional human therapists, likely due to discomfort with emotional intimacy and vulnerability. These findings align with Bartholomew and Horowitz’s [\nPersonality traits, particularly negative affectivity, detachment, and psychoticism, were significant predictors of willingness to engage with CA-based therapy. These traits reflect tendencies toward emotional dysregulation, social withdrawal, and unconventional thinking, which may drive preferences for less interpersonal forms of therapy. The findings align with Marengo et al [\nDemographic factors, including gender, education, and relationship status, also played a role in shaping preferences for CA-based therapy. While gender differences were not statistically significant, the trend suggested that men were slightly more inclined toward AI therapy than women. This aligns with previous findings suggesting that men are generally more open to adopting new technologies [\nThe findings have several practical and ethical implications. First, they highlight the need for CA-based therapies to be designed with sensitivity to individual differences, particularly attachment styles and personality traits. For instance, individuals with high detachment may benefit from interventions that gradually build emotional engagement, while those with high epistemic trust may prioritize transparency and reliability in AI responses. Based on these findings, we recommend that developers incorporate adaptive interaction styles into CA systems, such as pacing strategies, tailored disclosure prompts, and emotionally neutral yet supportive communication styles, to accommodate users who struggle with emotional closeness or fear of judgment. Second, our results underscore the importance of addressing the potential risks associated with CA-based therapy. While these technologies offer valuable alternatives, particularly for individuals who struggle with traditional therapy, they also carry risks of overreliance and reduced critical thinking [\nThis study offered a novel contribution to the emerging field of digital mental health by focusing not only on the technological acceptability of CAs, but also on the psychological determinants that underpin individual preferences for AI-mediated therapy. While previous research has highlighted user satisfaction, perceived usefulness, or the technical capabilities of CAs, relatively little attention has been paid to why certain individuals are more psychologically predisposed to prefer AI over human interaction in therapeutic contexts. By integrating constructs such as epistemic trust, fear of intimacy, attachment style, and maladaptive personality traits, this study provides a more comprehensive and person-centered model of CA engagement. This approach fills a critical gap in the literature and offers clinically relevant insights for tailoring CA-based interventions to the psychological needs and vulnerabilities of different user profiles. Nonetheless, while providing valuable insights, this study is not without limitations. The sample was drawn from a specific population (university students), which may limit the generalizability of the findings. More specifically, the participants were all enrolled in a psychology degree program, which likely reflects a cohort that is highly educated, psychologically literate, and potentially more open to digital therapeutic tools than the general population. This homogeneity may have biased responses toward higher levels of epistemic trust and engagement with AI, which could inflate associations between psychological variables and preference for CA-based therapy. As noted in broader critiques of online survey methodology (eg, Andrade [\nThis study contributes to the growing literature on AI-mediated mental health interventions by identifying key psychological and demographic predictors of preferences for CA-based therapy. The findings emphasize the importance of epistemic trust, attachment styles, personality traits, and demographic factors in shaping attitudes toward AI in mental health care. While these technologies offer promising alternatives to traditional therapy, their integration must be approached with caution to ensure ethical and effective mental health support. Future research should continue to explore the dynamic interactions between individual differences and technological features, paving the way for personalized and equitable mental health interventions.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "39627547", "pmcid": "12298950", "title": "The Association Between Identity Functioning and Personality Pathology in Female Patients with Eating Disorders", "publication_year": "N/A", "abstract": "Aims. In the present study, we investigated the associations between the three identity dimensions of Kaufman (Consolidated Identity, Disturbed Identity, Lack of Identity) and symptoms of personality disorders (PDs) in 176 female inpatients with an eating disorder (ED). We examined five aspects: the prevalence of categorical PD diagnoses in patients with EDs; the relationship between dimensional PD scores and identity dimensions as well as their relationships with age and ED subtype; and the unique variance in dimensional PD scores explained by identity dimensions, while controlling for age and ED subtype. Methods. To assess identity functioning, we made use of the Self-Concept and Identity Measure, and to assess PDs, we used the categorical and dimensional scores of the Assessment of DSM-IV Personality Disorders. Results. The findings showed that the avoidant, obsessive–compulsive, and borderline categorical PDs were the most frequently reported PDs. Age was negatively related to all Cluster B PDs and Disturbed Identity, and binge-eating/purging ED patients reported significantly more Cluster B PD features compared to restrictive ED patients. ED subtype and identity dimensions were unrelated. Correlational analysis showed that all dimensional PD scores were positively related to Disturbed Identity and Lack of Identity and negatively related to Consolidated Identity. The results of the hierarchical regression analyses showed that Cluster A PDs were significantly predicted by Lack of Identity, controlled for age and ED subtype. Additionally, Cluster B PDs were significantly predicted by Disturbed Identity. Finally, two of the three cluster C PDs were predicted by Lack of Identity (avoidant and obsessive–compulsive PD), whereas the dependent PD was explained by Disturbed Identity. Conclusions. The co-occurrence of identity issues in both PDs and EDs underscores the role of identity as a transdiagnostic feature. Accordingly, using identity-based interventions in treatment may have broad therapeutic benefits across these disorders.", "full_text": "Understanding the associations between identity functioning and personality disorders (PDs) in eating disorders (EDs) offers critical insights into the co-occurrence of these complex conditions. Identity disturbance not only underpins many of the core features of EDs but also serves as a bridge linking EDs to co-occurring personality pathology. In the present study, we will investigate the prevalence of categorical PDs in patients with EDs, examine the associations between identity functioning and dimensional PD scores as well as their relationships with age and ED subtype, and research the unique variance that identity dimensions can explain in dimensional PD scores (while controlling for age and ED subtype).\nIn Erikson’s [\nTo advance the study of identity in both community and clinical populations, Kaufman et al. [\nBruch [\nNumerous empirical studies have shown that individuals with eating disorders (EDs) exhibit greater identity confusion, and that maladaptive identity functioning is positively correlated with ED symptom severity [\nGiven the high prevalence of identity disturbances among individuals with eating disorders (EDs) and their established association with personality disorders (PDs) [\nBy subtype, individuals with ED binge/purge type (ED-BP) show higher rates of Cluster B PDs, especially the borderline PD, compared to restrictive-type ED (ED-R) patients [\nWhile identity disturbance is a diagnostic criterion for the borderline PD, the Alternative Model for Personality Disorders (AMPD) in DSM-5 Section III [\nTo date, only two studies have examined identity impairments—as conceptualized by Kaufman [\nSecond, Tressova et al. [\nThe present study aimed to examine the prevalence of categorical PDs in patients with EDs and was the first to investigate the associations between identity functioning, as conceptualized by Kaufman et al. [\nSecond, we investigated whether age and ED subtype—restrictive (ED-R) versus binge/purge (ED-BP)—were associated with dimensional symptom scores of PDs. Prior research in ED populations has demonstrated significantly negative associations between age and PD symptoms, with younger individuals typically exhibiting more pronounced PD traits [\nThird, we explored associations between age, ED subtype, and Kaufman’s et al. [\nFourth, we examined associations between the three identity dimensions and the dimensional symptom scores of PDs, by controlling for age and ED subtype. Consistent with the existing literature [\nFifth, we investigated the unique contribution of each identity dimension to the variance in dimensional symptoms scores of PDs while controlling for age and ED subtype. Specifically, we expected that Cluster A PDs would be primarily predicted by Lack of Identity, whereas Cluster B PDs would be significantly associated with Disturbed Identity [\nData were collected from the clinical records of female inpatients treated at a specialized unit for EDs in Flanders (Belgium). The current sample included 176 female inpatients (age ≥ 18 years), of whom 46 (26.1%) were diagnosed as AN-R, 16 as AN-BP (9.1%), 23 as BN (13.1%), 8 (4.5%) as BED, and 83 (47.2%) as EDNOS by means of the EDI-3 Symptom Checklist (EDI-3 SC) [\nPatients gave written informed consent and permission to the pseudonymized use of their data for research purposes by signing an informed consent form at admission and before filling out the questionnaires on the PC. This procedure was approved by the medical–ethical committee of the clinic and the Social and Societal Ethics Committee of KU Leuven. Patients were not compensated for their participation in this study.\nAll ED patients completed the Self-Concept and Identity Measure (SCIM [\nThe Self-Concept and Identity Measure (SCIM [\nThe Assessment of DSM-IV Personality Disorders (ADP-IV [\nAll analyses were performed by means of the program SPSS, version 29. First, to determine the prevalence of the categorical PDs in our ED sample, we calculated the number (percentages) of the patients who met the diagnostic criteria of the 10 categorical PDs. Second, we calculated the descriptive statistics of the dimensional symptom scores of PDs. To investigate the association between the dimensional symptom scores of PDs and age, we calculated the Pearson correlation coefficients. To investigate whether the dimensional symptoms scores of PDs differed between ED subtype (ED-R vs. ED-BP), we performed a MANOVA with the dimensional symptom scores of PDs as dependent variables and ED subtype as independent variable. Third, to investigate the descriptive statistics of the three SCIM identity scales, we calculated the means and standard deviations of the three scales. Associations between the SCIM scales and age were calculated by means of the Pearson correlation coefficients. To investigate differences in the three SCIM scales between ED subtype, we performed a MANOVA with the SCIM scales as dependent variables and ED subtype as independent variable. Fourth, to determine the associations between the three SCIM identity scales and the dimensional symptom scores of PDs (controlled for age and ED subtype depending on the outcomes of the prior analyses), we calculated partial correlations. Hemphill [\nThe prevalence rates of the categorical PDs in our ED sample are displayed in\nThe means (standard deviations) of the dimensional symptom scores of PDs are shown in\nThe mean scores on the three SCIM identity scale scores are displayed in\nThe partial correlations between the three SCIM identity scales and the dimensional PD scales (controlled for age and ED subtype (ED-R vs. ED-BP);\nThe results of the hierarchical regression analyses with the dimensional PD scales as dependent variables are displayed in\nConcerning Cluster A PDs, Lack of Identity positively predicted the dimensional scores of all three Cluster A PDs (paranoid, schizoid, and schizotypal), while controlling for age, ED subtype, and the other SCIM scales. Regarding Cluster B PDs, age was significantly negatively related to the dimensional scores of all Cluster B PDs (step 1), indicating that Cluster B PDs are more frequently reported by younger female patients with an ED. After controlling for age, ED subtype also significantly predicted the dimensional scores of three out of four Cluster B PDs (excluding the narcissistic PD), suggesting that Cluster B PDs are more prevalent in patients with binge-eating/purging-type EDs compared to restrictive-type EDs. Furthermore, Disturbed Identity positively predicted unique variance in all dimensional Cluster B PDs, after controlling for age and ED subtype. Additionally, the dimensional borderline PD was also positively predicted by Lack of Identity, and the narcissistic PD by Consolidated Identity. Finally, for Cluster C PDs, the dependent PD was significantly positively predicted by Disturbed Identity, whereas the avoidant and obsessive–compulsive PDs were significantly predicted by Lack of Identity, in line with the findings for Cluster A PDs.\nGiven the high comorbidity between eating disorders (EDs) and personality disorders (PDs) [\nIn line with prior research [\nIn line with previous research, we observed significant negative associations between age and dimensional scores of all Cluster B PDs, as well as the dependent PD [\nAs hypothesized and in line with prior findings [\nIn line with earlier research, Disturbed Identity and Lack of Identity were significantly positively associated with nearly all dimensional scores of PDs, except the narcissistic and histrionic PDs, which were not significantly correlated with Lack of Identity. Conversely, Consolidated Identity was negatively associated with most dimensional scores of PDs, supporting its role as a protective factor [\nFinally, when predicting PD symptoms controlled for age and ED subtype, Lack of Identity significantly predicted all Cluster A PDs (paranoid, schizoid, and schizotypal) and two Cluster C PDs (avoidant and obsessive–compulsive). These PDs are characterized by impaired identity integration. In Cluster A PDs, identity is often fragmented or unintegrated, resulting in bizarre thoughts, social withdrawal, and suspiciousness. As individuals with Cluster A PDs often present with a psychotic personality structure [\nAll dimensional Cluster B PDs scores were predicted by Disturbed Identity, typically expressed through a fluctuating self-image, externalized self-worth, and fragmented internal cohesion [\nFinally, the dependent PD was also predicted by Disturbed Identity alone, suggesting a failure in the individuation processes, resulting in an identity excessively reliant on close relationships and vulnerable to interpersonal disruptions [\nWhen considering age, ED subtype, and identity dimensions, the proportion of explained variance in PD scores ranged from R\nThe co-occurrence of identity disturbance in both PDs and EDs underscores its role as a transdiagnostic feature. Given its central role, identity disturbance can be considered a valuable treatment target in both PDs and EDs. Schema therapy (ST), for example, addresses maladaptive schemas underlying identity disturbance, helping patients develop a more integrated and stable sense of self; it has shown efficacy for both PDs and chronic EDs [\nThe present cross-sectional study examining the association between identity dimensions and dimensional scores of PDs in female patients with an ED via self-report measures presents several limitations that warrant consideration. These limitations pertain to the sample and the methodological constraints inherent in self-report designs and the cross-sectional nature of the study, which collectively impact the interpretability and generalizability of the findings. The exclusive focus on a female inpatient sample limits the generalizability of the findings to male patients and individuals receiving outpatient treatment. Additionally, EDNOS represents a heterogeneous category, and collapsing it into restrictive versus binge/purge groups may mask important clinical differences. Furthermore, we did not have access to patients’ medical files and therefore lacked information on detailed sociodemographic variables as well as physical and psychological comorbidities, which should be addressed in future studies. Finally, as most participants were White and from Western backgrounds (i.e., Flemish), the findings may not be generalizable to individuals from other ethnic, cultural, or regional groups. The reliance on self-report measures introduces susceptibility to social desirability bias and may be particularly problematic in individuals with EDs and comorbid personality disorders, who may have impaired introspective capacity [\nIn sum, the co-occurrence of identity issues in both PDs and EDs underscores its role as a transdiagnostic feature. Addressing identity issues in treatment may therefore have broad therapeutic benefits across these disorders.", "content_for_embedding": "Understanding the associations between identity functioning and personality disorders (PDs) in eating disorders (EDs) offers critical insights into the co-occurrence of these complex conditions. Identity disturbance not only underpins many of the core features of EDs but also serves as a bridge linking EDs to co-occurring personality pathology. In the present study, we will investigate the prevalence of categorical PDs in patients with EDs, examine the associations between identity functioning and dimensional PD scores as well as their relationships with age and ED subtype, and research the unique variance that identity dimensions can explain in dimensional PD scores (while controlling for age and ED subtype).\nIn Erikson’s [\nTo advance the study of identity in both community and clinical populations, Kaufman et al. [\nBruch [\nNumerous empirical studies have shown that individuals with eating disorders (EDs) exhibit greater identity confusion, and that maladaptive identity functioning is positively correlated with ED symptom severity [\nGiven the high prevalence of identity disturbances among individuals with eating disorders (EDs) and their established association with personality disorders (PDs) [\nBy subtype, individuals with ED binge/purge type (ED-BP) show higher rates of Cluster B PDs, especially the borderline PD, compared to restrictive-type ED (ED-R) patients [\nWhile identity disturbance is a diagnostic criterion for the borderline PD, the Alternative Model for Personality Disorders (AMPD) in DSM-5 Section III [\nTo date, only two studies have examined identity impairments—as conceptualized by Kaufman [\nSecond, Tressova et al. [\nThe present study aimed to examine the prevalence of categorical PDs in patients with EDs and was the first to investigate the associations between identity functioning, as conceptualized by Kaufman et al. [\nSecond, we investigated whether age and ED subtype—restrictive (ED-R) versus binge/purge (ED-BP)—were associated with dimensional symptom scores of PDs. Prior research in ED populations has demonstrated significantly negative associations between age and PD symptoms, with younger individuals typically exhibiting more pronounced PD traits [\nThird, we explored associations between age, ED subtype, and Kaufman’s et al. [\nFourth, we examined associations between the three identity dimensions and the dimensional symptom scores of PDs, by controlling for age and ED subtype. Consistent with the existing literature [\nFifth, we investigated the unique contribution of each identity dimension to the variance in dimensional symptoms scores of PDs while controlling for age and ED subtype. Specifically, we expected that Cluster A PDs would be primarily predicted by Lack of Identity, whereas Cluster B PDs would be significantly associated with Disturbed Identity [\nData were collected from the clinical records of female inpatients treated at a specialized unit for EDs in Flanders (Belgium). The current sample included 176 female inpatients (age ≥ 18 years), of whom 46 (26.1%) were diagnosed as AN-R, 16 as AN-BP (9.1%), 23 as BN (13.1%), 8 (4.5%) as BED, and 83 (47.2%) as EDNOS by means of the EDI-3 Symptom Checklist (EDI-3 SC) [\nPatients gave written informed consent and permission to the pseudonymized use of their data for research purposes by signing an informed consent form at admission and before filling out the questionnaires on the PC. This procedure was approved by the medical–ethical committee of the clinic and the Social and Societal Ethics Committee of KU Leuven. Patients were not compensated for their participation in this study.\nAll ED patients completed the Self-Concept and Identity Measure (SCIM [\nThe Self-Concept and Identity Measure (SCIM [\nThe Assessment of DSM-IV Personality Disorders (ADP-IV [\nAll analyses were performed by means of the program SPSS, version 29. First, to determine the prevalence of the categorical PDs in our ED sample, we calculated the number (percentages) of the patients who met the diagnostic criteria of the 10 categorical PDs. Second, we calculated the descriptive statistics of the dimensional symptom scores of PDs. To investigate the association between the dimensional symptom scores of PDs and age, we calculated the Pearson correlation coefficients. To investigate whether the dimensional symptoms scores of PDs differed between ED subtype (ED-R vs. ED-BP), we performed a MANOVA with the dimensional symptom scores of PDs as dependent variables and ED subtype as independent variable. Third, to investigate the descriptive statistics of the three SCIM identity scales, we calculated the means and standard deviations of the three scales. Associations between the SCIM scales and age were calculated by means of the Pearson correlation coefficients. To investigate differences in the three SCIM scales between ED subtype, we performed a MANOVA with the SCIM scales as dependent variables and ED subtype as independent variable. Fourth, to determine the associations between the three SCIM identity scales and the dimensional symptom scores of PDs (controlled for age and ED subtype depending on the outcomes of the prior analyses), we calculated partial correlations. Hemphill [\nThe prevalence rates of the categorical PDs in our ED sample are displayed in\nThe means (standard deviations) of the dimensional symptom scores of PDs are shown in\nThe mean scores on the three SCIM identity scale scores are displayed in\nThe partial correlations between the three SCIM identity scales and the dimensional PD scales (controlled for age and ED subtype (ED-R vs. ED-BP);\nThe results of the hierarchical regression analyses with the dimensional PD scales as dependent variables are displayed in\nConcerning Cluster A PDs, Lack of Identity positively predicted the dimensional scores of all three Cluster A PDs (paranoid, schizoid, and schizotypal), while controlling for age, ED subtype, and the other SCIM scales. Regarding Cluster B PDs, age was significantly negatively related to the dimensional scores of all Cluster B PDs (step 1), indicating that Cluster B PDs are more frequently reported by younger female patients with an ED. After controlling for age, ED subtype also significantly predicted the dimensional scores of three out of four Cluster B PDs (excluding the narcissistic PD), suggesting that Cluster B PDs are more prevalent in patients with binge-eating/purging-type EDs compared to restrictive-type EDs. Furthermore, Disturbed Identity positively predicted unique variance in all dimensional Cluster B PDs, after controlling for age and ED subtype. Additionally, the dimensional borderline PD was also positively predicted by Lack of Identity, and the narcissistic PD by Consolidated Identity. Finally, for Cluster C PDs, the dependent PD was significantly positively predicted by Disturbed Identity, whereas the avoidant and obsessive–compulsive PDs were significantly predicted by Lack of Identity, in line with the findings for Cluster A PDs.\nGiven the high comorbidity between eating disorders (EDs) and personality disorders (PDs) [\nIn line with prior research [\nIn line with previous research, we observed significant negative associations between age and dimensional scores of all Cluster B PDs, as well as the dependent PD [\nAs hypothesized and in line with prior findings [\nIn line with earlier research, Disturbed Identity and Lack of Identity were significantly positively associated with nearly all dimensional scores of PDs, except the narcissistic and histrionic PDs, which were not significantly correlated with Lack of Identity. Conversely, Consolidated Identity was negatively associated with most dimensional scores of PDs, supporting its role as a protective factor [\nFinally, when predicting PD symptoms controlled for age and ED subtype, Lack of Identity significantly predicted all Cluster A PDs (paranoid, schizoid, and schizotypal) and two Cluster C PDs (avoidant and obsessive–compulsive). These PDs are characterized by impaired identity integration. In Cluster A PDs, identity is often fragmented or unintegrated, resulting in bizarre thoughts, social withdrawal, and suspiciousness. As individuals with Cluster A PDs often present with a psychotic personality structure [\nAll dimensional Cluster B PDs scores were predicted by Disturbed Identity, typically expressed through a fluctuating self-image, externalized self-worth, and fragmented internal cohesion [\nFinally, the dependent PD was also predicted by Disturbed Identity alone, suggesting a failure in the individuation processes, resulting in an identity excessively reliant on close relationships and vulnerable to interpersonal disruptions [\nWhen considering age, ED subtype, and identity dimensions, the proportion of explained variance in PD scores ranged from R\nThe co-occurrence of identity disturbance in both PDs and EDs underscores its role as a transdiagnostic feature. Given its central role, identity disturbance can be considered a valuable treatment target in both PDs and EDs. Schema therapy (ST), for example, addresses maladaptive schemas underlying identity disturbance, helping patients develop a more integrated and stable sense of self; it has shown efficacy for both PDs and chronic EDs [\nThe present cross-sectional study examining the association between identity dimensions and dimensional scores of PDs in female patients with an ED via self-report measures presents several limitations that warrant consideration. These limitations pertain to the sample and the methodological constraints inherent in self-report designs and the cross-sectional nature of the study, which collectively impact the interpretability and generalizability of the findings. The exclusive focus on a female inpatient sample limits the generalizability of the findings to male patients and individuals receiving outpatient treatment. Additionally, EDNOS represents a heterogeneous category, and collapsing it into restrictive versus binge/purge groups may mask important clinical differences. Furthermore, we did not have access to patients’ medical files and therefore lacked information on detailed sociodemographic variables as well as physical and psychological comorbidities, which should be addressed in future studies. Finally, as most participants were White and from Western backgrounds (i.e., Flemish), the findings may not be generalizable to individuals from other ethnic, cultural, or regional groups. The reliance on self-report measures introduces susceptibility to social desirability bias and may be particularly problematic in individuals with EDs and comorbid personality disorders, who may have impaired introspective capacity [\nIn sum, the co-occurrence of identity issues in both PDs and EDs underscores its role as a transdiagnostic feature. Addressing identity issues in treatment may therefore have broad therapeutic benefits across these disorders.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "39577484", "pmcid": "12302815", "title": "ADHD and Suicide Risk: The Overlooked Roles of Comorbid Disorders and Stimulant Medications", "publication_year": "2025", "abstract": "Does Attention Deficit Hyperactivity Disorder (ADHD) increase the risk of suicidality among children? This article critically examines a notable study by", "full_text": "Does Attention Deficit Hyperactivity Disorder (ADHD) – the most common neurodevelopmental diagnosis in children (\n“The results revealed that elevated hyperactivity scores, surpassing the ADHD diagnosis threshold, were significantly associated with increased rates of suicidal behavior. Hyperactivity demonstrated a stronger association with lifetime suicide attempts compared to inattention. Moreover, children's self-reported ADHD symptoms exhibited a stronger correlation with suicide attempts than parental reports. This study highlights the critical role of hyperactivity in understanding suicidal behaviors among children with ADHD. It underscores the importance of considering hyperactivity-related symptoms in assessment and treatment approaches for suicidal behavior in this population.”\nIn this article, I discuss the study by\nDespite the significance of these concerns, my formal commentary on this study was rejected by the\nThe analysis of the study by Shahnovsky et al. begins with a close inspection of its methodology, followed by an analysis of its findings later in this article. As implied above, the study focused on testing direct links between characteristics of ADHD (inattention and hyperactivity) and suicide risk (suicide attempts and suicide behaviors). Such an approach, which emphasizes simple, unidimensional relationships between two variables, is accep in pioneering studies exploring phenomena that have not been previously investigated. However, when building on existing literature, it is essential to consider factors that are already well-documented.\nIn the case of the relationship between ADHD and suicidality, two key variables extensively discussed in the literature are the presence of comorbid disorders and the use of common medications prescribed for ADHD (\nPrevious studies linking ADHD to suicidality have consistently noted that, in most cases, the risk of suicide is better explained by the presence of other psychiatric disorders (\nIn the case of ADHD, this conflation – attributing suicidality to the disorder’s core characteristics (e.g., hyperactivity) – is well illustrated in a systematic review by Balaz and Kereszteny (Balazs & Kereszteny, 2017). In this review, the relationship between ADHD and suicide risk was frequently mediated by other psychiatric conditions. In fact, the authors of this review previously reported that the correlation between ADHD symptoms and suicide risk was entirely mediated by symptoms of other disorders (\nThis issue seems to concern Shanhovsky et al. as well. In the limitations section of their article, they acknowledge that “\nThis discrepancy between the two studies raises critical questions about the validity of attributing suicidality directly to ADHD. Why did the authors not integrate their own findings from the earlier study, which was based on overlapping data and essentially highlighted the importance of accounting for comorbidities? Additionally, how should we interpret the current findings of a positive relationship between hyperactivity and suicide risk when, in their previous study, the authors found\nA further, and perhaps more troubling, methodological gap in the study by Shanhovsky et al. concerns the potential contribution of psychiatric medications in general, and the first-line pharmacological treatment for ADHD in particular, to the observed suicide risk. Could the reported increased risk in this study be not a consequence of the diagnosis itself, but rather an unintended effect of the stimulant medications commonly prescribed as its treatment of choice (\nIndeed, the limitation section of the article by Shahnovsky et al. acknowledges that they “\nMoreover, the discussion of antidepressants in the limitations section may be less relevant for children aged 7–12, compared with the potential contribution of stimulants – the first-line treatment for ADHD – which was not mentioned in this section. As documented in the authors’ “separate study,” antidepressants were used by 58.6% of adolescents but only 15% of children. By contrast, stimulants were used by 22.5% of children and 13.5% of adolescents. This suggests that stimulants are more pertinent to the current study, which focuses on the link between hyperactivity and suicidality in young children.\nNot only was this straightforward possibility left unexamined, but the authors also state in their introduction: “It is now well established that significant associations exist between ADHD and suicidal behavior and that stimulant medications may help attenuate this link” (bold added). Before addressing the specific source they cite to support this claim, it is important to consider the broader context of the literature, which is, at best, inconclusive – and at worst, suggestive of a negative impact, as will be demonstrated in the following section. For instance, a 2020 meta-analysis examining a range of functional outcomes of ADHD medications identified two studies on suicidality (\nThe sole source cited by the authors to substantiate their claim regarding the protective effects of ADHD medications on suicidality is a study by\nI admit that I can understand the confusion regarding this source, as Shoval et al. also reported an interaction effect, which they interpreted as suggesting that “in children with substantial externalizing symptoms, ADHD medication use may be associated with less suicidality.” However, this interpretation does not negate the negative main effect of the medications on suicidality, and it is likely inaccurate.\nThis interpretation hinges on the observation that the association between externalizing symptoms and suicidality remained significant only among children who did not receive ADHD medications (\nThe study by Shoval et al. is, of course, not the only one to find a connection between ADHD medications and an increased risk of suicidality. For example, a large-scale study conducted in the Netherlands found that adults aged 18–40 who started using methylphenidate were twice as likely to attempt suicide compared to a control group with similar demographics (\nNotably, the risk associated with the medications, according to this UK study, was particularly high among young children (11–14) – a group similar in age to the very young children (7–12) examined in the study by Shanhovsky et al. While the absolute risk of death by suicide in this age group was very low (as suicide deaths are extremely rare at such young ages), the relative differences within this low-risk group were striking. In the UK study, young children who used stimulant medications were nearly 162 times more likely to die by suicide compared to those who did not (\nThis troubling figure may stem from the relatively common occurrence of suicidal thoughts triggered by these medications. Indeed, even small-scale experimental studies have reported suicidal ideation or behaviors as adverse outcomes of these treatments (e.g.,\nMoreover, ADHD medications, such as methylphenidate, may also contribute to suicidal ideation through their well-documented depression-related effects (\nHaving addressed the critical methodological gaps in the study by Shahnovsky et al., it is equally important to examine its actual findings and evaluate the extent to which they support the broader narrative linking ADHD symptoms to suicide risk. Below is a summary of the findings reported in the study:\nChildren's self-reported hyperactivity was significantly related to lifetime suicide attempts.\nChildren's self-reported inattention was not significantly related to lifetime suicide attempts.\nChildren's self-reported inattention and hyperactivity were not significantly related to suicide behaviors (though the authors note they approached significance).\nParental reports of both hyperactivity and inattention were not significantly related to lifetime suicide attempts.\nParental reports of both hyperactivity and inattention were not significantly related to suicide behaviors.\nAs this summary shows, ADHD symptoms were largely unrelated to suicide risk. The only significant finding, which linked hyperactivity (but not inattention) to past suicide attempts (but not suicidal behaviors), was based solely on children’s self-reported responses. This raises a critical question: how can children as young as 7 years old – or even those at the upper end of the age range, 12 years old – reliably evaluate their own levels of hyperactivity or inattention, let alone compare these to standardized clinical thresholds?\nSupporting this reliability concern, the study's concordance test between parent and child reports revealed a “very low level of agreement… suggesting almost no concordance between the children's and parents' reports on ADHD symptoms.” This striking disparity underscores the potential distortion in children’s self-perceptions and further calls into question the reliability of the sole significant result.\nFurthermore, even if the authors' entire set of hypotheses had been statistically confirmed, it is important to recognize that basic symptom measures of hyperactivity and inattention (without the use of broader, standardized assessments) provide an incomplete and potentially misleading picture. This concern is particularly relevant in the case of hyperactivity, which can arise from a wide range of neurodevelopmental, emotional, or situational factors unrelated to ADHD itself.\nTaken together, these predominantly non-significant findings, which rely on unreliable self-reports of very young children, challenge the narrative presented in the study’s abstract (see the opening of this article) and cast serious doubt on the validity of hyperactivity as a critical risk factor for suicidality. In my view, the pattern of results suggests that other variables, likely unrelated to ADHD symptoms as discussed throughout this article, may offer a far more robust and accurate explanation for understanding suicide risk in children.\nAltogether, the actual findings of the study, combined with its omission of critical variables known to increase suicide risk (i.e., comorbid disorders and ADHD medications) and its misinterpretation of previous research (which has essentially documented a troubling link between ADHD medications and suicide risk) (\nThese methodological and interpretative gaps not only limit the study's utility but also risk perpetuating harmful misconceptions. Clinicians might act on its conclusions and prescribe ADHD medications to suppress the supposedly dangerous hyperactivity – medications that were not accounted for in the study and that are well-documented to increase depression and suicide risk (as shown throughout the current article).\nTo avoid such potential harm, and to advance the field of suicidology in children, future research would benefit from a more nuanced and comprehensive approach. Assessments that include both comorbid conditions and negative effects of medications are essential to disentangle the complex relationship between ADHD, its treatments, and suicidality. In my view, addressing these gaps could bring us closer to identifying precise risk factors and developing safe interventions.\nThis recommendation is particularly critical given the growing recognition of the limited validity − and potential risks − of the biomedical framing of ADHD (\nAgainst this broader backdrop, the study by Shahnovsky et al. represents an important opportunity for reflection and constructive dialogue. Despite the critical observations raised throughout this article, please allow me to conclude by commending the authors once again for addressing such a crucial and challenging topic. Their lifelong dedication to advancing suicide prevention is deeply appreciated, and it is in this spirit that I offer these reflections. I hope that this discussion fosters a constructive dialogue that contributes to refining research practices and deepening our understanding of the tragic phenomenon of childhood suicide.\nThis supplementary material provides background on the editorial barriers encountered when attempting to publish the current article in the journal where the original study by\nUpon the publication of the study by Shahnovsky et al., which identified hyperactivity as a significant predictor of suicide attempts, I contacted EJIHPE to request an exception to the journal’s policy that prohibits commentaries and letters critiquing published articles. I argued that such a policy contradicts fundamental scientific norms and impedes open academic discourse. Additionally, I outlined several key concerns – detailed in the main article – regarding the study by Shahnovsky et al.\nFollowing this exchange, I was granted permission and explicitly encouraged to submit a formal commentary. However, despite this initial approval, my submission was later rejected on the grounds that the journal does not accept commentaries. The rejection was accompanied by two justifications:\nThat the study’s objective was “\nThat the study’s limitations section had already addressed most of my concerns.\nBelieving this rationale to be flawed, I appealed the decision, clearly demonstrating that the limitations section did not sufficiently address the key methodological issues I raised and that it even contained certain misrepresentations (as can be seen in the main article). Despite this, my appeal was denied without further justification.\nGiven these circumstances, I felt it was my ethical duty to publish my commentary elsewhere to ensure an open scholarly discussion of the study’s findings and their implications.", "content_for_embedding": "Does Attention Deficit Hyperactivity Disorder (ADHD) – the most common neurodevelopmental diagnosis in children (\n“The results revealed that elevated hyperactivity scores, surpassing the ADHD diagnosis threshold, were significantly associated with increased rates of suicidal behavior. Hyperactivity demonstrated a stronger association with lifetime suicide attempts compared to inattention. Moreover, children's self-reported ADHD symptoms exhibited a stronger correlation with suicide attempts than parental reports. This study highlights the critical role of hyperactivity in understanding suicidal behaviors among children with ADHD. It underscores the importance of considering hyperactivity-related symptoms in assessment and treatment approaches for suicidal behavior in this population.”\nIn this article, I discuss the study by\nDespite the significance of these concerns, my formal commentary on this study was rejected by the\nThe analysis of the study by Shahnovsky et al. begins with a close inspection of its methodology, followed by an analysis of its findings later in this article. As implied above, the study focused on testing direct links between characteristics of ADHD (inattention and hyperactivity) and suicide risk (suicide attempts and suicide behaviors). Such an approach, which emphasizes simple, unidimensional relationships between two variables, is accep in pioneering studies exploring phenomena that have not been previously investigated. However, when building on existing literature, it is essential to consider factors that are already well-documented.\nIn the case of the relationship between ADHD and suicidality, two key variables extensively discussed in the literature are the presence of comorbid disorders and the use of common medications prescribed for ADHD (\nPrevious studies linking ADHD to suicidality have consistently noted that, in most cases, the risk of suicide is better explained by the presence of other psychiatric disorders (\nIn the case of ADHD, this conflation – attributing suicidality to the disorder’s core characteristics (e.g., hyperactivity) – is well illustrated in a systematic review by Balaz and Kereszteny (Balazs & Kereszteny, 2017). In this review, the relationship between ADHD and suicide risk was frequently mediated by other psychiatric conditions. In fact, the authors of this review previously reported that the correlation between ADHD symptoms and suicide risk was entirely mediated by symptoms of other disorders (\nThis issue seems to concern Shanhovsky et al. as well. In the limitations section of their article, they acknowledge that “\nThis discrepancy between the two studies raises critical questions about the validity of attributing suicidality directly to ADHD. Why did the authors not integrate their own findings from the earlier study, which was based on overlapping data and essentially highlighted the importance of accounting for comorbidities? Additionally, how should we interpret the current findings of a positive relationship between hyperactivity and suicide risk when, in their previous study, the authors found\nA further, and perhaps more troubling, methodological gap in the study by Shanhovsky et al. concerns the potential contribution of psychiatric medications in general, and the first-line pharmacological treatment for ADHD in particular, to the observed suicide risk. Could the reported increased risk in this study be not a consequence of the diagnosis itself, but rather an unintended effect of the stimulant medications commonly prescribed as its treatment of choice (\nIndeed, the limitation section of the article by Shahnovsky et al. acknowledges that they “\nMoreover, the discussion of antidepressants in the limitations section may be less relevant for children aged 7–12, compared with the potential contribution of stimulants – the first-line treatment for ADHD – which was not mentioned in this section. As documented in the authors’ “separate study,” antidepressants were used by 58.6% of adolescents but only 15% of children. By contrast, stimulants were used by 22.5% of children and 13.5% of adolescents. This suggests that stimulants are more pertinent to the current study, which focuses on the link between hyperactivity and suicidality in young children.\nNot only was this straightforward possibility left unexamined, but the authors also state in their introduction: “It is now well established that significant associations exist between ADHD and suicidal behavior and that stimulant medications may help attenuate this link” (bold added). Before addressing the specific source they cite to support this claim, it is important to consider the broader context of the literature, which is, at best, inconclusive – and at worst, suggestive of a negative impact, as will be demonstrated in the following section. For instance, a 2020 meta-analysis examining a range of functional outcomes of ADHD medications identified two studies on suicidality (\nThe sole source cited by the authors to substantiate their claim regarding the protective effects of ADHD medications on suicidality is a study by\nI admit that I can understand the confusion regarding this source, as Shoval et al. also reported an interaction effect, which they interpreted as suggesting that “in children with substantial externalizing symptoms, ADHD medication use may be associated with less suicidality.” However, this interpretation does not negate the negative main effect of the medications on suicidality, and it is likely inaccurate.\nThis interpretation hinges on the observation that the association between externalizing symptoms and suicidality remained significant only among children who did not receive ADHD medications (\nThe study by Shoval et al. is, of course, not the only one to find a connection between ADHD medications and an increased risk of suicidality. For example, a large-scale study conducted in the Netherlands found that adults aged 18–40 who started using methylphenidate were twice as likely to attempt suicide compared to a control group with similar demographics (\nNotably, the risk associated with the medications, according to this UK study, was particularly high among young children (11–14) – a group similar in age to the very young children (7–12) examined in the study by Shanhovsky et al. While the absolute risk of death by suicide in this age group was very low (as suicide deaths are extremely rare at such young ages), the relative differences within this low-risk group were striking. In the UK study, young children who used stimulant medications were nearly 162 times more likely to die by suicide compared to those who did not (\nThis troubling figure may stem from the relatively common occurrence of suicidal thoughts triggered by these medications. Indeed, even small-scale experimental studies have reported suicidal ideation or behaviors as adverse outcomes of these treatments (e.g.,\nMoreover, ADHD medications, such as methylphenidate, may also contribute to suicidal ideation through their well-documented depression-related effects (\nHaving addressed the critical methodological gaps in the study by Shahnovsky et al., it is equally important to examine its actual findings and evaluate the extent to which they support the broader narrative linking ADHD symptoms to suicide risk. Below is a summary of the findings reported in the study:\nChildren's self-reported hyperactivity was significantly related to lifetime suicide attempts.\nChildren's self-reported inattention was not significantly related to lifetime suicide attempts.\nChildren's self-reported inattention and hyperactivity were not significantly related to suicide behaviors (though the authors note they approached significance).\nParental reports of both hyperactivity and inattention were not significantly related to lifetime suicide attempts.\nParental reports of both hyperactivity and inattention were not significantly related to suicide behaviors.\nAs this summary shows, ADHD symptoms were largely unrelated to suicide risk. The only significant finding, which linked hyperactivity (but not inattention) to past suicide attempts (but not suicidal behaviors), was based solely on children’s self-reported responses. This raises a critical question: how can children as young as 7 years old – or even those at the upper end of the age range, 12 years old – reliably evaluate their own levels of hyperactivity or inattention, let alone compare these to standardized clinical thresholds?\nSupporting this reliability concern, the study's concordance test between parent and child reports revealed a “very low level of agreement… suggesting almost no concordance between the children's and parents' reports on ADHD symptoms.” This striking disparity underscores the potential distortion in children’s self-perceptions and further calls into question the reliability of the sole significant result.\nFurthermore, even if the authors' entire set of hypotheses had been statistically confirmed, it is important to recognize that basic symptom measures of hyperactivity and inattention (without the use of broader, standardized assessments) provide an incomplete and potentially misleading picture. This concern is particularly relevant in the case of hyperactivity, which can arise from a wide range of neurodevelopmental, emotional, or situational factors unrelated to ADHD itself.\nTaken together, these predominantly non-significant findings, which rely on unreliable self-reports of very young children, challenge the narrative presented in the study’s abstract (see the opening of this article) and cast serious doubt on the validity of hyperactivity as a critical risk factor for suicidality. In my view, the pattern of results suggests that other variables, likely unrelated to ADHD symptoms as discussed throughout this article, may offer a far more robust and accurate explanation for understanding suicide risk in children.\nAltogether, the actual findings of the study, combined with its omission of critical variables known to increase suicide risk (i.e., comorbid disorders and ADHD medications) and its misinterpretation of previous research (which has essentially documented a troubling link between ADHD medications and suicide risk) (\nThese methodological and interpretative gaps not only limit the study's utility but also risk perpetuating harmful misconceptions. Clinicians might act on its conclusions and prescribe ADHD medications to suppress the supposedly dangerous hyperactivity – medications that were not accounted for in the study and that are well-documented to increase depression and suicide risk (as shown throughout the current article).\nTo avoid such potential harm, and to advance the field of suicidology in children, future research would benefit from a more nuanced and comprehensive approach. Assessments that include both comorbid conditions and negative effects of medications are essential to disentangle the complex relationship between ADHD, its treatments, and suicidality. In my view, addressing these gaps could bring us closer to identifying precise risk factors and developing safe interventions.\nThis recommendation is particularly critical given the growing recognition of the limited validity − and potential risks − of the biomedical framing of ADHD (\nAgainst this broader backdrop, the study by Shahnovsky et al. represents an important opportunity for reflection and constructive dialogue. Despite the critical observations raised throughout this article, please allow me to conclude by commending the authors once again for addressing such a crucial and challenging topic. Their lifelong dedication to advancing suicide prevention is deeply appreciated, and it is in this spirit that I offer these reflections. I hope that this discussion fosters a constructive dialogue that contributes to refining research practices and deepening our understanding of the tragic phenomenon of childhood suicide.\nThis supplementary material provides background on the editorial barriers encountered when attempting to publish the current article in the journal where the original study by\nUpon the publication of the study by Shahnovsky et al., which identified hyperactivity as a significant predictor of suicide attempts, I contacted EJIHPE to request an exception to the journal’s policy that prohibits commentaries and letters critiquing published articles. I argued that such a policy contradicts fundamental scientific norms and impedes open academic discourse. Additionally, I outlined several key concerns – detailed in the main article – regarding the study by Shahnovsky et al.\nFollowing this exchange, I was granted permission and explicitly encouraged to submit a formal commentary. However, despite this initial approval, my submission was later rejected on the grounds that the journal does not accept commentaries. The rejection was accompanied by two justifications:\nThat the study’s objective was “\nThat the study’s limitations section had already addressed most of my concerns.\nBelieving this rationale to be flawed, I appealed the decision, clearly demonstrating that the limitations section did not sufficiently address the key methodological issues I raised and that it even contained certain misrepresentations (as can be seen in the main article). Despite this, my appeal was denied without further justification.\nGiven these circumstances, I felt it was my ethical duty to publish my commentary elsewhere to ensure an open scholarly discussion of the study’s findings and their implications.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "39531700", "pmcid": "12307767", "title": "‘It's Really Who They Are and What They Want’: Staff Perspectives on Supporting Autonomy for Autistic Adults With Intellectual Disabilities", "publication_year": "N/A", "abstract": "", "full_text": "Autonomy, according to Self‐Determination Theory (SDT), refers to acting volitionally, willingly, and with choice (Deci and Ryan\nSelf‐determination requires having opportunities to be self‐determined, such as participating in transition planning from high school to postsecondary education, choosing what leisure activities to participate in, and deciding where to live. It also requires having the capacity to engage in self‐determined behaviours, such as goal setting, problem solving, and planning skills. However, where an individual lacks the capacity to be self‐determined on their own, appropriate supports can be provided to mitigate challenges (Kuld et al.\nAutistic individuals experience lower levels of self‐determination than both their non‐autistic peers and those with other developmental disabilities (Chou et al.\nPeople with intellectual disabilities experience greater well‐being in environments that encourage autonomy (Frielink et al.\nWhile the literature identifies autonomy‐supportive strategies for people with intellectual disabilities or Autistic people, there is a lack of autonomy‐supportive strategies specifically for Autistic adults with intellectual disabilities. This is a critical gap in knowledge and service provision. Our qualitative descriptive study, guided by Ryan and Deci's (\nHow they support autonomy for Autistic participants with intellectual disabilities, and\nWhat skills, strategies and/or resources they perceive are necessary to enhance Autistic participants' autonomy.\nWe chose interpretive description because it is flexible and adaptable, making it suitable for qualitative participatory research (Thorne\nJR has personal ties to the autism community, including being Autistic and being the mother of an Autistic young adult who participated in the ASP's programme at the time of the study. Additionally, she worked at the ASP and created the ASP's programme, although she had not had direct responsibility for it for 5 years at the time of the study. She was, however, a member of the Executive Team at the ASP at the time of the study. Rooted in nursing science, proponents of interpretive description acknowledge that having a professional relationship with stakeholders (e.g., staff) can support participant engagement, but must be balanced with researcher reflection on the potential impact of this relationship on data acquisition and analyses (Thorne\nHB is an Autistic professor who researches thriving and belonging for Autistic people. AB is an Autistic parent of an Autistic child, and a member of her local Autistic rights community. CD is an Autistic Registered Social Service Worker with a second bachelor's degree in Disability Studies and Psychology. AK is an Autistic Linguist who supports Autistic people with higher needs than his own and often uses language, paralanguage and physical communication to assist people who experience challenges with communication. AL is an Autistic university graduate with a bachelor's degree in computer science. Their unique perspectives benefitted this research. DN and STH are both non‐autistic clinicians, scholars, and allies, with close connections to the Autistic community.\nThis research was conducted within the innovative post‐secondary transition program of a major Canadian, non‐profit, multi‐disciplinary ASP, which aimed to equip Autistic adults with intellectual disabilities with knowledge and skills to live and thrive in the community. Two of the program's expected outcomes were increased self‐determination and self‐advocacy (\nThe ASP program ran out of three apartments in a walkable community with access to public transportation within a large city. It operated from Monday to Friday for 6 h per day, during which Autistic adults participated in various work and leisure activities, including learning modules such as time management and applying for jobs; volunteering at a food bank and a meal delivery service for seniors; paid employment through building maintenance; and leisure activities such as the gym, swimming, and community walks.\nAt the time of data collection, the program had 19 participants (20–27 years; 17 identified as men and 2 identified as women) who all had diagnoses of autism and intellectual disability. To support individualised skill development, the program maintained a high staff‐to‐participant ratio of approximately 1:2.\nDue to JR's relationship with the ASP, a manager distributed and collected the study information letter and consent forms. The manager did not have a vested interest in whether the staff participated and made it clear to all staff that participation was optional and would not affect their employment.\nParticipants included six of eight front‐line staff, the two supervisors and the program director for a total of 82% staff. Demographic information for each staff participant (hereafter called ‘staff’ or ‘staff member’) is in Table\nDemographics.\nAn external facilitator who was not part of the ASP or the research team collected all data to eliminate any perceived power imbalance due to the role of JR in the organisation. This facilitator was experienced and skilled in running focus groups, conducting in‐depth qualitative interviews, and was familiar with the disability service sector.\nWe chose a focus group for the six front line staff because the interaction among participants often promotes richer and fuller data toward a common goal than individual interviews due to the interactive discussion and ‘piggybacking’ on others' ideas (Thorne\nThe remaining three staff were interviewed by the same external facilitator in a group interview with two staff (supervisors; approximately 70 min) and a single interview with the other staff member (program director; approximately 60 min). The interviews were divided into these groups to avoid potential power imbalances and help participants feel comfortable to provide honest and potentially vulnerable information (Morgan\nAdditionally, ACP meetings took place monthly where we discussed and determined the research questions, data collection methods, data analysis and interpretation, and dissemination strategies. Analyses were also informed by recordings of these meetings, as well as JR's reflexive journal.\nBraun and Clarke's (\nData analysis process. ACP, Autistic Community Partners; LA, Lead Author; RT, Research Team.\nThe grey bars at the top and bottom of the data analysis process indicate the Braun & Clarke phase.\nOur first objective was to learn from staff how they supported autonomy for the ASP's Autistic participants with intellectual disabilities. Our second objective was to learn from staff what skills, strategies and/or resources they perceive as necessary to enhance the participants' autonomy. We identified three themes related to these objectives: (1)\nThemes and Subthemes.\nStaff identified that strong relationships between them and Autistic participants were crucial to support participants' autonomy.\nStaff know the participants underscores staff appreciation for the individuality of each program participant and reflects their belief in the importance of developing a deep understanding of each participant. Staff emphasised that it takes time to get to know each participant.\nAnd sometimes the people I've worked with for a long time, I feel like I could read their minds. So, I think we just have that really strong desire to get to know the people that we're supporting…\nStaff care about participants describes the importance of staff being open, responsive, empathetic and non‐judgmental to support the autonomy of program participants. Staff also brought a sense of warmth, respect and high regard for each participant. Staff at all levels articulated this factor. For example, a front‐line staff commented, ‘I think that's kind of at the heart of what makes this program successful ‐ having staff that care’, and a supervisor said,\nAll of them (staff) really care about the participants and they don't necessarily only care in the way that ‘this is my job’… They care about that these people's lives are awesome, and they're having a great day and are furthering their goals.\ngenuinely understanding who the people around us are and the things that they hold dear so that we can facilitate that process in a way that honours who they are, and it's not an extension of us or an extension of … their parents or the program. It's really who they are and what they want.\nStaff tailor choice‐making refers to the use and perceived benefits of individualised support for making choices. Staff indicated that they use the four essentials of Person‐Centred Active Support: (1) little and often, (2) maximising choice and control, (3) graded assistance, and (4) every moment has potential (Mansell and Beadle‐Brown\n[by] giving as much information as possible and giving it in a way that can help them (program participants) understand the concept of each choice\nStaff feel supported by the organisation refers to the culture of the ASP, which enabled them to try new things, make mistakes and learn from them. Staff felt encouraged ‘to dive into that interest [of the program participant] and to follow that desire’, even if it was something they had not tried before. This encouragement was also reflected by a supervisor,\nThe team, they don't meet each other with judgement. They share their successes; they share their mistakes as staff, and the environment is so supportive and learning‐based that nobody's worried about saying ‘I messed this up big time’. And everybody is so supportive, and they just do something different next time. And that attitude seeps into the participants too.\nStaff identified that an emotionally safe, comfortable environment was important for participants' autonomy.\nStaff need more training, refers for their need for more consistent initial training and ongoing training in co‐occurring conditions, conflict resolution, and mental health first aid. Staff mentioned that ‘Half the time our staff doesn't even get trained the way we would like them to be, because [team lead] gets pulled in a thousand different directions or [program manager] is running five different programs at once’. One staff member identified that ‘I kind of had to learn a lot of this on the fly and it was really hard to learn all of that on the fly’. Staff also identified an unmet need for ongoing professional development (PD),\nSo I feel like that lack of funding really translates into lack of resources for PD, which if we were all trained in Mental Health First Aid, and, … given the opportunity to learn about what to do when someone discloses abuse or talks about suicidality …like obviously it's not realistic to expect everyone in this program to be trained as psychologists and able to support people in their mental health … but even within the context of our day to day, that stuff comes up all the time.\nParents/guardians may need support as they foster autonomy, reflects how staff felt that direct, open conversations with participants' families/guardians about their young adult's need to progress toward typical adult responsibilities and experiences within the safe environment of the ASP's program supported the generalisation of autonomy beyond the ASP program. Staff strived to create a safe space for program participants to learn and test their autonomy. One staff member commented, ‘you [program participant] make a radical decision and it blows up in your face, we're still going to be there to make sure you're okay and you're safe’.\nThe importance of communication with parents/guardians was particularly notable related to topics that they felt the program participants needed and wanted, but that parents/guardians had previously discouraged or prohibited, such as sexuality. As a staff member commented, ‘so many of our families grew up with their adult in that [protective] paradigm that they really, really struggle to let go of that control’. Staff also emphasised that the autonomy of parents/guardians was often prioritised over the autonomy of the program participant, especially when the desires of parents/guardians conflicted with the program participants. One staff remarked, ‘It can be as simple as … a movie choice where they wanna pick an action movie that's PG 13 and a parent might want them to see a G‐rated animated movie’. Staff also highlighted the importance of having frank discussions with parents/guardians about what is important to the participant. As one staff put it,\nI think so many of our families, their hearts are in the best possible place. They love their adults so profoundly and they just want the best for them. But realistically, perception of best practice and what best looks like has changed. It's really, really hard to overcome a lifetime of understanding in a really small amount of contact that we have with families.\nReduced stigma and ableism in the community refers to the need for understanding and acceptance from the community to better support program participants' autonomy. Staff spoke about stigma and ableism faced when doing activities in the community. One staff member remarked, ‘there's definitely widespread community ignorance’ that leads to ‘people not knowing how to respond to us or participants or, you know, behaviours that might be exhibited’.\nIn another example during a trip to a coffee shop, ‘we're at [coffee shop] waiting to order drinks and there's a line of 25 people … and people are starting to get mad that we're taking too long…’. The staff member then described her struggle to support the program participants' opportunity to make an autonomous decision (i.e., what drink to order), ‘we all work really hard at finding that balance where, you know, we're not antagonizing community members and kind of facilitating a negative perception of the people we're supporting’. Staff's anxiety about receiving social censure from the community interfered with their ability to advocate for program participants to have enough time to complete transactions independently, interfering with their autonomy.\nIncreased funding refers to both the need for liveable wages and to be paid for adequate time to build relationships to effectively support the program participants. Low wages impacted the ASP's ability to hire and retain staff. Staff remarked that ‘we have the minimum amount of staff that we need to keep [program] running. So, if one of us gets sick, one of us can't show up or goes on vacation, then we're left stressed out and that can also affect the way we support our participants, greatly’. Staff also discussed the low wages, ‘We are at the mercy of a lot of factors and the number of times I've been told ‘I wish we could pay you more’ is outrageous … but that doesn't pay our mortgages’.\nThis theme summarises the skills that staff think would support program participants to be more autonomous. We identified four subthemes: self‐advocacy, interoceptive awareness, working effectively with others and identifying pros and cons of choices.\nMany of the program participants primarily communicated through gestures and actions, which were not always understood by others, especially those who did not know the participants well. Staff wanted the program participants to have their perspectives known, as reflected in this comment from a front‐line staff,\nI think that there has been a very clear discrepancy in terms of representing individuals who are less able to advocate for themselves, right. So, like people who don't necessarily communicate verbally or have trouble with expressive language or, you know, are under the care of a guardian or, you know, work with aides. So, I feel like I was really intrigued by the potential to kind of help those people express themselves a little bit more.\nInteroceptive awareness refers to the ability to identify internal feelings within one's body such as hunger, the need to urinate, and feelings such as anger, embarrassment and fear (DuBois et al.\nWorking effectively with others reflects that participants need skills for successful group participation, which was how the program was structured. For example, one staff member commented, ‘[it] is like a democracy. We have to respect everybody's choice, but it's also a group so we have to kind of also get a democratic vote quite often, to lead to some kind of choice’. Inherently, participants needed to recognise that working with others meant that they needed to compromise at times because it was not possible for everyone to always get their choice. Staff felt that the group context was,\nsuper applicable to society and existing around other people and… how to consider your actions in relation to others…that's really crucial to understanding realistic decision‐making and realistic autonomy within the context of living in the world.\nPros and cons of choices refers to the need for participants to understand the impact of their choices to help them make informed choices. One staff member said, ‘There are a lot of factors that go into making a choice and I feel like we make a really concerted effort to explore those factors and why they matter or if they matter’. Another staff member suggested they help program participants by asking ‘what happens when you make those decisions? How does it affect the people around you?’ Staff said that they also worked on understanding how a choice may impact how the participant feels, ‘if you don't sleep at night, you're gonna be tired all day and you have to deal with that’. They felt that this knowledge could help program participants make choices that are aligned with their values, goals and desires, which fosters self‐determination.\nMany services for Autistic people do not support self‐determination (Hodgetts et al.\nAlthough we had conceptualised this study with a focus on autonomy, our findings relate to all three basic psychological needs that Ryan and Deci (\nHowever, it takes time to build relationships, and staff turnover interferes with the establishment of relationships. Murray et al. (\nTailoring choice‐making to program participants' needs and abilities was perceived to enhance both opportunity and capacity for self‐determination. This individualisation contributes to maximising choice and control, one of four essentials of Person‐Centred Active Support known to increase program participants' levels of engagement and autonomy (Felce et al.\nParents/guardians, as the primary people in program participants' lives, have considerable influence over opportunities to be self‐determined. In supporting autonomy, it is necessary to strike a balance between what is important to the person being supported and consideration of their health and safety (Sanderson and Lewis\nStaff identified a need for Mental Health First Aid training, so they are equipped when a participant discloses abuse or suicidal ideation. Suicidality is known to be higher in Autistic adults (e.g., Cassidy and Rodgers\nWhile we were not specifically studying stigma and ableism, staff identified stigma and ableism as a barrier to autonomy, particularly when in the community. The dominant deficit‐based narrative of autism contributes to the stigma and ableism that Autistic people and their support staff or parents/guardians experience (Huang et al.\nThe capacity to be self‐determined may require support (Cheak‐Zamora et al.\nAlthough this study was situated within one service provider, many of our learnings may be generalisable to other service providers who want to support autonomy for Autistic people with intellectual disabilities. Service providers can support autonomy by adopting frameworks such as Person‐Centred Active Support to ensure that programme participants have opportunities to make choices and be engaged in meaningful activities and relationships (Murphy et al.\nService providers can provide training on supporting self‐determination to parents/guardians of programme participants. One evidence‐based approach is the La Trobe Support for Decision‐making Practice Framework (Douglas and Bigby\nSystem advocacy is required to address the issue of low pay in this sector. Service providers may be able to facilitate the engagement of a variety of groups and organisations to advocate for increased funding. Resolving the issue of pay is critical to the retention of staff and thus to the quality of life for programme participants.\nAutistic people are often stigmatised, which harms their wellbeing (den Houting et al.\nOne limitation of this study is that we only recruited staff from one service provider. Interviewing staff from other service providers may have had different results, especially because the program in which these staff work is designed as an autonomy‐supportive environment. However, we believe that our findings can generalise to other organisations by suggesting strategies that programs that are not yet autonomy‐supportive can use or validating approaches that autonomy‐supportive programs are using. Additionally, due to JR's relationship with the ASP and promised anonymity to staff participants (as per our ethics approval), we are unable to attribute comments to specific staff, even by using pseudonyms. Another limitation is that all data are based on staff reports and perceptions, with no direct observation of the program in action or input from parents/guardians, although participant perspectives were reported elsewhere (Ryan et al.\nThis study revealed key elements for autonomy and autonomy support for Autistic adults with intellectual disabilities from the perspectives of staff at a post‐secondary transition programme. Relationships were identified as critical, and an emotionally safe, comfortable environment was important for enhanced autonomy. Finally, staff identified several skill areas that would benefit programme participants to enhance their autonomy. This is all crucial information for supporting self‐determination for Autistic adults with intellectual disabilities. It also points to the need for more of this type of research, across geographic and cultural borders, with an Autistic‐centred and inclusive perspective on quality‐of‐life issues for this population.\nJ.R. contributed to all aspects of the study, including conception, design, data analysis, interpretation, and drafting of the manuscript. S.T.H. contributed to conception, design, analysis, interpretation, and critical review of the manuscript. H.B., C.D., A.L., A.B., and A.K. contributed to design, analysis, interpretation, and critical review of the manuscript. D.N. contributed to design and critical review of the manuscript. All authors approved the submitted manuscript and agreed to be accountable for this work.\nAt the time of data collection and analysis, J.R. was an employee of the autism service provider. Detailed information on how we navigated this is within the article. H.B. is a volunteer board member for the autism service provider with no involvement in day‐to‐day operations. The remaining authors have no competing interests to declare.\nThe University of Alberta's Research Ethics Board approved this study (Pro00103146).", "content_for_embedding": "Autonomy, according to Self‐Determination Theory (SDT), refers to acting volitionally, willingly, and with choice (Deci and Ryan\nSelf‐determination requires having opportunities to be self‐determined, such as participating in transition planning from high school to postsecondary education, choosing what leisure activities to participate in, and deciding where to live. It also requires having the capacity to engage in self‐determined behaviours, such as goal setting, problem solving, and planning skills. However, where an individual lacks the capacity to be self‐determined on their own, appropriate supports can be provided to mitigate challenges (Kuld et al.\nAutistic individuals experience lower levels of self‐determination than both their non‐autistic peers and those with other developmental disabilities (Chou et al.\nPeople with intellectual disabilities experience greater well‐being in environments that encourage autonomy (Frielink et al.\nWhile the literature identifies autonomy‐supportive strategies for people with intellectual disabilities or Autistic people, there is a lack of autonomy‐supportive strategies specifically for Autistic adults with intellectual disabilities. This is a critical gap in knowledge and service provision. Our qualitative descriptive study, guided by Ryan and Deci's (\nHow they support autonomy for Autistic participants with intellectual disabilities, and\nWhat skills, strategies and/or resources they perceive are necessary to enhance Autistic participants' autonomy.\nWe chose interpretive description because it is flexible and adaptable, making it suitable for qualitative participatory research (Thorne\nJR has personal ties to the autism community, including being Autistic and being the mother of an Autistic young adult who participated in the ASP's programme at the time of the study. Additionally, she worked at the ASP and created the ASP's programme, although she had not had direct responsibility for it for 5 years at the time of the study. She was, however, a member of the Executive Team at the ASP at the time of the study. Rooted in nursing science, proponents of interpretive description acknowledge that having a professional relationship with stakeholders (e.g., staff) can support participant engagement, but must be balanced with researcher reflection on the potential impact of this relationship on data acquisition and analyses (Thorne\nHB is an Autistic professor who researches thriving and belonging for Autistic people. AB is an Autistic parent of an Autistic child, and a member of her local Autistic rights community. CD is an Autistic Registered Social Service Worker with a second bachelor's degree in Disability Studies and Psychology. AK is an Autistic Linguist who supports Autistic people with higher needs than his own and often uses language, paralanguage and physical communication to assist people who experience challenges with communication. AL is an Autistic university graduate with a bachelor's degree in computer science. Their unique perspectives benefitted this research. DN and STH are both non‐autistic clinicians, scholars, and allies, with close connections to the Autistic community.\nThis research was conducted within the innovative post‐secondary transition program of a major Canadian, non‐profit, multi‐disciplinary ASP, which aimed to equip Autistic adults with intellectual disabilities with knowledge and skills to live and thrive in the community. Two of the program's expected outcomes were increased self‐determination and self‐advocacy (\nThe ASP program ran out of three apartments in a walkable community with access to public transportation within a large city. It operated from Monday to Friday for 6 h per day, during which Autistic adults participated in various work and leisure activities, including learning modules such as time management and applying for jobs; volunteering at a food bank and a meal delivery service for seniors; paid employment through building maintenance; and leisure activities such as the gym, swimming, and community walks.\nAt the time of data collection, the program had 19 participants (20–27 years; 17 identified as men and 2 identified as women) who all had diagnoses of autism and intellectual disability. To support individualised skill development, the program maintained a high staff‐to‐participant ratio of approximately 1:2.\nDue to JR's relationship with the ASP, a manager distributed and collected the study information letter and consent forms. The manager did not have a vested interest in whether the staff participated and made it clear to all staff that participation was optional and would not affect their employment.\nParticipants included six of eight front‐line staff, the two supervisors and the program director for a total of 82% staff. Demographic information for each staff participant (hereafter called ‘staff’ or ‘staff member’) is in Table\nDemographics.\nAn external facilitator who was not part of the ASP or the research team collected all data to eliminate any perceived power imbalance due to the role of JR in the organisation. This facilitator was experienced and skilled in running focus groups, conducting in‐depth qualitative interviews, and was familiar with the disability service sector.\nWe chose a focus group for the six front line staff because the interaction among participants often promotes richer and fuller data toward a common goal than individual interviews due to the interactive discussion and ‘piggybacking’ on others' ideas (Thorne\nThe remaining three staff were interviewed by the same external facilitator in a group interview with two staff (supervisors; approximately 70 min) and a single interview with the other staff member (program director; approximately 60 min). The interviews were divided into these groups to avoid potential power imbalances and help participants feel comfortable to provide honest and potentially vulnerable information (Morgan\nAdditionally, ACP meetings took place monthly where we discussed and determined the research questions, data collection methods, data analysis and interpretation, and dissemination strategies. Analyses were also informed by recordings of these meetings, as well as JR's reflexive journal.\nBraun and Clarke's (\nData analysis process. ACP, Autistic Community Partners; LA, Lead Author; RT, Research Team.\nThe grey bars at the top and bottom of the data analysis process indicate the Braun & Clarke phase.\nOur first objective was to learn from staff how they supported autonomy for the ASP's Autistic participants with intellectual disabilities. Our second objective was to learn from staff what skills, strategies and/or resources they perceive as necessary to enhance the participants' autonomy. We identified three themes related to these objectives: (1)\nThemes and Subthemes.\nStaff identified that strong relationships between them and Autistic participants were crucial to support participants' autonomy.\nStaff know the participants underscores staff appreciation for the individuality of each program participant and reflects their belief in the importance of developing a deep understanding of each participant. Staff emphasised that it takes time to get to know each participant.\nAnd sometimes the people I've worked with for a long time, I feel like I could read their minds. So, I think we just have that really strong desire to get to know the people that we're supporting…\nStaff care about participants describes the importance of staff being open, responsive, empathetic and non‐judgmental to support the autonomy of program participants. Staff also brought a sense of warmth, respect and high regard for each participant. Staff at all levels articulated this factor. For example, a front‐line staff commented, ‘I think that's kind of at the heart of what makes this program successful ‐ having staff that care’, and a supervisor said,\nAll of them (staff) really care about the participants and they don't necessarily only care in the way that ‘this is my job’… They care about that these people's lives are awesome, and they're having a great day and are furthering their goals.\ngenuinely understanding who the people around us are and the things that they hold dear so that we can facilitate that process in a way that honours who they are, and it's not an extension of us or an extension of … their parents or the program. It's really who they are and what they want.\nStaff tailor choice‐making refers to the use and perceived benefits of individualised support for making choices. Staff indicated that they use the four essentials of Person‐Centred Active Support: (1) little and often, (2) maximising choice and control, (3) graded assistance, and (4) every moment has potential (Mansell and Beadle‐Brown\n[by] giving as much information as possible and giving it in a way that can help them (program participants) understand the concept of each choice\nStaff feel supported by the organisation refers to the culture of the ASP, which enabled them to try new things, make mistakes and learn from them. Staff felt encouraged ‘to dive into that interest [of the program participant] and to follow that desire’, even if it was something they had not tried before. This encouragement was also reflected by a supervisor,\nThe team, they don't meet each other with judgement. They share their successes; they share their mistakes as staff, and the environment is so supportive and learning‐based that nobody's worried about saying ‘I messed this up big time’. And everybody is so supportive, and they just do something different next time. And that attitude seeps into the participants too.\nStaff identified that an emotionally safe, comfortable environment was important for participants' autonomy.\nStaff need more training, refers for their need for more consistent initial training and ongoing training in co‐occurring conditions, conflict resolution, and mental health first aid. Staff mentioned that ‘Half the time our staff doesn't even get trained the way we would like them to be, because [team lead] gets pulled in a thousand different directions or [program manager] is running five different programs at once’. One staff member identified that ‘I kind of had to learn a lot of this on the fly and it was really hard to learn all of that on the fly’. Staff also identified an unmet need for ongoing professional development (PD),\nSo I feel like that lack of funding really translates into lack of resources for PD, which if we were all trained in Mental Health First Aid, and, … given the opportunity to learn about what to do when someone discloses abuse or talks about suicidality …like obviously it's not realistic to expect everyone in this program to be trained as psychologists and able to support people in their mental health … but even within the context of our day to day, that stuff comes up all the time.\nParents/guardians may need support as they foster autonomy, reflects how staff felt that direct, open conversations with participants' families/guardians about their young adult's need to progress toward typical adult responsibilities and experiences within the safe environment of the ASP's program supported the generalisation of autonomy beyond the ASP program. Staff strived to create a safe space for program participants to learn and test their autonomy. One staff member commented, ‘you [program participant] make a radical decision and it blows up in your face, we're still going to be there to make sure you're okay and you're safe’.\nThe importance of communication with parents/guardians was particularly notable related to topics that they felt the program participants needed and wanted, but that parents/guardians had previously discouraged or prohibited, such as sexuality. As a staff member commented, ‘so many of our families grew up with their adult in that [protective] paradigm that they really, really struggle to let go of that control’. Staff also emphasised that the autonomy of parents/guardians was often prioritised over the autonomy of the program participant, especially when the desires of parents/guardians conflicted with the program participants. One staff remarked, ‘It can be as simple as … a movie choice where they wanna pick an action movie that's PG 13 and a parent might want them to see a G‐rated animated movie’. Staff also highlighted the importance of having frank discussions with parents/guardians about what is important to the participant. As one staff put it,\nI think so many of our families, their hearts are in the best possible place. They love their adults so profoundly and they just want the best for them. But realistically, perception of best practice and what best looks like has changed. It's really, really hard to overcome a lifetime of understanding in a really small amount of contact that we have with families.\nReduced stigma and ableism in the community refers to the need for understanding and acceptance from the community to better support program participants' autonomy. Staff spoke about stigma and ableism faced when doing activities in the community. One staff member remarked, ‘there's definitely widespread community ignorance’ that leads to ‘people not knowing how to respond to us or participants or, you know, behaviours that might be exhibited’.\nIn another example during a trip to a coffee shop, ‘we're at [coffee shop] waiting to order drinks and there's a line of 25 people … and people are starting to get mad that we're taking too long…’. The staff member then described her struggle to support the program participants' opportunity to make an autonomous decision (i.e., what drink to order), ‘we all work really hard at finding that balance where, you know, we're not antagonizing community members and kind of facilitating a negative perception of the people we're supporting’. Staff's anxiety about receiving social censure from the community interfered with their ability to advocate for program participants to have enough time to complete transactions independently, interfering with their autonomy.\nIncreased funding refers to both the need for liveable wages and to be paid for adequate time to build relationships to effectively support the program participants. Low wages impacted the ASP's ability to hire and retain staff. Staff remarked that ‘we have the minimum amount of staff that we need to keep [program] running. So, if one of us gets sick, one of us can't show up or goes on vacation, then we're left stressed out and that can also affect the way we support our participants, greatly’. Staff also discussed the low wages, ‘We are at the mercy of a lot of factors and the number of times I've been told ‘I wish we could pay you more’ is outrageous … but that doesn't pay our mortgages’.\nThis theme summarises the skills that staff think would support program participants to be more autonomous. We identified four subthemes: self‐advocacy, interoceptive awareness, working effectively with others and identifying pros and cons of choices.\nMany of the program participants primarily communicated through gestures and actions, which were not always understood by others, especially those who did not know the participants well. Staff wanted the program participants to have their perspectives known, as reflected in this comment from a front‐line staff,\nI think that there has been a very clear discrepancy in terms of representing individuals who are less able to advocate for themselves, right. So, like people who don't necessarily communicate verbally or have trouble with expressive language or, you know, are under the care of a guardian or, you know, work with aides. So, I feel like I was really intrigued by the potential to kind of help those people express themselves a little bit more.\nInteroceptive awareness refers to the ability to identify internal feelings within one's body such as hunger, the need to urinate, and feelings such as anger, embarrassment and fear (DuBois et al.\nWorking effectively with others reflects that participants need skills for successful group participation, which was how the program was structured. For example, one staff member commented, ‘[it] is like a democracy. We have to respect everybody's choice, but it's also a group so we have to kind of also get a democratic vote quite often, to lead to some kind of choice’. Inherently, participants needed to recognise that working with others meant that they needed to compromise at times because it was not possible for everyone to always get their choice. Staff felt that the group context was,\nsuper applicable to society and existing around other people and… how to consider your actions in relation to others…that's really crucial to understanding realistic decision‐making and realistic autonomy within the context of living in the world.\nPros and cons of choices refers to the need for participants to understand the impact of their choices to help them make informed choices. One staff member said, ‘There are a lot of factors that go into making a choice and I feel like we make a really concerted effort to explore those factors and why they matter or if they matter’. Another staff member suggested they help program participants by asking ‘what happens when you make those decisions? How does it affect the people around you?’ Staff said that they also worked on understanding how a choice may impact how the participant feels, ‘if you don't sleep at night, you're gonna be tired all day and you have to deal with that’. They felt that this knowledge could help program participants make choices that are aligned with their values, goals and desires, which fosters self‐determination.\nMany services for Autistic people do not support self‐determination (Hodgetts et al.\nAlthough we had conceptualised this study with a focus on autonomy, our findings relate to all three basic psychological needs that Ryan and Deci (\nHowever, it takes time to build relationships, and staff turnover interferes with the establishment of relationships. Murray et al. (\nTailoring choice‐making to program participants' needs and abilities was perceived to enhance both opportunity and capacity for self‐determination. This individualisation contributes to maximising choice and control, one of four essentials of Person‐Centred Active Support known to increase program participants' levels of engagement and autonomy (Felce et al.\nParents/guardians, as the primary people in program participants' lives, have considerable influence over opportunities to be self‐determined. In supporting autonomy, it is necessary to strike a balance between what is important to the person being supported and consideration of their health and safety (Sanderson and Lewis\nStaff identified a need for Mental Health First Aid training, so they are equipped when a participant discloses abuse or suicidal ideation. Suicidality is known to be higher in Autistic adults (e.g., Cassidy and Rodgers\nWhile we were not specifically studying stigma and ableism, staff identified stigma and ableism as a barrier to autonomy, particularly when in the community. The dominant deficit‐based narrative of autism contributes to the stigma and ableism that Autistic people and their support staff or parents/guardians experience (Huang et al.\nThe capacity to be self‐determined may require support (Cheak‐Zamora et al.\nAlthough this study was situated within one service provider, many of our learnings may be generalisable to other service providers who want to support autonomy for Autistic people with intellectual disabilities. Service providers can support autonomy by adopting frameworks such as Person‐Centred Active Support to ensure that programme participants have opportunities to make choices and be engaged in meaningful activities and relationships (Murphy et al.\nService providers can provide training on supporting self‐determination to parents/guardians of programme participants. One evidence‐based approach is the La Trobe Support for Decision‐making Practice Framework (Douglas and Bigby\nSystem advocacy is required to address the issue of low pay in this sector. Service providers may be able to facilitate the engagement of a variety of groups and organisations to advocate for increased funding. Resolving the issue of pay is critical to the retention of staff and thus to the quality of life for programme participants.\nAutistic people are often stigmatised, which harms their wellbeing (den Houting et al.\nOne limitation of this study is that we only recruited staff from one service provider. Interviewing staff from other service providers may have had different results, especially because the program in which these staff work is designed as an autonomy‐supportive environment. However, we believe that our findings can generalise to other organisations by suggesting strategies that programs that are not yet autonomy‐supportive can use or validating approaches that autonomy‐supportive programs are using. Additionally, due to JR's relationship with the ASP and promised anonymity to staff participants (as per our ethics approval), we are unable to attribute comments to specific staff, even by using pseudonyms. Another limitation is that all data are based on staff reports and perceptions, with no direct observation of the program in action or input from parents/guardians, although participant perspectives were reported elsewhere (Ryan et al.\nThis study revealed key elements for autonomy and autonomy support for Autistic adults with intellectual disabilities from the perspectives of staff at a post‐secondary transition programme. Relationships were identified as critical, and an emotionally safe, comfortable environment was important for enhanced autonomy. Finally, staff identified several skill areas that would benefit programme participants to enhance their autonomy. This is all crucial information for supporting self‐determination for Autistic adults with intellectual disabilities. It also points to the need for more of this type of research, across geographic and cultural borders, with an Autistic‐centred and inclusive perspective on quality‐of‐life issues for this population.\nJ.R. contributed to all aspects of the study, including conception, design, data analysis, interpretation, and drafting of the manuscript. S.T.H. contributed to conception, design, analysis, interpretation, and critical review of the manuscript. H.B., C.D., A.L., A.B., and A.K. contributed to design, analysis, interpretation, and critical review of the manuscript. D.N. contributed to design and critical review of the manuscript. All authors approved the submitted manuscript and agreed to be accountable for this work.\nAt the time of data collection and analysis, J.R. was an employee of the autism service provider. Detailed information on how we navigated this is within the article. H.B. is a volunteer board member for the autism service provider with no involvement in day‐to‐day operations. The remaining authors have no competing interests to declare.\nThe University of Alberta's Research Ethics Board approved this study (Pro00103146).", "topic": "Neurodevelopmental_disorder"}
{"pmid": "39397184", "pmcid": "12307315", "title": "Barriers and facilitators to sports participation in autistic Europeans: insights from a large-scale questionnaire survey", "publication_year": "N/A", "abstract": "", "full_text": "Autism encompasses a broad range of neuropsychological conditions, characterized by differences in social interaction and communication, as well as potential impacts on sensory processing and motor coordination. Socially, autistic people often experience, for instance, difficulties in understanding others’ behavior or interpreting social and emotional cues (\nIt is well-established that individuals with autism can benefit from therapeutic interventions designed to reduce or eliminate these maladaptive behaviors (\nHowever, it appears that autistic individuals are generally less physically active than their non-autistic peers (\nIn this context, our study is part of an ERASMUS + project, a flagship program of the European Union aiming at promoting cooperation and mobility in education, training, youth, and sports. The project SACREE\nThe objectives of this study are threefold. Firstly, we examined the frequency and types of sports activities practiced by European citizens, as well as the available infrastructures and resources. Secondly, we explored the individual and contextual factors influencing sports participation, including age, gender, environment and motivations. Thirdly, we aimed to identify perceived barriers and potential levers to promote greater participation in physical and sports activities.\nThe results of this research contribute significantly to the existing literature on sports sociology and public health. Moreover, they will provide a solid foundation for developing policy recommendations and concrete initiatives to promote a sustainable sports culture in Europe. By integrating comparative perspectives between countries and highlighting best practices, this study aims to foster constructive dialogue among institutional, associative, and academic stakeholders involved in sports development across Europe.\nThe choice of an online questionnaire as the primary data collection tool is based on several considerations. First, this method enables access to a large sample of participants across different European territories while reducing the costs and logistical constraints associated with field surveys. Second, the anonymity provided by this mode of response fosters honest and spontaneous participant feedback, thereby enhancing the reliability of the responses. Finally, the standardization of questions ensures comparability of results across countries and age groups.\nThus, an online survey was disseminated by the European partners of the project through their respective regional and national networks in the field of Autism and sport, and was translated into five different languages: English, French, Italian, Portuguese, and Croatian (\nGeneral organization of the survey. y.o., years old.\nAt the beginning of the survey, participants were provided with detailed information about the purpose and scope of the European project. They were also given the opportunity to electronically sign the consent form, thereby providing their informed consent for data collection. Notably, the introductory information specified that the survey could be completed by a third party on behalf of the autistic individual, such as a parent, sibling, caregiver, or another representative. One of the first pieces of information collected in the survey concerned the profile of the respondent—whether it was the autistic individual themselves or a relative or caregiver. Regardless of who completed the survey, all questions were designed to assess the opinions and experiences of the autistic individual.\nImportantly, no personal data, such as names, addresses, or phone numbers, was collected to ensure anonymity and data privacy. However, participants were given the option to voluntarily provide their email addresses if they wished to stay informed about the progress and outcomes of the project.\nThe survey aimed to gather information across a wide range of areas. Initially, demographic data such as the participant's country of residence, age, and gender were collected. Following this, the survey was divided into two main sections based on the participant's response to the initial question regarding sport and physical activity: “Do you practice a physical activity or sport?”\nIf the participant answered “yes”, they were directed to a dedicated section focusing on their sport-related practices and experiences. This section included questions about the specifics of their physical activity or sport practice, such as the number of sessions per week, the average duration of each session, and the type of facility used (e.g., professional club, home, or other settings). Additionally, it explored the social context of their practice, such as whether they engaged in activities with other autistic individuals, family members, or others. This section also delved into the motivations behind engaging in sport, with questions like, “What motivated you to start practicing a sport?” and “What do you enjoy about participating in physical activities or sports?”. Furthermore, participants were asked for their opinions on broader topics related to sport and autism, including accessibility, with questions such as, “In your opinion, is physical activity or sport sufficiently accessible for autistic people?”.\nFor participants who answered “no” to the initial question about practicing physical activity or sport, a separate, shorter section was presented. This section aimed to understand the barriers that prevent individuals from engaging in sports or physical activities. Questions included, “What are the reasons you do not practice a sport or physical activity?” and “Is your lack of participation linked to accessibility issues?”. Similar to the previous section, participants were asked for their perspectives on general topics related to sport and autism, including the accessibility of sports for autistic individuals.\nThe survey was designed to be concise and user-friendly, containing no more than 20 questions, depending on the participant's responses and the section they completed. It was calibrated to take no more than 15 min to complete. To ensure accessibility and ease of use, all questions were presented in a multiple-choice format, with no open-ended questions included.\nData are presented in percentages and mean ± SD for the following variables: participant characteristics such as age and gender distribution, as well as for physical activity parameters including frequency of practice (number of sessions per week) and session duration (adjusted according to age). Descriptive statistics were performed using Microsoft EXCEL software. Other statistical analyses were performed using JASP Software [version 0.19, JASP 290 Team (2020), University of Amsterdam]. Two-tailed\nA total of 540 responses were gathered, from Portugal (\nThe total population represented 57.7% of men (age: 23.0 ± 13.2 years old), 39.6% of women (age: 29.0 ± 15.8 years old) and 3.1% of non-binary persons (age: 27.7 ± 10.5 years old). The age distribution ranged from 3 to 71 years old among autistic individuals (total mean age: 25.6 ± 14.5 years old) (see\nAge pyramid of the population.\nRegarding sports and physical activity, 71.2% of the respondents reported engaging in regular physical activity, while 28.8% indicated they did not participate in any. The sport practitioners had a mean aged of 26 ± 14 years and composed by 59% males, 38% female and 3% non-binary individuals. As for the non-sport practitioners, their mean age was 25 ± 15 years, with 50% identify as females, 45% as males and 4% as non-binary.\nAmong those who practiced sports, respondents provided information on the practice-dose, including frequency and duration of their activities (\nSport dose of the population. y.o., years old.\nConcerning the context of their sports practice, 56.8% of respondents reported practicing in a sports club, 38.5% engaged in free practice, and 10.8% participated in a specialized structure. Additionally, 4.1% declared practicing exclusively in a school setting. 34% declared practicing their activity also in a competitive way, while 66% declared not practicing competition at all. We also asked the participants about their reasons for engaging in sports. Among practitioners, 37.8% reported being introduced to sports through their family, 33.1% started on their own, 12.2% were influenced by a friend, and 11.5% began through school sports.\nRegarding the type of practice, respondents reported engaging in various sports activities (\nType of sport practiced.\nNext, we questioned practitioners about the social context of their practice and their motivation. Among respondents, 37.2% reported practicing alone, 34.5% practiced with both autistic and non-autistic partners, 21.6% practiced exclusively with relatives (parents or siblings), and 10.8% declared practicing only with other autistic individuals. Concerning the choice of their practice, 55.4% declared practicing because they like this activity, 21.6% declared that they didn't have other choice (only activity available for them, etc.), 19.6% because it was the most practical (the closest structure, etc), and 12.2% because some relatives (friends, family) were practicing it.\nFinally, when asked the practitioners about the accessibility of sport-practice for autistic people, only 27% stated it is accessible, while 74% responded that is not.\nOver the responder who reported not to practice any sport activity, 54.1% declared that the reason of not practicing was related to the lack of structure which accept autistic individuals. 22.2% declared not knowing where to practice. 6.17% declared not being attracted by sport practice, 3.4% not to have time for practicing sport, and the remaining respondents cited various other reasons (e.g., cost, distance, difficulty, etc.).\nWhen asked if they think sport is accessible enough for autistic people, 35.5% answered “yes”, while 64.5% responded “no”.\nIn the context of a European ERASMUS + project, the SACREE Sport & Autism project aims to provide a comprehensive overview of sports practices among autistic Europeans and identify the factors that promote or hinder regular physical activity. To achieve this, we designed an online questionnaire to be completed by autistic individuals, their families or by their caregivers. With more than 500 answers, we gathered valuable insights into the sport practices of the European autistic individuals, including the frequency and the duration, the type and the context of their practice. This study also provides insight into the reasons why autistic individuals do not engage in sports.\nIt is well known that engaging in sports is essential for promoting physical and mental health, as the WHO advocates regular physical activity to prevent non-communicable diseases such as cardiovascular diseases, diabetes, and certain cancers. For autistic peoples, practice a physical activity is known to improve overall physical fitness, including parameters such as cardiovascular and muscular functions (\nThe sport participation rate observed in the present study (71.2%) is higher than those typically reported in the literature. For example, previous studies have found participation rates of 52.8% among Australian children at age 9% and 42% among Australian adults (\nBeyond of the aim to improve physical fitness and physical and mental health, the use of sport with autistic individuals appears essential to positively modulate autism characteristics. Whether for the decrease of stereotypy (\nThus, it seems essential to develop solutions to increase the accessibility of sports practice for autistic individual in order to align with general recommendations and fully leverage the benefits of physical activity.\nThanks to the responses from sport practitioners, this study provides innovative insights into the types of practice favored and preferred by autistic individuals.\nFirstly, our results showed that individual practices were predominant, accounting for nearly 80% of activities. This preference for individual practices raises an important point, which could be explained by interpersonal barriers such as lack of social support or differences in social skills (\nSecondly, a notable finding is the predominance of individual and aquatic sports among respondents, with over 20% reporting participation in swimming or other aquatic activities—placing it at the top of the list of practiced physical activities. This result is consistent with existing literature, which highlights the popularity of swimming among autistic individuals (\nThirdly, we found that autistic people tend to prefer predictable activities, commonly referred to as open-skill sports, rather than unpredictable practices, known as closed-skill sports. This preference can undeniably be explained by the characteristics of autistic individuals, who often exhibit a strong inclination toward structured and predictable activities (\nFinally, another important point is that, according to findings, two-thirds of autistic individuals have reported engaging exclusively in recreational activities rather than competitive ones. This result raises a new question: is this a matter of personal preference, or are competitive activities simply less accessible to autistic individuals?\nThe present study indicates that, quantitatively, autistic individuals tend to engage in less physical activity than recommended by global organizations such as the WHO or scientific literature. Qualitatively, their typical sports practice is predominantly non-competitive, individual, and focused on closed-skill activities, with aquatic activities being the most common. Contrary to common belief, while these activities provide a calm, safe, and predictable environment, they also contribute to the development of communication and social skills in autistic individuals.\nHowever, the lower interest of autistic people in competitive, team-based, or open-skill activities (e.g., soccer, racket sports, or combat sports) may partly stem from misconceptions about the potential barriers they face in these contexts. The study reveals that the main obstacles to sports participation among autistic individuals remain limited accessibility and a lack of communication with their families and caregivers.\nThis study has several limitations that suggest avenues for future research. First, the survey was distributed through ERASMUS + project partners and in a limited number of languages, potentially restricting the sample to certain countries. More importantly, the autistic individuals reached through the project's communication channels, within networks promoting sports participation, may already be aware of and engaged in sports. This could lead to an underestimation of the proportion of non-practitioners and, consequently, limit insights into the reasons for non-participation. Future large-scale studies specifically targeting non-practitioners could help fill this gap. Also, it would also be of interest, with a larger and more balanced number of respondents per country, to conduct a country-specific analysis. This would help to account for disparities in socioeconomic development and autism-related infrastructure between countries. Another limitation concerns the heterogeneity of autism spectrum disorder. Stratifying the population based on specific characteristics, such as predominant social processing deficits, motor impairments, stereotyped and repetitive behaviors, or language and cognitive difficulties, would be highly relevant. Barriers to physical activity, as well as the types of sports practiced, are likely to differ depending on these characteristics. However, the sample size in our study did not allow such an analysis.\nIn conclusion, this study once again shows the importance of raising awareness about the benefits of sports for autistic individuals. It is essential to fight misconceptions and biases surrounding autism and sports, particularly among coaches, families, and caregivers. However, this study presents several limitations. First, a substantial part of the data relies on reports from proxies rather than directly from autistic individuals, which may introduce some discrepancies in the responses. Additionally, the use of self-reported data inherently carries the risk of subjective inaccuracies. The online survey format, while convenient for reaching a broad audience, may have led to a selection bias favoring participants interested in sports, and consecutively already engaged in sport practice. Also, given the well-known heterogeneity of autism in terms of symptoms and individual characteristics, it is difficult for a standardized questionnaire to fully reflect the specific needs and experiences of each respondent within this diverse population. The study did not specifically investigate which types of facilities were considered lacking, nor did it explore participants’ detailed perceptions of what accessibility entails in this context, thereby limiting the depth of understanding regarding environmental barriers and potential avenues for improvement.\nFuture research should include qualitative studies, based for instance on structured interviews, to explore in greater depth the barriers and facilitators to sports participation from the perspective of autistic individuals themselves, providing a more nuanced understanding of their lived experiences. Intervention studies are also needed to test the effectiveness of adapted sports programs and identify which approaches are most supportive. In addition, research should focus on the specific features of sports that yield the greatest benefits for different autistic individuals, recognizing the diversity within the spectrum. Longitudinal studies would be valuable to track changes in participation and outcomes over time, while cross-cultural comparisons could highlight on how social, cultural, and systemic factors influence access and engagement in sports across different contexts.", "content_for_embedding": "Autism encompasses a broad range of neuropsychological conditions, characterized by differences in social interaction and communication, as well as potential impacts on sensory processing and motor coordination. Socially, autistic people often experience, for instance, difficulties in understanding others’ behavior or interpreting social and emotional cues (\nIt is well-established that individuals with autism can benefit from therapeutic interventions designed to reduce or eliminate these maladaptive behaviors (\nHowever, it appears that autistic individuals are generally less physically active than their non-autistic peers (\nIn this context, our study is part of an ERASMUS + project, a flagship program of the European Union aiming at promoting cooperation and mobility in education, training, youth, and sports. The project SACREE\nThe objectives of this study are threefold. Firstly, we examined the frequency and types of sports activities practiced by European citizens, as well as the available infrastructures and resources. Secondly, we explored the individual and contextual factors influencing sports participation, including age, gender, environment and motivations. Thirdly, we aimed to identify perceived barriers and potential levers to promote greater participation in physical and sports activities.\nThe results of this research contribute significantly to the existing literature on sports sociology and public health. Moreover, they will provide a solid foundation for developing policy recommendations and concrete initiatives to promote a sustainable sports culture in Europe. By integrating comparative perspectives between countries and highlighting best practices, this study aims to foster constructive dialogue among institutional, associative, and academic stakeholders involved in sports development across Europe.\nThe choice of an online questionnaire as the primary data collection tool is based on several considerations. First, this method enables access to a large sample of participants across different European territories while reducing the costs and logistical constraints associated with field surveys. Second, the anonymity provided by this mode of response fosters honest and spontaneous participant feedback, thereby enhancing the reliability of the responses. Finally, the standardization of questions ensures comparability of results across countries and age groups.\nThus, an online survey was disseminated by the European partners of the project through their respective regional and national networks in the field of Autism and sport, and was translated into five different languages: English, French, Italian, Portuguese, and Croatian (\nGeneral organization of the survey. y.o., years old.\nAt the beginning of the survey, participants were provided with detailed information about the purpose and scope of the European project. They were also given the opportunity to electronically sign the consent form, thereby providing their informed consent for data collection. Notably, the introductory information specified that the survey could be completed by a third party on behalf of the autistic individual, such as a parent, sibling, caregiver, or another representative. One of the first pieces of information collected in the survey concerned the profile of the respondent—whether it was the autistic individual themselves or a relative or caregiver. Regardless of who completed the survey, all questions were designed to assess the opinions and experiences of the autistic individual.\nImportantly, no personal data, such as names, addresses, or phone numbers, was collected to ensure anonymity and data privacy. However, participants were given the option to voluntarily provide their email addresses if they wished to stay informed about the progress and outcomes of the project.\nThe survey aimed to gather information across a wide range of areas. Initially, demographic data such as the participant's country of residence, age, and gender were collected. Following this, the survey was divided into two main sections based on the participant's response to the initial question regarding sport and physical activity: “Do you practice a physical activity or sport?”\nIf the participant answered “yes”, they were directed to a dedicated section focusing on their sport-related practices and experiences. This section included questions about the specifics of their physical activity or sport practice, such as the number of sessions per week, the average duration of each session, and the type of facility used (e.g., professional club, home, or other settings). Additionally, it explored the social context of their practice, such as whether they engaged in activities with other autistic individuals, family members, or others. This section also delved into the motivations behind engaging in sport, with questions like, “What motivated you to start practicing a sport?” and “What do you enjoy about participating in physical activities or sports?”. Furthermore, participants were asked for their opinions on broader topics related to sport and autism, including accessibility, with questions such as, “In your opinion, is physical activity or sport sufficiently accessible for autistic people?”.\nFor participants who answered “no” to the initial question about practicing physical activity or sport, a separate, shorter section was presented. This section aimed to understand the barriers that prevent individuals from engaging in sports or physical activities. Questions included, “What are the reasons you do not practice a sport or physical activity?” and “Is your lack of participation linked to accessibility issues?”. Similar to the previous section, participants were asked for their perspectives on general topics related to sport and autism, including the accessibility of sports for autistic individuals.\nThe survey was designed to be concise and user-friendly, containing no more than 20 questions, depending on the participant's responses and the section they completed. It was calibrated to take no more than 15 min to complete. To ensure accessibility and ease of use, all questions were presented in a multiple-choice format, with no open-ended questions included.\nData are presented in percentages and mean ± SD for the following variables: participant characteristics such as age and gender distribution, as well as for physical activity parameters including frequency of practice (number of sessions per week) and session duration (adjusted according to age). Descriptive statistics were performed using Microsoft EXCEL software. Other statistical analyses were performed using JASP Software [version 0.19, JASP 290 Team (2020), University of Amsterdam]. Two-tailed\nA total of 540 responses were gathered, from Portugal (\nThe total population represented 57.7% of men (age: 23.0 ± 13.2 years old), 39.6% of women (age: 29.0 ± 15.8 years old) and 3.1% of non-binary persons (age: 27.7 ± 10.5 years old). The age distribution ranged from 3 to 71 years old among autistic individuals (total mean age: 25.6 ± 14.5 years old) (see\nAge pyramid of the population.\nRegarding sports and physical activity, 71.2% of the respondents reported engaging in regular physical activity, while 28.8% indicated they did not participate in any. The sport practitioners had a mean aged of 26 ± 14 years and composed by 59% males, 38% female and 3% non-binary individuals. As for the non-sport practitioners, their mean age was 25 ± 15 years, with 50% identify as females, 45% as males and 4% as non-binary.\nAmong those who practiced sports, respondents provided information on the practice-dose, including frequency and duration of their activities (\nSport dose of the population. y.o., years old.\nConcerning the context of their sports practice, 56.8% of respondents reported practicing in a sports club, 38.5% engaged in free practice, and 10.8% participated in a specialized structure. Additionally, 4.1% declared practicing exclusively in a school setting. 34% declared practicing their activity also in a competitive way, while 66% declared not practicing competition at all. We also asked the participants about their reasons for engaging in sports. Among practitioners, 37.8% reported being introduced to sports through their family, 33.1% started on their own, 12.2% were influenced by a friend, and 11.5% began through school sports.\nRegarding the type of practice, respondents reported engaging in various sports activities (\nType of sport practiced.\nNext, we questioned practitioners about the social context of their practice and their motivation. Among respondents, 37.2% reported practicing alone, 34.5% practiced with both autistic and non-autistic partners, 21.6% practiced exclusively with relatives (parents or siblings), and 10.8% declared practicing only with other autistic individuals. Concerning the choice of their practice, 55.4% declared practicing because they like this activity, 21.6% declared that they didn't have other choice (only activity available for them, etc.), 19.6% because it was the most practical (the closest structure, etc), and 12.2% because some relatives (friends, family) were practicing it.\nFinally, when asked the practitioners about the accessibility of sport-practice for autistic people, only 27% stated it is accessible, while 74% responded that is not.\nOver the responder who reported not to practice any sport activity, 54.1% declared that the reason of not practicing was related to the lack of structure which accept autistic individuals. 22.2% declared not knowing where to practice. 6.17% declared not being attracted by sport practice, 3.4% not to have time for practicing sport, and the remaining respondents cited various other reasons (e.g., cost, distance, difficulty, etc.).\nWhen asked if they think sport is accessible enough for autistic people, 35.5% answered “yes”, while 64.5% responded “no”.\nIn the context of a European ERASMUS + project, the SACREE Sport & Autism project aims to provide a comprehensive overview of sports practices among autistic Europeans and identify the factors that promote or hinder regular physical activity. To achieve this, we designed an online questionnaire to be completed by autistic individuals, their families or by their caregivers. With more than 500 answers, we gathered valuable insights into the sport practices of the European autistic individuals, including the frequency and the duration, the type and the context of their practice. This study also provides insight into the reasons why autistic individuals do not engage in sports.\nIt is well known that engaging in sports is essential for promoting physical and mental health, as the WHO advocates regular physical activity to prevent non-communicable diseases such as cardiovascular diseases, diabetes, and certain cancers. For autistic peoples, practice a physical activity is known to improve overall physical fitness, including parameters such as cardiovascular and muscular functions (\nThe sport participation rate observed in the present study (71.2%) is higher than those typically reported in the literature. For example, previous studies have found participation rates of 52.8% among Australian children at age 9% and 42% among Australian adults (\nBeyond of the aim to improve physical fitness and physical and mental health, the use of sport with autistic individuals appears essential to positively modulate autism characteristics. Whether for the decrease of stereotypy (\nThus, it seems essential to develop solutions to increase the accessibility of sports practice for autistic individual in order to align with general recommendations and fully leverage the benefits of physical activity.\nThanks to the responses from sport practitioners, this study provides innovative insights into the types of practice favored and preferred by autistic individuals.\nFirstly, our results showed that individual practices were predominant, accounting for nearly 80% of activities. This preference for individual practices raises an important point, which could be explained by interpersonal barriers such as lack of social support or differences in social skills (\nSecondly, a notable finding is the predominance of individual and aquatic sports among respondents, with over 20% reporting participation in swimming or other aquatic activities—placing it at the top of the list of practiced physical activities. This result is consistent with existing literature, which highlights the popularity of swimming among autistic individuals (\nThirdly, we found that autistic people tend to prefer predictable activities, commonly referred to as open-skill sports, rather than unpredictable practices, known as closed-skill sports. This preference can undeniably be explained by the characteristics of autistic individuals, who often exhibit a strong inclination toward structured and predictable activities (\nFinally, another important point is that, according to findings, two-thirds of autistic individuals have reported engaging exclusively in recreational activities rather than competitive ones. This result raises a new question: is this a matter of personal preference, or are competitive activities simply less accessible to autistic individuals?\nThe present study indicates that, quantitatively, autistic individuals tend to engage in less physical activity than recommended by global organizations such as the WHO or scientific literature. Qualitatively, their typical sports practice is predominantly non-competitive, individual, and focused on closed-skill activities, with aquatic activities being the most common. Contrary to common belief, while these activities provide a calm, safe, and predictable environment, they also contribute to the development of communication and social skills in autistic individuals.\nHowever, the lower interest of autistic people in competitive, team-based, or open-skill activities (e.g., soccer, racket sports, or combat sports) may partly stem from misconceptions about the potential barriers they face in these contexts. The study reveals that the main obstacles to sports participation among autistic individuals remain limited accessibility and a lack of communication with their families and caregivers.\nThis study has several limitations that suggest avenues for future research. First, the survey was distributed through ERASMUS + project partners and in a limited number of languages, potentially restricting the sample to certain countries. More importantly, the autistic individuals reached through the project's communication channels, within networks promoting sports participation, may already be aware of and engaged in sports. This could lead to an underestimation of the proportion of non-practitioners and, consequently, limit insights into the reasons for non-participation. Future large-scale studies specifically targeting non-practitioners could help fill this gap. Also, it would also be of interest, with a larger and more balanced number of respondents per country, to conduct a country-specific analysis. This would help to account for disparities in socioeconomic development and autism-related infrastructure between countries. Another limitation concerns the heterogeneity of autism spectrum disorder. Stratifying the population based on specific characteristics, such as predominant social processing deficits, motor impairments, stereotyped and repetitive behaviors, or language and cognitive difficulties, would be highly relevant. Barriers to physical activity, as well as the types of sports practiced, are likely to differ depending on these characteristics. However, the sample size in our study did not allow such an analysis.\nIn conclusion, this study once again shows the importance of raising awareness about the benefits of sports for autistic individuals. It is essential to fight misconceptions and biases surrounding autism and sports, particularly among coaches, families, and caregivers. However, this study presents several limitations. First, a substantial part of the data relies on reports from proxies rather than directly from autistic individuals, which may introduce some discrepancies in the responses. Additionally, the use of self-reported data inherently carries the risk of subjective inaccuracies. The online survey format, while convenient for reaching a broad audience, may have led to a selection bias favoring participants interested in sports, and consecutively already engaged in sport practice. Also, given the well-known heterogeneity of autism in terms of symptoms and individual characteristics, it is difficult for a standardized questionnaire to fully reflect the specific needs and experiences of each respondent within this diverse population. The study did not specifically investigate which types of facilities were considered lacking, nor did it explore participants’ detailed perceptions of what accessibility entails in this context, thereby limiting the depth of understanding regarding environmental barriers and potential avenues for improvement.\nFuture research should include qualitative studies, based for instance on structured interviews, to explore in greater depth the barriers and facilitators to sports participation from the perspective of autistic individuals themselves, providing a more nuanced understanding of their lived experiences. Intervention studies are also needed to test the effectiveness of adapted sports programs and identify which approaches are most supportive. In addition, research should focus on the specific features of sports that yield the greatest benefits for different autistic individuals, recognizing the diversity within the spectrum. Longitudinal studies would be valuable to track changes in participation and outcomes over time, while cross-cultural comparisons could highlight on how social, cultural, and systemic factors influence access and engagement in sports across different contexts.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "39354858", "pmcid": "12305132", "title": "Effects of combined preconception and prenatal myo-inositol, probiotics, and trace element supplementation on the outcomes of depressed mothers", "publication_year": "N/A", "abstract": "", "full_text": "\nThe incidence of perinatal depression is a growing public health concern, affecting approximately 10%-20% of women during pregnancy and the postpartum period[\nMyo-inositol, a naturally occurring compound in the vitamin B complex, has gained attention for its potential benefits in modulating mood and metabolic parameters[\nIn addition, the gut–brain axis is increasingly recognized as a pivotal factor in mental health, with probiotics playing a crucial role in this connection[\nTrace elements such as zinc and iron are essential for numerous biological functions, including the immune response and oxygen transport, which are vital during pregnancy for maternal health and fetal development[\nThe integration of myo-inositol, probiotics, and trace elements into a combined supplementation strategy offers a novel, holistic approach to enhancing maternal mood, quality of life, and fetal development[\nWe conducted a retrospective analysis of 314 pregnant women who were diagnosed with depression and treated at our hospital between January 2019 and December 2021. Patient data were obtained from the medical recording system. The participants were divided into two groups on the basis of whether they received combined supplementation with myo-inositol, probiotics, or trace elements before pregnancy. The intervention group comprised 161 women who received the supplements, whereas the control group included 153 women who did not.\nThe Institutional Review Board and Ethics Committee of the Second Children and Women’s Healthcare of Jinan City approved this study. Given that the research was retrospective and exclusively utilized de-identified patient data, which did not affect patient care or pose any harm, informed consent was unnecessary. This waiver of consent was granted following the regulatory and ethical guidelines governing retrospective research studies.\n\n\nThree months prior to planning conception, participants began taking the supplements, which continued until the end of pregnancy. Both the intervention and control formulations were packaged identically and stored at temperatures between 2-6 °C. These compounds were administered twice daily and presented similar sensory characteristics. Both formulations contained common ingredients: Folic acid (400 μg/day, lot number H12020215, Tianjin Lisheng Pharmaceutical Co., Ltd., China), vitamin D (10 μg/day, lot number H35021450, Sinopharm Holding Xingsha Pharmaceutical (Xiamen) Co., Ltd., China), vitamin B2 (1.8 mg/day, lot number H42020612, Central China Pharmaceutical Co., Ltd.), vitamin B6 (2.6 mg/day, lot number H42020613, Central China Pharmaceutical Co., Ltd.), and vitamin B12 (5.2 μg/day, lot number H14023321, Shanxi Yunpeng Pharmaceutical Co., Ltd.). The intervention formulation also included myo-inositol (4 g/day, lot number H32026275, Jiangsu Suhua Pharmaceutical Group Co., Ltd.), calcium iron zinc tablets (1 g/day, lot number SC10736098210111, Jiangxi Shangshang Industrial Co., Ltd.), and probiotics [\nMaternal biomarkers were assessed at two key timepoints: At the time of planning pregnancy (prior to intervention) and1 week before delivery. After 8 h of fasting, 4 mL of venous blood was collected from each participant. Blood samples were immediately centrifuged at 3000 rpm for 10 min at 4 °C to separate plasma, which was then stored at -80 °C until analysis. The plasma concentrations of folate, homocysteine (indicative of 1-carbon status and other physiological conditions and deficiencies in folate and B-vitamins), riboflavin, flavin mononucleotide (FMN) (indicative of riboflavin status), and myo-inositol were measured in the control and intervention groups\nAt the time of planning pregnancy (prior to intervention) and 2 days postpartum, women completed a questionnaire designed to collect data on maternal mood. This process followed an explanation provided by a physician. Two physicians recorded and statistically analyzed the collected data. The positive affect (PA) and negative affect (NA) schedule was employed to evaluate participants’ current mood, achieving an interclass correlation of 0.93[\nThe participants also completed the state-trait anxiety inventory, which includes 40 items and has a Cronbach’s α of 0.837[\nThe Patient Health Questionnaire-8 (PHQ-8), which has a Cronbach’s alpha of 0.922[\nAt the time of planning pregnancy (prior to intervention) and 2 days postpartum, participants completed the World Health Organization Quality of life Assessment: Brief Version questionnaire, which has a Cronbach’s alpha of 0.90[\nThe questionnaire items were rated on five-point Likert scales, where “1” denotes “very poor; very dissatisfied; not at all; and never” and “5” represents “very good; very satisfied; an extreme amount; extremely; completely; and always”. The items were summed and standardized across four domains: Physical health; psychological; social relationships; and environment. Higher scores indicated greater perceptions of quality or aptitude within each domain.\nUltrasound measurements of fetal biparietal diameter (BPD), femoral length (FL), transverse abdominal diameter, anterior-posterior abdominal diameter, and abdominal circumference (AC) were collected and recorded within 1 week prior to delivery. These measurements were conducted and analyzed by professional ultrasound technicians to ensure data quality.\nThe BPD was assessed from the outer edge of the parietal bone nearest the probe to the inner edge of the parietal bone on the opposite side\nAfter birth, two physicians recorded various neonatal data, including gestational age at birth, the number of admissions to the neonatal ward, cases of sepsis, placental weight, placental area, and umbilical cord length. Neonatal length, weight, and head circumference were measured\nThe data were analyzed\nThis retrospective cohort study compared the effects of preconception and prenatal supplementation with myo-inositol, probiotics, and trace elements on mood, quality of life, and fetal development among depressed mothers. Table\nBaseline characteristics\nData are presented as\nTable\nComparison of baseline biomarkers before intervention between the two groups\nData are presented as mean ± SD. FMN: Flavin mononucleotide.\nTable\nComparison of biomarkers between the two groups 1 week before delivery\nData are presented as mean ± SD. FMN: Flavin mononucleotide.\nTable\nComparison of baseline mood scale scores before the intervention between the two groups\nData are presented as mean ± SD. PANAS-NOW: Positive and negative affect schedule-now; PA: Positive affect; NA: Negative affect; STAI: State-trait anxiety inventory; PHQ-8: Patient Health Questionnaire-8.\nThe intervention group presented higher scores for TA (16.34 ± 3.14\n\nTable\nComparison of baseline World Health Organization Quality of life Assessment: Brief Version scores before intervention between the two groups\nData are presented as mean ± SD.\nThe intervention group had significantly higher scores in the psychological domain (38.75 ± 7.36\n\nUltrasound examination conducted 1 week before delivery revealed a significantly greater BPD of 9.38 ± 1.13 cm in the intervention group than in the control group (9.12 ± 1.05 cm;\n\nTable\nComparison of basic neonatal conditions at birth between the two groups\nData are presented as mean ± SD.\nThe selection of biomarkers in this study was guided by their established roles in perinatal health and potential interactions with the administered supplements. Myo-inositol has been shown to enhance insulin sensitivity and improve glucose metabolism, crucial for preventing GDM. Elevated levels of myo-inositol have also been linked to improved neuroplasticity and neurotransmitter signaling, potentially alleviating depressive symptoms. Zinc, an essential trace element, plays a vital role in immune function and oxidative stress reduction, both important for maternal and fetal well-being. Additionally, probiotics such as\nThis retrospective cohort study examined the effects of combined preconception and prenatal supplementation with myo-inositol, probiotics, and trace elements on mood, quality of life, and fetal development among pregnant women diagnosed with mild to moderate depression. One of the most intriguing insights from this study is the significant reduction in pregnancy-related complications observed in the intervention group, specifically the lower prevalence of GDM and gestational hypertension. The inclusion of myo-inositol, which has been implicated in improved insulin signaling and carbohydrate metabolism, likely contributed to these findings[\nThe observed increase in certain blood indices in the intervention group provides further insights into the biological underpinnings of these outcomes. The elevated levels of inositol, iron, and zinc, along with increased probiotic concentrations observed near term, are worth mentioning. The role of myo-inositol in cellular signaling and osmoregulation may positively affect fetal and maternal tissue responses to stress and nutrient transfer[\nIn terms of maternal mood, the results indicated a notable improvement among those receiving the supplementation, as evidenced by lower anxiety and depression scores postpartum than in the controls. The reduction in the NA and TA scores emphasized the potential mood-stabilizing benefits of this supplement combination[\nThe quality of life enhancements in the psychological and environmental domains observed in the intervention group could be attributed to interconnected improvements in mood and physiological well-being[\nAssessments of fetal development indicated that the intervention group exhibited favorable outcomes, such as increased BPD and FL measured by ultrasound, along with increased neonatal body length at birth. These outcomes may be directly influenced by the role of myo-inositol in cell growth and differentiation, trace element contributions to fetal development, and probiotics ensuring maternal health and lowering adverse outcomes[\nRecent randomized controlled trials on myo-inositol during pregnancy have shown benefits in reducing GDM and other complications[\nAlthough certain variables such as calcium levels, neonatal birth weight, and head circumference did not reach traditional statistical significance, they exhibited small to moderate effect sizes, suggesting potential clinical relevance. Specifically, despite the non-significant difference in calcium levels, considering the increased demand for calcium during pregnancy and its importance for fetal bone development, these trends warrant further exploration. Additionally, changes in neonatal birth weight and head circumference may reflect the impact of the intervention on fetal growth. Future studies should aim to verify these trends through larger sample sizes or extended follow-up periods to determine if these variables indeed hold clinical significance.\nThis study revealed multiple practical implications and important directions for future research. Although retrospective analyses cannot confirm causality, the observed correlations encourage further exploration of combining nutritional supplements with traditional therapies for pregnant women with mild to moderate depression. Particularly, in situations where pharmacological interventions face challenges, supplement regimens can serve as an adjunctive strategy to promote maternal and neonatal health. For instance, tailoring supplement formulations based on regional dietary habits, genetic backgrounds, and socioeconomic statuses may enhance their efficacy and applicability.\nHowever, this study had certain limitations, such as potential selection bias and inherent constraints from the retrospective design. These issues should be addressed in future prospective and randomized controlled trials. Expanding the socioeconomic backgrounds, geographic locations, and cultural differences of study participants can validate the generalizability and external validity of the findings. Extending the follow-up period can help assess the impact on postnatal development and maternal mental health, particularly at different stages of child growth (\nFuture studies should optimize sample selection and increase sample sizes to include populations from diverse socioeconomic backgrounds and regions, ensuring broad applicability of the findings. Measurement indicators should incorporate new biomarkers reflecting maternal-fetal health or use advanced imaging techniques to monitor fetal growth, thereby obtaining more comprehensive data support. Adjusting supplement dosages and combinations based on individual differences is crucial. Genetic testing can identify which populations benefit most from specific supplements, and micronutrient ratios can be adjusted based on regional dietary habits to maximize intervention effects and minimize adverse reactions. Conducting multicenter collaborative studies will further enhance the representativeness and reliability of the data, providing scientific evidence for developing personalized nutritional interventions.\nOur study suggested that combined preconception and prenatal supplementation with myo-inositol, probiotics, and trace elements may confer significant benefits in improving pregnancy outcomes, mood, and quality of life in depressed mothers. The findings underscored the value of such nutritional interventions, providing an integrative approach to address complex physiological and psychological demands during pregnancy. As research progresses, these insights can shape guidelines for enhancing prenatal care, contributing to healthier pregnancies and neonatal development.", "content_for_embedding": "\nThe incidence of perinatal depression is a growing public health concern, affecting approximately 10%-20% of women during pregnancy and the postpartum period[\nMyo-inositol, a naturally occurring compound in the vitamin B complex, has gained attention for its potential benefits in modulating mood and metabolic parameters[\nIn addition, the gut–brain axis is increasingly recognized as a pivotal factor in mental health, with probiotics playing a crucial role in this connection[\nTrace elements such as zinc and iron are essential for numerous biological functions, including the immune response and oxygen transport, which are vital during pregnancy for maternal health and fetal development[\nThe integration of myo-inositol, probiotics, and trace elements into a combined supplementation strategy offers a novel, holistic approach to enhancing maternal mood, quality of life, and fetal development[\nWe conducted a retrospective analysis of 314 pregnant women who were diagnosed with depression and treated at our hospital between January 2019 and December 2021. Patient data were obtained from the medical recording system. The participants were divided into two groups on the basis of whether they received combined supplementation with myo-inositol, probiotics, or trace elements before pregnancy. The intervention group comprised 161 women who received the supplements, whereas the control group included 153 women who did not.\nThe Institutional Review Board and Ethics Committee of the Second Children and Women’s Healthcare of Jinan City approved this study. Given that the research was retrospective and exclusively utilized de-identified patient data, which did not affect patient care or pose any harm, informed consent was unnecessary. This waiver of consent was granted following the regulatory and ethical guidelines governing retrospective research studies.\n\n\nThree months prior to planning conception, participants began taking the supplements, which continued until the end of pregnancy. Both the intervention and control formulations were packaged identically and stored at temperatures between 2-6 °C. These compounds were administered twice daily and presented similar sensory characteristics. Both formulations contained common ingredients: Folic acid (400 μg/day, lot number H12020215, Tianjin Lisheng Pharmaceutical Co., Ltd., China), vitamin D (10 μg/day, lot number H35021450, Sinopharm Holding Xingsha Pharmaceutical (Xiamen) Co., Ltd., China), vitamin B2 (1.8 mg/day, lot number H42020612, Central China Pharmaceutical Co., Ltd.), vitamin B6 (2.6 mg/day, lot number H42020613, Central China Pharmaceutical Co., Ltd.), and vitamin B12 (5.2 μg/day, lot number H14023321, Shanxi Yunpeng Pharmaceutical Co., Ltd.). The intervention formulation also included myo-inositol (4 g/day, lot number H32026275, Jiangsu Suhua Pharmaceutical Group Co., Ltd.), calcium iron zinc tablets (1 g/day, lot number SC10736098210111, Jiangxi Shangshang Industrial Co., Ltd.), and probiotics [\nMaternal biomarkers were assessed at two key timepoints: At the time of planning pregnancy (prior to intervention) and1 week before delivery. After 8 h of fasting, 4 mL of venous blood was collected from each participant. Blood samples were immediately centrifuged at 3000 rpm for 10 min at 4 °C to separate plasma, which was then stored at -80 °C until analysis. The plasma concentrations of folate, homocysteine (indicative of 1-carbon status and other physiological conditions and deficiencies in folate and B-vitamins), riboflavin, flavin mononucleotide (FMN) (indicative of riboflavin status), and myo-inositol were measured in the control and intervention groups\nAt the time of planning pregnancy (prior to intervention) and 2 days postpartum, women completed a questionnaire designed to collect data on maternal mood. This process followed an explanation provided by a physician. Two physicians recorded and statistically analyzed the collected data. The positive affect (PA) and negative affect (NA) schedule was employed to evaluate participants’ current mood, achieving an interclass correlation of 0.93[\nThe participants also completed the state-trait anxiety inventory, which includes 40 items and has a Cronbach’s α of 0.837[\nThe Patient Health Questionnaire-8 (PHQ-8), which has a Cronbach’s alpha of 0.922[\nAt the time of planning pregnancy (prior to intervention) and 2 days postpartum, participants completed the World Health Organization Quality of life Assessment: Brief Version questionnaire, which has a Cronbach’s alpha of 0.90[\nThe questionnaire items were rated on five-point Likert scales, where “1” denotes “very poor; very dissatisfied; not at all; and never” and “5” represents “very good; very satisfied; an extreme amount; extremely; completely; and always”. The items were summed and standardized across four domains: Physical health; psychological; social relationships; and environment. Higher scores indicated greater perceptions of quality or aptitude within each domain.\nUltrasound measurements of fetal biparietal diameter (BPD), femoral length (FL), transverse abdominal diameter, anterior-posterior abdominal diameter, and abdominal circumference (AC) were collected and recorded within 1 week prior to delivery. These measurements were conducted and analyzed by professional ultrasound technicians to ensure data quality.\nThe BPD was assessed from the outer edge of the parietal bone nearest the probe to the inner edge of the parietal bone on the opposite side\nAfter birth, two physicians recorded various neonatal data, including gestational age at birth, the number of admissions to the neonatal ward, cases of sepsis, placental weight, placental area, and umbilical cord length. Neonatal length, weight, and head circumference were measured\nThe data were analyzed\nThis retrospective cohort study compared the effects of preconception and prenatal supplementation with myo-inositol, probiotics, and trace elements on mood, quality of life, and fetal development among depressed mothers. Table\nBaseline characteristics\nData are presented as\nTable\nComparison of baseline biomarkers before intervention between the two groups\nData are presented as mean ± SD. FMN: Flavin mononucleotide.\nTable\nComparison of biomarkers between the two groups 1 week before delivery\nData are presented as mean ± SD. FMN: Flavin mononucleotide.\nTable\nComparison of baseline mood scale scores before the intervention between the two groups\nData are presented as mean ± SD. PANAS-NOW: Positive and negative affect schedule-now; PA: Positive affect; NA: Negative affect; STAI: State-trait anxiety inventory; PHQ-8: Patient Health Questionnaire-8.\nThe intervention group presented higher scores for TA (16.34 ± 3.14\n\nTable\nComparison of baseline World Health Organization Quality of life Assessment: Brief Version scores before intervention between the two groups\nData are presented as mean ± SD.\nThe intervention group had significantly higher scores in the psychological domain (38.75 ± 7.36\n\nUltrasound examination conducted 1 week before delivery revealed a significantly greater BPD of 9.38 ± 1.13 cm in the intervention group than in the control group (9.12 ± 1.05 cm;\n\nTable\nComparison of basic neonatal conditions at birth between the two groups\nData are presented as mean ± SD.\nThe selection of biomarkers in this study was guided by their established roles in perinatal health and potential interactions with the administered supplements. Myo-inositol has been shown to enhance insulin sensitivity and improve glucose metabolism, crucial for preventing GDM. Elevated levels of myo-inositol have also been linked to improved neuroplasticity and neurotransmitter signaling, potentially alleviating depressive symptoms. Zinc, an essential trace element, plays a vital role in immune function and oxidative stress reduction, both important for maternal and fetal well-being. Additionally, probiotics such as\nThis retrospective cohort study examined the effects of combined preconception and prenatal supplementation with myo-inositol, probiotics, and trace elements on mood, quality of life, and fetal development among pregnant women diagnosed with mild to moderate depression. One of the most intriguing insights from this study is the significant reduction in pregnancy-related complications observed in the intervention group, specifically the lower prevalence of GDM and gestational hypertension. The inclusion of myo-inositol, which has been implicated in improved insulin signaling and carbohydrate metabolism, likely contributed to these findings[\nThe observed increase in certain blood indices in the intervention group provides further insights into the biological underpinnings of these outcomes. The elevated levels of inositol, iron, and zinc, along with increased probiotic concentrations observed near term, are worth mentioning. The role of myo-inositol in cellular signaling and osmoregulation may positively affect fetal and maternal tissue responses to stress and nutrient transfer[\nIn terms of maternal mood, the results indicated a notable improvement among those receiving the supplementation, as evidenced by lower anxiety and depression scores postpartum than in the controls. The reduction in the NA and TA scores emphasized the potential mood-stabilizing benefits of this supplement combination[\nThe quality of life enhancements in the psychological and environmental domains observed in the intervention group could be attributed to interconnected improvements in mood and physiological well-being[\nAssessments of fetal development indicated that the intervention group exhibited favorable outcomes, such as increased BPD and FL measured by ultrasound, along with increased neonatal body length at birth. These outcomes may be directly influenced by the role of myo-inositol in cell growth and differentiation, trace element contributions to fetal development, and probiotics ensuring maternal health and lowering adverse outcomes[\nRecent randomized controlled trials on myo-inositol during pregnancy have shown benefits in reducing GDM and other complications[\nAlthough certain variables such as calcium levels, neonatal birth weight, and head circumference did not reach traditional statistical significance, they exhibited small to moderate effect sizes, suggesting potential clinical relevance. Specifically, despite the non-significant difference in calcium levels, considering the increased demand for calcium during pregnancy and its importance for fetal bone development, these trends warrant further exploration. Additionally, changes in neonatal birth weight and head circumference may reflect the impact of the intervention on fetal growth. Future studies should aim to verify these trends through larger sample sizes or extended follow-up periods to determine if these variables indeed hold clinical significance.\nThis study revealed multiple practical implications and important directions for future research. Although retrospective analyses cannot confirm causality, the observed correlations encourage further exploration of combining nutritional supplements with traditional therapies for pregnant women with mild to moderate depression. Particularly, in situations where pharmacological interventions face challenges, supplement regimens can serve as an adjunctive strategy to promote maternal and neonatal health. For instance, tailoring supplement formulations based on regional dietary habits, genetic backgrounds, and socioeconomic statuses may enhance their efficacy and applicability.\nHowever, this study had certain limitations, such as potential selection bias and inherent constraints from the retrospective design. These issues should be addressed in future prospective and randomized controlled trials. Expanding the socioeconomic backgrounds, geographic locations, and cultural differences of study participants can validate the generalizability and external validity of the findings. Extending the follow-up period can help assess the impact on postnatal development and maternal mental health, particularly at different stages of child growth (\nFuture studies should optimize sample selection and increase sample sizes to include populations from diverse socioeconomic backgrounds and regions, ensuring broad applicability of the findings. Measurement indicators should incorporate new biomarkers reflecting maternal-fetal health or use advanced imaging techniques to monitor fetal growth, thereby obtaining more comprehensive data support. Adjusting supplement dosages and combinations based on individual differences is crucial. Genetic testing can identify which populations benefit most from specific supplements, and micronutrient ratios can be adjusted based on regional dietary habits to maximize intervention effects and minimize adverse reactions. Conducting multicenter collaborative studies will further enhance the representativeness and reliability of the data, providing scientific evidence for developing personalized nutritional interventions.\nOur study suggested that combined preconception and prenatal supplementation with myo-inositol, probiotics, and trace elements may confer significant benefits in improving pregnancy outcomes, mood, and quality of life in depressed mothers. The findings underscored the value of such nutritional interventions, providing an integrative approach to address complex physiological and psychological demands during pregnancy. As research progresses, these insights can shape guidelines for enhancing prenatal care, contributing to healthier pregnancies and neonatal development.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "39061385", "pmcid": "12309550", "title": "Symptom-specific gut microbial and metabolic profiles in ADHD reveal SCFA deficiency as a Key pathogenic mechanism", "publication_year": "2025", "abstract": "Previous evidence links gut microbiota to attention-deficit/hyperactivity disorder (ADHD) through the gut-brain axis. However, the specific microbiota contributing to symptoms remain unclear. To characterize the gut microbial profile related to different symptoms and explore the mediation mechanism between microbiota alterations and the core ADHD symptoms, we conducted shotgun metagenomic sequencing and fecal metabolomics analysis on 94 ADHD patients and 94 age- and gender-matched controls. Microbial characteristics of three subgroups exhibiting different ADHD core symptom presentations were analyzed. We developed a metabolic model and conducted causal mediation analyses to examine how metabolites connect the microbiota to the symptoms. Fecal microbiota transplantation in mice was employed to validate the findings. The redundancy analysis identified ADHD symptoms as environmental gradients and explained the changes in beta diversity (F = 1.345, pFDR = 0.015). Greater gut microbial alterations were observed in combined presentations (ADHD-C). Several beneficial bacteria involved in short-chain fatty acid synthesis were found to be downregulated, with Lactobacillus sanfranciscensis notably linked to all three core symptoms (p.adj = 1.04E–13; p.adj = 5.07E–07; p.adj = 2.61E–05). Various taxa, functional pathways, and metabolites associated with specific ADHD symptom domains were identified. Imidazoleacetic acid partially mediated the effects between Lactobacillus sanfranciscensis and inattention (p = 0.012). In mice subjected to feces from ADHD patients with a low abundance of Lactobacillus sanfranciscensis, treatment with this strain greatly improved both hyperactivity (t = 2.665, p = 0.0237) and inattention (t = 2.389, p = 0.0380), while acetate supplementation only alleviated inattention (t = 2.362, p = 0.0398). Our findings suggest that different ADHD symptoms were related to common and different gut microbiota and metabolites. Fecal microbiota transplantation in mice validated the hypothesis that gut microbial composition affects ADHD symptoms through metabolic alterations. This study provides more insight into the mechanisms underlying metabolic disturbances in ADHD and elucidates the role of gut microbiota in these processes.", "full_text": "Attention-deficit/hyperactivity disorder (ADHD) is one of the most commonly diagnosed psychiatric conditions in children and adolescents, with a global prevalence of 3–5%.\nAlthough ADHD is highly heritable,\nThrough the microbiota-gut-brain axis (MGBA), the effects of the gut microbiota on neurodevelopment have gained more recognition recently. The gut microbiota is commonly considered to regulate neurodevelopment through three pathways – the immune pathway, the neuronal pathway, and the endocrine/systemic pathway, with overlaps and interaction in between.\nResearch has shown that many ADHD-related risk factors also influence the microbiota, such as delivery method, gestational age, type of feeding, maternal health, and early life stressors.\nPrevious studies utilizing 16S rRNA gene amplicon or shotgun metagenomic sequencing have preliminarily identified differences in gut microbiota composition between ADHD and controls.\nOne hundred and eighty-eight participants aged 6–16 years were recruited from the Child and Adolescent Mental Health Center at Peking University Sixth Hospital, Yan’an Third People’s Hospital, and local schools. Of these, 94 were ADHD patients and 94 were age- and gender-matched healthy controls. The initial diagnoses of patients were made by senior psychiatrists using the DSM-5 criteria,\nPatients with ADHD and healthy controls were excluded when they met the following exclusion criteria: (1) history of treatment with any medication for ADHD; (2) use of psychoactive drugs, antibiotics, probiotics, or traditional Chinese medicine within 1 month prior to sample collection; and (3) special dietary preferences (such as vegan or ketogenic diets) or significant changes in diet within the previous month. Participants were excluded if they had comorbid psychiatric, neurological, gastrointestinal, or metabolic conditions. Additionally, individuals with IQs below 70 according to Raven’s Standard Progressive Matrices\nFollowing the guidelines outlined in the Declaration of Helsinki, the research was granted authorization by the Ethics Committee of Peking University Sixth Hospital (Approval No. 2021–79). Informed consent was obtained from legal guardians, while children aged 8 years or older signed the informed consent on their own.\nADHD symptoms were measured using the Attention-Deficit/Hyperactivity Disorder Rating Scale,\nThe Children Behavior Checklist (CBCL), a widely recognized children behavior assessment tool,\nThe Conners Parental Symptom Questionnaire (PSQ) is completed by the child’s primary caregiver based on the child’s daily behavior.\nFood frequency questionnaires (FFQ) are an effective instrument for assessing typical dietary intake and its relationship with health and disease outcomes.\nStandardized procedures were followed for fecal sample collection, after which the samples were frozen at −80°C. Microbial DNA was extracted from 200 mg fecal samples from 188 participants using the QIAamp PowerFecal Pro DNA Kit. The DNA concentration was measured using a microplate reader, and its integrity was assessed by agarose gel electrophoresis.\nSamples were sequenced on the MGISEQ 2000 platform by Beijing Genomics Institute using PE150 mode with an insert size of 300–400 bp. Prior to bioinformatic analysis, SOAPnuke (v.2.2.1)\nHigh-quality short reads from each DNA sample were assembled into contigs using a multiple k-mer size strategy with MEGAHIT software\nAll participants were initially assigned sequential subject identifiers upon recruitment. After completing fecal sample collection, all samples were randomly reordered using the sample() function in R software (version 4.2.0), and new identification numbers (ADHD: A001-A094; Controls: H001-H094) were assigned accordingly. Metabolomics profiling was performed on the first 31 ADHD patients (A001-A031) and 31 controls (H001-H031) based on the ascending order of these IDs. The 20 μL sample and 20 μL standard were mixed with HM400 releasing agent for extraction. Following centrifugation at 18,000 g for 10 min at 4°C, the supernatant was collected for LC-MS/MS analysis.\nMetabolite separation and quantification were carried out using a Waters ACQUITY UPLC I-Class Plus (Waters, USA) in conjunction with a QTRAP 6500+ high-sensitivity mass spectrometer (SCIEX, USA). Chromatographic separation was achieved using a BEH C18 column (2.1 mm × 10 cm, 1.7 μm; Waters). The QTRAP 6500+ mass spectrometer, equipped with an ESI Turbo Ion Spray interface, was operated with the following parameters: ion source temperature at 400°C, ion spray voltage (IS) at 4500 V (positive mode) and −4500 V (negative mode), and ion source gases I (GS1), II (GS2), and curtain gas (CUR) set to 60, 60, and 35 psi, respectively.\nQuantitative analysis was performed using Skyline software (v.21.1.0.146). This software, configured for monoisotopic peaks with a mass tolerance of 0.6 Da and a mass range of 50–1500 Da, was used to generate a data matrix that included metabolite identification and quantification results for subsequent information analysis and processing. Quality control (QC) samples were generated from a mixture of sample extracts to assess the consistency of the sample under identical treatment. During data collection, a certain number of QC samples were inserted in test samples to monitor the repeatability of the analytical process. The results exported by Skyline software were imported into metaX\nMetabolic pathways were identified using open database sources such as MetaboAnalyst, the Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway database, and the Human Metabolome Database.\nFour-week-old male C57BL/6J mice (initial weight 13–16 g; Gempharmatech Co., Ltd) were housed at a temperature of 22–23°C on a 12-h light/dark cycle with ad libitum access to water and food except during experimental sessions. The study was approved by the Biomedical Ethics Committee of Peking University. After the acclimatization period, mice were orally administered a cocktail of four antibiotics (ABX) for 7 days: ampicillin (200 mg/kg/day, Solarbio Cat#A6920), vancomycin (100 mg/kg/day, VIANEX S.A. PLANTC), neomycin (200 mg/kg/day, SIGMA Cat#N6386), and metronidazole (200 mg/kg/day, SIGMA Cat#M1547).\nSubsequently, mice were subjected to fecal microbiota transplantation (FMT) from ADHD patients with a low abundance of beneficial bacteria\nBehavioral experiments were conducted during the light period. Exploratory activity and hyperactivity behavior were measured using an Open-Field apparatus (40 × 40 × 25 cm). For the five days prior to the test, the mice were handled for 5 min every day, followed by a 5-min familiarization period in the box. Each mouse was placed in the center of the open-field apparatus. A square that was 10 cm from the wall was designated as the center zone. Traveled distance and time spent in the center zone of each animal were recorded for a single 4-min session with a video-imaging system.\nMice were trained using a Five-Choice Serial Reaction Time Task (5-CSRTT) procedure according to a published protocol and previous studies.\nDuring training, the LED of one of the five response holes will be on, and mice were trained to use their noses to locate the lit hole in order to receive a food pellet as a reward. Each session began with the illumination of the response holes light and the food magazine light, followed by the delivery of one food pellet (20 mg/pellet). Once the first food pellet was collected, the intertrial interval (ITI) commenced. At the end of the ITI, one of the five response holes on the chamber wall opposite the food magazine was illuminated for a brief period, known as the stimulus duration (SD). A correct response to this hole within the limited hold (LH) period resulted in the response holes light turning off, the food magazine light turning on, and delivery of one food pellet. After the pellet was collected, the next ITI began. The target stimulus varied pseudorandomly between trials to increase attentional load.\nTraining was divided into seven successive stages with specific criteria for ITI, SD, and LH, which had to be met for two consecutive days before progression to the next stage (Supplementary Fig. 6). A typical training session lasted 30 min or completed 100 trials, whichever came first. Responses into the non-target hole were considered incorrect responses, while responses during the ITI before target stimulus presentation were classified as premature responses, and a failure to respond was recorded as an omission. The average latency to correct responses and correct responses rate reflected the mice’s attention; the premature rate indicated the level of impulsivity.\nMice feces were collected before and after antibiotic treatment (ABX), after fecal microbiota transplantation (FMT), and after the rescue procedure (\nAfter obtaining genus-level ASVs, the data were normalized to ensure sample comparability; sequence count normalization was conducted through rarefaction to address uneven sequencing depths by the ‘rrarefy’ function in Vegan,\nStatistical analyses were performed using R software (version 4.2.0) and Statistical Product and Service Solutions (SPSS, version 26.0). Mean and standard deviation were utilized for continuous variables (including demographic data, dietary data, and psychometric parameters). Kruskal – Wallis tests and post-hoc Wilcoxon rank-sum pairwise tests, with p-values adjusted for multiple testing via the Benjamini – Hochberg method, were applied for inter-group comparisons. Correlation analysis was conducted using partial correlation analysis by the “spearman” method in the R package ppcor. When applicable, age, gender, BMI, SPM, site and principal component of diets were adjusted as covariates. A two-tailed p-value ≤0.05 was considered statistically significant.\nWe performed power analysis and created the species rarefaction curves by the function ‘specaccum’ in the R package vegan\nTo analyze the interrelationship between the microbiota present in stool samples and ADHD symptoms, we used redundancy analysis (RDA) from the R package vegan,\nTo identify significant biomarkers, we compared all species between two groups using LEfSe analysis, which assisted in identifying genomic biomarkers that characterize statistical differences between biological groups.\nFor metabolomics, after normalization to total peak intensity, the multivariate data were dimensionally reduced by principal component analysis (PCA) to analyze groupings, trends (intra-group and inter-group similarities and differences), and outliers in the data set. Using Partial Least Squares-Discriminant Analysis (PLS-DA) of the R package mixOmics\nTo further investigate the correlation between gut microbiota function and fecal metabolites, we employed the MIMOSA model from the R package MIMOSA2.\nThe causal mediation analysis was conducted to explore the influence and interactions of microbiota and metabolites, using the ‘mediate’ function in the R package mediation.\nA total of 188 children and adolescents, consisting of 94 patients with ADHD (56 ADHD-I, 29 ADHD-C, 9 ADHD-HI) and 94 TDs, were recruited.\nDemographics, intelligence, and clinical symptoms of ADHD subgroup and typically developing controls (TD) in the study cohort.\nBMI, body mass index; SPM, Raven’s Standard Progress Matrice;\nWe carried out shotgun metagenomic sequencing for all participants and obtained an average of 9,973,835,522 clean bases per sample. Detailed information on gut microbiota sequencing data was given in Supplementary Table 3. We employed species rarefaction curves to assess and predict the degree to which species richness in the community increases with sample size. The curve for groups TD, IA, and C exhibited a flat trajectory during the terminal phases, indicating that the sample sizes were adequate and the subsequent analyses were reasonable (Supplementary Fig. 1).\nIn terms of taxonomic diversity, we first compared the top 10 relative abundances of microbiota at the level of genus, the Firmicutes-to-Bacteroidetes ratio (F/B ratio), alpha diversity, and beta diversity between ADHD subgroups and TDs. The relative abundance of the top 10 genera of microbiota (Phocaeicola, Bacteroides, Alistipes, Parabacteroides, Faecalibacterium, Roseburia, Bifidobacterium, Escherichia, Lachnospira, Megamonas, and others) did not differ significantly (pFDR >0.05;\nThe overview of the microbiome profiles in three ADHD presentations and TD. (A) the top 10 taxa of relative abundance. The relative compositions of microbiota at the genus level were not significantly different among ADHD subgroups and group TD. The pFDR values of group comparisons are presented followed by legends of microbiota; (B) the Firmicutes to the bacteroidetes ratio. There was no group difference among ADHD subgroups and group TD using ANOVA corrected by FDR; (C) observed species, Shannon index, Simpson index, and Pielou’s evenness index for each group. Data are plotted as ±standard deviation; (D) RDA analysis of microbial community structure and ADHD symptoms in all participants; (E) RDA analysis of microbial community structure and CBCL. CBCL_SOM: somatic complaints of CBCL; CBCL_WIT: withdrawn of CBCL; CBCL_AGS: aggressive behavior of CBCL; CBCL_ANX: anxious/depressed symptoms; CBCL_SOC: social problems of CBCL; CBCL_HA: hyperactivity behaviors of CBCL; CBCL_DEL: delinquent behaviors of CBCL; (F) RDA analysis of microbial community structure and PSQ.\nAlpha diversity indexes for the ADHD subgroups and TDs.\nTotal five indexes of alpha-diversity showed no group differences between ADHD subgroups and TD. S.obs (observed species) were used to estimate the indexes of the total number of species in the community. Shannon index, Simpson index, and Pielou’s evenness index were used to measure the microbial diversity in the sample. Phylogenetic diversity (PD) whole tree was the diversity index calculated the distance of the evolutionary tree.\nThe significance tests of the community structure with greater between-group difference than the within-group difference.\nAnosim similarity analysis is a non-parametric test to test whether the between-group difference is significantly greater than the difference within the group to judge whether the grouping is meaningful. MRPP analysis is similar to Anosim analysis, but the ordering method is different. It analyzes whether the microbial community structure difference between groups is significant. Adonis tests the differences between groups by partitioning the distance matrix among sources of variation and using a permutation test to assess the significance of these differences.\nFurthermore, we used constrained ordination analysis to investigate the correlation between the microbial community structure and ADHD symptoms in all participants. To identify the optimal distribution of our data model (either a linear, unimodal, or bimodal distribution), we implemented a detrended correspondence analysis (DCA). The length value indicated that the linear model fitted our data, with the first axis (DCA1) having a length of 2.58 (less than 3) (Supplementary Table 4). We applied the redundancy analysis (RDA) to a linear model. We found that at the species level, Component 1 from the RDA explained 57.98% of the variance (22.88% with Component 2 scaling) (ANOVA like permutation test F = 1.345, pFDR = 0.015,\nThe ANOVA like permutation test of the redundancy analysis (RDA) between the microbial community structure and ADHD symptoms.\nRDA1 and RDA2 represent the proportion of species distribution explained by each axis in the analysis. The model’s R\nWe conducted a comprehensive analysis of the microbiota community variations from phylum to species levels between ADHD subgroups and group TD to identify potential evolutionary biomarkers linked to ADHD based on the gut microbiome. LEfSe analysis identified dominant bacterial biomarkers contributing to the group disparities. Specifically, 5 bacterial taxa were enriched in group IA and 12 were enriched in group TD when contrasting IA and TD (\n(A) a taxonomic cladogram and an LDA scores bar plot of identified differential taxa between group IA and TD; (B) a taxonomic cladogram and an LDA scores bar plot of identified differential taxa between group HA and TD; (C) a taxonomic cladogram and an LDA scores bar plot of identified differential taxa between group C and TD. The LDA score (log 10) > 2 and\nLinear discriminant analysis of three ADHD subgroups and group TD concurrently revealed that family\nTo further elucidate the association between differential microbiota and symptoms, partial correlation analysis was carried out. After adjusting for various confounding factors, genus\n(A) differential correlation patterns of microbiota with ADHD symptoms. Pairs with pFDR < 0.05 are shown in the picture. The color of each grid represents the value of correlation coefficient. Blue color represents the negative correlation and red color represents the positive correlation; (B)-(D) the relative abundance of microbial function annotated by the KEGG database and significant microbial function among ADHD subgroups and group TD. The **symbol represents the pFDR < 0.05, while the *symbol represents the pFDR < 0.1; (E) differential correlation patterns of functional pathways with ADHD symptoms. Pairs with p-value < 0.05 are shown in the picture. The color of each grid represents the value of correlation coefficient. Blue color represents the negative correlation and red color represents the positive correlation.\nIn the comparative analyses between ADHD subgroups and group TD, as well as the correlation analysis between ADHD symptoms and microbiota, the microbial features existing consistent results were considered more robust. Species\nAfter gene prediction, the total number of genes we obtained and the distribution of genes with different lengths were displayed in Supplementary Figure 2. First, we assessed the microbial function annotated by the KEGG database. We totally annotated the genes expressed by the microbiota to 5 pathways at Level 1, 29 pathways at Level 2, 202 pathways at Level 3, and 6935 KEGG orthology (Supplementary Fig. 3). We next focused on all metabolic pathways of Level 3 and employed STAMP to identify 11 differential pathways between group TD and group C (\nIn group C, tryptophan metabolism, biotin metabolism, histidine metabolism, fatty acid metabolism, and biosynthesis of unsaturated fatty acids were downregulated, while lysine biosynthesis, arginine biosynthesis, phenylalanine, tyrosine and tryptophan biosynthesis, and terpenoid backbone biosynthesis were upregulated (\nFurthermore, we employed partial correlation analysis to investigate relationships between three domains of ADHD symptoms and KEGG pathways, adjusting for sex, age, BMI, SPM, site, and dietary variables. Results demonstrated that biotin metabolism showed negative correlations with all three symptoms, and aminoacyl-tRNA biosynthesis displayed positive correlations with all symptoms (\nSimilarly, pathways demonstrating consistent results in both comparative analysis and correlation analysis were considered more robust. The biotin metabolism pathway showed increased abundance in group TD in all three pairs of comparisons, and correlation analysis also demonstrated that this pathway was negatively correlated with all three ADHD symptoms. The relative abundance of tryptophan metabolism was downregulated in group IA and group C and the pathway also showed a negative correlation with inattention symptoms. The relative abundance of terpenoid backbone biosynthesis was upregulated in group HA and group C, and the pathway also showed a positive correlation with impulsivity symptoms. In addition, group C, which exhibited symptoms of inattention, hyperactivity, and impulsivity, demonstrated differences in biosynthesis of unsaturated fatty acids, fatty acid metabolism, and histidine metabolism. Correspondingly, correlation analysis revealed that the first two pathways were associated with inattention, while histidine metabolism was associated with impulsivity.\nTo further elucidate the alterations in bacterial metabolism, we conducted untargeted metabolomics using fecal samples. The baseline comparison results between metabolomic subgroups and the full cohort are provided in Supplementary Table 7. No significant differences were observed in all these key variables, which supported the representativeness of the metabolomic subgroups. A total of 307 metabolites were identified, with classifications and the number of each class presented in Supplementary Figure 4. The comprehensive details of each identified metabolite are presented in Supplementary Table 8.\nBased on the differential metabolite screening criteria, there were 21 downregulated metabolites identified in group ADHD compared to group TD (\n(A) Volcano plot of the different metabolites between group ADHD and group TD. The abscissa is the Fold change converted by log2, and the ordinate is the q-value converted by log10. The circles represent metabolites with a VIP > 1. Blue circles represent significant metabolites, while gray circles represent non-significant metabolites; (B) the KEGG pathway enrichment metabolic network of differential metabolites between groups, with node size representing the number of candidate genes in pathway; (C) bubble diagram for enrichment analysis based on the KEGG database. RichFactor is the ratio of differential metabolites annotated to the total number of identified metabolites annotated in a certain pathway; (D) differential correlation patterns of the metabolites with ADHD symptoms. The size of circles represents -log10(pFDR), pairs with pFDR < 0.05 are shown in the picture. The color of circle represents the value of correlation coefficient; (E) path diagram of the mediation analysis model of imidazoleacetic acid between\nTo explore the relationship between the significant differential metabolites and ADHD symptoms, we conducted a partial correlation analysis. After adjusting various confounding factors, we found that inattention symptom was negatively correlated with 12-hydroxystearic acid, all-trans-retinoic acid, lithocholic acid acetate methyl ester, vanillin, 4-guanidinobutyric acid, imidazoleacetic acid, 12-tridecanoic acid, and taurochendeoxycholic acid. Hyperactivity symptom was negatively correlated with 12-hydroxystearic acid, all-trans-retinoic acid, lithocholic acid acetate methyl ester, linoleic acid, 3,6-diketocholanic acid ethyl ester, and quinolinic acid. Impulsivity symptoms also had a negative correlation with vanillin, 4-guanidinobutyric acid, quinolinic acid, and ricinoleic acid (\nTo further explore the association between metagenomics and metabolomics between groups, we used the MIMOSA model to predict the impact of gut microbiota composition or function on metabolite concentrations. Based on the metabolic network approach, we then identified eight metabolites regulated by gut microbiome functions, which were annotated by KEGG orthology, including 4-Hydroxybenzoic acid, imidazoleacetic acid, hydroxyproline, 4-aminobutyric acid, 4-guanidinobutyric acid, L-asparagine, D-xylose, and pidolic acid. Importantly, imidazoleacetic acid, 4-aminobutyric acid, and 4-guanidinobutyric acid were previously identified as key differential metabolites between group ADHD and group TD, and all three are classified as short-chain fatty acids (SCFAs). It is noteworthy that the top producing pathways of these three metabolites are\nResults of MIMOSA model to predict the impact of gut microbiota composition or function on metabolite concentrations.\nID: KEGG compound ID for that metabolite; R\nTo investigate the influence and interactions of microbiota and metabolites on ADHD, we selected differential species and metabolites most strongly correlated with ADHD symptoms. The causal mediation analysis indicated a total effect of\nTo verify the pathway from microbiota to metabolites and subsequently to ADHD symptoms, we conducted a fecal microbiota transplantation experiment in mice. Detailed information on the sequencing data of mice fecal samples was presented in Supplementary Table 12. The 16S rRNA analysis of mice fecal microbiota showed a significant reduction in alpha diversity following treatment with ABX. In terms of beta diversity, the microbiota of ABX-treated mice exhibited a distinct distribution pattern compared to wild-type mice (Supplementary Fig. 7). These findings validated the effectiveness of antibiotic treatment in altering the gut microbiota. After fecal microbiota transplantation from different sources, we observed that mice subjected to feces from ADHD patients with a low abundance of beneficial bacteria in group FMT-A exhibited hyperactive behavior (\nIn the rescue experiments for mice exhibiting ADHD-related symptoms after receiving FMT from ADHD patients, we found that compared to the control group (FMT-A-C), group FMT-A-R1, which received treatment with\n(A) workflow diagram of fecal microbiota transplantation (FMT) and rescue experiments in mice. ABX: orally administered a cocktail of four antibiotics, FMT: fecal microbiota transplantation; (B) performance of mice in the open field test and 5-choice serial reaction time task (5-CSRTT) following different rescue interventions; (C) relative abundance of the genus\nDue to the limitations of 16S rRNA sequencing, we focused on the relative abundance of the genus\nMental health includes mental, emotional, social, and behavioral functions, occurring along a continuum from optimal to poor.\nThe metagenomic data demonstrated gut dysbiosis in patients with ADHD. While comparing gut microbiota taxa between ADHD subgroups and group TD, there were no significant differences observed in alpha diversity between patients with ADHD and TDs, which aligns with several previous studies.\nTo explore the relationship between taxa and ADHD symptoms, we employed LEfSe analysis between ADHD subgroups exhibiting different domains of symptoms and group TD, as well as correlation analysis between symptoms and microbiota. Microbial features that exhibited consistent results were deemed more robust. The LEfSe analysis of the ADHD subgroups and group TD revealed that the family\nRegarding the harmful bacteria enriched in ADHD groups or positively correlated with ADHD symptoms, both methods identified\nThe analysis of predicted microbial functions revealed significant differences between ADHD subgroups and group TD. The most significant pathways include several amino acid-related pathways, such as tryptophan metabolism, phenylalanine, tyrosine and tryptophan biosynthesis, and lysine biosynthesis. As Li et al. reported, gut microbiota actively reshapes the host’s amino acid balance through the metabolism of intestinal amino acids.\nOur analysis of metagenomic functional pathways and fecal metabolites concurrently revealed a downregulation of both fatty acid metabolism and the biosynthesis of unsaturated fatty acids in ADHD. The most significantly enriched process was the biosynthesis of unsaturated fatty acids. Unsaturated fatty acids, including MUFAs,\nIn addition, through the correlation analysis of metabolomics and metagenomics, we identified eight metabolites regulated by gut microbiota functions, three of which (imidazoleacetic acid, 4-aminobutyric acid, and 4-guanidinobutyric acid) also exhibited significant differences between groups. The three metabolites are categorized as short-chain fatty acids (SCFAs), and we have also identified several key enzymes that contribute significantly to their synthesis. This suggests that the impact of gut microbiota on ADHD pathogenesis may be mediated through the synthesis of SCFAs by regulating the expression of certain enzymes. Consistent with our findings, in previous studies, aberrant levels of SCFAs have been implicated in disease pathogenesis and are generally present in diminished quantities.\nIn summary, in the analysis of linear discriminant analysis and symptom-related species from metagenomics, we identified probiotics primarily responsible for the production of short-chain fatty acids (SCFAs). This aligns with the findings from the association analysis between metagenomics and metabolomics, where the metabolites modulated by gut microbiota and significantly downregulated in cases were primarily SCFAs. Additionally, the important overlapped pathways in the metagenomic differential functional pathways and the differential metabolites enrichment analysis were fatty acid metabolism and biosynthesis of unsaturated fatty acids, with SCFAs being one of the key substances involved in these pathways. These findings collectively reveal a disturbance in fatty acid metabolism associated with the pathogenesis of ADHD. To further validate the hypothesis that SCFA-producing microbes affect ADHD pathogenesis through the mediation of SCFAs, we conducted a causal mediation analysis. The results confirmed that\nThe main strengths of our study include a larger sample size of the Chinese population compared to previous studies. At the same time, we excluded participants with other psychiatric, neurological, gastrointestinal, and metabolic conditions, as well as those with active use of psychoactive drugs, antibiotics, and probiotics. Methodologically, we employed shotgun metagenomic sequencing, which offers greater species identification depth compared to 16S rRNA sequencing. In terms of analysis, we conducted subgroup analyses of ADHD clinical symptoms, and the comparison between group C and group TD provided more comprehensive and detailed information that may have been overlooked without the application of subgroup analysis. Regarding study content, previous research has mostly focused on measuring plasma concentrations of amino acids and fatty acids as well as analyzing their correlation with clinical symptoms. In contrast, our study, for the first time, investigates the pathogenic role of gut microbiota in ADHD through species variations, gene pathway expression and fecal-targeted metabolomics. Specifically, it reveals the involvement of gut microbiota in disrupted fatty acid and amino acid metabolism, particularly in the biosynthesis of unsaturated fatty acids. Furthermore, we formulated a hypothesis that gut microbiota affects ADHD symptoms through metabolic variations. We then subsequently conducted fecal microbiota transplantation experiment in mice to validate the hypothesis. This contributes to a deeper understanding of the mechanisms underlying metabolic disturbances in ADHD and addresses gaps in previous studies by linking the gut-brain axis mechanism to ADHD through gut microbiota profiles.\nThere are also some limitations to our study. First, excluding patients with gastrointestinal conditions or special diets may preclude participants with more aberrant microbiota compositions, thereby hindering the detection of correlations between gastrointestinal symptoms, food style, and microbial profiles. Second, due to the lower prevalence of the hyperactive/impulsive subtype in clinical settings, the sample size of group HA in our cohort might have been underpowered, and the sample size for each subgroup might be imbalanced. To address this problem, we emphasize the convergent evidence from our correlation analysis between microbial taxa, functions, and symptoms, which partially mitigates subgroup limitations. Third, we performed a cross-sectional study, which does not allow for confirming the causal directions between the correlational link between differential species, functional pathways, fecal metabolites, and the disease or symptoms. To address this problem, we conducted animal experiments; however, further longitudinal work in human populations should be undertaken to assess age-associated and other variations in gut microbiota.\nBuilding upon our findings and the current progress of gut-brain axis research, large-scale prospective longitudinal studies are essential to track the dynamic development of the gut microbiome and its relationship with the onset, progression, and symptom fluctuation of ADHD. In parallel, well-designed randomized controlled trials evaluating the efficacy of dietary modifications, specific prebiotics, probiotics, or microbiota transplantation are warranted to explore the therapeutic potential of targeting microbial and metabolic dysbiosis in ADHD. Furthermore, mechanistic investigations into how gut microbes and their metabolites influence gut-brain signaling pathways, along with integrative multi-omics approaches encompassing host genetics, transcriptomics, and metabolomics, will be crucial for advancing our understanding of the complex biological underpinnings of ADHD and identifying novel therapeutic targets.\nIn conclusion, our study characterized the distinct gut microbiota and fetal metabolite profiles in patients with ADHD and its subtypes. We observed more gut microbial alterations in patients from group C compared to those in group IA or HA. Moreover, we employed metagenomics and fecal metabolomics techniques for the first time to elucidate the role of gut microbiota in the dysregulation of fatty acid and amino acid metabolism, with a particular focus on the biosynthesis of unsaturated fatty acids and SCFAs. Through causal mediation analysis of population sample data and mouse experiments of fecal microbiota transplantation, we further validated the pathway from microbiota to metabolites and subsequently to ADHD symptoms. The study provides new evidence supporting the association between the microbiota-gut-brain axis and ADHD and contributes to a deeper understanding of the mechanisms underlying these metabolic disturbances in ADHD.", "content_for_embedding": "Attention-deficit/hyperactivity disorder (ADHD) is one of the most commonly diagnosed psychiatric conditions in children and adolescents, with a global prevalence of 3–5%.\nAlthough ADHD is highly heritable,\nThrough the microbiota-gut-brain axis (MGBA), the effects of the gut microbiota on neurodevelopment have gained more recognition recently. The gut microbiota is commonly considered to regulate neurodevelopment through three pathways – the immune pathway, the neuronal pathway, and the endocrine/systemic pathway, with overlaps and interaction in between.\nResearch has shown that many ADHD-related risk factors also influence the microbiota, such as delivery method, gestational age, type of feeding, maternal health, and early life stressors.\nPrevious studies utilizing 16S rRNA gene amplicon or shotgun metagenomic sequencing have preliminarily identified differences in gut microbiota composition between ADHD and controls.\nOne hundred and eighty-eight participants aged 6–16 years were recruited from the Child and Adolescent Mental Health Center at Peking University Sixth Hospital, Yan’an Third People’s Hospital, and local schools. Of these, 94 were ADHD patients and 94 were age- and gender-matched healthy controls. The initial diagnoses of patients were made by senior psychiatrists using the DSM-5 criteria,\nPatients with ADHD and healthy controls were excluded when they met the following exclusion criteria: (1) history of treatment with any medication for ADHD; (2) use of psychoactive drugs, antibiotics, probiotics, or traditional Chinese medicine within 1 month prior to sample collection; and (3) special dietary preferences (such as vegan or ketogenic diets) or significant changes in diet within the previous month. Participants were excluded if they had comorbid psychiatric, neurological, gastrointestinal, or metabolic conditions. Additionally, individuals with IQs below 70 according to Raven’s Standard Progressive Matrices\nFollowing the guidelines outlined in the Declaration of Helsinki, the research was granted authorization by the Ethics Committee of Peking University Sixth Hospital (Approval No. 2021–79). Informed consent was obtained from legal guardians, while children aged 8 years or older signed the informed consent on their own.\nADHD symptoms were measured using the Attention-Deficit/Hyperactivity Disorder Rating Scale,\nThe Children Behavior Checklist (CBCL), a widely recognized children behavior assessment tool,\nThe Conners Parental Symptom Questionnaire (PSQ) is completed by the child’s primary caregiver based on the child’s daily behavior.\nFood frequency questionnaires (FFQ) are an effective instrument for assessing typical dietary intake and its relationship with health and disease outcomes.\nStandardized procedures were followed for fecal sample collection, after which the samples were frozen at −80°C. Microbial DNA was extracted from 200 mg fecal samples from 188 participants using the QIAamp PowerFecal Pro DNA Kit. The DNA concentration was measured using a microplate reader, and its integrity was assessed by agarose gel electrophoresis.\nSamples were sequenced on the MGISEQ 2000 platform by Beijing Genomics Institute using PE150 mode with an insert size of 300–400 bp. Prior to bioinformatic analysis, SOAPnuke (v.2.2.1)\nHigh-quality short reads from each DNA sample were assembled into contigs using a multiple k-mer size strategy with MEGAHIT software\nAll participants were initially assigned sequential subject identifiers upon recruitment. After completing fecal sample collection, all samples were randomly reordered using the sample() function in R software (version 4.2.0), and new identification numbers (ADHD: A001-A094; Controls: H001-H094) were assigned accordingly. Metabolomics profiling was performed on the first 31 ADHD patients (A001-A031) and 31 controls (H001-H031) based on the ascending order of these IDs. The 20 μL sample and 20 μL standard were mixed with HM400 releasing agent for extraction. Following centrifugation at 18,000 g for 10 min at 4°C, the supernatant was collected for LC-MS/MS analysis.\nMetabolite separation and quantification were carried out using a Waters ACQUITY UPLC I-Class Plus (Waters, USA) in conjunction with a QTRAP 6500+ high-sensitivity mass spectrometer (SCIEX, USA). Chromatographic separation was achieved using a BEH C18 column (2.1 mm × 10 cm, 1.7 μm; Waters). The QTRAP 6500+ mass spectrometer, equipped with an ESI Turbo Ion Spray interface, was operated with the following parameters: ion source temperature at 400°C, ion spray voltage (IS) at 4500 V (positive mode) and −4500 V (negative mode), and ion source gases I (GS1), II (GS2), and curtain gas (CUR) set to 60, 60, and 35 psi, respectively.\nQuantitative analysis was performed using Skyline software (v.21.1.0.146). This software, configured for monoisotopic peaks with a mass tolerance of 0.6 Da and a mass range of 50–1500 Da, was used to generate a data matrix that included metabolite identification and quantification results for subsequent information analysis and processing. Quality control (QC) samples were generated from a mixture of sample extracts to assess the consistency of the sample under identical treatment. During data collection, a certain number of QC samples were inserted in test samples to monitor the repeatability of the analytical process. The results exported by Skyline software were imported into metaX\nMetabolic pathways were identified using open database sources such as MetaboAnalyst, the Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway database, and the Human Metabolome Database.\nFour-week-old male C57BL/6J mice (initial weight 13–16 g; Gempharmatech Co., Ltd) were housed at a temperature of 22–23°C on a 12-h light/dark cycle with ad libitum access to water and food except during experimental sessions. The study was approved by the Biomedical Ethics Committee of Peking University. After the acclimatization period, mice were orally administered a cocktail of four antibiotics (ABX) for 7 days: ampicillin (200 mg/kg/day, Solarbio Cat#A6920), vancomycin (100 mg/kg/day, VIANEX S.A. PLANTC), neomycin (200 mg/kg/day, SIGMA Cat#N6386), and metronidazole (200 mg/kg/day, SIGMA Cat#M1547).\nSubsequently, mice were subjected to fecal microbiota transplantation (FMT) from ADHD patients with a low abundance of beneficial bacteria\nBehavioral experiments were conducted during the light period. Exploratory activity and hyperactivity behavior were measured using an Open-Field apparatus (40 × 40 × 25 cm). For the five days prior to the test, the mice were handled for 5 min every day, followed by a 5-min familiarization period in the box. Each mouse was placed in the center of the open-field apparatus. A square that was 10 cm from the wall was designated as the center zone. Traveled distance and time spent in the center zone of each animal were recorded for a single 4-min session with a video-imaging system.\nMice were trained using a Five-Choice Serial Reaction Time Task (5-CSRTT) procedure according to a published protocol and previous studies.\nDuring training, the LED of one of the five response holes will be on, and mice were trained to use their noses to locate the lit hole in order to receive a food pellet as a reward. Each session began with the illumination of the response holes light and the food magazine light, followed by the delivery of one food pellet (20 mg/pellet). Once the first food pellet was collected, the intertrial interval (ITI) commenced. At the end of the ITI, one of the five response holes on the chamber wall opposite the food magazine was illuminated for a brief period, known as the stimulus duration (SD). A correct response to this hole within the limited hold (LH) period resulted in the response holes light turning off, the food magazine light turning on, and delivery of one food pellet. After the pellet was collected, the next ITI began. The target stimulus varied pseudorandomly between trials to increase attentional load.\nTraining was divided into seven successive stages with specific criteria for ITI, SD, and LH, which had to be met for two consecutive days before progression to the next stage (Supplementary Fig. 6). A typical training session lasted 30 min or completed 100 trials, whichever came first. Responses into the non-target hole were considered incorrect responses, while responses during the ITI before target stimulus presentation were classified as premature responses, and a failure to respond was recorded as an omission. The average latency to correct responses and correct responses rate reflected the mice’s attention; the premature rate indicated the level of impulsivity.\nMice feces were collected before and after antibiotic treatment (ABX), after fecal microbiota transplantation (FMT), and after the rescue procedure (\nAfter obtaining genus-level ASVs, the data were normalized to ensure sample comparability; sequence count normalization was conducted through rarefaction to address uneven sequencing depths by the ‘rrarefy’ function in Vegan,\nStatistical analyses were performed using R software (version 4.2.0) and Statistical Product and Service Solutions (SPSS, version 26.0). Mean and standard deviation were utilized for continuous variables (including demographic data, dietary data, and psychometric parameters). Kruskal – Wallis tests and post-hoc Wilcoxon rank-sum pairwise tests, with p-values adjusted for multiple testing via the Benjamini – Hochberg method, were applied for inter-group comparisons. Correlation analysis was conducted using partial correlation analysis by the “spearman” method in the R package ppcor. When applicable, age, gender, BMI, SPM, site and principal component of diets were adjusted as covariates. A two-tailed p-value ≤0.05 was considered statistically significant.\nWe performed power analysis and created the species rarefaction curves by the function ‘specaccum’ in the R package vegan\nTo analyze the interrelationship between the microbiota present in stool samples and ADHD symptoms, we used redundancy analysis (RDA) from the R package vegan,\nTo identify significant biomarkers, we compared all species between two groups using LEfSe analysis, which assisted in identifying genomic biomarkers that characterize statistical differences between biological groups.\nFor metabolomics, after normalization to total peak intensity, the multivariate data were dimensionally reduced by principal component analysis (PCA) to analyze groupings, trends (intra-group and inter-group similarities and differences), and outliers in the data set. Using Partial Least Squares-Discriminant Analysis (PLS-DA) of the R package mixOmics\nTo further investigate the correlation between gut microbiota function and fecal metabolites, we employed the MIMOSA model from the R package MIMOSA2.\nThe causal mediation analysis was conducted to explore the influence and interactions of microbiota and metabolites, using the ‘mediate’ function in the R package mediation.\nA total of 188 children and adolescents, consisting of 94 patients with ADHD (56 ADHD-I, 29 ADHD-C, 9 ADHD-HI) and 94 TDs, were recruited.\nDemographics, intelligence, and clinical symptoms of ADHD subgroup and typically developing controls (TD) in the study cohort.\nBMI, body mass index; SPM, Raven’s Standard Progress Matrice;\nWe carried out shotgun metagenomic sequencing for all participants and obtained an average of 9,973,835,522 clean bases per sample. Detailed information on gut microbiota sequencing data was given in Supplementary Table 3. We employed species rarefaction curves to assess and predict the degree to which species richness in the community increases with sample size. The curve for groups TD, IA, and C exhibited a flat trajectory during the terminal phases, indicating that the sample sizes were adequate and the subsequent analyses were reasonable (Supplementary Fig. 1).\nIn terms of taxonomic diversity, we first compared the top 10 relative abundances of microbiota at the level of genus, the Firmicutes-to-Bacteroidetes ratio (F/B ratio), alpha diversity, and beta diversity between ADHD subgroups and TDs. The relative abundance of the top 10 genera of microbiota (Phocaeicola, Bacteroides, Alistipes, Parabacteroides, Faecalibacterium, Roseburia, Bifidobacterium, Escherichia, Lachnospira, Megamonas, and others) did not differ significantly (pFDR >0.05;\nThe overview of the microbiome profiles in three ADHD presentations and TD. (A) the top 10 taxa of relative abundance. The relative compositions of microbiota at the genus level were not significantly different among ADHD subgroups and group TD. The pFDR values of group comparisons are presented followed by legends of microbiota; (B) the Firmicutes to the bacteroidetes ratio. There was no group difference among ADHD subgroups and group TD using ANOVA corrected by FDR; (C) observed species, Shannon index, Simpson index, and Pielou’s evenness index for each group. Data are plotted as ±standard deviation; (D) RDA analysis of microbial community structure and ADHD symptoms in all participants; (E) RDA analysis of microbial community structure and CBCL. CBCL_SOM: somatic complaints of CBCL; CBCL_WIT: withdrawn of CBCL; CBCL_AGS: aggressive behavior of CBCL; CBCL_ANX: anxious/depressed symptoms; CBCL_SOC: social problems of CBCL; CBCL_HA: hyperactivity behaviors of CBCL; CBCL_DEL: delinquent behaviors of CBCL; (F) RDA analysis of microbial community structure and PSQ.\nAlpha diversity indexes for the ADHD subgroups and TDs.\nTotal five indexes of alpha-diversity showed no group differences between ADHD subgroups and TD. S.obs (observed species) were used to estimate the indexes of the total number of species in the community. Shannon index, Simpson index, and Pielou’s evenness index were used to measure the microbial diversity in the sample. Phylogenetic diversity (PD) whole tree was the diversity index calculated the distance of the evolutionary tree.\nThe significance tests of the community structure with greater between-group difference than the within-group difference.\nAnosim similarity analysis is a non-parametric test to test whether the between-group difference is significantly greater than the difference within the group to judge whether the grouping is meaningful. MRPP analysis is similar to Anosim analysis, but the ordering method is different. It analyzes whether the microbial community structure difference between groups is significant. Adonis tests the differences between groups by partitioning the distance matrix among sources of variation and using a permutation test to assess the significance of these differences.\nFurthermore, we used constrained ordination analysis to investigate the correlation between the microbial community structure and ADHD symptoms in all participants. To identify the optimal distribution of our data model (either a linear, unimodal, or bimodal distribution), we implemented a detrended correspondence analysis (DCA). The length value indicated that the linear model fitted our data, with the first axis (DCA1) having a length of 2.58 (less than 3) (Supplementary Table 4). We applied the redundancy analysis (RDA) to a linear model. We found that at the species level, Component 1 from the RDA explained 57.98% of the variance (22.88% with Component 2 scaling) (ANOVA like permutation test F = 1.345, pFDR = 0.015,\nThe ANOVA like permutation test of the redundancy analysis (RDA) between the microbial community structure and ADHD symptoms.\nRDA1 and RDA2 represent the proportion of species distribution explained by each axis in the analysis. The model’s R\nWe conducted a comprehensive analysis of the microbiota community variations from phylum to species levels between ADHD subgroups and group TD to identify potential evolutionary biomarkers linked to ADHD based on the gut microbiome. LEfSe analysis identified dominant bacterial biomarkers contributing to the group disparities. Specifically, 5 bacterial taxa were enriched in group IA and 12 were enriched in group TD when contrasting IA and TD (\n(A) a taxonomic cladogram and an LDA scores bar plot of identified differential taxa between group IA and TD; (B) a taxonomic cladogram and an LDA scores bar plot of identified differential taxa between group HA and TD; (C) a taxonomic cladogram and an LDA scores bar plot of identified differential taxa between group C and TD. The LDA score (log 10) > 2 and\nLinear discriminant analysis of three ADHD subgroups and group TD concurrently revealed that family\nTo further elucidate the association between differential microbiota and symptoms, partial correlation analysis was carried out. After adjusting for various confounding factors, genus\n(A) differential correlation patterns of microbiota with ADHD symptoms. Pairs with pFDR < 0.05 are shown in the picture. The color of each grid represents the value of correlation coefficient. Blue color represents the negative correlation and red color represents the positive correlation; (B)-(D) the relative abundance of microbial function annotated by the KEGG database and significant microbial function among ADHD subgroups and group TD. The **symbol represents the pFDR < 0.05, while the *symbol represents the pFDR < 0.1; (E) differential correlation patterns of functional pathways with ADHD symptoms. Pairs with p-value < 0.05 are shown in the picture. The color of each grid represents the value of correlation coefficient. Blue color represents the negative correlation and red color represents the positive correlation.\nIn the comparative analyses between ADHD subgroups and group TD, as well as the correlation analysis between ADHD symptoms and microbiota, the microbial features existing consistent results were considered more robust. Species\nAfter gene prediction, the total number of genes we obtained and the distribution of genes with different lengths were displayed in Supplementary Figure 2. First, we assessed the microbial function annotated by the KEGG database. We totally annotated the genes expressed by the microbiota to 5 pathways at Level 1, 29 pathways at Level 2, 202 pathways at Level 3, and 6935 KEGG orthology (Supplementary Fig. 3). We next focused on all metabolic pathways of Level 3 and employed STAMP to identify 11 differential pathways between group TD and group C (\nIn group C, tryptophan metabolism, biotin metabolism, histidine metabolism, fatty acid metabolism, and biosynthesis of unsaturated fatty acids were downregulated, while lysine biosynthesis, arginine biosynthesis, phenylalanine, tyrosine and tryptophan biosynthesis, and terpenoid backbone biosynthesis were upregulated (\nFurthermore, we employed partial correlation analysis to investigate relationships between three domains of ADHD symptoms and KEGG pathways, adjusting for sex, age, BMI, SPM, site, and dietary variables. Results demonstrated that biotin metabolism showed negative correlations with all three symptoms, and aminoacyl-tRNA biosynthesis displayed positive correlations with all symptoms (\nSimilarly, pathways demonstrating consistent results in both comparative analysis and correlation analysis were considered more robust. The biotin metabolism pathway showed increased abundance in group TD in all three pairs of comparisons, and correlation analysis also demonstrated that this pathway was negatively correlated with all three ADHD symptoms. The relative abundance of tryptophan metabolism was downregulated in group IA and group C and the pathway also showed a negative correlation with inattention symptoms. The relative abundance of terpenoid backbone biosynthesis was upregulated in group HA and group C, and the pathway also showed a positive correlation with impulsivity symptoms. In addition, group C, which exhibited symptoms of inattention, hyperactivity, and impulsivity, demonstrated differences in biosynthesis of unsaturated fatty acids, fatty acid metabolism, and histidine metabolism. Correspondingly, correlation analysis revealed that the first two pathways were associated with inattention, while histidine metabolism was associated with impulsivity.\nTo further elucidate the alterations in bacterial metabolism, we conducted untargeted metabolomics using fecal samples. The baseline comparison results between metabolomic subgroups and the full cohort are provided in Supplementary Table 7. No significant differences were observed in all these key variables, which supported the representativeness of the metabolomic subgroups. A total of 307 metabolites were identified, with classifications and the number of each class presented in Supplementary Figure 4. The comprehensive details of each identified metabolite are presented in Supplementary Table 8.\nBased on the differential metabolite screening criteria, there were 21 downregulated metabolites identified in group ADHD compared to group TD (\n(A) Volcano plot of the different metabolites between group ADHD and group TD. The abscissa is the Fold change converted by log2, and the ordinate is the q-value converted by log10. The circles represent metabolites with a VIP > 1. Blue circles represent significant metabolites, while gray circles represent non-significant metabolites; (B) the KEGG pathway enrichment metabolic network of differential metabolites between groups, with node size representing the number of candidate genes in pathway; (C) bubble diagram for enrichment analysis based on the KEGG database. RichFactor is the ratio of differential metabolites annotated to the total number of identified metabolites annotated in a certain pathway; (D) differential correlation patterns of the metabolites with ADHD symptoms. The size of circles represents -log10(pFDR), pairs with pFDR < 0.05 are shown in the picture. The color of circle represents the value of correlation coefficient; (E) path diagram of the mediation analysis model of imidazoleacetic acid between\nTo explore the relationship between the significant differential metabolites and ADHD symptoms, we conducted a partial correlation analysis. After adjusting various confounding factors, we found that inattention symptom was negatively correlated with 12-hydroxystearic acid, all-trans-retinoic acid, lithocholic acid acetate methyl ester, vanillin, 4-guanidinobutyric acid, imidazoleacetic acid, 12-tridecanoic acid, and taurochendeoxycholic acid. Hyperactivity symptom was negatively correlated with 12-hydroxystearic acid, all-trans-retinoic acid, lithocholic acid acetate methyl ester, linoleic acid, 3,6-diketocholanic acid ethyl ester, and quinolinic acid. Impulsivity symptoms also had a negative correlation with vanillin, 4-guanidinobutyric acid, quinolinic acid, and ricinoleic acid (\nTo further explore the association between metagenomics and metabolomics between groups, we used the MIMOSA model to predict the impact of gut microbiota composition or function on metabolite concentrations. Based on the metabolic network approach, we then identified eight metabolites regulated by gut microbiome functions, which were annotated by KEGG orthology, including 4-Hydroxybenzoic acid, imidazoleacetic acid, hydroxyproline, 4-aminobutyric acid, 4-guanidinobutyric acid, L-asparagine, D-xylose, and pidolic acid. Importantly, imidazoleacetic acid, 4-aminobutyric acid, and 4-guanidinobutyric acid were previously identified as key differential metabolites between group ADHD and group TD, and all three are classified as short-chain fatty acids (SCFAs). It is noteworthy that the top producing pathways of these three metabolites are\nResults of MIMOSA model to predict the impact of gut microbiota composition or function on metabolite concentrations.\nID: KEGG compound ID for that metabolite; R\nTo investigate the influence and interactions of microbiota and metabolites on ADHD, we selected differential species and metabolites most strongly correlated with ADHD symptoms. The causal mediation analysis indicated a total effect of\nTo verify the pathway from microbiota to metabolites and subsequently to ADHD symptoms, we conducted a fecal microbiota transplantation experiment in mice. Detailed information on the sequencing data of mice fecal samples was presented in Supplementary Table 12. The 16S rRNA analysis of mice fecal microbiota showed a significant reduction in alpha diversity following treatment with ABX. In terms of beta diversity, the microbiota of ABX-treated mice exhibited a distinct distribution pattern compared to wild-type mice (Supplementary Fig. 7). These findings validated the effectiveness of antibiotic treatment in altering the gut microbiota. After fecal microbiota transplantation from different sources, we observed that mice subjected to feces from ADHD patients with a low abundance of beneficial bacteria in group FMT-A exhibited hyperactive behavior (\nIn the rescue experiments for mice exhibiting ADHD-related symptoms after receiving FMT from ADHD patients, we found that compared to the control group (FMT-A-C), group FMT-A-R1, which received treatment with\n(A) workflow diagram of fecal microbiota transplantation (FMT) and rescue experiments in mice. ABX: orally administered a cocktail of four antibiotics, FMT: fecal microbiota transplantation; (B) performance of mice in the open field test and 5-choice serial reaction time task (5-CSRTT) following different rescue interventions; (C) relative abundance of the genus\nDue to the limitations of 16S rRNA sequencing, we focused on the relative abundance of the genus\nMental health includes mental, emotional, social, and behavioral functions, occurring along a continuum from optimal to poor.\nThe metagenomic data demonstrated gut dysbiosis in patients with ADHD. While comparing gut microbiota taxa between ADHD subgroups and group TD, there were no significant differences observed in alpha diversity between patients with ADHD and TDs, which aligns with several previous studies.\nTo explore the relationship between taxa and ADHD symptoms, we employed LEfSe analysis between ADHD subgroups exhibiting different domains of symptoms and group TD, as well as correlation analysis between symptoms and microbiota. Microbial features that exhibited consistent results were deemed more robust. The LEfSe analysis of the ADHD subgroups and group TD revealed that the family\nRegarding the harmful bacteria enriched in ADHD groups or positively correlated with ADHD symptoms, both methods identified\nThe analysis of predicted microbial functions revealed significant differences between ADHD subgroups and group TD. The most significant pathways include several amino acid-related pathways, such as tryptophan metabolism, phenylalanine, tyrosine and tryptophan biosynthesis, and lysine biosynthesis. As Li et al. reported, gut microbiota actively reshapes the host’s amino acid balance through the metabolism of intestinal amino acids.\nOur analysis of metagenomic functional pathways and fecal metabolites concurrently revealed a downregulation of both fatty acid metabolism and the biosynthesis of unsaturated fatty acids in ADHD. The most significantly enriched process was the biosynthesis of unsaturated fatty acids. Unsaturated fatty acids, including MUFAs,\nIn addition, through the correlation analysis of metabolomics and metagenomics, we identified eight metabolites regulated by gut microbiota functions, three of which (imidazoleacetic acid, 4-aminobutyric acid, and 4-guanidinobutyric acid) also exhibited significant differences between groups. The three metabolites are categorized as short-chain fatty acids (SCFAs), and we have also identified several key enzymes that contribute significantly to their synthesis. This suggests that the impact of gut microbiota on ADHD pathogenesis may be mediated through the synthesis of SCFAs by regulating the expression of certain enzymes. Consistent with our findings, in previous studies, aberrant levels of SCFAs have been implicated in disease pathogenesis and are generally present in diminished quantities.\nIn summary, in the analysis of linear discriminant analysis and symptom-related species from metagenomics, we identified probiotics primarily responsible for the production of short-chain fatty acids (SCFAs). This aligns with the findings from the association analysis between metagenomics and metabolomics, where the metabolites modulated by gut microbiota and significantly downregulated in cases were primarily SCFAs. Additionally, the important overlapped pathways in the metagenomic differential functional pathways and the differential metabolites enrichment analysis were fatty acid metabolism and biosynthesis of unsaturated fatty acids, with SCFAs being one of the key substances involved in these pathways. These findings collectively reveal a disturbance in fatty acid metabolism associated with the pathogenesis of ADHD. To further validate the hypothesis that SCFA-producing microbes affect ADHD pathogenesis through the mediation of SCFAs, we conducted a causal mediation analysis. The results confirmed that\nThe main strengths of our study include a larger sample size of the Chinese population compared to previous studies. At the same time, we excluded participants with other psychiatric, neurological, gastrointestinal, and metabolic conditions, as well as those with active use of psychoactive drugs, antibiotics, and probiotics. Methodologically, we employed shotgun metagenomic sequencing, which offers greater species identification depth compared to 16S rRNA sequencing. In terms of analysis, we conducted subgroup analyses of ADHD clinical symptoms, and the comparison between group C and group TD provided more comprehensive and detailed information that may have been overlooked without the application of subgroup analysis. Regarding study content, previous research has mostly focused on measuring plasma concentrations of amino acids and fatty acids as well as analyzing their correlation with clinical symptoms. In contrast, our study, for the first time, investigates the pathogenic role of gut microbiota in ADHD through species variations, gene pathway expression and fecal-targeted metabolomics. Specifically, it reveals the involvement of gut microbiota in disrupted fatty acid and amino acid metabolism, particularly in the biosynthesis of unsaturated fatty acids. Furthermore, we formulated a hypothesis that gut microbiota affects ADHD symptoms through metabolic variations. We then subsequently conducted fecal microbiota transplantation experiment in mice to validate the hypothesis. This contributes to a deeper understanding of the mechanisms underlying metabolic disturbances in ADHD and addresses gaps in previous studies by linking the gut-brain axis mechanism to ADHD through gut microbiota profiles.\nThere are also some limitations to our study. First, excluding patients with gastrointestinal conditions or special diets may preclude participants with more aberrant microbiota compositions, thereby hindering the detection of correlations between gastrointestinal symptoms, food style, and microbial profiles. Second, due to the lower prevalence of the hyperactive/impulsive subtype in clinical settings, the sample size of group HA in our cohort might have been underpowered, and the sample size for each subgroup might be imbalanced. To address this problem, we emphasize the convergent evidence from our correlation analysis between microbial taxa, functions, and symptoms, which partially mitigates subgroup limitations. Third, we performed a cross-sectional study, which does not allow for confirming the causal directions between the correlational link between differential species, functional pathways, fecal metabolites, and the disease or symptoms. To address this problem, we conducted animal experiments; however, further longitudinal work in human populations should be undertaken to assess age-associated and other variations in gut microbiota.\nBuilding upon our findings and the current progress of gut-brain axis research, large-scale prospective longitudinal studies are essential to track the dynamic development of the gut microbiome and its relationship with the onset, progression, and symptom fluctuation of ADHD. In parallel, well-designed randomized controlled trials evaluating the efficacy of dietary modifications, specific prebiotics, probiotics, or microbiota transplantation are warranted to explore the therapeutic potential of targeting microbial and metabolic dysbiosis in ADHD. Furthermore, mechanistic investigations into how gut microbes and their metabolites influence gut-brain signaling pathways, along with integrative multi-omics approaches encompassing host genetics, transcriptomics, and metabolomics, will be crucial for advancing our understanding of the complex biological underpinnings of ADHD and identifying novel therapeutic targets.\nIn conclusion, our study characterized the distinct gut microbiota and fetal metabolite profiles in patients with ADHD and its subtypes. We observed more gut microbial alterations in patients from group C compared to those in group IA or HA. Moreover, we employed metagenomics and fecal metabolomics techniques for the first time to elucidate the role of gut microbiota in the dysregulation of fatty acid and amino acid metabolism, with a particular focus on the biosynthesis of unsaturated fatty acids and SCFAs. Through causal mediation analysis of population sample data and mouse experiments of fecal microbiota transplantation, we further validated the pathway from microbiota to metabolites and subsequently to ADHD symptoms. The study provides new evidence supporting the association between the microbiota-gut-brain axis and ADHD and contributes to a deeper understanding of the mechanisms underlying these metabolic disturbances in ADHD.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "39011183", "pmcid": "12309550", "title": "Symptom-specific gut microbial and metabolic profiles in ADHD reveal SCFA deficiency as a Key pathogenic mechanism", "publication_year": "2025", "abstract": "Previous evidence links gut microbiota to attention-deficit/hyperactivity disorder (ADHD) through the gut-brain axis. However, the specific microbiota contributing to symptoms remain unclear. To characterize the gut microbial profile related to different symptoms and explore the mediation mechanism between microbiota alterations and the core ADHD symptoms, we conducted shotgun metagenomic sequencing and fecal metabolomics analysis on 94 ADHD patients and 94 age- and gender-matched controls. Microbial characteristics of three subgroups exhibiting different ADHD core symptom presentations were analyzed. We developed a metabolic model and conducted causal mediation analyses to examine how metabolites connect the microbiota to the symptoms. Fecal microbiota transplantation in mice was employed to validate the findings. The redundancy analysis identified ADHD symptoms as environmental gradients and explained the changes in beta diversity (F = 1.345, pFDR = 0.015). Greater gut microbial alterations were observed in combined presentations (ADHD-C). Several beneficial bacteria involved in short-chain fatty acid synthesis were found to be downregulated, with Lactobacillus sanfranciscensis notably linked to all three core symptoms (p.adj = 1.04E–13; p.adj = 5.07E–07; p.adj = 2.61E–05). Various taxa, functional pathways, and metabolites associated with specific ADHD symptom domains were identified. Imidazoleacetic acid partially mediated the effects between Lactobacillus sanfranciscensis and inattention (p = 0.012). In mice subjected to feces from ADHD patients with a low abundance of Lactobacillus sanfranciscensis, treatment with this strain greatly improved both hyperactivity (t = 2.665, p = 0.0237) and inattention (t = 2.389, p = 0.0380), while acetate supplementation only alleviated inattention (t = 2.362, p = 0.0398). Our findings suggest that different ADHD symptoms were related to common and different gut microbiota and metabolites. Fecal microbiota transplantation in mice validated the hypothesis that gut microbial composition affects ADHD symptoms through metabolic alterations. This study provides more insight into the mechanisms underlying metabolic disturbances in ADHD and elucidates the role of gut microbiota in these processes.", "full_text": "Attention-deficit/hyperactivity disorder (ADHD) is one of the most commonly diagnosed psychiatric conditions in children and adolescents, with a global prevalence of 3–5%.\nAlthough ADHD is highly heritable,\nThrough the microbiota-gut-brain axis (MGBA), the effects of the gut microbiota on neurodevelopment have gained more recognition recently. The gut microbiota is commonly considered to regulate neurodevelopment through three pathways – the immune pathway, the neuronal pathway, and the endocrine/systemic pathway, with overlaps and interaction in between.\nResearch has shown that many ADHD-related risk factors also influence the microbiota, such as delivery method, gestational age, type of feeding, maternal health, and early life stressors.\nPrevious studies utilizing 16S rRNA gene amplicon or shotgun metagenomic sequencing have preliminarily identified differences in gut microbiota composition between ADHD and controls.\nOne hundred and eighty-eight participants aged 6–16 years were recruited from the Child and Adolescent Mental Health Center at Peking University Sixth Hospital, Yan’an Third People’s Hospital, and local schools. Of these, 94 were ADHD patients and 94 were age- and gender-matched healthy controls. The initial diagnoses of patients were made by senior psychiatrists using the DSM-5 criteria,\nPatients with ADHD and healthy controls were excluded when they met the following exclusion criteria: (1) history of treatment with any medication for ADHD; (2) use of psychoactive drugs, antibiotics, probiotics, or traditional Chinese medicine within 1 month prior to sample collection; and (3) special dietary preferences (such as vegan or ketogenic diets) or significant changes in diet within the previous month. Participants were excluded if they had comorbid psychiatric, neurological, gastrointestinal, or metabolic conditions. Additionally, individuals with IQs below 70 according to Raven’s Standard Progressive Matrices\nFollowing the guidelines outlined in the Declaration of Helsinki, the research was granted authorization by the Ethics Committee of Peking University Sixth Hospital (Approval No. 2021–79). Informed consent was obtained from legal guardians, while children aged 8 years or older signed the informed consent on their own.\nADHD symptoms were measured using the Attention-Deficit/Hyperactivity Disorder Rating Scale,\nThe Children Behavior Checklist (CBCL), a widely recognized children behavior assessment tool,\nThe Conners Parental Symptom Questionnaire (PSQ) is completed by the child’s primary caregiver based on the child’s daily behavior.\nFood frequency questionnaires (FFQ) are an effective instrument for assessing typical dietary intake and its relationship with health and disease outcomes.\nStandardized procedures were followed for fecal sample collection, after which the samples were frozen at −80°C. Microbial DNA was extracted from 200 mg fecal samples from 188 participants using the QIAamp PowerFecal Pro DNA Kit. The DNA concentration was measured using a microplate reader, and its integrity was assessed by agarose gel electrophoresis.\nSamples were sequenced on the MGISEQ 2000 platform by Beijing Genomics Institute using PE150 mode with an insert size of 300–400 bp. Prior to bioinformatic analysis, SOAPnuke (v.2.2.1)\nHigh-quality short reads from each DNA sample were assembled into contigs using a multiple k-mer size strategy with MEGAHIT software\nAll participants were initially assigned sequential subject identifiers upon recruitment. After completing fecal sample collection, all samples were randomly reordered using the sample() function in R software (version 4.2.0), and new identification numbers (ADHD: A001-A094; Controls: H001-H094) were assigned accordingly. Metabolomics profiling was performed on the first 31 ADHD patients (A001-A031) and 31 controls (H001-H031) based on the ascending order of these IDs. The 20 μL sample and 20 μL standard were mixed with HM400 releasing agent for extraction. Following centrifugation at 18,000 g for 10 min at 4°C, the supernatant was collected for LC-MS/MS analysis.\nMetabolite separation and quantification were carried out using a Waters ACQUITY UPLC I-Class Plus (Waters, USA) in conjunction with a QTRAP 6500+ high-sensitivity mass spectrometer (SCIEX, USA). Chromatographic separation was achieved using a BEH C18 column (2.1 mm × 10 cm, 1.7 μm; Waters). The QTRAP 6500+ mass spectrometer, equipped with an ESI Turbo Ion Spray interface, was operated with the following parameters: ion source temperature at 400°C, ion spray voltage (IS) at 4500 V (positive mode) and −4500 V (negative mode), and ion source gases I (GS1), II (GS2), and curtain gas (CUR) set to 60, 60, and 35 psi, respectively.\nQuantitative analysis was performed using Skyline software (v.21.1.0.146). This software, configured for monoisotopic peaks with a mass tolerance of 0.6 Da and a mass range of 50–1500 Da, was used to generate a data matrix that included metabolite identification and quantification results for subsequent information analysis and processing. Quality control (QC) samples were generated from a mixture of sample extracts to assess the consistency of the sample under identical treatment. During data collection, a certain number of QC samples were inserted in test samples to monitor the repeatability of the analytical process. The results exported by Skyline software were imported into metaX\nMetabolic pathways were identified using open database sources such as MetaboAnalyst, the Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway database, and the Human Metabolome Database.\nFour-week-old male C57BL/6J mice (initial weight 13–16 g; Gempharmatech Co., Ltd) were housed at a temperature of 22–23°C on a 12-h light/dark cycle with ad libitum access to water and food except during experimental sessions. The study was approved by the Biomedical Ethics Committee of Peking University. After the acclimatization period, mice were orally administered a cocktail of four antibiotics (ABX) for 7 days: ampicillin (200 mg/kg/day, Solarbio Cat#A6920), vancomycin (100 mg/kg/day, VIANEX S.A. PLANTC), neomycin (200 mg/kg/day, SIGMA Cat#N6386), and metronidazole (200 mg/kg/day, SIGMA Cat#M1547).\nSubsequently, mice were subjected to fecal microbiota transplantation (FMT) from ADHD patients with a low abundance of beneficial bacteria\nBehavioral experiments were conducted during the light period. Exploratory activity and hyperactivity behavior were measured using an Open-Field apparatus (40 × 40 × 25 cm). For the five days prior to the test, the mice were handled for 5 min every day, followed by a 5-min familiarization period in the box. Each mouse was placed in the center of the open-field apparatus. A square that was 10 cm from the wall was designated as the center zone. Traveled distance and time spent in the center zone of each animal were recorded for a single 4-min session with a video-imaging system.\nMice were trained using a Five-Choice Serial Reaction Time Task (5-CSRTT) procedure according to a published protocol and previous studies.\nDuring training, the LED of one of the five response holes will be on, and mice were trained to use their noses to locate the lit hole in order to receive a food pellet as a reward. Each session began with the illumination of the response holes light and the food magazine light, followed by the delivery of one food pellet (20 mg/pellet). Once the first food pellet was collected, the intertrial interval (ITI) commenced. At the end of the ITI, one of the five response holes on the chamber wall opposite the food magazine was illuminated for a brief period, known as the stimulus duration (SD). A correct response to this hole within the limited hold (LH) period resulted in the response holes light turning off, the food magazine light turning on, and delivery of one food pellet. After the pellet was collected, the next ITI began. The target stimulus varied pseudorandomly between trials to increase attentional load.\nTraining was divided into seven successive stages with specific criteria for ITI, SD, and LH, which had to be met for two consecutive days before progression to the next stage (Supplementary Fig. 6). A typical training session lasted 30 min or completed 100 trials, whichever came first. Responses into the non-target hole were considered incorrect responses, while responses during the ITI before target stimulus presentation were classified as premature responses, and a failure to respond was recorded as an omission. The average latency to correct responses and correct responses rate reflected the mice’s attention; the premature rate indicated the level of impulsivity.\nMice feces were collected before and after antibiotic treatment (ABX), after fecal microbiota transplantation (FMT), and after the rescue procedure (\nAfter obtaining genus-level ASVs, the data were normalized to ensure sample comparability; sequence count normalization was conducted through rarefaction to address uneven sequencing depths by the ‘rrarefy’ function in Vegan,\nStatistical analyses were performed using R software (version 4.2.0) and Statistical Product and Service Solutions (SPSS, version 26.0). Mean and standard deviation were utilized for continuous variables (including demographic data, dietary data, and psychometric parameters). Kruskal – Wallis tests and post-hoc Wilcoxon rank-sum pairwise tests, with p-values adjusted for multiple testing via the Benjamini – Hochberg method, were applied for inter-group comparisons. Correlation analysis was conducted using partial correlation analysis by the “spearman” method in the R package ppcor. When applicable, age, gender, BMI, SPM, site and principal component of diets were adjusted as covariates. A two-tailed p-value ≤0.05 was considered statistically significant.\nWe performed power analysis and created the species rarefaction curves by the function ‘specaccum’ in the R package vegan\nTo analyze the interrelationship between the microbiota present in stool samples and ADHD symptoms, we used redundancy analysis (RDA) from the R package vegan,\nTo identify significant biomarkers, we compared all species between two groups using LEfSe analysis, which assisted in identifying genomic biomarkers that characterize statistical differences between biological groups.\nFor metabolomics, after normalization to total peak intensity, the multivariate data were dimensionally reduced by principal component analysis (PCA) to analyze groupings, trends (intra-group and inter-group similarities and differences), and outliers in the data set. Using Partial Least Squares-Discriminant Analysis (PLS-DA) of the R package mixOmics\nTo further investigate the correlation between gut microbiota function and fecal metabolites, we employed the MIMOSA model from the R package MIMOSA2.\nThe causal mediation analysis was conducted to explore the influence and interactions of microbiota and metabolites, using the ‘mediate’ function in the R package mediation.\nA total of 188 children and adolescents, consisting of 94 patients with ADHD (56 ADHD-I, 29 ADHD-C, 9 ADHD-HI) and 94 TDs, were recruited.\nDemographics, intelligence, and clinical symptoms of ADHD subgroup and typically developing controls (TD) in the study cohort.\nBMI, body mass index; SPM, Raven’s Standard Progress Matrice;\nWe carried out shotgun metagenomic sequencing for all participants and obtained an average of 9,973,835,522 clean bases per sample. Detailed information on gut microbiota sequencing data was given in Supplementary Table 3. We employed species rarefaction curves to assess and predict the degree to which species richness in the community increases with sample size. The curve for groups TD, IA, and C exhibited a flat trajectory during the terminal phases, indicating that the sample sizes were adequate and the subsequent analyses were reasonable (Supplementary Fig. 1).\nIn terms of taxonomic diversity, we first compared the top 10 relative abundances of microbiota at the level of genus, the Firmicutes-to-Bacteroidetes ratio (F/B ratio), alpha diversity, and beta diversity between ADHD subgroups and TDs. The relative abundance of the top 10 genera of microbiota (Phocaeicola, Bacteroides, Alistipes, Parabacteroides, Faecalibacterium, Roseburia, Bifidobacterium, Escherichia, Lachnospira, Megamonas, and others) did not differ significantly (pFDR >0.05;\nThe overview of the microbiome profiles in three ADHD presentations and TD. (A) the top 10 taxa of relative abundance. The relative compositions of microbiota at the genus level were not significantly different among ADHD subgroups and group TD. The pFDR values of group comparisons are presented followed by legends of microbiota; (B) the Firmicutes to the bacteroidetes ratio. There was no group difference among ADHD subgroups and group TD using ANOVA corrected by FDR; (C) observed species, Shannon index, Simpson index, and Pielou’s evenness index for each group. Data are plotted as ±standard deviation; (D) RDA analysis of microbial community structure and ADHD symptoms in all participants; (E) RDA analysis of microbial community structure and CBCL. CBCL_SOM: somatic complaints of CBCL; CBCL_WIT: withdrawn of CBCL; CBCL_AGS: aggressive behavior of CBCL; CBCL_ANX: anxious/depressed symptoms; CBCL_SOC: social problems of CBCL; CBCL_HA: hyperactivity behaviors of CBCL; CBCL_DEL: delinquent behaviors of CBCL; (F) RDA analysis of microbial community structure and PSQ.\nAlpha diversity indexes for the ADHD subgroups and TDs.\nTotal five indexes of alpha-diversity showed no group differences between ADHD subgroups and TD. S.obs (observed species) were used to estimate the indexes of the total number of species in the community. Shannon index, Simpson index, and Pielou’s evenness index were used to measure the microbial diversity in the sample. Phylogenetic diversity (PD) whole tree was the diversity index calculated the distance of the evolutionary tree.\nThe significance tests of the community structure with greater between-group difference than the within-group difference.\nAnosim similarity analysis is a non-parametric test to test whether the between-group difference is significantly greater than the difference within the group to judge whether the grouping is meaningful. MRPP analysis is similar to Anosim analysis, but the ordering method is different. It analyzes whether the microbial community structure difference between groups is significant. Adonis tests the differences between groups by partitioning the distance matrix among sources of variation and using a permutation test to assess the significance of these differences.\nFurthermore, we used constrained ordination analysis to investigate the correlation between the microbial community structure and ADHD symptoms in all participants. To identify the optimal distribution of our data model (either a linear, unimodal, or bimodal distribution), we implemented a detrended correspondence analysis (DCA). The length value indicated that the linear model fitted our data, with the first axis (DCA1) having a length of 2.58 (less than 3) (Supplementary Table 4). We applied the redundancy analysis (RDA) to a linear model. We found that at the species level, Component 1 from the RDA explained 57.98% of the variance (22.88% with Component 2 scaling) (ANOVA like permutation test F = 1.345, pFDR = 0.015,\nThe ANOVA like permutation test of the redundancy analysis (RDA) between the microbial community structure and ADHD symptoms.\nRDA1 and RDA2 represent the proportion of species distribution explained by each axis in the analysis. The model’s R\nWe conducted a comprehensive analysis of the microbiota community variations from phylum to species levels between ADHD subgroups and group TD to identify potential evolutionary biomarkers linked to ADHD based on the gut microbiome. LEfSe analysis identified dominant bacterial biomarkers contributing to the group disparities. Specifically, 5 bacterial taxa were enriched in group IA and 12 were enriched in group TD when contrasting IA and TD (\n(A) a taxonomic cladogram and an LDA scores bar plot of identified differential taxa between group IA and TD; (B) a taxonomic cladogram and an LDA scores bar plot of identified differential taxa between group HA and TD; (C) a taxonomic cladogram and an LDA scores bar plot of identified differential taxa between group C and TD. The LDA score (log 10) > 2 and\nLinear discriminant analysis of three ADHD subgroups and group TD concurrently revealed that family\nTo further elucidate the association between differential microbiota and symptoms, partial correlation analysis was carried out. After adjusting for various confounding factors, genus\n(A) differential correlation patterns of microbiota with ADHD symptoms. Pairs with pFDR < 0.05 are shown in the picture. The color of each grid represents the value of correlation coefficient. Blue color represents the negative correlation and red color represents the positive correlation; (B)-(D) the relative abundance of microbial function annotated by the KEGG database and significant microbial function among ADHD subgroups and group TD. The **symbol represents the pFDR < 0.05, while the *symbol represents the pFDR < 0.1; (E) differential correlation patterns of functional pathways with ADHD symptoms. Pairs with p-value < 0.05 are shown in the picture. The color of each grid represents the value of correlation coefficient. Blue color represents the negative correlation and red color represents the positive correlation.\nIn the comparative analyses between ADHD subgroups and group TD, as well as the correlation analysis between ADHD symptoms and microbiota, the microbial features existing consistent results were considered more robust. Species\nAfter gene prediction, the total number of genes we obtained and the distribution of genes with different lengths were displayed in Supplementary Figure 2. First, we assessed the microbial function annotated by the KEGG database. We totally annotated the genes expressed by the microbiota to 5 pathways at Level 1, 29 pathways at Level 2, 202 pathways at Level 3, and 6935 KEGG orthology (Supplementary Fig. 3). We next focused on all metabolic pathways of Level 3 and employed STAMP to identify 11 differential pathways between group TD and group C (\nIn group C, tryptophan metabolism, biotin metabolism, histidine metabolism, fatty acid metabolism, and biosynthesis of unsaturated fatty acids were downregulated, while lysine biosynthesis, arginine biosynthesis, phenylalanine, tyrosine and tryptophan biosynthesis, and terpenoid backbone biosynthesis were upregulated (\nFurthermore, we employed partial correlation analysis to investigate relationships between three domains of ADHD symptoms and KEGG pathways, adjusting for sex, age, BMI, SPM, site, and dietary variables. Results demonstrated that biotin metabolism showed negative correlations with all three symptoms, and aminoacyl-tRNA biosynthesis displayed positive correlations with all symptoms (\nSimilarly, pathways demonstrating consistent results in both comparative analysis and correlation analysis were considered more robust. The biotin metabolism pathway showed increased abundance in group TD in all three pairs of comparisons, and correlation analysis also demonstrated that this pathway was negatively correlated with all three ADHD symptoms. The relative abundance of tryptophan metabolism was downregulated in group IA and group C and the pathway also showed a negative correlation with inattention symptoms. The relative abundance of terpenoid backbone biosynthesis was upregulated in group HA and group C, and the pathway also showed a positive correlation with impulsivity symptoms. In addition, group C, which exhibited symptoms of inattention, hyperactivity, and impulsivity, demonstrated differences in biosynthesis of unsaturated fatty acids, fatty acid metabolism, and histidine metabolism. Correspondingly, correlation analysis revealed that the first two pathways were associated with inattention, while histidine metabolism was associated with impulsivity.\nTo further elucidate the alterations in bacterial metabolism, we conducted untargeted metabolomics using fecal samples. The baseline comparison results between metabolomic subgroups and the full cohort are provided in Supplementary Table 7. No significant differences were observed in all these key variables, which supported the representativeness of the metabolomic subgroups. A total of 307 metabolites were identified, with classifications and the number of each class presented in Supplementary Figure 4. The comprehensive details of each identified metabolite are presented in Supplementary Table 8.\nBased on the differential metabolite screening criteria, there were 21 downregulated metabolites identified in group ADHD compared to group TD (\n(A) Volcano plot of the different metabolites between group ADHD and group TD. The abscissa is the Fold change converted by log2, and the ordinate is the q-value converted by log10. The circles represent metabolites with a VIP > 1. Blue circles represent significant metabolites, while gray circles represent non-significant metabolites; (B) the KEGG pathway enrichment metabolic network of differential metabolites between groups, with node size representing the number of candidate genes in pathway; (C) bubble diagram for enrichment analysis based on the KEGG database. RichFactor is the ratio of differential metabolites annotated to the total number of identified metabolites annotated in a certain pathway; (D) differential correlation patterns of the metabolites with ADHD symptoms. The size of circles represents -log10(pFDR), pairs with pFDR < 0.05 are shown in the picture. The color of circle represents the value of correlation coefficient; (E) path diagram of the mediation analysis model of imidazoleacetic acid between\nTo explore the relationship between the significant differential metabolites and ADHD symptoms, we conducted a partial correlation analysis. After adjusting various confounding factors, we found that inattention symptom was negatively correlated with 12-hydroxystearic acid, all-trans-retinoic acid, lithocholic acid acetate methyl ester, vanillin, 4-guanidinobutyric acid, imidazoleacetic acid, 12-tridecanoic acid, and taurochendeoxycholic acid. Hyperactivity symptom was negatively correlated with 12-hydroxystearic acid, all-trans-retinoic acid, lithocholic acid acetate methyl ester, linoleic acid, 3,6-diketocholanic acid ethyl ester, and quinolinic acid. Impulsivity symptoms also had a negative correlation with vanillin, 4-guanidinobutyric acid, quinolinic acid, and ricinoleic acid (\nTo further explore the association between metagenomics and metabolomics between groups, we used the MIMOSA model to predict the impact of gut microbiota composition or function on metabolite concentrations. Based on the metabolic network approach, we then identified eight metabolites regulated by gut microbiome functions, which were annotated by KEGG orthology, including 4-Hydroxybenzoic acid, imidazoleacetic acid, hydroxyproline, 4-aminobutyric acid, 4-guanidinobutyric acid, L-asparagine, D-xylose, and pidolic acid. Importantly, imidazoleacetic acid, 4-aminobutyric acid, and 4-guanidinobutyric acid were previously identified as key differential metabolites between group ADHD and group TD, and all three are classified as short-chain fatty acids (SCFAs). It is noteworthy that the top producing pathways of these three metabolites are\nResults of MIMOSA model to predict the impact of gut microbiota composition or function on metabolite concentrations.\nID: KEGG compound ID for that metabolite; R\nTo investigate the influence and interactions of microbiota and metabolites on ADHD, we selected differential species and metabolites most strongly correlated with ADHD symptoms. The causal mediation analysis indicated a total effect of\nTo verify the pathway from microbiota to metabolites and subsequently to ADHD symptoms, we conducted a fecal microbiota transplantation experiment in mice. Detailed information on the sequencing data of mice fecal samples was presented in Supplementary Table 12. The 16S rRNA analysis of mice fecal microbiota showed a significant reduction in alpha diversity following treatment with ABX. In terms of beta diversity, the microbiota of ABX-treated mice exhibited a distinct distribution pattern compared to wild-type mice (Supplementary Fig. 7). These findings validated the effectiveness of antibiotic treatment in altering the gut microbiota. After fecal microbiota transplantation from different sources, we observed that mice subjected to feces from ADHD patients with a low abundance of beneficial bacteria in group FMT-A exhibited hyperactive behavior (\nIn the rescue experiments for mice exhibiting ADHD-related symptoms after receiving FMT from ADHD patients, we found that compared to the control group (FMT-A-C), group FMT-A-R1, which received treatment with\n(A) workflow diagram of fecal microbiota transplantation (FMT) and rescue experiments in mice. ABX: orally administered a cocktail of four antibiotics, FMT: fecal microbiota transplantation; (B) performance of mice in the open field test and 5-choice serial reaction time task (5-CSRTT) following different rescue interventions; (C) relative abundance of the genus\nDue to the limitations of 16S rRNA sequencing, we focused on the relative abundance of the genus\nMental health includes mental, emotional, social, and behavioral functions, occurring along a continuum from optimal to poor.\nThe metagenomic data demonstrated gut dysbiosis in patients with ADHD. While comparing gut microbiota taxa between ADHD subgroups and group TD, there were no significant differences observed in alpha diversity between patients with ADHD and TDs, which aligns with several previous studies.\nTo explore the relationship between taxa and ADHD symptoms, we employed LEfSe analysis between ADHD subgroups exhibiting different domains of symptoms and group TD, as well as correlation analysis between symptoms and microbiota. Microbial features that exhibited consistent results were deemed more robust. The LEfSe analysis of the ADHD subgroups and group TD revealed that the family\nRegarding the harmful bacteria enriched in ADHD groups or positively correlated with ADHD symptoms, both methods identified\nThe analysis of predicted microbial functions revealed significant differences between ADHD subgroups and group TD. The most significant pathways include several amino acid-related pathways, such as tryptophan metabolism, phenylalanine, tyrosine and tryptophan biosynthesis, and lysine biosynthesis. As Li et al. reported, gut microbiota actively reshapes the host’s amino acid balance through the metabolism of intestinal amino acids.\nOur analysis of metagenomic functional pathways and fecal metabolites concurrently revealed a downregulation of both fatty acid metabolism and the biosynthesis of unsaturated fatty acids in ADHD. The most significantly enriched process was the biosynthesis of unsaturated fatty acids. Unsaturated fatty acids, including MUFAs,\nIn addition, through the correlation analysis of metabolomics and metagenomics, we identified eight metabolites regulated by gut microbiota functions, three of which (imidazoleacetic acid, 4-aminobutyric acid, and 4-guanidinobutyric acid) also exhibited significant differences between groups. The three metabolites are categorized as short-chain fatty acids (SCFAs), and we have also identified several key enzymes that contribute significantly to their synthesis. This suggests that the impact of gut microbiota on ADHD pathogenesis may be mediated through the synthesis of SCFAs by regulating the expression of certain enzymes. Consistent with our findings, in previous studies, aberrant levels of SCFAs have been implicated in disease pathogenesis and are generally present in diminished quantities.\nIn summary, in the analysis of linear discriminant analysis and symptom-related species from metagenomics, we identified probiotics primarily responsible for the production of short-chain fatty acids (SCFAs). This aligns with the findings from the association analysis between metagenomics and metabolomics, where the metabolites modulated by gut microbiota and significantly downregulated in cases were primarily SCFAs. Additionally, the important overlapped pathways in the metagenomic differential functional pathways and the differential metabolites enrichment analysis were fatty acid metabolism and biosynthesis of unsaturated fatty acids, with SCFAs being one of the key substances involved in these pathways. These findings collectively reveal a disturbance in fatty acid metabolism associated with the pathogenesis of ADHD. To further validate the hypothesis that SCFA-producing microbes affect ADHD pathogenesis through the mediation of SCFAs, we conducted a causal mediation analysis. The results confirmed that\nThe main strengths of our study include a larger sample size of the Chinese population compared to previous studies. At the same time, we excluded participants with other psychiatric, neurological, gastrointestinal, and metabolic conditions, as well as those with active use of psychoactive drugs, antibiotics, and probiotics. Methodologically, we employed shotgun metagenomic sequencing, which offers greater species identification depth compared to 16S rRNA sequencing. In terms of analysis, we conducted subgroup analyses of ADHD clinical symptoms, and the comparison between group C and group TD provided more comprehensive and detailed information that may have been overlooked without the application of subgroup analysis. Regarding study content, previous research has mostly focused on measuring plasma concentrations of amino acids and fatty acids as well as analyzing their correlation with clinical symptoms. In contrast, our study, for the first time, investigates the pathogenic role of gut microbiota in ADHD through species variations, gene pathway expression and fecal-targeted metabolomics. Specifically, it reveals the involvement of gut microbiota in disrupted fatty acid and amino acid metabolism, particularly in the biosynthesis of unsaturated fatty acids. Furthermore, we formulated a hypothesis that gut microbiota affects ADHD symptoms through metabolic variations. We then subsequently conducted fecal microbiota transplantation experiment in mice to validate the hypothesis. This contributes to a deeper understanding of the mechanisms underlying metabolic disturbances in ADHD and addresses gaps in previous studies by linking the gut-brain axis mechanism to ADHD through gut microbiota profiles.\nThere are also some limitations to our study. First, excluding patients with gastrointestinal conditions or special diets may preclude participants with more aberrant microbiota compositions, thereby hindering the detection of correlations between gastrointestinal symptoms, food style, and microbial profiles. Second, due to the lower prevalence of the hyperactive/impulsive subtype in clinical settings, the sample size of group HA in our cohort might have been underpowered, and the sample size for each subgroup might be imbalanced. To address this problem, we emphasize the convergent evidence from our correlation analysis between microbial taxa, functions, and symptoms, which partially mitigates subgroup limitations. Third, we performed a cross-sectional study, which does not allow for confirming the causal directions between the correlational link between differential species, functional pathways, fecal metabolites, and the disease or symptoms. To address this problem, we conducted animal experiments; however, further longitudinal work in human populations should be undertaken to assess age-associated and other variations in gut microbiota.\nBuilding upon our findings and the current progress of gut-brain axis research, large-scale prospective longitudinal studies are essential to track the dynamic development of the gut microbiome and its relationship with the onset, progression, and symptom fluctuation of ADHD. In parallel, well-designed randomized controlled trials evaluating the efficacy of dietary modifications, specific prebiotics, probiotics, or microbiota transplantation are warranted to explore the therapeutic potential of targeting microbial and metabolic dysbiosis in ADHD. Furthermore, mechanistic investigations into how gut microbes and their metabolites influence gut-brain signaling pathways, along with integrative multi-omics approaches encompassing host genetics, transcriptomics, and metabolomics, will be crucial for advancing our understanding of the complex biological underpinnings of ADHD and identifying novel therapeutic targets.\nIn conclusion, our study characterized the distinct gut microbiota and fetal metabolite profiles in patients with ADHD and its subtypes. We observed more gut microbial alterations in patients from group C compared to those in group IA or HA. Moreover, we employed metagenomics and fecal metabolomics techniques for the first time to elucidate the role of gut microbiota in the dysregulation of fatty acid and amino acid metabolism, with a particular focus on the biosynthesis of unsaturated fatty acids and SCFAs. Through causal mediation analysis of population sample data and mouse experiments of fecal microbiota transplantation, we further validated the pathway from microbiota to metabolites and subsequently to ADHD symptoms. The study provides new evidence supporting the association between the microbiota-gut-brain axis and ADHD and contributes to a deeper understanding of the mechanisms underlying these metabolic disturbances in ADHD.", "content_for_embedding": "Attention-deficit/hyperactivity disorder (ADHD) is one of the most commonly diagnosed psychiatric conditions in children and adolescents, with a global prevalence of 3–5%.\nAlthough ADHD is highly heritable,\nThrough the microbiota-gut-brain axis (MGBA), the effects of the gut microbiota on neurodevelopment have gained more recognition recently. The gut microbiota is commonly considered to regulate neurodevelopment through three pathways – the immune pathway, the neuronal pathway, and the endocrine/systemic pathway, with overlaps and interaction in between.\nResearch has shown that many ADHD-related risk factors also influence the microbiota, such as delivery method, gestational age, type of feeding, maternal health, and early life stressors.\nPrevious studies utilizing 16S rRNA gene amplicon or shotgun metagenomic sequencing have preliminarily identified differences in gut microbiota composition between ADHD and controls.\nOne hundred and eighty-eight participants aged 6–16 years were recruited from the Child and Adolescent Mental Health Center at Peking University Sixth Hospital, Yan’an Third People’s Hospital, and local schools. Of these, 94 were ADHD patients and 94 were age- and gender-matched healthy controls. The initial diagnoses of patients were made by senior psychiatrists using the DSM-5 criteria,\nPatients with ADHD and healthy controls were excluded when they met the following exclusion criteria: (1) history of treatment with any medication for ADHD; (2) use of psychoactive drugs, antibiotics, probiotics, or traditional Chinese medicine within 1 month prior to sample collection; and (3) special dietary preferences (such as vegan or ketogenic diets) or significant changes in diet within the previous month. Participants were excluded if they had comorbid psychiatric, neurological, gastrointestinal, or metabolic conditions. Additionally, individuals with IQs below 70 according to Raven’s Standard Progressive Matrices\nFollowing the guidelines outlined in the Declaration of Helsinki, the research was granted authorization by the Ethics Committee of Peking University Sixth Hospital (Approval No. 2021–79). Informed consent was obtained from legal guardians, while children aged 8 years or older signed the informed consent on their own.\nADHD symptoms were measured using the Attention-Deficit/Hyperactivity Disorder Rating Scale,\nThe Children Behavior Checklist (CBCL), a widely recognized children behavior assessment tool,\nThe Conners Parental Symptom Questionnaire (PSQ) is completed by the child’s primary caregiver based on the child’s daily behavior.\nFood frequency questionnaires (FFQ) are an effective instrument for assessing typical dietary intake and its relationship with health and disease outcomes.\nStandardized procedures were followed for fecal sample collection, after which the samples were frozen at −80°C. Microbial DNA was extracted from 200 mg fecal samples from 188 participants using the QIAamp PowerFecal Pro DNA Kit. The DNA concentration was measured using a microplate reader, and its integrity was assessed by agarose gel electrophoresis.\nSamples were sequenced on the MGISEQ 2000 platform by Beijing Genomics Institute using PE150 mode with an insert size of 300–400 bp. Prior to bioinformatic analysis, SOAPnuke (v.2.2.1)\nHigh-quality short reads from each DNA sample were assembled into contigs using a multiple k-mer size strategy with MEGAHIT software\nAll participants were initially assigned sequential subject identifiers upon recruitment. After completing fecal sample collection, all samples were randomly reordered using the sample() function in R software (version 4.2.0), and new identification numbers (ADHD: A001-A094; Controls: H001-H094) were assigned accordingly. Metabolomics profiling was performed on the first 31 ADHD patients (A001-A031) and 31 controls (H001-H031) based on the ascending order of these IDs. The 20 μL sample and 20 μL standard were mixed with HM400 releasing agent for extraction. Following centrifugation at 18,000 g for 10 min at 4°C, the supernatant was collected for LC-MS/MS analysis.\nMetabolite separation and quantification were carried out using a Waters ACQUITY UPLC I-Class Plus (Waters, USA) in conjunction with a QTRAP 6500+ high-sensitivity mass spectrometer (SCIEX, USA). Chromatographic separation was achieved using a BEH C18 column (2.1 mm × 10 cm, 1.7 μm; Waters). The QTRAP 6500+ mass spectrometer, equipped with an ESI Turbo Ion Spray interface, was operated with the following parameters: ion source temperature at 400°C, ion spray voltage (IS) at 4500 V (positive mode) and −4500 V (negative mode), and ion source gases I (GS1), II (GS2), and curtain gas (CUR) set to 60, 60, and 35 psi, respectively.\nQuantitative analysis was performed using Skyline software (v.21.1.0.146). This software, configured for monoisotopic peaks with a mass tolerance of 0.6 Da and a mass range of 50–1500 Da, was used to generate a data matrix that included metabolite identification and quantification results for subsequent information analysis and processing. Quality control (QC) samples were generated from a mixture of sample extracts to assess the consistency of the sample under identical treatment. During data collection, a certain number of QC samples were inserted in test samples to monitor the repeatability of the analytical process. The results exported by Skyline software were imported into metaX\nMetabolic pathways were identified using open database sources such as MetaboAnalyst, the Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway database, and the Human Metabolome Database.\nFour-week-old male C57BL/6J mice (initial weight 13–16 g; Gempharmatech Co., Ltd) were housed at a temperature of 22–23°C on a 12-h light/dark cycle with ad libitum access to water and food except during experimental sessions. The study was approved by the Biomedical Ethics Committee of Peking University. After the acclimatization period, mice were orally administered a cocktail of four antibiotics (ABX) for 7 days: ampicillin (200 mg/kg/day, Solarbio Cat#A6920), vancomycin (100 mg/kg/day, VIANEX S.A. PLANTC), neomycin (200 mg/kg/day, SIGMA Cat#N6386), and metronidazole (200 mg/kg/day, SIGMA Cat#M1547).\nSubsequently, mice were subjected to fecal microbiota transplantation (FMT) from ADHD patients with a low abundance of beneficial bacteria\nBehavioral experiments were conducted during the light period. Exploratory activity and hyperactivity behavior were measured using an Open-Field apparatus (40 × 40 × 25 cm). For the five days prior to the test, the mice were handled for 5 min every day, followed by a 5-min familiarization period in the box. Each mouse was placed in the center of the open-field apparatus. A square that was 10 cm from the wall was designated as the center zone. Traveled distance and time spent in the center zone of each animal were recorded for a single 4-min session with a video-imaging system.\nMice were trained using a Five-Choice Serial Reaction Time Task (5-CSRTT) procedure according to a published protocol and previous studies.\nDuring training, the LED of one of the five response holes will be on, and mice were trained to use their noses to locate the lit hole in order to receive a food pellet as a reward. Each session began with the illumination of the response holes light and the food magazine light, followed by the delivery of one food pellet (20 mg/pellet). Once the first food pellet was collected, the intertrial interval (ITI) commenced. At the end of the ITI, one of the five response holes on the chamber wall opposite the food magazine was illuminated for a brief period, known as the stimulus duration (SD). A correct response to this hole within the limited hold (LH) period resulted in the response holes light turning off, the food magazine light turning on, and delivery of one food pellet. After the pellet was collected, the next ITI began. The target stimulus varied pseudorandomly between trials to increase attentional load.\nTraining was divided into seven successive stages with specific criteria for ITI, SD, and LH, which had to be met for two consecutive days before progression to the next stage (Supplementary Fig. 6). A typical training session lasted 30 min or completed 100 trials, whichever came first. Responses into the non-target hole were considered incorrect responses, while responses during the ITI before target stimulus presentation were classified as premature responses, and a failure to respond was recorded as an omission. The average latency to correct responses and correct responses rate reflected the mice’s attention; the premature rate indicated the level of impulsivity.\nMice feces were collected before and after antibiotic treatment (ABX), after fecal microbiota transplantation (FMT), and after the rescue procedure (\nAfter obtaining genus-level ASVs, the data were normalized to ensure sample comparability; sequence count normalization was conducted through rarefaction to address uneven sequencing depths by the ‘rrarefy’ function in Vegan,\nStatistical analyses were performed using R software (version 4.2.0) and Statistical Product and Service Solutions (SPSS, version 26.0). Mean and standard deviation were utilized for continuous variables (including demographic data, dietary data, and psychometric parameters). Kruskal – Wallis tests and post-hoc Wilcoxon rank-sum pairwise tests, with p-values adjusted for multiple testing via the Benjamini – Hochberg method, were applied for inter-group comparisons. Correlation analysis was conducted using partial correlation analysis by the “spearman” method in the R package ppcor. When applicable, age, gender, BMI, SPM, site and principal component of diets were adjusted as covariates. A two-tailed p-value ≤0.05 was considered statistically significant.\nWe performed power analysis and created the species rarefaction curves by the function ‘specaccum’ in the R package vegan\nTo analyze the interrelationship between the microbiota present in stool samples and ADHD symptoms, we used redundancy analysis (RDA) from the R package vegan,\nTo identify significant biomarkers, we compared all species between two groups using LEfSe analysis, which assisted in identifying genomic biomarkers that characterize statistical differences between biological groups.\nFor metabolomics, after normalization to total peak intensity, the multivariate data were dimensionally reduced by principal component analysis (PCA) to analyze groupings, trends (intra-group and inter-group similarities and differences), and outliers in the data set. Using Partial Least Squares-Discriminant Analysis (PLS-DA) of the R package mixOmics\nTo further investigate the correlation between gut microbiota function and fecal metabolites, we employed the MIMOSA model from the R package MIMOSA2.\nThe causal mediation analysis was conducted to explore the influence and interactions of microbiota and metabolites, using the ‘mediate’ function in the R package mediation.\nA total of 188 children and adolescents, consisting of 94 patients with ADHD (56 ADHD-I, 29 ADHD-C, 9 ADHD-HI) and 94 TDs, were recruited.\nDemographics, intelligence, and clinical symptoms of ADHD subgroup and typically developing controls (TD) in the study cohort.\nBMI, body mass index; SPM, Raven’s Standard Progress Matrice;\nWe carried out shotgun metagenomic sequencing for all participants and obtained an average of 9,973,835,522 clean bases per sample. Detailed information on gut microbiota sequencing data was given in Supplementary Table 3. We employed species rarefaction curves to assess and predict the degree to which species richness in the community increases with sample size. The curve for groups TD, IA, and C exhibited a flat trajectory during the terminal phases, indicating that the sample sizes were adequate and the subsequent analyses were reasonable (Supplementary Fig. 1).\nIn terms of taxonomic diversity, we first compared the top 10 relative abundances of microbiota at the level of genus, the Firmicutes-to-Bacteroidetes ratio (F/B ratio), alpha diversity, and beta diversity between ADHD subgroups and TDs. The relative abundance of the top 10 genera of microbiota (Phocaeicola, Bacteroides, Alistipes, Parabacteroides, Faecalibacterium, Roseburia, Bifidobacterium, Escherichia, Lachnospira, Megamonas, and others) did not differ significantly (pFDR >0.05;\nThe overview of the microbiome profiles in three ADHD presentations and TD. (A) the top 10 taxa of relative abundance. The relative compositions of microbiota at the genus level were not significantly different among ADHD subgroups and group TD. The pFDR values of group comparisons are presented followed by legends of microbiota; (B) the Firmicutes to the bacteroidetes ratio. There was no group difference among ADHD subgroups and group TD using ANOVA corrected by FDR; (C) observed species, Shannon index, Simpson index, and Pielou’s evenness index for each group. Data are plotted as ±standard deviation; (D) RDA analysis of microbial community structure and ADHD symptoms in all participants; (E) RDA analysis of microbial community structure and CBCL. CBCL_SOM: somatic complaints of CBCL; CBCL_WIT: withdrawn of CBCL; CBCL_AGS: aggressive behavior of CBCL; CBCL_ANX: anxious/depressed symptoms; CBCL_SOC: social problems of CBCL; CBCL_HA: hyperactivity behaviors of CBCL; CBCL_DEL: delinquent behaviors of CBCL; (F) RDA analysis of microbial community structure and PSQ.\nAlpha diversity indexes for the ADHD subgroups and TDs.\nTotal five indexes of alpha-diversity showed no group differences between ADHD subgroups and TD. S.obs (observed species) were used to estimate the indexes of the total number of species in the community. Shannon index, Simpson index, and Pielou’s evenness index were used to measure the microbial diversity in the sample. Phylogenetic diversity (PD) whole tree was the diversity index calculated the distance of the evolutionary tree.\nThe significance tests of the community structure with greater between-group difference than the within-group difference.\nAnosim similarity analysis is a non-parametric test to test whether the between-group difference is significantly greater than the difference within the group to judge whether the grouping is meaningful. MRPP analysis is similar to Anosim analysis, but the ordering method is different. It analyzes whether the microbial community structure difference between groups is significant. Adonis tests the differences between groups by partitioning the distance matrix among sources of variation and using a permutation test to assess the significance of these differences.\nFurthermore, we used constrained ordination analysis to investigate the correlation between the microbial community structure and ADHD symptoms in all participants. To identify the optimal distribution of our data model (either a linear, unimodal, or bimodal distribution), we implemented a detrended correspondence analysis (DCA). The length value indicated that the linear model fitted our data, with the first axis (DCA1) having a length of 2.58 (less than 3) (Supplementary Table 4). We applied the redundancy analysis (RDA) to a linear model. We found that at the species level, Component 1 from the RDA explained 57.98% of the variance (22.88% with Component 2 scaling) (ANOVA like permutation test F = 1.345, pFDR = 0.015,\nThe ANOVA like permutation test of the redundancy analysis (RDA) between the microbial community structure and ADHD symptoms.\nRDA1 and RDA2 represent the proportion of species distribution explained by each axis in the analysis. The model’s R\nWe conducted a comprehensive analysis of the microbiota community variations from phylum to species levels between ADHD subgroups and group TD to identify potential evolutionary biomarkers linked to ADHD based on the gut microbiome. LEfSe analysis identified dominant bacterial biomarkers contributing to the group disparities. Specifically, 5 bacterial taxa were enriched in group IA and 12 were enriched in group TD when contrasting IA and TD (\n(A) a taxonomic cladogram and an LDA scores bar plot of identified differential taxa between group IA and TD; (B) a taxonomic cladogram and an LDA scores bar plot of identified differential taxa between group HA and TD; (C) a taxonomic cladogram and an LDA scores bar plot of identified differential taxa between group C and TD. The LDA score (log 10) > 2 and\nLinear discriminant analysis of three ADHD subgroups and group TD concurrently revealed that family\nTo further elucidate the association between differential microbiota and symptoms, partial correlation analysis was carried out. After adjusting for various confounding factors, genus\n(A) differential correlation patterns of microbiota with ADHD symptoms. Pairs with pFDR < 0.05 are shown in the picture. The color of each grid represents the value of correlation coefficient. Blue color represents the negative correlation and red color represents the positive correlation; (B)-(D) the relative abundance of microbial function annotated by the KEGG database and significant microbial function among ADHD subgroups and group TD. The **symbol represents the pFDR < 0.05, while the *symbol represents the pFDR < 0.1; (E) differential correlation patterns of functional pathways with ADHD symptoms. Pairs with p-value < 0.05 are shown in the picture. The color of each grid represents the value of correlation coefficient. Blue color represents the negative correlation and red color represents the positive correlation.\nIn the comparative analyses between ADHD subgroups and group TD, as well as the correlation analysis between ADHD symptoms and microbiota, the microbial features existing consistent results were considered more robust. Species\nAfter gene prediction, the total number of genes we obtained and the distribution of genes with different lengths were displayed in Supplementary Figure 2. First, we assessed the microbial function annotated by the KEGG database. We totally annotated the genes expressed by the microbiota to 5 pathways at Level 1, 29 pathways at Level 2, 202 pathways at Level 3, and 6935 KEGG orthology (Supplementary Fig. 3). We next focused on all metabolic pathways of Level 3 and employed STAMP to identify 11 differential pathways between group TD and group C (\nIn group C, tryptophan metabolism, biotin metabolism, histidine metabolism, fatty acid metabolism, and biosynthesis of unsaturated fatty acids were downregulated, while lysine biosynthesis, arginine biosynthesis, phenylalanine, tyrosine and tryptophan biosynthesis, and terpenoid backbone biosynthesis were upregulated (\nFurthermore, we employed partial correlation analysis to investigate relationships between three domains of ADHD symptoms and KEGG pathways, adjusting for sex, age, BMI, SPM, site, and dietary variables. Results demonstrated that biotin metabolism showed negative correlations with all three symptoms, and aminoacyl-tRNA biosynthesis displayed positive correlations with all symptoms (\nSimilarly, pathways demonstrating consistent results in both comparative analysis and correlation analysis were considered more robust. The biotin metabolism pathway showed increased abundance in group TD in all three pairs of comparisons, and correlation analysis also demonstrated that this pathway was negatively correlated with all three ADHD symptoms. The relative abundance of tryptophan metabolism was downregulated in group IA and group C and the pathway also showed a negative correlation with inattention symptoms. The relative abundance of terpenoid backbone biosynthesis was upregulated in group HA and group C, and the pathway also showed a positive correlation with impulsivity symptoms. In addition, group C, which exhibited symptoms of inattention, hyperactivity, and impulsivity, demonstrated differences in biosynthesis of unsaturated fatty acids, fatty acid metabolism, and histidine metabolism. Correspondingly, correlation analysis revealed that the first two pathways were associated with inattention, while histidine metabolism was associated with impulsivity.\nTo further elucidate the alterations in bacterial metabolism, we conducted untargeted metabolomics using fecal samples. The baseline comparison results between metabolomic subgroups and the full cohort are provided in Supplementary Table 7. No significant differences were observed in all these key variables, which supported the representativeness of the metabolomic subgroups. A total of 307 metabolites were identified, with classifications and the number of each class presented in Supplementary Figure 4. The comprehensive details of each identified metabolite are presented in Supplementary Table 8.\nBased on the differential metabolite screening criteria, there were 21 downregulated metabolites identified in group ADHD compared to group TD (\n(A) Volcano plot of the different metabolites between group ADHD and group TD. The abscissa is the Fold change converted by log2, and the ordinate is the q-value converted by log10. The circles represent metabolites with a VIP > 1. Blue circles represent significant metabolites, while gray circles represent non-significant metabolites; (B) the KEGG pathway enrichment metabolic network of differential metabolites between groups, with node size representing the number of candidate genes in pathway; (C) bubble diagram for enrichment analysis based on the KEGG database. RichFactor is the ratio of differential metabolites annotated to the total number of identified metabolites annotated in a certain pathway; (D) differential correlation patterns of the metabolites with ADHD symptoms. The size of circles represents -log10(pFDR), pairs with pFDR < 0.05 are shown in the picture. The color of circle represents the value of correlation coefficient; (E) path diagram of the mediation analysis model of imidazoleacetic acid between\nTo explore the relationship between the significant differential metabolites and ADHD symptoms, we conducted a partial correlation analysis. After adjusting various confounding factors, we found that inattention symptom was negatively correlated with 12-hydroxystearic acid, all-trans-retinoic acid, lithocholic acid acetate methyl ester, vanillin, 4-guanidinobutyric acid, imidazoleacetic acid, 12-tridecanoic acid, and taurochendeoxycholic acid. Hyperactivity symptom was negatively correlated with 12-hydroxystearic acid, all-trans-retinoic acid, lithocholic acid acetate methyl ester, linoleic acid, 3,6-diketocholanic acid ethyl ester, and quinolinic acid. Impulsivity symptoms also had a negative correlation with vanillin, 4-guanidinobutyric acid, quinolinic acid, and ricinoleic acid (\nTo further explore the association between metagenomics and metabolomics between groups, we used the MIMOSA model to predict the impact of gut microbiota composition or function on metabolite concentrations. Based on the metabolic network approach, we then identified eight metabolites regulated by gut microbiome functions, which were annotated by KEGG orthology, including 4-Hydroxybenzoic acid, imidazoleacetic acid, hydroxyproline, 4-aminobutyric acid, 4-guanidinobutyric acid, L-asparagine, D-xylose, and pidolic acid. Importantly, imidazoleacetic acid, 4-aminobutyric acid, and 4-guanidinobutyric acid were previously identified as key differential metabolites between group ADHD and group TD, and all three are classified as short-chain fatty acids (SCFAs). It is noteworthy that the top producing pathways of these three metabolites are\nResults of MIMOSA model to predict the impact of gut microbiota composition or function on metabolite concentrations.\nID: KEGG compound ID for that metabolite; R\nTo investigate the influence and interactions of microbiota and metabolites on ADHD, we selected differential species and metabolites most strongly correlated with ADHD symptoms. The causal mediation analysis indicated a total effect of\nTo verify the pathway from microbiota to metabolites and subsequently to ADHD symptoms, we conducted a fecal microbiota transplantation experiment in mice. Detailed information on the sequencing data of mice fecal samples was presented in Supplementary Table 12. The 16S rRNA analysis of mice fecal microbiota showed a significant reduction in alpha diversity following treatment with ABX. In terms of beta diversity, the microbiota of ABX-treated mice exhibited a distinct distribution pattern compared to wild-type mice (Supplementary Fig. 7). These findings validated the effectiveness of antibiotic treatment in altering the gut microbiota. After fecal microbiota transplantation from different sources, we observed that mice subjected to feces from ADHD patients with a low abundance of beneficial bacteria in group FMT-A exhibited hyperactive behavior (\nIn the rescue experiments for mice exhibiting ADHD-related symptoms after receiving FMT from ADHD patients, we found that compared to the control group (FMT-A-C), group FMT-A-R1, which received treatment with\n(A) workflow diagram of fecal microbiota transplantation (FMT) and rescue experiments in mice. ABX: orally administered a cocktail of four antibiotics, FMT: fecal microbiota transplantation; (B) performance of mice in the open field test and 5-choice serial reaction time task (5-CSRTT) following different rescue interventions; (C) relative abundance of the genus\nDue to the limitations of 16S rRNA sequencing, we focused on the relative abundance of the genus\nMental health includes mental, emotional, social, and behavioral functions, occurring along a continuum from optimal to poor.\nThe metagenomic data demonstrated gut dysbiosis in patients with ADHD. While comparing gut microbiota taxa between ADHD subgroups and group TD, there were no significant differences observed in alpha diversity between patients with ADHD and TDs, which aligns with several previous studies.\nTo explore the relationship between taxa and ADHD symptoms, we employed LEfSe analysis between ADHD subgroups exhibiting different domains of symptoms and group TD, as well as correlation analysis between symptoms and microbiota. Microbial features that exhibited consistent results were deemed more robust. The LEfSe analysis of the ADHD subgroups and group TD revealed that the family\nRegarding the harmful bacteria enriched in ADHD groups or positively correlated with ADHD symptoms, both methods identified\nThe analysis of predicted microbial functions revealed significant differences between ADHD subgroups and group TD. The most significant pathways include several amino acid-related pathways, such as tryptophan metabolism, phenylalanine, tyrosine and tryptophan biosynthesis, and lysine biosynthesis. As Li et al. reported, gut microbiota actively reshapes the host’s amino acid balance through the metabolism of intestinal amino acids.\nOur analysis of metagenomic functional pathways and fecal metabolites concurrently revealed a downregulation of both fatty acid metabolism and the biosynthesis of unsaturated fatty acids in ADHD. The most significantly enriched process was the biosynthesis of unsaturated fatty acids. Unsaturated fatty acids, including MUFAs,\nIn addition, through the correlation analysis of metabolomics and metagenomics, we identified eight metabolites regulated by gut microbiota functions, three of which (imidazoleacetic acid, 4-aminobutyric acid, and 4-guanidinobutyric acid) also exhibited significant differences between groups. The three metabolites are categorized as short-chain fatty acids (SCFAs), and we have also identified several key enzymes that contribute significantly to their synthesis. This suggests that the impact of gut microbiota on ADHD pathogenesis may be mediated through the synthesis of SCFAs by regulating the expression of certain enzymes. Consistent with our findings, in previous studies, aberrant levels of SCFAs have been implicated in disease pathogenesis and are generally present in diminished quantities.\nIn summary, in the analysis of linear discriminant analysis and symptom-related species from metagenomics, we identified probiotics primarily responsible for the production of short-chain fatty acids (SCFAs). This aligns with the findings from the association analysis between metagenomics and metabolomics, where the metabolites modulated by gut microbiota and significantly downregulated in cases were primarily SCFAs. Additionally, the important overlapped pathways in the metagenomic differential functional pathways and the differential metabolites enrichment analysis were fatty acid metabolism and biosynthesis of unsaturated fatty acids, with SCFAs being one of the key substances involved in these pathways. These findings collectively reveal a disturbance in fatty acid metabolism associated with the pathogenesis of ADHD. To further validate the hypothesis that SCFA-producing microbes affect ADHD pathogenesis through the mediation of SCFAs, we conducted a causal mediation analysis. The results confirmed that\nThe main strengths of our study include a larger sample size of the Chinese population compared to previous studies. At the same time, we excluded participants with other psychiatric, neurological, gastrointestinal, and metabolic conditions, as well as those with active use of psychoactive drugs, antibiotics, and probiotics. Methodologically, we employed shotgun metagenomic sequencing, which offers greater species identification depth compared to 16S rRNA sequencing. In terms of analysis, we conducted subgroup analyses of ADHD clinical symptoms, and the comparison between group C and group TD provided more comprehensive and detailed information that may have been overlooked without the application of subgroup analysis. Regarding study content, previous research has mostly focused on measuring plasma concentrations of amino acids and fatty acids as well as analyzing their correlation with clinical symptoms. In contrast, our study, for the first time, investigates the pathogenic role of gut microbiota in ADHD through species variations, gene pathway expression and fecal-targeted metabolomics. Specifically, it reveals the involvement of gut microbiota in disrupted fatty acid and amino acid metabolism, particularly in the biosynthesis of unsaturated fatty acids. Furthermore, we formulated a hypothesis that gut microbiota affects ADHD symptoms through metabolic variations. We then subsequently conducted fecal microbiota transplantation experiment in mice to validate the hypothesis. This contributes to a deeper understanding of the mechanisms underlying metabolic disturbances in ADHD and addresses gaps in previous studies by linking the gut-brain axis mechanism to ADHD through gut microbiota profiles.\nThere are also some limitations to our study. First, excluding patients with gastrointestinal conditions or special diets may preclude participants with more aberrant microbiota compositions, thereby hindering the detection of correlations between gastrointestinal symptoms, food style, and microbial profiles. Second, due to the lower prevalence of the hyperactive/impulsive subtype in clinical settings, the sample size of group HA in our cohort might have been underpowered, and the sample size for each subgroup might be imbalanced. To address this problem, we emphasize the convergent evidence from our correlation analysis between microbial taxa, functions, and symptoms, which partially mitigates subgroup limitations. Third, we performed a cross-sectional study, which does not allow for confirming the causal directions between the correlational link between differential species, functional pathways, fecal metabolites, and the disease or symptoms. To address this problem, we conducted animal experiments; however, further longitudinal work in human populations should be undertaken to assess age-associated and other variations in gut microbiota.\nBuilding upon our findings and the current progress of gut-brain axis research, large-scale prospective longitudinal studies are essential to track the dynamic development of the gut microbiome and its relationship with the onset, progression, and symptom fluctuation of ADHD. In parallel, well-designed randomized controlled trials evaluating the efficacy of dietary modifications, specific prebiotics, probiotics, or microbiota transplantation are warranted to explore the therapeutic potential of targeting microbial and metabolic dysbiosis in ADHD. Furthermore, mechanistic investigations into how gut microbes and their metabolites influence gut-brain signaling pathways, along with integrative multi-omics approaches encompassing host genetics, transcriptomics, and metabolomics, will be crucial for advancing our understanding of the complex biological underpinnings of ADHD and identifying novel therapeutic targets.\nIn conclusion, our study characterized the distinct gut microbiota and fetal metabolite profiles in patients with ADHD and its subtypes. We observed more gut microbial alterations in patients from group C compared to those in group IA or HA. Moreover, we employed metagenomics and fecal metabolomics techniques for the first time to elucidate the role of gut microbiota in the dysregulation of fatty acid and amino acid metabolism, with a particular focus on the biosynthesis of unsaturated fatty acids and SCFAs. Through causal mediation analysis of population sample data and mouse experiments of fecal microbiota transplantation, we further validated the pathway from microbiota to metabolites and subsequently to ADHD symptoms. The study provides new evidence supporting the association between the microbiota-gut-brain axis and ADHD and contributes to a deeper understanding of the mechanisms underlying these metabolic disturbances in ADHD.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "38962516", "pmcid": "12309153", "title": "Understanding Capabilities, Opportunities, and Motivations of Walking for Physical Activity Among Adults With Intellectual Disabilities: A Qualitative Theory‐Based Study", "publication_year": "N/A", "abstract": "", "full_text": "\n\nThe COM‐B model is a theoretical framework used to understand capabilities, opportunities, and motivations for a behaviour.\nThis study used interviews, photo‐based methods, and a focus group with adults with learning disabilities to apply the COM‐B to walking for physical activity.\nThere are many different capabilities, opportunities, and sources of motivation identified that impact on walking for adults with learning disabilities.\nFrom the perspective of adults with learning disabilities, the important findings were that walking is better when walking in a group, walking should have a purpose (e.g., walking to the shops), that everyone has individual needs, and everyone needs to feel included.\nWalking is a free form of physical activity associated with reduced risk for all‐cause mortality, obesity, diabetes, and major depressive disorder (Kelly et al.\nPrevious interventions to increase walking and physical activity of adults with intellectual disabilities have reported limited effectiveness (Melville et al.\nTestable theoretical frameworks can help to understand how to improve physical activity and walking. The most frequently used theories in lifestyle change interventions with adults with intellectual disabilities are the Transtheoretical Model, Social Cognitive Theory, and Theory of Planned Behaviour (Rana et al.\nIn recent years, researchers have been using a specific theoretical framework called the COM‐B model to understand the social support caregivers provide for physical activity for adults with intellectual disabilities (Bossink et al.\nSummary of COM‐B model.\n\nAt the centre of a wider framework called the Behaviour Change Wheel, which is used to guide intervention development (BCW; Michie et al.\nEthical approval was provided by the University of Glasgow College of Medical, Veterinary, and Life Sciences ethics committee. Additional procedures were in place to facilitate informed consent, such as producing\nAll research team members have expertise in working with adults with intellectual disabilities and/or lifestyle modification. The team included a representative from the non‐profit organisation Values into Action Scotland (VIAS) which supports adults with intellectual disabilities to achieve their goals. Involvement of VIAS helped to ensure the research was relevant and accessible for people with intellectual disabilities.\nThe researcher primarily responsible for data collection and analysis aligns with the philosophical stance of critical realism. Critical realism argues that reality exists independent of the researcher and understanding is shaped by human experiences; however, this understanding can be improved by rigorous research (Lyons and Coyle\nThe qualitative study design enabled understanding of the capabilities, opportunities and motivations for walking from the perspective of adults with intellectual disabilities. As the COM‐B is used in the context of behaviour change interventions, the use of qualitative methods ensured the influences of walking identified reflected people's lived experiences (O'Cathain et al.\nThe study included two data collection pathways, both adopting photo‐elicitation methods. Pathway one: semi‐structured interviews (in‐person or using remote methods) were conducted with researcher‐directed photo‐elicitation methods. Pathway two: participant‐directed photo‐elicitation methods followed by a focus group to discuss the photographs taken. Throughout the process, a reflexive approach to data collection and analysis ensured the process was inclusive and accessible.\nPurposive sampling sought adults (≥ 18 years) who identified as having mild to moderate intellectual disabilities and lived in the Greater Glasgow area. Recruitment and data collection took place between August 2022 and May 2023. Based on the recommendation of VIAS, a small financial incentive of a £20 gift voucher was used.\nFor pathway one, a provisional sample of\nFor pathway two, the tentative sample was\nA demographic questionnaire collected data on participant age, gender identity, residential setting, and post code to calculate the Scottish Index of Multiple Deprivation (SIMD; Scottish Government\nThe interviews involved an initial photo‐elicitation activity and then followed a semi‐structured interview schedule reflecting the COM‐B behavioural diagnosis (see SI File\nThe images represented environmental influences of walking outlined in previous literature (e.g., dogs, weather, green spaces, roads, the dark); three example images are provided in Figure\nExample photographs used to facilitate discussion.\nThe interviews could be conducted in person or remotely using Zoom (a video conferencing platform). The audio of the in‐person interviews was recorded with a Dictaphone, and the remote interviews were recorded over Zoom. The audio recordings allowed the researcher to transcribe the audio verbatim and enabled the transcriptions to be checked for accuracy against the initial recordings. A reflexive approach to data collection allowed for adaptations to the methods. These adaptations included the provision of more context to the questions and greater explanation for the photo elicitation activity.\nIn situ data were gathered during a walk using photograph‐based methods to support adults with intellectual disabilities to be involved in the data collection process (Overmars‐Marx et al.\nData were analysed using the framework approach to thematic analysis as the goal was to map influences of walking onto the existing framework of the COM‐B (Gale et al.\nThe categorisation onto the COM‐B involved reference to the Theoretical Domains Framework (TDF). The TDF is based on the synthesis of existing theories relating to behaviours and behaviour change, and is often used alongside the COM‐B to expand the influences (Cane et al.\nOnce the coding framework was applied to the remaining interview transcripts, a framework matrix was produced using NVIVO. The influences identified for capabilities, opportunities, and motivations to go on a walk were presented by cases (by each participant included in the study). The framework matrix helped to explore the important participant characteristics, such as gender, age, and SIMD. An example excerpt from the matrix for ‘physical opportunities’ has been provided in Appendix\nThe focus group data were analysed using the coding framework developed for the interviews as a guide. The data was treated as separate but complementary to the data collected during the interviews. Therefore, new codes were generated when analysing this data, and not all the existing codes were relevant.\nThroughout the research process there was close collaboration with Values into Action Scotland (VIAS), with a member of VIAS attending all team meetings and involved in all decisions made. There was a separate patient and public involvement (PPI) meeting with people with lived experiences once there were preliminary findings from both the interviews and focus group. This was held in May 2023 at the lead researcher's University, with financial compensation provided for the participants' time. PPI consisted of three adults with intellectual disabilities, with one person attending to provide additional support. The researcher produced easy read slides which were approved in advance by VIAS. Feedback was given on the initial interpretation of the findings, which were integrated into the results.\nA total of 12 adults with mild to moderate intellectual disabilities were interviewed, and nine participants had a source of support present. As can be seen in Table\nDemographic characteristics of interview participants.\nTwo participants requested to support each other.\nParticipant did not disclose postcode.\nPsychological capabilities relate to knowledge, psychological skills, and mental processes (Michie et al.\nI know I'm quite vulnerable, even though I hate that word, I am classed as vulnerable. So like if a stranger come up to me and say do you want to come to my place or do you want to come see my dog …I might tend to go with a stranger if they asked me. [Participant 8]\nWalking influences mapped under Capabilities.\n\nPhysical capabilities in the COM‐B are defined as relating to physical skills, strength, and stamina (Michie et al.\nPhysical opportunities relate to the physical resources people have access to, and more conceptual resources, such as time (Michie et al.\nThere's a wee park up beside me you know, so I walk there and then I walk back down. You know, and just kind of sit about a wee while and then say right. It's not even just that, the fresh air gives you…makes you feel good. [Participant 4]\nWalking influences mapped under Opportunities.\n\nWalking in the dark was seen as either peaceful or unsafe because of poor visibility or due to other people. Gender differences in perceptions of walking in the dark became evident during the analysis. Although two men taking part did appraise the dark as unsafe, the other men participating reported no safety concerns or felt the dark made walking peaceful and relaxing: ‘Really good, I like going out for a walk at night‐time…because it's quiet and nobody's around’. [Participant 10, Man]. Importantly, one of the men felt that walking in the dark was unsafe, but these risks were attributed to women:\n…especially if you were a lady. I've known so many ladies that sadly has walked home by themself at night through like dark allies… The dark ally or the darks path and sadly they've been sexually assaulted, or they've been… it's been all over the Glasgow live [Participant 5, Man]\nReflecting this, all of the women taking part appraised walking in the dark as unsafe with this predominantly linked to other people being dangerous: ‘It's kinda… because it is getting frightening now when you go out, if you understand. You know because you're afraid to go out at night now because you don't know what's going to happen anymore.’ [Participant 4, Woman] Women also described wider safety concerns when walking in isolated areas and on ‘lonely roads’:\nI know, but it's an empty street as well remember. [Participant 6, attending support] ‘Nope. It's a one in five chance that you get attacked and have you read the reports today? There's been more attacks on Glasgow than there was like ten years ago’. [Participant 6, Woman]\nWhile describing physical opportunities, participants also referred to tangible resources, in the form of suitable clothes and water. With participants also referencing the need for wider funding and organisational support, which related to walking groups. However, the need for tangible resources highlighted accessibility concerns, with not everyone having access to the same opportunities and previously available options closing due to the COVID‐19 pandemic: ‘Well, it's just where everything was closed due to COVID’. [Participant 6].\nSocial opportunities are defined as relating to interpersonal influences, cultural and social norms (Michie et al.\nAll participants reported the negative impact of other people, as participants described experiencing harassment and discrimination by members of the public and within the wider perceptions of society: ‘See soon as you get diagnosed with a learning disability you're supposed to go inside, out the road because you're no’ supposed to have the common sense or the way to speak or whatever…’ [Participant 4]\nHaving a dog, or knowing someone with a dog, facilitated walking; however, dogs can pull and make walking difficult. Walking was also facilitated by the presence of walking groups and organisations providing support for people with intellectual disabilities. However, these groups were not available to everyone and many groups closed during the COVID‐19 pandemic.\n… it's nice to walk in a…we enjoyed that again walking in a crowd? Because you heard everybody chatting and so it was nice to chat to the other people as well. No just me. Isn't it, you enjoyed that? [[Participant 6], Attending support]\nAdditionally, level of deprivation contributed to variations in access to these resources. One participant lived in an area classified as ‘least deprived’. Compared to the other participants, the participant had more opportunities through access to football clubs, voluntary working positions, dance classes, youth clubs and walking clubs. Emphasising the impact of financial resources and support availability contributing to disparities in opportunities for walking.\nReflective motivation relates to reflective processes, such as making plans (Michie et al.\nAdditionally, reflective motivation was increased when there was a purpose or a goal, with the most reported being walking to the shops. Another recurrent influence was the impact of walking on physical health benefits, with walking described as being ‘good’ for you, contributing to weight loss and being a form of exercise. ‘Well… when you're sitting you've just got your belly, it's just sitting, but when you're walking you're burning the muscles in your belly and it burns all the fat away. All the fat away… I'll need to start again.’ [Participant 11]\nWalking influences mapped under Motivation.\n\nAutomatic motivation is defined as ‘automatic processes’, which includes emotional reactions (Michie et al.\nSeven participants also described the impact of fear and anxiety on their walking, with fear tied to bad experiences with members of the public that made them feel unsafe, anxiety over catching COVID‐19, and fear of falling and becoming injured.\nSo and then I get feared [scared] to go out if that happens. I mean, being honest with you, I fall in the house so I do. I'm just… I'm clumsy in the house do you know what I mean, because sometimes you trip over your own feet. [Participant 4]\nParticipants involved in this pathway were not involved in pathway two. Five participants took part during this stage which included four men and one woman, aged between 24 and 40 years old. All participants were part of a walking group facilitated by a non‐profit organisation for people with intellectual disabilities. One of the participants was non‐ambulatory and used a wheel chair. During data collection, a source of support was present with each participant along with the organiser of the walking group. Participants had difficulties completing the full demographic questionnaire, so only gender and age were recorded.\nThe focus group described physical capabilities that impacted on capacity to go on a walk. Participants described that some people had visual impairments and emphasised that walking routes need to be accessible, with one member of the walking group trained to identify potential hazards (Table\nExample photographs and illustrative quotes.\n‘I would also… I would also need to know the routes, emm the safety aspects. [Focus group, Participant 1]\n… Keep people safe. [Focus group, Participant 4]’\n‘It was really shaky, and… It was really shaky… but that day, that was really risky.’ [Focus group, Participant 1]\n‘Especially [Focus group, Participant 1], that's your mode for you being able to use your hands to wheel yourself, isn't it? And that's taking away your independence’. [Walking group organiser]\n‘I liked it because em… I liked pretty much all of it really’ [Focus group, Participant 1]\n‘It was good that the weather was nice as well’. [Focus group support]\n‘Well this was a hazard the police shouldn't have been parked in the middle of the pedestrian highway because there was spaces where they could have parked their car and they wouldn't have had to park in the middle of the highway’. [Focus group, Participant 1]\n‘No one's…\n‘When you were on the walk, how did seeing flowers make you feel? [Researcher]\nHappy. I like gold. [Focus group, Participant 4]’\n‘Happy’. [Focus group, Participant 4]\n‘And why is that?’ [Researcher]\n‘Because the colours… Nature’ [Focus group, Participant 4]\n‘All the pink stuff and then it falls on the grass. Oh the pink stuff …the blooms’. [Focus group, Participant 2]\n‘Being together’. [Focus group, Participant 4]\n‘[Focus group, Participant 2] looks forward to it. Before it even starts, he likes talking about it before he goes’. [Focus group, support]\n‘Seeing everyone’. [Focus group, Participant 5]\nParks were considered by participants to be good places to walk, and on the day of the walk, the weather was pleasant, which facilitated walking (Table\nDuring the walk, there were police in the park and the presence of police cars was seen as a potential hazard but the police were described as helping to keep people safe (Table\nThe walk took place during the spring when flowers were in bloom. The researcher was directed to take photographs of the cherry blossoms and other flowers as the sight made the participant ‘happy’ (Table\nThe PPI group agreed with the findings and felt like it captured their experiences of walking. They emphasised that walking in a group helps improve the walking experience, and that there should also be a reason for a walk, such as walking to the shops. The involvement group stressed that everyone has individual needs, and that it is important that everyone feels included.\nThis study was the first to use the COM‐B model to develop a behavioural diagnosis of walking among adults with mild to moderate intellectual disabilities. The findings emphasise the complexity of understanding influences of walking for adults with intellectual disabilities and the need for a flexible theoretical framework. The multiple capabilities, opportunities, and motivations were interacting, with many of the influences identified as unique to the experience of having an intellectual disability.\nPeople involved in the study described how limitations in adaptive skills impacted on their psychological capability to independently walk outdoors. Reduced autonomy, safety concerns, and a reliance on social support can ultimately restrict the opportunities people with intellectual disabilities have for walks (Brooker et al.\nWalking opportunities may also be impacted by gender, with women participants more likely to perceive walking in the dark or on ‘lonely roads’ as unsafe. In research involving people without intellectual disabilities, women and girls feel less safe walking alone in the dark and in greenspaces like parks (Office of National Statistics\nFor all participants, walking was tied to the social opportunity of having consistent social support. However, receiving social support relies on the capabilities, opportunities, and motivation of support providers, along with the wider financial resources available to access meaningful support (Bossink et al.\nNevertheless, opportunities for meeting other people were a main source of reflective motivation and identified as a key priority by the PPI group of people with lived experiences. These findings have important implications as adults with intellectual disabilities are at increased risk of experiencing loneliness and have reduced social connections (Alexandra et al.\nThe reflective motivation of walking with a purpose or reason for a walk was also appraised as an important finding by the PPI group. These findings taken within the wider context of behaviour change could indicate the benefit of behaviour change techniques, such as ‘goal setting’ or ‘action planning’. Goal setting and action planning have been adopted in interventions with people with intellectual disabilities (Rana et al.\nThe PPI group emphasised that everyone has individual needs and that everyone should feel included. Involvement of people with intellectual disabilities in behaviour change research ensures the interventions are accessible and reflect individual needs (Westrop et al.\nThe findings were bound to the specific experiences of adults with mild to moderate intellectual disabilities living in Greater Glasgow, limiting the transferability of the findings. Further research is required to confirm the capabilities, opportunities, and motivations for walking among adults with intellectual disabilities in different contexts. Although a potential intersection between gender and having a disability was observed, the data did not allow for consideration of other intersecting identities such as racial and ethnic identity or level of intellectual disability. The focus group also only included one woman, which reflected the ratio within the walking group.\nThe main implication and strength of this study relates to the application of the COM‐B to understand walking among adults with intellectual disabilities. Specificity is considered important when applying the COM‐B to a behaviour (Michie et al.\nA major strength and implication of this study relates to the involvement of people with lived experiences in the research. Having this involvement helped to ensure the study was accessible and helped to prioritise findings important to people with intellectual disabilities. The use of qualitative methodology further facilitated meaningful involvement and ensured there was flexibility to reflect individual preferences (e.g., option of remote or in‐person interviews).\nThere is a need to adopt accessible methods to facilitate understanding of walking among people with severe and profound intellectual disabilities who were excluded from this study. Researchers must consider the impact of intersecting identities on walking experiences. It is essential for researchers to involve people with lived experiences throughout the research process to ensure findings best reflect the needs and ensure that everyone feels included. More research is required in exploring the applications of the COM‐B in a behaviour change context for adults with intellectual disabilities.\nThe COM‐B is a flexible framework that can be applied to understanding walking for adults with intellectual disabilities. The findings emphasise the complexity of behaviour change in this population, due to many interacting capabilities, opportunities, and motivations. Involvement of people with lived experiences helps to identify the key findings important to people with intellectual disabilities. Future researchers should ensure that all experiences are captured by involving the people experiencing multiple intersecting sources of disadvantage.\nThe authors declare no conflicts of interest.\n\n", "content_for_embedding": "\n\nThe COM‐B model is a theoretical framework used to understand capabilities, opportunities, and motivations for a behaviour.\nThis study used interviews, photo‐based methods, and a focus group with adults with learning disabilities to apply the COM‐B to walking for physical activity.\nThere are many different capabilities, opportunities, and sources of motivation identified that impact on walking for adults with learning disabilities.\nFrom the perspective of adults with learning disabilities, the important findings were that walking is better when walking in a group, walking should have a purpose (e.g., walking to the shops), that everyone has individual needs, and everyone needs to feel included.\nWalking is a free form of physical activity associated with reduced risk for all‐cause mortality, obesity, diabetes, and major depressive disorder (Kelly et al.\nPrevious interventions to increase walking and physical activity of adults with intellectual disabilities have reported limited effectiveness (Melville et al.\nTestable theoretical frameworks can help to understand how to improve physical activity and walking. The most frequently used theories in lifestyle change interventions with adults with intellectual disabilities are the Transtheoretical Model, Social Cognitive Theory, and Theory of Planned Behaviour (Rana et al.\nIn recent years, researchers have been using a specific theoretical framework called the COM‐B model to understand the social support caregivers provide for physical activity for adults with intellectual disabilities (Bossink et al.\nSummary of COM‐B model.\n\nAt the centre of a wider framework called the Behaviour Change Wheel, which is used to guide intervention development (BCW; Michie et al.\nEthical approval was provided by the University of Glasgow College of Medical, Veterinary, and Life Sciences ethics committee. Additional procedures were in place to facilitate informed consent, such as producing\nAll research team members have expertise in working with adults with intellectual disabilities and/or lifestyle modification. The team included a representative from the non‐profit organisation Values into Action Scotland (VIAS) which supports adults with intellectual disabilities to achieve their goals. Involvement of VIAS helped to ensure the research was relevant and accessible for people with intellectual disabilities.\nThe researcher primarily responsible for data collection and analysis aligns with the philosophical stance of critical realism. Critical realism argues that reality exists independent of the researcher and understanding is shaped by human experiences; however, this understanding can be improved by rigorous research (Lyons and Coyle\nThe qualitative study design enabled understanding of the capabilities, opportunities and motivations for walking from the perspective of adults with intellectual disabilities. As the COM‐B is used in the context of behaviour change interventions, the use of qualitative methods ensured the influences of walking identified reflected people's lived experiences (O'Cathain et al.\nThe study included two data collection pathways, both adopting photo‐elicitation methods. Pathway one: semi‐structured interviews (in‐person or using remote methods) were conducted with researcher‐directed photo‐elicitation methods. Pathway two: participant‐directed photo‐elicitation methods followed by a focus group to discuss the photographs taken. Throughout the process, a reflexive approach to data collection and analysis ensured the process was inclusive and accessible.\nPurposive sampling sought adults (≥ 18 years) who identified as having mild to moderate intellectual disabilities and lived in the Greater Glasgow area. Recruitment and data collection took place between August 2022 and May 2023. Based on the recommendation of VIAS, a small financial incentive of a £20 gift voucher was used.\nFor pathway one, a provisional sample of\nFor pathway two, the tentative sample was\nA demographic questionnaire collected data on participant age, gender identity, residential setting, and post code to calculate the Scottish Index of Multiple Deprivation (SIMD; Scottish Government\nThe interviews involved an initial photo‐elicitation activity and then followed a semi‐structured interview schedule reflecting the COM‐B behavioural diagnosis (see SI File\nThe images represented environmental influences of walking outlined in previous literature (e.g., dogs, weather, green spaces, roads, the dark); three example images are provided in Figure\nExample photographs used to facilitate discussion.\nThe interviews could be conducted in person or remotely using Zoom (a video conferencing platform). The audio of the in‐person interviews was recorded with a Dictaphone, and the remote interviews were recorded over Zoom. The audio recordings allowed the researcher to transcribe the audio verbatim and enabled the transcriptions to be checked for accuracy against the initial recordings. A reflexive approach to data collection allowed for adaptations to the methods. These adaptations included the provision of more context to the questions and greater explanation for the photo elicitation activity.\nIn situ data were gathered during a walk using photograph‐based methods to support adults with intellectual disabilities to be involved in the data collection process (Overmars‐Marx et al.\nData were analysed using the framework approach to thematic analysis as the goal was to map influences of walking onto the existing framework of the COM‐B (Gale et al.\nThe categorisation onto the COM‐B involved reference to the Theoretical Domains Framework (TDF). The TDF is based on the synthesis of existing theories relating to behaviours and behaviour change, and is often used alongside the COM‐B to expand the influences (Cane et al.\nOnce the coding framework was applied to the remaining interview transcripts, a framework matrix was produced using NVIVO. The influences identified for capabilities, opportunities, and motivations to go on a walk were presented by cases (by each participant included in the study). The framework matrix helped to explore the important participant characteristics, such as gender, age, and SIMD. An example excerpt from the matrix for ‘physical opportunities’ has been provided in Appendix\nThe focus group data were analysed using the coding framework developed for the interviews as a guide. The data was treated as separate but complementary to the data collected during the interviews. Therefore, new codes were generated when analysing this data, and not all the existing codes were relevant.\nThroughout the research process there was close collaboration with Values into Action Scotland (VIAS), with a member of VIAS attending all team meetings and involved in all decisions made. There was a separate patient and public involvement (PPI) meeting with people with lived experiences once there were preliminary findings from both the interviews and focus group. This was held in May 2023 at the lead researcher's University, with financial compensation provided for the participants' time. PPI consisted of three adults with intellectual disabilities, with one person attending to provide additional support. The researcher produced easy read slides which were approved in advance by VIAS. Feedback was given on the initial interpretation of the findings, which were integrated into the results.\nA total of 12 adults with mild to moderate intellectual disabilities were interviewed, and nine participants had a source of support present. As can be seen in Table\nDemographic characteristics of interview participants.\nTwo participants requested to support each other.\nParticipant did not disclose postcode.\nPsychological capabilities relate to knowledge, psychological skills, and mental processes (Michie et al.\nI know I'm quite vulnerable, even though I hate that word, I am classed as vulnerable. So like if a stranger come up to me and say do you want to come to my place or do you want to come see my dog …I might tend to go with a stranger if they asked me. [Participant 8]\nWalking influences mapped under Capabilities.\n\nPhysical capabilities in the COM‐B are defined as relating to physical skills, strength, and stamina (Michie et al.\nPhysical opportunities relate to the physical resources people have access to, and more conceptual resources, such as time (Michie et al.\nThere's a wee park up beside me you know, so I walk there and then I walk back down. You know, and just kind of sit about a wee while and then say right. It's not even just that, the fresh air gives you…makes you feel good. [Participant 4]\nWalking influences mapped under Opportunities.\n\nWalking in the dark was seen as either peaceful or unsafe because of poor visibility or due to other people. Gender differences in perceptions of walking in the dark became evident during the analysis. Although two men taking part did appraise the dark as unsafe, the other men participating reported no safety concerns or felt the dark made walking peaceful and relaxing: ‘Really good, I like going out for a walk at night‐time…because it's quiet and nobody's around’. [Participant 10, Man]. Importantly, one of the men felt that walking in the dark was unsafe, but these risks were attributed to women:\n…especially if you were a lady. I've known so many ladies that sadly has walked home by themself at night through like dark allies… The dark ally or the darks path and sadly they've been sexually assaulted, or they've been… it's been all over the Glasgow live [Participant 5, Man]\nReflecting this, all of the women taking part appraised walking in the dark as unsafe with this predominantly linked to other people being dangerous: ‘It's kinda… because it is getting frightening now when you go out, if you understand. You know because you're afraid to go out at night now because you don't know what's going to happen anymore.’ [Participant 4, Woman] Women also described wider safety concerns when walking in isolated areas and on ‘lonely roads’:\nI know, but it's an empty street as well remember. [Participant 6, attending support] ‘Nope. It's a one in five chance that you get attacked and have you read the reports today? There's been more attacks on Glasgow than there was like ten years ago’. [Participant 6, Woman]\nWhile describing physical opportunities, participants also referred to tangible resources, in the form of suitable clothes and water. With participants also referencing the need for wider funding and organisational support, which related to walking groups. However, the need for tangible resources highlighted accessibility concerns, with not everyone having access to the same opportunities and previously available options closing due to the COVID‐19 pandemic: ‘Well, it's just where everything was closed due to COVID’. [Participant 6].\nSocial opportunities are defined as relating to interpersonal influences, cultural and social norms (Michie et al.\nAll participants reported the negative impact of other people, as participants described experiencing harassment and discrimination by members of the public and within the wider perceptions of society: ‘See soon as you get diagnosed with a learning disability you're supposed to go inside, out the road because you're no’ supposed to have the common sense or the way to speak or whatever…’ [Participant 4]\nHaving a dog, or knowing someone with a dog, facilitated walking; however, dogs can pull and make walking difficult. Walking was also facilitated by the presence of walking groups and organisations providing support for people with intellectual disabilities. However, these groups were not available to everyone and many groups closed during the COVID‐19 pandemic.\n… it's nice to walk in a…we enjoyed that again walking in a crowd? Because you heard everybody chatting and so it was nice to chat to the other people as well. No just me. Isn't it, you enjoyed that? [[Participant 6], Attending support]\nAdditionally, level of deprivation contributed to variations in access to these resources. One participant lived in an area classified as ‘least deprived’. Compared to the other participants, the participant had more opportunities through access to football clubs, voluntary working positions, dance classes, youth clubs and walking clubs. Emphasising the impact of financial resources and support availability contributing to disparities in opportunities for walking.\nReflective motivation relates to reflective processes, such as making plans (Michie et al.\nAdditionally, reflective motivation was increased when there was a purpose or a goal, with the most reported being walking to the shops. Another recurrent influence was the impact of walking on physical health benefits, with walking described as being ‘good’ for you, contributing to weight loss and being a form of exercise. ‘Well… when you're sitting you've just got your belly, it's just sitting, but when you're walking you're burning the muscles in your belly and it burns all the fat away. All the fat away… I'll need to start again.’ [Participant 11]\nWalking influences mapped under Motivation.\n\nAutomatic motivation is defined as ‘automatic processes’, which includes emotional reactions (Michie et al.\nSeven participants also described the impact of fear and anxiety on their walking, with fear tied to bad experiences with members of the public that made them feel unsafe, anxiety over catching COVID‐19, and fear of falling and becoming injured.\nSo and then I get feared [scared] to go out if that happens. I mean, being honest with you, I fall in the house so I do. I'm just… I'm clumsy in the house do you know what I mean, because sometimes you trip over your own feet. [Participant 4]\nParticipants involved in this pathway were not involved in pathway two. Five participants took part during this stage which included four men and one woman, aged between 24 and 40 years old. All participants were part of a walking group facilitated by a non‐profit organisation for people with intellectual disabilities. One of the participants was non‐ambulatory and used a wheel chair. During data collection, a source of support was present with each participant along with the organiser of the walking group. Participants had difficulties completing the full demographic questionnaire, so only gender and age were recorded.\nThe focus group described physical capabilities that impacted on capacity to go on a walk. Participants described that some people had visual impairments and emphasised that walking routes need to be accessible, with one member of the walking group trained to identify potential hazards (Table\nExample photographs and illustrative quotes.\n‘I would also… I would also need to know the routes, emm the safety aspects. [Focus group, Participant 1]\n… Keep people safe. [Focus group, Participant 4]’\n‘It was really shaky, and… It was really shaky… but that day, that was really risky.’ [Focus group, Participant 1]\n‘Especially [Focus group, Participant 1], that's your mode for you being able to use your hands to wheel yourself, isn't it? And that's taking away your independence’. [Walking group organiser]\n‘I liked it because em… I liked pretty much all of it really’ [Focus group, Participant 1]\n‘It was good that the weather was nice as well’. [Focus group support]\n‘Well this was a hazard the police shouldn't have been parked in the middle of the pedestrian highway because there was spaces where they could have parked their car and they wouldn't have had to park in the middle of the highway’. [Focus group, Participant 1]\n‘No one's…\n‘When you were on the walk, how did seeing flowers make you feel? [Researcher]\nHappy. I like gold. [Focus group, Participant 4]’\n‘Happy’. [Focus group, Participant 4]\n‘And why is that?’ [Researcher]\n‘Because the colours… Nature’ [Focus group, Participant 4]\n‘All the pink stuff and then it falls on the grass. Oh the pink stuff …the blooms’. [Focus group, Participant 2]\n‘Being together’. [Focus group, Participant 4]\n‘[Focus group, Participant 2] looks forward to it. Before it even starts, he likes talking about it before he goes’. [Focus group, support]\n‘Seeing everyone’. [Focus group, Participant 5]\nParks were considered by participants to be good places to walk, and on the day of the walk, the weather was pleasant, which facilitated walking (Table\nDuring the walk, there were police in the park and the presence of police cars was seen as a potential hazard but the police were described as helping to keep people safe (Table\nThe walk took place during the spring when flowers were in bloom. The researcher was directed to take photographs of the cherry blossoms and other flowers as the sight made the participant ‘happy’ (Table\nThe PPI group agreed with the findings and felt like it captured their experiences of walking. They emphasised that walking in a group helps improve the walking experience, and that there should also be a reason for a walk, such as walking to the shops. The involvement group stressed that everyone has individual needs, and that it is important that everyone feels included.\nThis study was the first to use the COM‐B model to develop a behavioural diagnosis of walking among adults with mild to moderate intellectual disabilities. The findings emphasise the complexity of understanding influences of walking for adults with intellectual disabilities and the need for a flexible theoretical framework. The multiple capabilities, opportunities, and motivations were interacting, with many of the influences identified as unique to the experience of having an intellectual disability.\nPeople involved in the study described how limitations in adaptive skills impacted on their psychological capability to independently walk outdoors. Reduced autonomy, safety concerns, and a reliance on social support can ultimately restrict the opportunities people with intellectual disabilities have for walks (Brooker et al.\nWalking opportunities may also be impacted by gender, with women participants more likely to perceive walking in the dark or on ‘lonely roads’ as unsafe. In research involving people without intellectual disabilities, women and girls feel less safe walking alone in the dark and in greenspaces like parks (Office of National Statistics\nFor all participants, walking was tied to the social opportunity of having consistent social support. However, receiving social support relies on the capabilities, opportunities, and motivation of support providers, along with the wider financial resources available to access meaningful support (Bossink et al.\nNevertheless, opportunities for meeting other people were a main source of reflective motivation and identified as a key priority by the PPI group of people with lived experiences. These findings have important implications as adults with intellectual disabilities are at increased risk of experiencing loneliness and have reduced social connections (Alexandra et al.\nThe reflective motivation of walking with a purpose or reason for a walk was also appraised as an important finding by the PPI group. These findings taken within the wider context of behaviour change could indicate the benefit of behaviour change techniques, such as ‘goal setting’ or ‘action planning’. Goal setting and action planning have been adopted in interventions with people with intellectual disabilities (Rana et al.\nThe PPI group emphasised that everyone has individual needs and that everyone should feel included. Involvement of people with intellectual disabilities in behaviour change research ensures the interventions are accessible and reflect individual needs (Westrop et al.\nThe findings were bound to the specific experiences of adults with mild to moderate intellectual disabilities living in Greater Glasgow, limiting the transferability of the findings. Further research is required to confirm the capabilities, opportunities, and motivations for walking among adults with intellectual disabilities in different contexts. Although a potential intersection between gender and having a disability was observed, the data did not allow for consideration of other intersecting identities such as racial and ethnic identity or level of intellectual disability. The focus group also only included one woman, which reflected the ratio within the walking group.\nThe main implication and strength of this study relates to the application of the COM‐B to understand walking among adults with intellectual disabilities. Specificity is considered important when applying the COM‐B to a behaviour (Michie et al.\nA major strength and implication of this study relates to the involvement of people with lived experiences in the research. Having this involvement helped to ensure the study was accessible and helped to prioritise findings important to people with intellectual disabilities. The use of qualitative methodology further facilitated meaningful involvement and ensured there was flexibility to reflect individual preferences (e.g., option of remote or in‐person interviews).\nThere is a need to adopt accessible methods to facilitate understanding of walking among people with severe and profound intellectual disabilities who were excluded from this study. Researchers must consider the impact of intersecting identities on walking experiences. It is essential for researchers to involve people with lived experiences throughout the research process to ensure findings best reflect the needs and ensure that everyone feels included. More research is required in exploring the applications of the COM‐B in a behaviour change context for adults with intellectual disabilities.\nThe COM‐B is a flexible framework that can be applied to understanding walking for adults with intellectual disabilities. The findings emphasise the complexity of behaviour change in this population, due to many interacting capabilities, opportunities, and motivations. Involvement of people with lived experiences helps to identify the key findings important to people with intellectual disabilities. Future researchers should ensure that all experiences are captured by involving the people experiencing multiple intersecting sources of disadvantage.\nThe authors declare no conflicts of interest.\n\n", "topic": "Neurodevelopmental_disorder"}
{"pmid": "38866332", "pmcid": "12303367", "title": "Systematic Review: The Psychosocial Impacts of Autism-Related Genetic Testing", "publication_year": "N/A", "abstract": "We systematically searched for articles on the impacts of receiving genetic test results about autism. Our search returned 22 studies that varied widely. Seventeen focused on parents/caregivers of autistic children, three on the prenatal context, and two on autistic adults. Psychological impacts of receiving results varied and included relief, peace of mind, reduced guilt, disappointment, fear, frustration, stress, blame, and guilt. Results varied widely, making it hard to compare studies; one clear outcome is that more research with and for autistic people is needed, including children when possible.", "full_text": "", "content_for_embedding": "We systematically searched for articles on the impacts of receiving genetic test results about autism. Our search returned 22 studies that varied widely. Seventeen focused on parents/caregivers of autistic children, three on the prenatal context, and two on autistic adults. Psychological impacts of receiving results varied and included relief, peace of mind, reduced guilt, disappointment, fear, frustration, stress, blame, and guilt. Results varied widely, making it hard to compare studies; one clear outcome is that more research with and for autistic people is needed, including children when possible.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "38820683", "pmcid": "12307927", "title": "Neurodevelopmental status of children aged 12 to 60 months conceived with artificial oocyte activation in a Cross-Sectional study", "publication_year": "N/A", "abstract": "The potential effect of artificial oocyte activation (AOA) following intracytoplasmic sperm injection (ICSI) on neurodevelopment remains uncertain. Since AOA does not fully replicate the physiological Ca²⁺ oscillations essential for fertilization, concerns persist regarding its safety. This study evaluates neurodevelopmental outcomes in children conceived via ICSI-AOA compared to conventional ICSI. A multicentre, cross-sectional study was conducted at Keio University Hospital and eight affiliated institutions, assessing 158 children (ICSI:", "full_text": "Artificial oocyte activation (AOA) supports fertilization by temporarily elevating calcium (Ca\nAOA cannot replicate the normal patterns of calcium oscillation\nRecent studies have reported aberrant DNA methylation in imprinted genes (e.g.,\nA 2020 survey by the Japanese Ministry of Health, Labour, and Welfare reported that 67.3% of assisted reproduction facilities had adopted AOA\nTherefore, we aimed to investigate the impact of ICSI-AOA on paediatric neurodevelopment. A cross-sectional design was employed, involving Keio University and eight affiliated institutions under the Japanese Institute for Standardization of Assisted Reproductive Technology (JISART), supported by Tokyo Medical University and the University of Tokyo. Neurodevelopmental assessment was conducted using the Japanese version of the Ages and Stages Questionnaires, 3rd Edition (J-ASQ-3), which evaluates communication, gross motor, fine motor, problem-solving, and personal-social skills.\nOverall, 158 cases were analysed, among which 81 and 77 were in the ICSI-alone and ICSI-AOA groups, respectively, with one twin pregnancy in the ICSI-AOA group. The median maternal age at delivery (ICSI, 35.0 [interquartile range = 32.0–38.0] vs. ICSI-AOA, 36.0 [33.0–39.0] years) and paternal age (ICSI, 38.0 [34.5–41.0] vs. ICSI-AOA, 37.0 [33.0–40.0] years), the proportion of mothers employed as office workers (ICSI, 17.3% vs. ICSI-AOA, 28.9%), and maternal educational background were comparable (Table\n\nParental and children Characteristics.\nWe examined the influence of sibling presence and social engagement on neurodevelopment by analysing singleton birth rates, sibling composition, and levels of social engagement between the groups. The singleton birth rates were 98.7% and 100% in the ICSI-AOA and ICSI-alone groups, respectively, showing comparable rates. No significant differences in sibling composition were observed between the groups. The proportion of children participating in social activities was similar between the ICSI-AOA (77.9%) and ICSI-alone (85.2%) groups (Table\nAll 81 and 77 children in the ICSI-alone and ICSI-AOA groups, respectively, completed the J-ASQ-3 questionnaire without any missing responses. The participants were categorized into nine groups based on age, each completing the corresponding age-appropriate J-ASQ-3 questionnaire. Specifically, the ICSI-alone and ICSI-AOA groups showed no significant differences in any of the five J-ASQ-3 subdomain scores—communication, gross motor, fine motor, problem-solving, or personal-social skills—across all age groups (Fig.\n\nJ-ASQ-3 cores at age 12–60 months | Total raw scores on each J-ASQ-3 domain (communication, gross motor, fine motor, problem-solving, and personal-social) for children born via ICSI alone and ICSI-AOA at 12, 18, 24, 30, 36, 42, 48, 54, and 60 months of age. No significant group differences are found in any of the J-ASQ-3 domains (\n\nComparison of the J-ASQ-3 scores between the ICSI-alone and ICSI-AOA Groups.\n\nComparison of the numbers below cutoff and in monitoring zones based on the J-ASQ-3 scores between the ICSI-alone and ICSI-AOA Groups.\nEach AOA method poses distinct neurodevelopmental risks. Therefore, we evaluate the J-ASQ-3 scores associated with each reagent used for AOA. The AOA protocol comprised 59, 15, and 3 cases treated with A23187, ionomycin, and electrical stimulation, respectively. No mechanical stimulation, SrCl₂, or phospholipase C zeta (PLCζ) cases were reported (Supplementary Table\n\nJ-ASQ-3 scores for comparing neurodevelopment in children conceived with ICSI-AOA using A23817 or ionophores | Total raw scores on each J-ASQ-3 domain (communication, gross motor, fine motor, problem-solving, and personal-social) for children born with ICSI-AOA using A23817 or ionophores at 12, 18, 24, 30, 36, 42, 48, 54, and 60 months of age. Both groups have no significant differences at all age points and in all domains (\nIdentifying factors associated with neurodevelopmental delays is essential for recognizing at-risk children and enabling timely interventions. We identified populations at high risk of developmental delay requiring evaluation or follow-up within each subdomain. Children scoring below the monitoring zone on the J-ASQ-3 (Supplementary Fig. S2) were identified, and their backgrounds, including maternal and paternal age, child’s sex, presence of siblings, group living status, gestational age at delivery, birth weight, and delivery mode, were compared with those of children scoring within the normal range. Among these factors, maternal age, sibling composition, and child’s sex were significantly associated with scores below the monitoring zone: higher maternal age (35.0 [32.0–38.0] vs. 37.0 [33.0–39.8] years; OR = 1.10 [1.01–1.20],\nThis is the first multicentre cross-sectional study to evaluate the long-term safety of ICSI, followed by AOA on neurodevelopment in a large cohort of children. Our findings suggest that the neurodevelopmental safety of ICSI-AOA is comparable to that of ICSI-alone in terms of social and motor development in 12–60 months. Analysis of scores below the cutoff and within the monitoring zone revealed no significant differences across all subdomains. No significant differences in the J-ASQ-3 scores were observed between the AOA methods using A23187 and ionomycin, suggesting that variations in the AOA techniques do not adversely affect neurodevelopmental outcomes.\nPrevious studies evaluating the language abilities of children aged 3–10 years conceived via ICSI-AOA, using the Reynell Developmental Language Scales, found that 4 of the 20 children scored below the 10th percentile in specific subdomains\nThis study did not include children born after AOA with SrCl\nRecent literature highlights concerns about neurodevelopmental delays in children born during the coronavirus disease 2019 (COVID-19) pandemic, particularly regarding language and communication skills\nEarly intervention is a well-established method of improving developmental outcomes in children with developmental delays. A study on the Early Start Denver Model, conducted over 2 years involving children diagnosed with autism spectrum disorder (ASD) at 18–30 months, showed improvements in Intelligence Quotient, adaptive behaviour, and electroencephalograph patterns that were similar to those of typically developing children\nIn our cohort, paternal age did not differ significantly between the conventional ICSI and ICSI-AOA groups (median 37.0 vs. 38.5 years;\nEpigenetic mechanisms govern gene expression, cellular function, and developmental processes, and DNA methylation plays a central role in normal embryonic development. Aberrant DNA methylation patterns in infants have been linked to an increased risk of ASD\nTo further explore the observed trend, it is noteworthy that in our cohort, the ICSI-AOA group showed numerically low J-ASQ-3 communication scores at 12, 18, and 24 months of age. However, this difference was no longer apparent by 30 months, suggesting any early developmental lag may be transient. This pattern, combined with the absence of significant between-group differences in the proportion of children falling below the threshold or requiring monitoring, suggests that AOA is unlikely to have lasting adverse effects on communication development. Nevertheless, these findings warrant cautious interpretation, and ongoing developmental surveillance remains important.\nThis study demonstrated AOA’s safety for neurodevelopment in children up to 60 months, reinforcing the recent decision by the HFEA\nThis study employed a cross-sectional design, assessing children aged 12–60 months using the J-ASQ-3, with no longitudinal follow-up. While heterogeneity and potential biases from environmental and genetic factors could not be eliminated, minimal bias was suggested, as no significant differences in social or environmental backgrounds were observed, except for a higher number of fathers with teaching professions in the ICSI-AOA group than in the ICSI-alone group. The COVID-19 pandemic may have affected developmental outcomes, given its impact on early childhood environments. Finally, this study lacked adequate data to compare various AOA methods, underscoring the necessity of longitudinal multicentre studies to assess the long-term safety and effectiveness of alternative techniques\nThis is the first study to demonstrate the long-term safety of ICSI, followed by AOA on neurodevelopment in a large cohort of children. Based on the findings, no significant concerns regarding any adverse effects of AOA on childhood neurodevelopment have been identified. These data add to the body of evidence available to physicians when considering approaches for couples experiencing fertilization failure. However, more detailed studies on the long-term childhood development born after all AOA types are needed before any definitive conclusions can be drawn.\nWe collected data on mothers who gave birth via ICSI-alone or ICSI-AOA at Keio University Hospital and eight JISART facilities between August 2018 and June 2023. Based on responses from the eight participating facilities, A23187-mediated AOA was performed using either a HEPES-buffered calcium ionophore (CIM-10, Kitazato Corporation, Japan) or A23187 obtained from SIGMA (C7522, USA), Gynemed (GM508 CultActive, Germany), or FujiFilm (019-20111, Japan). GM508 CultActive was supplied as a ready-to-use A23187 ionophore solution, with its concentration undisclosed. When preparing other A23187 solutions, stock concentrations were diluted in HEPES-buffered medium with DMSO to achieve final working concentrations of either 5 µM or 10 µM. In all cases, AOA was initiated within 30 min after ICSI and consisted of a single exposure at 37 °C for 5–15 min. Ionomycin (I-0634, Sigma-Aldrich, Belgium) was also used as a calcium ionophore. In this protocol, oocytes were exposed to a 5 µM ionomycin solution for 10 min, starting 20 min after ICSI.\nThe neurodevelopmental survey focused on children aged 12–60 months who were conceived via ICSI-alone or ICSI-AOA between August 2018 and January 2023. The exclusion criteria included cases involving testicular sperm extraction, mothers aged ≥ 43 years at the time of embryo transfer, and double embryo transfers using ICSI-alone and ICSI-AOA. No age restrictions were applied for fathers. Prior to completing the J-ASQ-3 and an additional questionnaire, written informed consent was obtained from all participants. To specifically assess the impact of ICSI-AOA on neurodevelopmental outcomes, we established a control group matched by offspring age. For each child born following ICSI-AOA, one age-matched control child was selected from the IVF database of the corresponding facility. These children were conceived and delivered during the same time period to ensure comparable durations of postnatal follow-up. All procedures were conducted in accordance with the relevant guidelines and regulations.\nOn December 8, 2023, all facilities were instructed to collect relevant cases and complete the case report forms. Among the 375 identified women, 326 children aged 12–60 months were selected. Questionnaires were distributed equally to both groups (163 ICSI-AOA and 163 ICSI) totalling 326 children on January 5, 2024, with February 18, 2024, as the submission deadline. However, participants were not informed about the survey in advance; therefore, a 1,000-yen gift card was included with the questionnaire.\nValid responses were obtained from 158 children (158/266, 59.4%), comprising 77 of 128 (60.2%) in the ICSI-AOA group and 81 of 138 (58.7%) in the ICSI group. Among the remaining cases: 60 questionnaires were undelivered, 104 were not returned, 3 were declined, and 1 was excluded for not meeting inclusion criteria. Parents were also asked to complete a paper-based questionnaire on factors influencing child development, including sibling composition and social activities (e.g., daycare or kindergarten), parental educational background, occupation, and household income.\nThe J-ASQ-3 is a level 1 screening tool that evaluates five developmental domains. This questionnaire, completed by parents or caregivers, is known for its high reliability and validity. It has been translated into several languages and is widely used in clinical and research settings internationally\nAll statistical analyses were conducted using IBM SPSS Statistics for Windows, version 28 (IBM Corp., Armonk, NY, USA) and GraphPad Prism 9 (GraphPad Software, Inc., La Jolla, CA, USA), with statistical significance considered at\nThe percentages of children identified as being below the monitoring threshold and cutoff levels indicative of delays, as defined by the ASQ-3 developer, were computed for each subdomain and the overall J-ASQ-3 outcome. Additionally, the odds ratios (ORs) were calculated using a binary logistic regression model. The independent variables included AOA presence, sex, gestational age at birth, and age in months during the J-ASQ-3 assessment. All results were reported with 95% confidence intervals (CIs).\nBelow is the link to the electronic supplementary material.\n\nSupplementary Material 1", "content_for_embedding": "Artificial oocyte activation (AOA) supports fertilization by temporarily elevating calcium (Ca\nAOA cannot replicate the normal patterns of calcium oscillation\nRecent studies have reported aberrant DNA methylation in imprinted genes (e.g.,\nA 2020 survey by the Japanese Ministry of Health, Labour, and Welfare reported that 67.3% of assisted reproduction facilities had adopted AOA\nTherefore, we aimed to investigate the impact of ICSI-AOA on paediatric neurodevelopment. A cross-sectional design was employed, involving Keio University and eight affiliated institutions under the Japanese Institute for Standardization of Assisted Reproductive Technology (JISART), supported by Tokyo Medical University and the University of Tokyo. Neurodevelopmental assessment was conducted using the Japanese version of the Ages and Stages Questionnaires, 3rd Edition (J-ASQ-3), which evaluates communication, gross motor, fine motor, problem-solving, and personal-social skills.\nOverall, 158 cases were analysed, among which 81 and 77 were in the ICSI-alone and ICSI-AOA groups, respectively, with one twin pregnancy in the ICSI-AOA group. The median maternal age at delivery (ICSI, 35.0 [interquartile range = 32.0–38.0] vs. ICSI-AOA, 36.0 [33.0–39.0] years) and paternal age (ICSI, 38.0 [34.5–41.0] vs. ICSI-AOA, 37.0 [33.0–40.0] years), the proportion of mothers employed as office workers (ICSI, 17.3% vs. ICSI-AOA, 28.9%), and maternal educational background were comparable (Table\n\nParental and children Characteristics.\nWe examined the influence of sibling presence and social engagement on neurodevelopment by analysing singleton birth rates, sibling composition, and levels of social engagement between the groups. The singleton birth rates were 98.7% and 100% in the ICSI-AOA and ICSI-alone groups, respectively, showing comparable rates. No significant differences in sibling composition were observed between the groups. The proportion of children participating in social activities was similar between the ICSI-AOA (77.9%) and ICSI-alone (85.2%) groups (Table\nAll 81 and 77 children in the ICSI-alone and ICSI-AOA groups, respectively, completed the J-ASQ-3 questionnaire without any missing responses. The participants were categorized into nine groups based on age, each completing the corresponding age-appropriate J-ASQ-3 questionnaire. Specifically, the ICSI-alone and ICSI-AOA groups showed no significant differences in any of the five J-ASQ-3 subdomain scores—communication, gross motor, fine motor, problem-solving, or personal-social skills—across all age groups (Fig.\n\nJ-ASQ-3 cores at age 12–60 months | Total raw scores on each J-ASQ-3 domain (communication, gross motor, fine motor, problem-solving, and personal-social) for children born via ICSI alone and ICSI-AOA at 12, 18, 24, 30, 36, 42, 48, 54, and 60 months of age. No significant group differences are found in any of the J-ASQ-3 domains (\n\nComparison of the J-ASQ-3 scores between the ICSI-alone and ICSI-AOA Groups.\n\nComparison of the numbers below cutoff and in monitoring zones based on the J-ASQ-3 scores between the ICSI-alone and ICSI-AOA Groups.\nEach AOA method poses distinct neurodevelopmental risks. Therefore, we evaluate the J-ASQ-3 scores associated with each reagent used for AOA. The AOA protocol comprised 59, 15, and 3 cases treated with A23187, ionomycin, and electrical stimulation, respectively. No mechanical stimulation, SrCl₂, or phospholipase C zeta (PLCζ) cases were reported (Supplementary Table\n\nJ-ASQ-3 scores for comparing neurodevelopment in children conceived with ICSI-AOA using A23817 or ionophores | Total raw scores on each J-ASQ-3 domain (communication, gross motor, fine motor, problem-solving, and personal-social) for children born with ICSI-AOA using A23817 or ionophores at 12, 18, 24, 30, 36, 42, 48, 54, and 60 months of age. Both groups have no significant differences at all age points and in all domains (\nIdentifying factors associated with neurodevelopmental delays is essential for recognizing at-risk children and enabling timely interventions. We identified populations at high risk of developmental delay requiring evaluation or follow-up within each subdomain. Children scoring below the monitoring zone on the J-ASQ-3 (Supplementary Fig. S2) were identified, and their backgrounds, including maternal and paternal age, child’s sex, presence of siblings, group living status, gestational age at delivery, birth weight, and delivery mode, were compared with those of children scoring within the normal range. Among these factors, maternal age, sibling composition, and child’s sex were significantly associated with scores below the monitoring zone: higher maternal age (35.0 [32.0–38.0] vs. 37.0 [33.0–39.8] years; OR = 1.10 [1.01–1.20],\nThis is the first multicentre cross-sectional study to evaluate the long-term safety of ICSI, followed by AOA on neurodevelopment in a large cohort of children. Our findings suggest that the neurodevelopmental safety of ICSI-AOA is comparable to that of ICSI-alone in terms of social and motor development in 12–60 months. Analysis of scores below the cutoff and within the monitoring zone revealed no significant differences across all subdomains. No significant differences in the J-ASQ-3 scores were observed between the AOA methods using A23187 and ionomycin, suggesting that variations in the AOA techniques do not adversely affect neurodevelopmental outcomes.\nPrevious studies evaluating the language abilities of children aged 3–10 years conceived via ICSI-AOA, using the Reynell Developmental Language Scales, found that 4 of the 20 children scored below the 10th percentile in specific subdomains\nThis study did not include children born after AOA with SrCl\nRecent literature highlights concerns about neurodevelopmental delays in children born during the coronavirus disease 2019 (COVID-19) pandemic, particularly regarding language and communication skills\nEarly intervention is a well-established method of improving developmental outcomes in children with developmental delays. A study on the Early Start Denver Model, conducted over 2 years involving children diagnosed with autism spectrum disorder (ASD) at 18–30 months, showed improvements in Intelligence Quotient, adaptive behaviour, and electroencephalograph patterns that were similar to those of typically developing children\nIn our cohort, paternal age did not differ significantly between the conventional ICSI and ICSI-AOA groups (median 37.0 vs. 38.5 years;\nEpigenetic mechanisms govern gene expression, cellular function, and developmental processes, and DNA methylation plays a central role in normal embryonic development. Aberrant DNA methylation patterns in infants have been linked to an increased risk of ASD\nTo further explore the observed trend, it is noteworthy that in our cohort, the ICSI-AOA group showed numerically low J-ASQ-3 communication scores at 12, 18, and 24 months of age. However, this difference was no longer apparent by 30 months, suggesting any early developmental lag may be transient. This pattern, combined with the absence of significant between-group differences in the proportion of children falling below the threshold or requiring monitoring, suggests that AOA is unlikely to have lasting adverse effects on communication development. Nevertheless, these findings warrant cautious interpretation, and ongoing developmental surveillance remains important.\nThis study demonstrated AOA’s safety for neurodevelopment in children up to 60 months, reinforcing the recent decision by the HFEA\nThis study employed a cross-sectional design, assessing children aged 12–60 months using the J-ASQ-3, with no longitudinal follow-up. While heterogeneity and potential biases from environmental and genetic factors could not be eliminated, minimal bias was suggested, as no significant differences in social or environmental backgrounds were observed, except for a higher number of fathers with teaching professions in the ICSI-AOA group than in the ICSI-alone group. The COVID-19 pandemic may have affected developmental outcomes, given its impact on early childhood environments. Finally, this study lacked adequate data to compare various AOA methods, underscoring the necessity of longitudinal multicentre studies to assess the long-term safety and effectiveness of alternative techniques\nThis is the first study to demonstrate the long-term safety of ICSI, followed by AOA on neurodevelopment in a large cohort of children. Based on the findings, no significant concerns regarding any adverse effects of AOA on childhood neurodevelopment have been identified. These data add to the body of evidence available to physicians when considering approaches for couples experiencing fertilization failure. However, more detailed studies on the long-term childhood development born after all AOA types are needed before any definitive conclusions can be drawn.\nWe collected data on mothers who gave birth via ICSI-alone or ICSI-AOA at Keio University Hospital and eight JISART facilities between August 2018 and June 2023. Based on responses from the eight participating facilities, A23187-mediated AOA was performed using either a HEPES-buffered calcium ionophore (CIM-10, Kitazato Corporation, Japan) or A23187 obtained from SIGMA (C7522, USA), Gynemed (GM508 CultActive, Germany), or FujiFilm (019-20111, Japan). GM508 CultActive was supplied as a ready-to-use A23187 ionophore solution, with its concentration undisclosed. When preparing other A23187 solutions, stock concentrations were diluted in HEPES-buffered medium with DMSO to achieve final working concentrations of either 5 µM or 10 µM. In all cases, AOA was initiated within 30 min after ICSI and consisted of a single exposure at 37 °C for 5–15 min. Ionomycin (I-0634, Sigma-Aldrich, Belgium) was also used as a calcium ionophore. In this protocol, oocytes were exposed to a 5 µM ionomycin solution for 10 min, starting 20 min after ICSI.\nThe neurodevelopmental survey focused on children aged 12–60 months who were conceived via ICSI-alone or ICSI-AOA between August 2018 and January 2023. The exclusion criteria included cases involving testicular sperm extraction, mothers aged ≥ 43 years at the time of embryo transfer, and double embryo transfers using ICSI-alone and ICSI-AOA. No age restrictions were applied for fathers. Prior to completing the J-ASQ-3 and an additional questionnaire, written informed consent was obtained from all participants. To specifically assess the impact of ICSI-AOA on neurodevelopmental outcomes, we established a control group matched by offspring age. For each child born following ICSI-AOA, one age-matched control child was selected from the IVF database of the corresponding facility. These children were conceived and delivered during the same time period to ensure comparable durations of postnatal follow-up. All procedures were conducted in accordance with the relevant guidelines and regulations.\nOn December 8, 2023, all facilities were instructed to collect relevant cases and complete the case report forms. Among the 375 identified women, 326 children aged 12–60 months were selected. Questionnaires were distributed equally to both groups (163 ICSI-AOA and 163 ICSI) totalling 326 children on January 5, 2024, with February 18, 2024, as the submission deadline. However, participants were not informed about the survey in advance; therefore, a 1,000-yen gift card was included with the questionnaire.\nValid responses were obtained from 158 children (158/266, 59.4%), comprising 77 of 128 (60.2%) in the ICSI-AOA group and 81 of 138 (58.7%) in the ICSI group. Among the remaining cases: 60 questionnaires were undelivered, 104 were not returned, 3 were declined, and 1 was excluded for not meeting inclusion criteria. Parents were also asked to complete a paper-based questionnaire on factors influencing child development, including sibling composition and social activities (e.g., daycare or kindergarten), parental educational background, occupation, and household income.\nThe J-ASQ-3 is a level 1 screening tool that evaluates five developmental domains. This questionnaire, completed by parents or caregivers, is known for its high reliability and validity. It has been translated into several languages and is widely used in clinical and research settings internationally\nAll statistical analyses were conducted using IBM SPSS Statistics for Windows, version 28 (IBM Corp., Armonk, NY, USA) and GraphPad Prism 9 (GraphPad Software, Inc., La Jolla, CA, USA), with statistical significance considered at\nThe percentages of children identified as being below the monitoring threshold and cutoff levels indicative of delays, as defined by the ASQ-3 developer, were computed for each subdomain and the overall J-ASQ-3 outcome. Additionally, the odds ratios (ORs) were calculated using a binary logistic regression model. The independent variables included AOA presence, sex, gestational age at birth, and age in months during the J-ASQ-3 assessment. All results were reported with 95% confidence intervals (CIs).\nBelow is the link to the electronic supplementary material.\n\nSupplementary Material 1", "topic": "Neurodevelopmental_disorder"}
{"pmid": "38776696", "pmcid": "12300379", "title": "Biomarkers and Neuropsychological Tools in Attention-Deficit/Hyperactivity Disorder: From Subjectivity to Precision Diagnosis", "publication_year": "N/A", "abstract": "Attention-deficit/hyperactivity disorder (ADHD) is a prevalent neurodevelopmental disorder with chronic inattention, hyperactivity, and impulsivity and is linked with significant functional impairment. Despite being highly prevalent, diagnosis of ADHD continues to rely on subjective assessment reports of behavior and is often delayed or inaccurate. This review summarizes current advances in biomarkers and neuropsychological tests for the improvement of ADHD diagnosis and treatment. Key biomarkers are neuroimaging methods (e.g., structural and functional MRI), electrophysiological measures (e.g., EEG, ERP), and biochemical measures (e.g., cortisol, vitamin D). Additionally, novel experimental measures, e.g., eye-tracking, pupillometry, and microbiome analysis, hold the promise to be objective and dynamic measures of ADHD symptoms. The review also comments on the impact of the burden of ADHD on quality of life, e.g., emotional well-being, academic achievement, and social functioning. Additionally, differences between individuals, such as age, sex, comorbidities, and the impact of social and family support, are also addressed in relation to ADHD outcomes. In summary, we highlight the potential of these emerging biomarkers and tools to revolutionize ADHD diagnosis and guide personalized treatment strategies. These insights have significant implications for improving patient outcomes.", "full_text": "Attention-deficit/hyperactivity disorder (ADHD) is one of the most common neurodevelopmental disorders, observed in approximately 5–7% of children worldwide and persisting into adulthood in nearly two-thirds of the cases [\nDespite the growing recognition of ADHD’s impact, a concerning issue remains the diagnosis itself. According to a Brazilian study, among children diagnosed with ADHD, about 35% had little or no impairment in areas of function, calling into question the validity of some of the diagnostic measures and reporting ADHD is frequently overdiagnosed based on symptom checklists alone [\nThis subjectivity highlights the urgent need for more objective and reliable diagnostic tools. Also, the increasing awareness of the limitations of traditional diagnostic methods has generated significant interest in the development of biomarkers and objective neuropsychological tests that would improve ADHD diagnosis. Recently, a number of studies have investigated neuroimaging, electrophysiological, and biochemical markers as objective measurement techniques for diagnosing ADHD. For example, certain neuroimaging studies documented the existence of atrophic changes within the prefrontal cortex and some of the attention and executive functioning areas, which are usually damaged in children with ADHD [\nFurthermore, ADHD can also be diagnosed by using EEG indices such as the theta/beta ratio. These oscillatory processes are ADHD markers, as they reflect attention and cognitive control deficits. For instance, many studies found the ADHD group to have elevated theta/beta ratios, which indicate maintained and concentrated attention. In addition, P300 of event-related potentials is known to be an indicator of cognitive resource allocation/execution speed and attention, and it has been found to be delayed in individuals with ADHD, making it a potential electrophysiological marker of ADHD [\nIn addition to the electrophysiological and neuroimaging markings, biochemical markers have shown importance in identifying ADHD. Certain inflammatory cytokines such as IL-6, IL-10, and TNF-α are suggested to be involved in the pathophysiology of ADHD [\nMoreover, new instruments for neuropsychological testing offer an objective assessment of ADHD symptoms. The design of computerized tasks and game-style measures enables the assessment of various cognitive functions, such as working memory, attention, and executive functioning, in real time [\nThis review intends to offer a general summary concerning the most recent developments in the fields of biomarkers and neuropsychological testing for ADHD diagnosis. In doing so, it will highlight the critical role these innovations play in refining diagnostic processes and guiding treatment. The review will also highlight the role of early diagnosis, the need for improved diagnostic criteria, and how biomarkers and cognitive tests can guide individualized interventions and improved patient outcomes.\nThis narrative review aims to synthesize existing literature on novel biomarkers and neuropsychological assessment tools used in the diagnosis of Attention-Deficit/Hyperactivity Disorder (ADHD). A comprehensive literature search was performed using two primary electronic databases, PubMed and Google Scholar, covering publications from 2011 to 2025. Search terms included keywords and combinations such as “ADHD diagnosis”, “ADHD biomarkers”, “vitamin D”, “EEG”, “fMRI” and “pupillometry”. All the studies were selected based on their relevance and contribution to the review topic.\nThe ADHD diagnosis is largely dependent upon behavioral symptoms outlined in the Diagnostic and Statistical Manual of Mental Disorders (DSM-5), which recapitulates symptoms within two categories: inattention and hyperactivity/impulsivity. Though such criteria have been in place for decades, they rely largely on subjective ratings by parents, teachers, and clinicians [\nParent-teacher rating scales, such as the Conners’ Rating Scales and Vanderbilt ADHD Diagnostic Rating Scales, are typical measures within the assessment process. These tools provide structured formats to measure a child’s behavior in different settings (e.g., home, school). Although very useful for initial screening, they are plagued with high observer bias. The reports are subjective, such that the observation of the behavior is based on experience or expectation and not a reflection of the child’s behavior. This produces false positives (over-diagnosis) and false negatives (under-diagnosis), resulting in delayed treatment or inappropriate intervention. Yet, these scales remain useful triage tools in primary care and other settings where full testing is not always feasible.\nThe routine diagnostic process typically begins with clinical interviews and behaviour ratings and is supplemented by measures such as the Conners’ Rating Scales and Vanderbilt ADHD Diagnostic Rating Scales. While helpful, they are not free from observer bias, overestimating the occurrence of ADHD. These measures provide a standardized rate of behaviour but remain susceptible to interpretation based on the clinician’s experience. For instance, teacher observation with reference to classroom behaviour is not always an accurate representation of a child’s entire range of symptoms, particularly outside the classroom, for instance, in the home environment or in social environments [\nThe sole major disadvantage of this subjective reliance is that it has the potential to introduce great inconsistency in diagnosis. Studies have proven that even teachers’ and parents’ ratings are not standardized and are dependent on expectations, personal history, and even the environment of observation. This could lead to misdiagnosis and delayed intervention for those children who need it early on [\nWhile behavioral testing remains the cornerstone of the diagnosis of ADHD, follow-up research has recognized the necessity of objective indicators. Growing awareness of the neurobiological underpinnings of ADHD prompted researchers to seek biomarkers, such as neuroimaging and electrophysiological measurements, to refine diagnostic accuracy and restrict the subjectivity of current measures. Structural and functional MRI studies have revealed patients with ADHD to have atrophic changes in the prefrontal cortex areas, which are areas involved with attention and executive function [\nApart from that, the heterogeneity of symptoms of ADHD is also an issue in its diagnosis. The symptoms are highly variable by age, gender, and comorbidities, and hence, it is challenging to utilize a single diagnostic method in every patient. It has been revealed through research that retrospective diagnosis eliminates early symptoms, especially in adolescents and adults, in whom ADHD is overshadowed by other psychiatric disorders such as anxiety and depression [\nEarly detection and treatment are necessary to improve long-term outcomes in children with ADHD. Untreated ADHD is strongly associated with academic underachievement, social impairment, and the development of comorbid conditions such as depression and anxiety [\nScreening initiatives such as the screening program in the UK have decreased waiting times for diagnosis and improved diagnostic efficacy. Waiting times for ADHD diagnosis were reduced from 28 weeks to 12 weeks in a study, which significantly enhanced service provision and patient outcomes [\nRecent progress in biomarker science has shed light on the neurobiological underpinnings of ADHD and has given rise to the hypothesis that the disorder can be more validly diagnosed by objective biomarkers such as neuroimaging, electrophysiological recordings, and biochemical markers. The subsequent sections describe recent technologies and assess the potential of these technologies to supplement or even supplant traditional subjective assessments, as is illustrated in\nNeuroimaging techniques, such as MRI, fMRI, and DTI, have provided valuable information regarding structural and functional impairments of ADHD. These techniques have all reported grey matter reduction in the prefrontal cortex and other relevant areas of cognitive control and attention [\nElectrophysiological tests, such as EEG and event-related potentials (ERPs), are another possible domain for the diagnosis of ADHD. EEG studies, particularly those using the theta/beta ratio, have found that ADHD patients exhibit heightened theta activity and reduced beta activity with cognition [\nBiochemical markers such as cortisol, vitamin D, and pro-inflammatory cytokines are increasingly emerging as key players in ADHD pathophysiology. Salivary cortisol, as a marker of stress response, has been linked with ADHD symptom severity [\nAlong with neuroimaging, other ADHD diagnostic methods such as biochemistry, eye-tracking, pupillometry, and microbiome evaluation are part of emerging diagnostics. These methods open new avenues for diagnosing ADHD-related difficulties, including attention, cognitive control, and physiological responsiveness, which require further assessment and improving clinical approaches to ADHD diagnosis\nTracking eye movement is a technology that has been marked as a non-invasive method of assessing interest and cognitive control in ADHD patients. With the help of eye-tracking technology, researchers are able to follow and measure the movements of the eye and the gaze in response to visual stimuli, which indicates the attention span of people with ADHD [\nPupillometry, or measuring the dilation of pupils in response to cognitive and emotional stimuli, is another laboratory test that is being applied in the ADHD field of research. It was suggested that pupillometry may serve as a measure of cognitive effort or engagement in a task and, therefore, could be an appropriate measure in the investigation of attentional processes in ADHD [\nAnother very promising area of ADHD research is studying the epidemiology of the microbiome as a possible biomarker. The gut-brain axis has been appreciated more recently for its critical contribution to the development of neurodevelopmental and psychiatric disorders such as ADHD. An imbalance in the gut microbiota accompanying ADHD, known as dysbiosis, is becoming increasingly accepted as a plausible causative factor [\nThe new biomarkers—eye-tracking, pupillometry, and microbiome analysis—propose to enhance established diagnostic methods and represent a major step towards more objective and individualized ADHD diagnosis. These technologies reveal critical underlying cognitive and physiological ADHD processes and may improve diagnostic precision, particularly in difficult cases where established behavioral assessments are bound to fail. With further research, it is reasonable to assume that ADHD will incorporate these instruments as integral parts of clinical practice, enabling clinicians to deliver more precise, effective, and targeted interventions.\nAttention-deficit/hyperactivity disorder (ADHD) is associated with impairments in several cognitive systems, such as attention, executive function, working memory, and response inhibition. These cognitive impairments underpin the clinical picture of ADHD and affect daily functioning in school, social, and work situations. Neuropsychological evaluation is instrumental in diagnosing ADHD and in determining its cognitive substrates. With computerized tasks, gamification, and real-time data tracking becoming increasingly prevalent, tests for ADHD have become increasingly objective, valid, and dynamic.\nAttention: The hallmark symptom of ADHD is the lack of ability to maintain attention, particularly in tasks that require the ability to maintain attention over time. Research has shown that ADHD patients consistently have deficits in sustained attention and selective attention, leading to compromised performance in tasks requiring the ability to suppress irrelevant stimuli [\nADHD Characteristics: Symptoms of attention-deficit hyperactivity disorder (ADHD) include everyday executive functioning skills, which involve goal-setting and action-shifting, planning, organization, and self-regulation (self-control). Among the executive functions overwhelmingly affected by ADHD, inhibition control and working memory seem to be the most relevant ones. Patients with ADHD demonstrate problems with the control of automatic response intervals, as well as the mental process organization [\nWorking Memory: Working memory is another cognitive domain sensitive to tracking ADHD. ADHD individuals usually have deficits in verbal and visual-spatial working memory, which diminishes their ability to perform short information retention and manipulation tasks [\nInhibition: The most profound executive dysfunction related to ADHD is usually regarded as the impairment of response inhibition. This form of impairment is observable in the performance of the Go/No-Go test and Stop-Signal Task (SST), where ADHD patients fail to inhibit prepotent responses [\nThe assessment of ADHD has recently been advanced by incorporating computer-based tests and game-like elements to improve the sensitivity of the diagnosis and its ecological validity. Neuropsychological tests that utilize subjective symptoms are far from optimal because, in some cases, they do not assess practical cognitive functioning in real life. However, CANTAB (Cambridge Neuropsychological Test Automated Battery), in its adaptive and dynamic form, allows the measurement of cognitive processes such as working memory, attention, and response inhibition of the ADHD patient, which is often more accurate than manual tests and is often more creative [\nCANTAB’s components, such as Stockings of Cambridge (SOC), Intra/Extra-Dimensional Shift (IED), and Spatial Working Memory (SWM), reveal differences in the ADHD group compared to controls regarding their cognition [\nIn addition to computerized assessments, ADHD symptom measurement through gamification has become increasingly more popular as an interactive strategy, particularly with children. For example, Cogmed Working Memory Training (WMT) is a gamified working memory training task designed to enhance working memory and cognitive control in individuals with ADHD [\nADHD evaluation with real-time data monitoring is indeed a novel, emerging method that tracks cognitive functioning while completing tasks. This method is more precise and accurate for capturing the representation of cognitive functioning and the shifting of attention, working memory, and inhibition on a moment-by-moment basis [\nMoreover, monitoring cognitive data in real-time can identify the longitudinally emerging cognitive deficits in patients with ADHD; thus, it can improve the discriminative power of diagnosing the condition. Such processes in real-time provide clinicians with better information in regard to the patient’s cognitive profile, enabling the formulation of precise diagnoses and more effective treatment.\nADHD goes beyond simply inattention, hyperactivity, and impulsivity. One of the greatest concerns of ADHD is the diminished quality of life that the affected individual experiences. ADHD impacts many aspects of a person’s life, such as their emotional state, psychosocial milestones, and everyday life activities. With the increasing research focus on ADHD, it has become clearer that assessment of quality of life indicators is critical in evaluating the overall impact of ADHD in patients, more so in children and adolescents.\nThe emotional well-being of an individual with ADHD is frequently neglected, which weakens self-esteem relative to peers without ADHD. Research chronicled that children with ADHD are at tremendous risk for developing concurrent mood disorders, which disrupt treatment and negatively impact overall prognosis. These emotional concerns are exacerbated by deficits in ADHD-related academic and social functioning, as children with ADHD frequently do not meet hopes academically [\nIn ADHD, inattention and impulsivity are linked to academic failure. Research shows students with ADHD have difficulties with planning tasks, completing homework, and attending to the class, which manifests as low achievement and school failure [\nADHD has an impact on social life functioning just as it does on academic work. ADHD patients are more likely to be socially impulsive and struggle with self-control in social interactions, resulting in inadequate social skills and peer interaction. Due to their poor social skills, children with ADHD often face peer rejection and struggle in group activities [\nMoreover, the impact of ADHD on daily functioning is profound because it impairs the individual’s ability to perform activities on a daily basis. With ADHD, remembering things such as time, organization, and even managing finances can be overwhelming to people [\nTo evaluate these different areas of QoL, numerous scales and tools have been designed to assess the multidimensional consequences of ADHD. Some of the most widely adopted measures include WHOQOL-BREF, which evaluates the overall quality of a person’s life in several domains [\nApart from the direct influence of ADHD symptoms on quality of life, individual differences—age, sex, and comorbidities—can influence the effect of the disorder on an individual as well. ADHD is expressed differently across different age groups, with children expressing more overt signs of hyperactivity, whereas adults experience long-term problems with inattention, organization, and impulsivity without the same level of hyperactivity. Research highlighted that adults with ADHD remain undiagnosed since the expression of the disorder decreases with age, resulting in misdiagnosis or delayed diagnosis that makes it difficult to intervene [\nNeuroimaging biomarkers in children, especially in the context of structural MRI investigations, reveal changes in areas such as the prefrontal cortex, which are related to cognitive control and attention, whereas adults with ADHD reveal less severe structural abnormalities, yet functional connectivity deficits in networks such as the default mode network (DMN) remain. Adult ADHD patients have been shown in functional MRI studies to have ratios of theta/beta for the measurement of attention that are relatively more consistent over time, but the neurological aspects of attention control tend to be less overt in nature than those found in children [\nAnother area of the differential biomarkers in children compared to adults involves the regulation of hormones. In children, dopaminergic markers are usually associated with hyperactivity and impulsivity, while adults with ADHD have disrupted neuroendocrine reactions, which have been associated with issues of emotional regulation and insomnia. The age-related differences should be considered when carrying out diagnostic processes to enhance precision among children and adults [\nAdditionally, studies with biochemical markers indicate that adults ADHD indicate a lower correlation between serum biomarkers such as homocysteine and vitamin B12 concentration compared to children. The variations highlight the possibilities of age-related diagnostic biomarkers [\nFurthermore, gender differences in ADHD symptomatology have come under closer examination over the last several decades. ADHD is widely thought to occur in more males than females; however, research suggests that females may occur in an alternative symptom profile, generally relating to inattention rather than hyperactivity. This results in the underdiagnosis of females because they do not manifest the disruptive behaviors that are the signature of ADHD in their male counterparts [\nComorbidities in ADHD are other factors that are important in understanding the ADHD presentation, which affects the patient’s severity level. The most common comorbidities include anxiety disorders, depression, and learning disabilities that can make the ADHD patient’s academic and social interactions much more difficult [\nBeyond personal attributes, social support perspectives also help determine the impact ADHD has on the individual’s life in terms of overall well-being. Support from parents, in particular, is one of the strongest protective factors mitigating the symptoms of ADHD. Children with ADHD who receive constant caring support and a well-organized framework from their families academically and socially outperform their peers who receive no such support [\nADHD diagnosis and treatment are areas experiencing particularly rapid change, driven by neuroimaging, biomarkers, cognitive profiling, and personalized medicine technologies. The use of objective, non-invasive methods in measuring ADHD, as well as its increasing multidimensionality, offers hope for managing ADHD optimally and improving its lifelong management. While the work is still in progress, the hope is that greater refinement of strategies designed to treat ADHD will result in more individualized and precise approaches, reducing the number of attempts needed to find the optimal treatment.\nUndiagnosed or untreated, ADHD can lead to long-term academic, social, and emotional consequences. However, early intervention can avoid such outcomes by making therapeutic intervention available in a timely manner. The latest research places a strong accent on the role of early intervention programs that focus on behavioral therapy, cognitive skills development, and education, which in turn have been shown to reduce the severity of symptoms as well as improve long-term academic and social functioning [\nA major breakthrough will be personalized therapy for ADHD, apart from a “one-size-fits-all” regimen. As ADHD is a highly heterogeneous disorder, patients will respond differently to various therapeutic interventions based on their individual genetic, neurobiological, and environmental profiles. Greater application of neuroimaging and electrophysiological biomarkers can identify the patients who would most likely benefit from specific types of treatments.\nFor example, the EEG theta/beta ratio biomarker indicates treatment response to neurofeedback, and other genetic biomarkers predict response to stimulant medications. These treatment strategies might enhance the therapeutic response, reduce adverse effects, and improve overall therapeutic outcomes [\nWith the progressive conception of ADHD, it is clear that interventions will depend heavily on cognitive profiling as well as biomarker information. Neuroimaging and genetic profiling make it increasingly clear for ADHD to delineate individual differences that manifest within the expression of the condition. For example, patients with ADHD also exhibit attention and executive function problems; some have been shown to possess structural and functional brain lesions such as decreased grey matter within the prefrontal cortex [\nAdditionally, cognitive profiling—measuring strengths and weaknesses within various domains of an individual’s profile—can inform tailored treatment strategies for the specific needs of each patient. Cognitive assessments such as CANTAB and Cogmed Working Memory Training Diagnostics can pinpoint cognitive impairment, and interventions aimed at constructing executive functions—escalating attention, working memory, and inhibition—can be developed [\nIn relation to prevention, research is being developed that supports the role of lifestyle changes, including diet, exercise, and sleep, in managing ADHD symptoms. For instance, the DASH diet, along with magnesium and vitamin D, has found some utility in improving ADHD-related behavioral outcomes in children [\nFurthermore, neurostimulation techniques, such as transcranial magnetic stimulation (TMS) and neurofeedback, are new emerging treatments for ADHD symptoms through modulating specific neural circuits involved in attention and impulse control [\nFuture research on ADHD must focus on several key areas. First, developmental follow-up studies of the longitudinal course of ADHD symptoms throughout childhood and into adulthood are needed to map out the natural history of the disease and identify its earliest warning signs. These studies could be helpful in identifying the most prognostic long-term outcome biomarkers and the most effective interventions throughout the life course.\nMultimodal approaches combining genetic, neuroimaging, and electrophysiological biomarkers with cognitive profiling must be adopted to customize treatment approaches. These approaches will determine the very specific biological and cognitive variables accounting for a particular person’s ADHD in order for more targeted treatments to be formed.\nFurthermore, since the science regarding the diagnosis and treatment of ADHD keeps changing, even greater collaboration and teamwork by clinicians, researchers, and policymakers are required to translate new knowledge into clinical practice efficiently. Biomarker research and treatment protocols individually tailored will be of immense value in promoting the quality of treatment of adult ADHD to an even greater extent.\nThis review points to the important breakthroughs in comprehending the neurobiological models of ADHD and the encouraging potential of biomarkers and neuropsychological assessment to enhance diagnosis and treatment. While conventional methods of diagnosis are still important, increasing studies of biomarkers herald a transition towards more objective, accurate, and individualized diagnoses. Early intervention with biomarkers and neuropsychological profiling is critical to minimize the long-term effects of ADHD on academic, emotional, and social outcomes.\nThe incorporation of biomarkers into clinical practice can facilitate personalized treatment, decreasing the trial-and-error process in ADHD care.\nNevertheless, difficulties lie ahead, especially the disparity between research output and its prospective practical implementation. Future research will prioritize longitudinal studies and multimodal integration of biomarkers to better resolve ADHD diagnosis and treatment tactics.\nSumming it up, the use of biomarkers and personalized medicine can potentially transform the treatment of ADHD, enhancing the quality of life for patients tremendously by providing more specific and efficient interventions.", "content_for_embedding": "Attention-deficit/hyperactivity disorder (ADHD) is one of the most common neurodevelopmental disorders, observed in approximately 5–7% of children worldwide and persisting into adulthood in nearly two-thirds of the cases [\nDespite the growing recognition of ADHD’s impact, a concerning issue remains the diagnosis itself. According to a Brazilian study, among children diagnosed with ADHD, about 35% had little or no impairment in areas of function, calling into question the validity of some of the diagnostic measures and reporting ADHD is frequently overdiagnosed based on symptom checklists alone [\nThis subjectivity highlights the urgent need for more objective and reliable diagnostic tools. Also, the increasing awareness of the limitations of traditional diagnostic methods has generated significant interest in the development of biomarkers and objective neuropsychological tests that would improve ADHD diagnosis. Recently, a number of studies have investigated neuroimaging, electrophysiological, and biochemical markers as objective measurement techniques for diagnosing ADHD. For example, certain neuroimaging studies documented the existence of atrophic changes within the prefrontal cortex and some of the attention and executive functioning areas, which are usually damaged in children with ADHD [\nFurthermore, ADHD can also be diagnosed by using EEG indices such as the theta/beta ratio. These oscillatory processes are ADHD markers, as they reflect attention and cognitive control deficits. For instance, many studies found the ADHD group to have elevated theta/beta ratios, which indicate maintained and concentrated attention. In addition, P300 of event-related potentials is known to be an indicator of cognitive resource allocation/execution speed and attention, and it has been found to be delayed in individuals with ADHD, making it a potential electrophysiological marker of ADHD [\nIn addition to the electrophysiological and neuroimaging markings, biochemical markers have shown importance in identifying ADHD. Certain inflammatory cytokines such as IL-6, IL-10, and TNF-α are suggested to be involved in the pathophysiology of ADHD [\nMoreover, new instruments for neuropsychological testing offer an objective assessment of ADHD symptoms. The design of computerized tasks and game-style measures enables the assessment of various cognitive functions, such as working memory, attention, and executive functioning, in real time [\nThis review intends to offer a general summary concerning the most recent developments in the fields of biomarkers and neuropsychological testing for ADHD diagnosis. In doing so, it will highlight the critical role these innovations play in refining diagnostic processes and guiding treatment. The review will also highlight the role of early diagnosis, the need for improved diagnostic criteria, and how biomarkers and cognitive tests can guide individualized interventions and improved patient outcomes.\nThis narrative review aims to synthesize existing literature on novel biomarkers and neuropsychological assessment tools used in the diagnosis of Attention-Deficit/Hyperactivity Disorder (ADHD). A comprehensive literature search was performed using two primary electronic databases, PubMed and Google Scholar, covering publications from 2011 to 2025. Search terms included keywords and combinations such as “ADHD diagnosis”, “ADHD biomarkers”, “vitamin D”, “EEG”, “fMRI” and “pupillometry”. All the studies were selected based on their relevance and contribution to the review topic.\nThe ADHD diagnosis is largely dependent upon behavioral symptoms outlined in the Diagnostic and Statistical Manual of Mental Disorders (DSM-5), which recapitulates symptoms within two categories: inattention and hyperactivity/impulsivity. Though such criteria have been in place for decades, they rely largely on subjective ratings by parents, teachers, and clinicians [\nParent-teacher rating scales, such as the Conners’ Rating Scales and Vanderbilt ADHD Diagnostic Rating Scales, are typical measures within the assessment process. These tools provide structured formats to measure a child’s behavior in different settings (e.g., home, school). Although very useful for initial screening, they are plagued with high observer bias. The reports are subjective, such that the observation of the behavior is based on experience or expectation and not a reflection of the child’s behavior. This produces false positives (over-diagnosis) and false negatives (under-diagnosis), resulting in delayed treatment or inappropriate intervention. Yet, these scales remain useful triage tools in primary care and other settings where full testing is not always feasible.\nThe routine diagnostic process typically begins with clinical interviews and behaviour ratings and is supplemented by measures such as the Conners’ Rating Scales and Vanderbilt ADHD Diagnostic Rating Scales. While helpful, they are not free from observer bias, overestimating the occurrence of ADHD. These measures provide a standardized rate of behaviour but remain susceptible to interpretation based on the clinician’s experience. For instance, teacher observation with reference to classroom behaviour is not always an accurate representation of a child’s entire range of symptoms, particularly outside the classroom, for instance, in the home environment or in social environments [\nThe sole major disadvantage of this subjective reliance is that it has the potential to introduce great inconsistency in diagnosis. Studies have proven that even teachers’ and parents’ ratings are not standardized and are dependent on expectations, personal history, and even the environment of observation. This could lead to misdiagnosis and delayed intervention for those children who need it early on [\nWhile behavioral testing remains the cornerstone of the diagnosis of ADHD, follow-up research has recognized the necessity of objective indicators. Growing awareness of the neurobiological underpinnings of ADHD prompted researchers to seek biomarkers, such as neuroimaging and electrophysiological measurements, to refine diagnostic accuracy and restrict the subjectivity of current measures. Structural and functional MRI studies have revealed patients with ADHD to have atrophic changes in the prefrontal cortex areas, which are areas involved with attention and executive function [\nApart from that, the heterogeneity of symptoms of ADHD is also an issue in its diagnosis. The symptoms are highly variable by age, gender, and comorbidities, and hence, it is challenging to utilize a single diagnostic method in every patient. It has been revealed through research that retrospective diagnosis eliminates early symptoms, especially in adolescents and adults, in whom ADHD is overshadowed by other psychiatric disorders such as anxiety and depression [\nEarly detection and treatment are necessary to improve long-term outcomes in children with ADHD. Untreated ADHD is strongly associated with academic underachievement, social impairment, and the development of comorbid conditions such as depression and anxiety [\nScreening initiatives such as the screening program in the UK have decreased waiting times for diagnosis and improved diagnostic efficacy. Waiting times for ADHD diagnosis were reduced from 28 weeks to 12 weeks in a study, which significantly enhanced service provision and patient outcomes [\nRecent progress in biomarker science has shed light on the neurobiological underpinnings of ADHD and has given rise to the hypothesis that the disorder can be more validly diagnosed by objective biomarkers such as neuroimaging, electrophysiological recordings, and biochemical markers. The subsequent sections describe recent technologies and assess the potential of these technologies to supplement or even supplant traditional subjective assessments, as is illustrated in\nNeuroimaging techniques, such as MRI, fMRI, and DTI, have provided valuable information regarding structural and functional impairments of ADHD. These techniques have all reported grey matter reduction in the prefrontal cortex and other relevant areas of cognitive control and attention [\nElectrophysiological tests, such as EEG and event-related potentials (ERPs), are another possible domain for the diagnosis of ADHD. EEG studies, particularly those using the theta/beta ratio, have found that ADHD patients exhibit heightened theta activity and reduced beta activity with cognition [\nBiochemical markers such as cortisol, vitamin D, and pro-inflammatory cytokines are increasingly emerging as key players in ADHD pathophysiology. Salivary cortisol, as a marker of stress response, has been linked with ADHD symptom severity [\nAlong with neuroimaging, other ADHD diagnostic methods such as biochemistry, eye-tracking, pupillometry, and microbiome evaluation are part of emerging diagnostics. These methods open new avenues for diagnosing ADHD-related difficulties, including attention, cognitive control, and physiological responsiveness, which require further assessment and improving clinical approaches to ADHD diagnosis\nTracking eye movement is a technology that has been marked as a non-invasive method of assessing interest and cognitive control in ADHD patients. With the help of eye-tracking technology, researchers are able to follow and measure the movements of the eye and the gaze in response to visual stimuli, which indicates the attention span of people with ADHD [\nPupillometry, or measuring the dilation of pupils in response to cognitive and emotional stimuli, is another laboratory test that is being applied in the ADHD field of research. It was suggested that pupillometry may serve as a measure of cognitive effort or engagement in a task and, therefore, could be an appropriate measure in the investigation of attentional processes in ADHD [\nAnother very promising area of ADHD research is studying the epidemiology of the microbiome as a possible biomarker. The gut-brain axis has been appreciated more recently for its critical contribution to the development of neurodevelopmental and psychiatric disorders such as ADHD. An imbalance in the gut microbiota accompanying ADHD, known as dysbiosis, is becoming increasingly accepted as a plausible causative factor [\nThe new biomarkers—eye-tracking, pupillometry, and microbiome analysis—propose to enhance established diagnostic methods and represent a major step towards more objective and individualized ADHD diagnosis. These technologies reveal critical underlying cognitive and physiological ADHD processes and may improve diagnostic precision, particularly in difficult cases where established behavioral assessments are bound to fail. With further research, it is reasonable to assume that ADHD will incorporate these instruments as integral parts of clinical practice, enabling clinicians to deliver more precise, effective, and targeted interventions.\nAttention-deficit/hyperactivity disorder (ADHD) is associated with impairments in several cognitive systems, such as attention, executive function, working memory, and response inhibition. These cognitive impairments underpin the clinical picture of ADHD and affect daily functioning in school, social, and work situations. Neuropsychological evaluation is instrumental in diagnosing ADHD and in determining its cognitive substrates. With computerized tasks, gamification, and real-time data tracking becoming increasingly prevalent, tests for ADHD have become increasingly objective, valid, and dynamic.\nAttention: The hallmark symptom of ADHD is the lack of ability to maintain attention, particularly in tasks that require the ability to maintain attention over time. Research has shown that ADHD patients consistently have deficits in sustained attention and selective attention, leading to compromised performance in tasks requiring the ability to suppress irrelevant stimuli [\nADHD Characteristics: Symptoms of attention-deficit hyperactivity disorder (ADHD) include everyday executive functioning skills, which involve goal-setting and action-shifting, planning, organization, and self-regulation (self-control). Among the executive functions overwhelmingly affected by ADHD, inhibition control and working memory seem to be the most relevant ones. Patients with ADHD demonstrate problems with the control of automatic response intervals, as well as the mental process organization [\nWorking Memory: Working memory is another cognitive domain sensitive to tracking ADHD. ADHD individuals usually have deficits in verbal and visual-spatial working memory, which diminishes their ability to perform short information retention and manipulation tasks [\nInhibition: The most profound executive dysfunction related to ADHD is usually regarded as the impairment of response inhibition. This form of impairment is observable in the performance of the Go/No-Go test and Stop-Signal Task (SST), where ADHD patients fail to inhibit prepotent responses [\nThe assessment of ADHD has recently been advanced by incorporating computer-based tests and game-like elements to improve the sensitivity of the diagnosis and its ecological validity. Neuropsychological tests that utilize subjective symptoms are far from optimal because, in some cases, they do not assess practical cognitive functioning in real life. However, CANTAB (Cambridge Neuropsychological Test Automated Battery), in its adaptive and dynamic form, allows the measurement of cognitive processes such as working memory, attention, and response inhibition of the ADHD patient, which is often more accurate than manual tests and is often more creative [\nCANTAB’s components, such as Stockings of Cambridge (SOC), Intra/Extra-Dimensional Shift (IED), and Spatial Working Memory (SWM), reveal differences in the ADHD group compared to controls regarding their cognition [\nIn addition to computerized assessments, ADHD symptom measurement through gamification has become increasingly more popular as an interactive strategy, particularly with children. For example, Cogmed Working Memory Training (WMT) is a gamified working memory training task designed to enhance working memory and cognitive control in individuals with ADHD [\nADHD evaluation with real-time data monitoring is indeed a novel, emerging method that tracks cognitive functioning while completing tasks. This method is more precise and accurate for capturing the representation of cognitive functioning and the shifting of attention, working memory, and inhibition on a moment-by-moment basis [\nMoreover, monitoring cognitive data in real-time can identify the longitudinally emerging cognitive deficits in patients with ADHD; thus, it can improve the discriminative power of diagnosing the condition. Such processes in real-time provide clinicians with better information in regard to the patient’s cognitive profile, enabling the formulation of precise diagnoses and more effective treatment.\nADHD goes beyond simply inattention, hyperactivity, and impulsivity. One of the greatest concerns of ADHD is the diminished quality of life that the affected individual experiences. ADHD impacts many aspects of a person’s life, such as their emotional state, psychosocial milestones, and everyday life activities. With the increasing research focus on ADHD, it has become clearer that assessment of quality of life indicators is critical in evaluating the overall impact of ADHD in patients, more so in children and adolescents.\nThe emotional well-being of an individual with ADHD is frequently neglected, which weakens self-esteem relative to peers without ADHD. Research chronicled that children with ADHD are at tremendous risk for developing concurrent mood disorders, which disrupt treatment and negatively impact overall prognosis. These emotional concerns are exacerbated by deficits in ADHD-related academic and social functioning, as children with ADHD frequently do not meet hopes academically [\nIn ADHD, inattention and impulsivity are linked to academic failure. Research shows students with ADHD have difficulties with planning tasks, completing homework, and attending to the class, which manifests as low achievement and school failure [\nADHD has an impact on social life functioning just as it does on academic work. ADHD patients are more likely to be socially impulsive and struggle with self-control in social interactions, resulting in inadequate social skills and peer interaction. Due to their poor social skills, children with ADHD often face peer rejection and struggle in group activities [\nMoreover, the impact of ADHD on daily functioning is profound because it impairs the individual’s ability to perform activities on a daily basis. With ADHD, remembering things such as time, organization, and even managing finances can be overwhelming to people [\nTo evaluate these different areas of QoL, numerous scales and tools have been designed to assess the multidimensional consequences of ADHD. Some of the most widely adopted measures include WHOQOL-BREF, which evaluates the overall quality of a person’s life in several domains [\nApart from the direct influence of ADHD symptoms on quality of life, individual differences—age, sex, and comorbidities—can influence the effect of the disorder on an individual as well. ADHD is expressed differently across different age groups, with children expressing more overt signs of hyperactivity, whereas adults experience long-term problems with inattention, organization, and impulsivity without the same level of hyperactivity. Research highlighted that adults with ADHD remain undiagnosed since the expression of the disorder decreases with age, resulting in misdiagnosis or delayed diagnosis that makes it difficult to intervene [\nNeuroimaging biomarkers in children, especially in the context of structural MRI investigations, reveal changes in areas such as the prefrontal cortex, which are related to cognitive control and attention, whereas adults with ADHD reveal less severe structural abnormalities, yet functional connectivity deficits in networks such as the default mode network (DMN) remain. Adult ADHD patients have been shown in functional MRI studies to have ratios of theta/beta for the measurement of attention that are relatively more consistent over time, but the neurological aspects of attention control tend to be less overt in nature than those found in children [\nAnother area of the differential biomarkers in children compared to adults involves the regulation of hormones. In children, dopaminergic markers are usually associated with hyperactivity and impulsivity, while adults with ADHD have disrupted neuroendocrine reactions, which have been associated with issues of emotional regulation and insomnia. The age-related differences should be considered when carrying out diagnostic processes to enhance precision among children and adults [\nAdditionally, studies with biochemical markers indicate that adults ADHD indicate a lower correlation between serum biomarkers such as homocysteine and vitamin B12 concentration compared to children. The variations highlight the possibilities of age-related diagnostic biomarkers [\nFurthermore, gender differences in ADHD symptomatology have come under closer examination over the last several decades. ADHD is widely thought to occur in more males than females; however, research suggests that females may occur in an alternative symptom profile, generally relating to inattention rather than hyperactivity. This results in the underdiagnosis of females because they do not manifest the disruptive behaviors that are the signature of ADHD in their male counterparts [\nComorbidities in ADHD are other factors that are important in understanding the ADHD presentation, which affects the patient’s severity level. The most common comorbidities include anxiety disorders, depression, and learning disabilities that can make the ADHD patient’s academic and social interactions much more difficult [\nBeyond personal attributes, social support perspectives also help determine the impact ADHD has on the individual’s life in terms of overall well-being. Support from parents, in particular, is one of the strongest protective factors mitigating the symptoms of ADHD. Children with ADHD who receive constant caring support and a well-organized framework from their families academically and socially outperform their peers who receive no such support [\nADHD diagnosis and treatment are areas experiencing particularly rapid change, driven by neuroimaging, biomarkers, cognitive profiling, and personalized medicine technologies. The use of objective, non-invasive methods in measuring ADHD, as well as its increasing multidimensionality, offers hope for managing ADHD optimally and improving its lifelong management. While the work is still in progress, the hope is that greater refinement of strategies designed to treat ADHD will result in more individualized and precise approaches, reducing the number of attempts needed to find the optimal treatment.\nUndiagnosed or untreated, ADHD can lead to long-term academic, social, and emotional consequences. However, early intervention can avoid such outcomes by making therapeutic intervention available in a timely manner. The latest research places a strong accent on the role of early intervention programs that focus on behavioral therapy, cognitive skills development, and education, which in turn have been shown to reduce the severity of symptoms as well as improve long-term academic and social functioning [\nA major breakthrough will be personalized therapy for ADHD, apart from a “one-size-fits-all” regimen. As ADHD is a highly heterogeneous disorder, patients will respond differently to various therapeutic interventions based on their individual genetic, neurobiological, and environmental profiles. Greater application of neuroimaging and electrophysiological biomarkers can identify the patients who would most likely benefit from specific types of treatments.\nFor example, the EEG theta/beta ratio biomarker indicates treatment response to neurofeedback, and other genetic biomarkers predict response to stimulant medications. These treatment strategies might enhance the therapeutic response, reduce adverse effects, and improve overall therapeutic outcomes [\nWith the progressive conception of ADHD, it is clear that interventions will depend heavily on cognitive profiling as well as biomarker information. Neuroimaging and genetic profiling make it increasingly clear for ADHD to delineate individual differences that manifest within the expression of the condition. For example, patients with ADHD also exhibit attention and executive function problems; some have been shown to possess structural and functional brain lesions such as decreased grey matter within the prefrontal cortex [\nAdditionally, cognitive profiling—measuring strengths and weaknesses within various domains of an individual’s profile—can inform tailored treatment strategies for the specific needs of each patient. Cognitive assessments such as CANTAB and Cogmed Working Memory Training Diagnostics can pinpoint cognitive impairment, and interventions aimed at constructing executive functions—escalating attention, working memory, and inhibition—can be developed [\nIn relation to prevention, research is being developed that supports the role of lifestyle changes, including diet, exercise, and sleep, in managing ADHD symptoms. For instance, the DASH diet, along with magnesium and vitamin D, has found some utility in improving ADHD-related behavioral outcomes in children [\nFurthermore, neurostimulation techniques, such as transcranial magnetic stimulation (TMS) and neurofeedback, are new emerging treatments for ADHD symptoms through modulating specific neural circuits involved in attention and impulse control [\nFuture research on ADHD must focus on several key areas. First, developmental follow-up studies of the longitudinal course of ADHD symptoms throughout childhood and into adulthood are needed to map out the natural history of the disease and identify its earliest warning signs. These studies could be helpful in identifying the most prognostic long-term outcome biomarkers and the most effective interventions throughout the life course.\nMultimodal approaches combining genetic, neuroimaging, and electrophysiological biomarkers with cognitive profiling must be adopted to customize treatment approaches. These approaches will determine the very specific biological and cognitive variables accounting for a particular person’s ADHD in order for more targeted treatments to be formed.\nFurthermore, since the science regarding the diagnosis and treatment of ADHD keeps changing, even greater collaboration and teamwork by clinicians, researchers, and policymakers are required to translate new knowledge into clinical practice efficiently. Biomarker research and treatment protocols individually tailored will be of immense value in promoting the quality of treatment of adult ADHD to an even greater extent.\nThis review points to the important breakthroughs in comprehending the neurobiological models of ADHD and the encouraging potential of biomarkers and neuropsychological assessment to enhance diagnosis and treatment. While conventional methods of diagnosis are still important, increasing studies of biomarkers herald a transition towards more objective, accurate, and individualized diagnoses. Early intervention with biomarkers and neuropsychological profiling is critical to minimize the long-term effects of ADHD on academic, emotional, and social outcomes.\nThe incorporation of biomarkers into clinical practice can facilitate personalized treatment, decreasing the trial-and-error process in ADHD care.\nNevertheless, difficulties lie ahead, especially the disparity between research output and its prospective practical implementation. Future research will prioritize longitudinal studies and multimodal integration of biomarkers to better resolve ADHD diagnosis and treatment tactics.\nSumming it up, the use of biomarkers and personalized medicine can potentially transform the treatment of ADHD, enhancing the quality of life for patients tremendously by providing more specific and efficient interventions.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "38733333", "pmcid": "12307757", "title": "Prior contextual information and autistic traits influence eye gaze behaviour and emotional valence ratings for facial expressions", "publication_year": "N/A", "abstract": "This study examined the influence of social top-down information on eye-gaze behaviour and valence perception in individuals with higher and lower autistic traits. Data from 57 participants (37 identified as female, 18 as male, 2 as non-binary;", "full_text": "Understanding how we observe and discriminate valence from facial expressions, particularly in the context of perceptual or contextual ambiguity, provides valuable insights into social cognitive processes. Ambiguity may arise from minimal facial expressions displayed by our interaction partner or from our limited knowledge of the events or experiences that give rise to these expressions (i.e., a lack of contextual information)\nEmotion perception, like all forms of perception, relies on the dynamic integration of bottom-up sensory input and top-down contextual influences\nAccording to the predictive coding perspectives of autism, behaviours typically associated with autism, such as insistence on sameness, social challenges, sensory hypersensitivities, and difficulties with movement and theory of mind, may arise from an imbalance between sensory input and prior knowledge (see\nAlongside research involving autistic individuals, an increasing number of studies have explored whether predictive processing differences are present in non-autistic individuals with high levels of autistic traits, often considered to constitute the\nTo our knowledge, this is the first study to examine the effect of prior contextual information and autistic traits on emotional valence perception within a predictive coding framework. The aim was to improve our understanding of how individuals with higher and lower autistic traits use prior contextual information when observing faces to evaluate their emotional valence. To split participants into higher and lower autistic traits groups, we used the Autism-Spectrum Quotient (AQ), a validated self-report tool used to measure autistic traits in both autistic and non-autistic individuals of typical intelligence\nWe would like to note that the aim of this study is not to label deviations in the higher autistic traits group as deficits, as is often the focus in traditional autism research. Rather than framing higher AQ scores in terms of neurodevelopmental pathways that deviate from a perceived norm, this study seeks to explore potential differences in social cognitive processes between individuals with higher and lower autistic traits. By doing so, it adopts a perspective that values diverse ways of processing information, consistent with the broader view of neurodiversity (see\nAs shown in Fig.\n\nLog-Transformed fixation duration differences for each valence category within each context. Higher fixation duration differences indicate longer fixation on the eyes relative to the mouth. Values below zero indicate longer looking at mouth than eyes. The horizontal lines within each box represent the median fixation duration difference. The dots represent individual participants identified as outliers.\nIn contrast to the prediction, for most of the valence categories, the effect of context on fixation duration differences in the higher AQ and lower AQ groups were similar. A significant interaction was observed for the\n\nLog-transformed fixation duration differences across valence categories, contexts and AQ groups. Higher fixation duration differences indicate longer fixation on the eyes relative to the mouth. Values below zero indicate longer looking at the mouth than the eyes. The only significant difference between the two AQ groups was for the\nThe main effect of context on fixation duration differences was significant for the majority of the valence categories. For the negatively-valenced faces, there was a higher fixation duration difference in the no-context than the negative-context for\nFor neutral faces, in both AQ groups, there was longer looking at the eyes relative to the mouth when no contextual information was provided (no-context) compared to when it was either positive- or negative-contexts, with a higher fixation duration difference in the negative-context than the positive-context (see Fig.\n\nLog-transformed fixation duration differences for neutral faces across contexts for each AQ group.\nAs shown in Fig.\n\nValence ratings by valence category, context and AQ group. The y-axis represents mean valence ratings, with values ranging from zero to six, where 0 indicates\nAs expected, for most of the valence categories, valence ratings in the lower AQ group differed for faces of the same valence category presented in different contexts, whereas this difference was not observed in the higher AQ group. For the lower AQ group, there was a significant or marginally significant effect of context in most of the valence categories: For the negatively-valenced faces, rating was significantly lower in the negative-context than the no-context for\nIn contrast to the effect of context on valence ratings observed in the lower AQ group, the higher AQ group did not show any significant differences:\nFor neutral faces, rating was significantly lower in the negative-context than no-context in the lower AQ group (\nAs an exploratory analysis, we included the five participants who had been excluded from the original 17 vs. 26 AQ split in the lower AQ group (AQ scores 18, 19, 22, 24, and 25). The overall pattern of results remained largely unchanged after their inclusion. In the lower AQ group, two contrasts that were previously non-significant became significant: for neutral faces, rating was significantly lower in the positive-context than no-context (\nAs examples of distribution patterns, participants’ mean valence ratings for slightly negative, neutral, and slightly positive faces across the relevant contexts are shown in (Fig.\n\nValence ratings by context and AQ group for slightly negative, neutral and slightly positive valence categories. The y-axis represents valence ratings for (\nIn this study, we explored the differences between individuals with higher and lower autistic traits in how they apply contextual priors when processing immediate sensory information during evaluation of emotional valence from facial expressions. Their lower-order, more automatic eye-gaze behaviour was assessed through fixation duration on the eyes and mouth, while their higher-order, cognitive-evaluative behaviour was inferred from their valence ratings. To investigate the influence of top-down information, participants completed a valence rating task in three distinct contexts: first, simply observing (no-context), then observing while imagining a dream-job offer scenario (positive-context), and lastly observing while imagining a dream-job rejection scenario (negative-context), with the order of the latter two contexts randomised. Findings showed that participants consistently fixated more on the eyes than the mouth across conditions, with the largest differences observed in the no-context condition compared to the positive- or negative-context conditions. Individuals with higher autistic traits exhibited similar or greater eye fixation durations compared to those with lower autistic traits, although with greater variability. Furthermore, the effect of context on valence ratings was observed in the lower autistic traits group but not in the higher autistic traits group. By recognising the diversity within these groups and the potential for shared characteristics, we aim to offer explanations to deepen our understanding of how individuals with different levels of autistic traits interpret and navigate social and emotional cues.\nBoth the higher and lower autistic traits groups showed longer fixation on the eyes than the mouth across valence categories and contexts, consistent with research showing that the eyes are a primary source of emotional information, especially for decoding negative emotions such as fear and anger\nDespite the general trend of reduced eye contact reported in autism literature\nAlthough longer fixation on the eyes than the mouth was a consistent pattern across both groups, valence categories and contexts, the largest fixation duration differences emerged in the no-context condition. This suggests that prior contextual information plays a role in shaping fixation behaviour, highlighting a dynamic interplay between sensory input and prior expectations in guiding attention. The absence of contextual information in the no-context condition likely increased ambiguity around emotion recognition. Greater informational ambiguity would have more strongly engaged the neural and cognitive mechanisms involved in emotion understanding, thereby facilitating interpretation. In particular, sensorimotor cortical activity, thought to reflect the brain’s internal mirroring of observed facial expressions to infer emotional meaning, has been shown to increase when categorising ambiguous neutral faces compared to easily recognisable happy or sad expressions\nThe influence of prior contextual information on fixation behaviour aligns with evidence that visual attention is often guided by visual expectation\nImportantly, the finding that both groups showed the greatest attention to the eyes in the no-context condition suggests that individuals with higher autistic traits, like those with lower traits, were influenced by contextual priors. One interpretation is that the explicit nature of the priors provided in the positive- and negative-context conditions reduced ambiguity and made it easier for both groups to integrate contextual cues in a way that influenced their eye gaze behaviour. Supporting this view, previous research has shown that individuals with varying levels of autistic traits tend to exhibit more similar decision-making behaviours when prior information is presented explicitly. This has been observed across various tasks involving visual cues predicting motion direction\nIn contrast to gaze behaviour, valence ratings differed between the autistic groups across contexts. Consistent with the hypothesis, only the lower autistic traits group exhibited context-sensitive valence ratings, perceiving both negatively- and positively-valenced faces as more negative when contextual information was provided than when it was absent. This pattern may reflect how contextual cues shaped emotional interpretation. In the negative-context (job rejection), alignment between the scenario and the facial expressions likely amplified perceived negativity, while in the positive-context (dream job offer), a mismatch between facial expressions and heightened expectations of happiness may have reduced perceived positivity, leading to lower ratings compared to the no-context condition. In contrast, the higher autistic traits group showed no significant differences in valence ratings across contexts. This finding aligns with predictive processing accounts of autism\nAnother noteworthy finding from our study was the high AQ scores in our sample, with 38% of participants scoring at or above 26. This may reflect broader societal shifts that have altered common patterns of socialising and increased acceptance of a more diverse range of behaviours, or it may be influenced by a biased population (e.g., psychology students). The causes of this trend were beyond the scope of the present study and warrant further investigation. The relatively small sample size, drawn primarily from a university student population, also limited the generalisability of the findings to broader populations. Another limitation was that individuals likely varied in their levels of empathy and emotional engagement with the imagined scenarios, which were not assessed in the current study. Previous research has shown that higher autistic traits are associated with higher alexithymic traits, which can impair emotional awareness and the ability to identify with emotional situations\nIt is essential to recognise that while many autistic traits may represent natural variations in behaviour that do not necessitate intervention, there are instances where these traits can lead to challenges in specific areas and require targeted support. Acknowledging and addressing the experiences of those who face significant difficulties due to their autism, or undiagnosed but impairing autistic traits, is crucial to fostering a more inclusive and understanding approach in autism research, clinical practice, and the wider society.\n62 participants were recruited using the University of Adelaide research participant pool and flyers posted around the campus. Eligible students received course credit for completing the study and other volunteers did not receive any compensation. Inclusion criteria included not having a previous mental illness diagnosis or history of neurological impairment, and being fluent in English. All participants except one were between the ages of 18 and 27. Data from the older participant were retained in the overall sample (\nAutistic trait levels were assessed using the 50-item autism spectrum quotient (AQ;\nThe AQ is based on the idea that autism spectrum conditions exist at the extreme end of a continuum of socio-communicative traits within the general population. It has been widely used in both clinical and non-clinical groups, demonstrating strong psychometric properties, including reliability\nFace stimuli were taken from the Amsterdam Dynamic Facial Expression Set - Bath Intensity Variations (ADFES-BIV;\nThe valence rating task began with a practice block containing four example trials to ensure task familiarity. The experimental task consisted of three blocks, each accompanied by different task instructions, with short breaks permitted between blocks. In Block A, participants received neutral contextual instructions: “You will see a series of faces showing positive or negative emotions. Look at each face carefully and rate the intensity of positive or negative emotion as accurately as possible”. Block A included 94 trials, consisting of 12 faces from each emotional valence category (i.e., very negative, negative, slightly negative, slightly positive, positive, very positive) and 22 neutral faces, thus covering the full valence scale. In Block B, participants were presented with negative contextual instructions: “Imagine that the person you will see on screen just got turned down from their dream job. Look at the faces carefully and rate the intensity of negative emotion as accurately as possible.” Block B consisted of 58 trials, presenting only negatively-valenced faces (very negative, negative, slightly negative) and neutral faces (12 from each negative valence category and 22 neutral). In Block C, participants were given positive contextual instructions: “Imagine that the person you will see on screen just received an offer for their dream job. Look at the faces carefully and rate the intensity of positive emotion as accurately as possible.” Block C also included 58 trials, presenting only positively-valenced faces (i.e., very positive, positive, slightly positive) and neutral faces (12 from each positive valence category and 22 neutral). Participants always completed Block A first, followed by Blocks B and C in randomised order. While the faces were drawn from the same stimulus set, only the emotional valence categories relevant to each block, along with neutral faces, were presented.\nEach trial started with a 2-second fixation cross, followed by the image of a face (image size 7338 × 4973; see Fig.\n\nSchematic representation of the valence rating task procedure. Each trial started with a fixation cross displayed for 2 s, followed by the presentation of a face image which remained on screen until the participant clicked on a valence rating. The arrow indicates the sequence of events over time. Face images are not shown here due to copyright restrictions.\nTobii Pro Eye Tracker software version 1.232 with a sampling frequency of 1200 Hz was used to track participants’ eye movements and fixations to the AOIs. Facial AOIs were created for each face by utilising the AOI drawing tool within Tobii Pro Lab. The AOIs analysed in this study were the eye area and the mouth. All AOIs were created following the same parameters, as described in Supplementary File 1 Fig. S3.\nPotential participants who emailed the researchers to express interest in the study were provided with a copy of the participant information sheet, which detailed the study and outlined the inclusion criteria. Following this, a suitable time slot for data collection was arranged, and participants attended the laboratory at the University of Adelaide at their designated time. Upon arrival, participants were assigned participant numbers to ensure de-identification. Electronic informed consent was obtained using the online survey platform Qualtrics. Participants then completed short demographics (i.e., gender and age) and the AQ\nData preparation and analyses were conducted using RStudio version 4.4.1\nAny remaining missing ratings were excluded as necessary during the analyses. Valence ratings from\nFor the fixation analysis, a fixation duration difference score was calculated for each trial as the time spent looking at the eyes minus the time spent looking at the mouth. This approach quantifies relative gaze preference between socially salient features while also minimising the need for multiple statistical comparisons and accounting for individual differences in overall fixation duration. Positive values indicated longer fixation on the eyes compared to the mouth, while negative values reflected longer fixation on the mouth than the eyes. To address skewness and reduce the influence of outliers in the data, a signed log transformation was applied. The resulting log-transformed mean fixation duration difference scores were then used as the outcome variable in the analyses.\nThe analyses investigated the influence of context (no-context, negative-context, positive-context) and AQ group (higher, lower) on valence ratings (0 = very negative to 6 = very positive) and fixation duration difference scores for different intensities (neutral, low, medium, high) of joyful and angry facial expressions (i.e., valence categories). In order to capture the effects of context and AQ group in each valence category, we fit separate models when conducting valence rating and fixation duration analyses. This way, we were able to understand the nuanced effects that could vary by specific emotions (positive, negative, neutral) and intensities (from very negative to very positive). In the valence rating analysis, for each valence category, a cumulative link mixed model (CLMM) was fitted to assess the interaction between context and AQ group on valence ratings. The Laplace approximation was used to estimate the parameters. CLMM was employed as it appropriately accounts for the ordinal nature of the valence rating variable and is robust to violations of parametric assumptions\nAll models included context, AQ group, and their interaction as fixed effects, with a random intercept for participants to account for repeated measures. Significant or close-to-significant interaction effects were followed up by Bonferroni-corrected post-hoc contrasts to evaluate any differences between the AQ groups. We conducted analyses both including and excluding the outlier participants to gain better insights into any influence of the outliers on the results. This approach leveraged the full dataset for comparison. In each analysis, outlier participants were identified based on their mean valence ratings or mean log-transformed fixation duration difference scores within each combination of context and AQ group (i.e., > 1.5 times of the interquartile range). Results are reported for both cases, using “incl.” for results including outliers and “excl.” for those excluding outliers (e.g.,\nBelow is the link to the electronic supplementary material.\n\nSupplementary Material 1\n\nSupplementary Material 2\n\nSupplementary Material 3", "content_for_embedding": "Understanding how we observe and discriminate valence from facial expressions, particularly in the context of perceptual or contextual ambiguity, provides valuable insights into social cognitive processes. Ambiguity may arise from minimal facial expressions displayed by our interaction partner or from our limited knowledge of the events or experiences that give rise to these expressions (i.e., a lack of contextual information)\nEmotion perception, like all forms of perception, relies on the dynamic integration of bottom-up sensory input and top-down contextual influences\nAccording to the predictive coding perspectives of autism, behaviours typically associated with autism, such as insistence on sameness, social challenges, sensory hypersensitivities, and difficulties with movement and theory of mind, may arise from an imbalance between sensory input and prior knowledge (see\nAlongside research involving autistic individuals, an increasing number of studies have explored whether predictive processing differences are present in non-autistic individuals with high levels of autistic traits, often considered to constitute the\nTo our knowledge, this is the first study to examine the effect of prior contextual information and autistic traits on emotional valence perception within a predictive coding framework. The aim was to improve our understanding of how individuals with higher and lower autistic traits use prior contextual information when observing faces to evaluate their emotional valence. To split participants into higher and lower autistic traits groups, we used the Autism-Spectrum Quotient (AQ), a validated self-report tool used to measure autistic traits in both autistic and non-autistic individuals of typical intelligence\nWe would like to note that the aim of this study is not to label deviations in the higher autistic traits group as deficits, as is often the focus in traditional autism research. Rather than framing higher AQ scores in terms of neurodevelopmental pathways that deviate from a perceived norm, this study seeks to explore potential differences in social cognitive processes between individuals with higher and lower autistic traits. By doing so, it adopts a perspective that values diverse ways of processing information, consistent with the broader view of neurodiversity (see\nAs shown in Fig.\n\nLog-Transformed fixation duration differences for each valence category within each context. Higher fixation duration differences indicate longer fixation on the eyes relative to the mouth. Values below zero indicate longer looking at mouth than eyes. The horizontal lines within each box represent the median fixation duration difference. The dots represent individual participants identified as outliers.\nIn contrast to the prediction, for most of the valence categories, the effect of context on fixation duration differences in the higher AQ and lower AQ groups were similar. A significant interaction was observed for the\n\nLog-transformed fixation duration differences across valence categories, contexts and AQ groups. Higher fixation duration differences indicate longer fixation on the eyes relative to the mouth. Values below zero indicate longer looking at the mouth than the eyes. The only significant difference between the two AQ groups was for the\nThe main effect of context on fixation duration differences was significant for the majority of the valence categories. For the negatively-valenced faces, there was a higher fixation duration difference in the no-context than the negative-context for\nFor neutral faces, in both AQ groups, there was longer looking at the eyes relative to the mouth when no contextual information was provided (no-context) compared to when it was either positive- or negative-contexts, with a higher fixation duration difference in the negative-context than the positive-context (see Fig.\n\nLog-transformed fixation duration differences for neutral faces across contexts for each AQ group.\nAs shown in Fig.\n\nValence ratings by valence category, context and AQ group. The y-axis represents mean valence ratings, with values ranging from zero to six, where 0 indicates\nAs expected, for most of the valence categories, valence ratings in the lower AQ group differed for faces of the same valence category presented in different contexts, whereas this difference was not observed in the higher AQ group. For the lower AQ group, there was a significant or marginally significant effect of context in most of the valence categories: For the negatively-valenced faces, rating was significantly lower in the negative-context than the no-context for\nIn contrast to the effect of context on valence ratings observed in the lower AQ group, the higher AQ group did not show any significant differences:\nFor neutral faces, rating was significantly lower in the negative-context than no-context in the lower AQ group (\nAs an exploratory analysis, we included the five participants who had been excluded from the original 17 vs. 26 AQ split in the lower AQ group (AQ scores 18, 19, 22, 24, and 25). The overall pattern of results remained largely unchanged after their inclusion. In the lower AQ group, two contrasts that were previously non-significant became significant: for neutral faces, rating was significantly lower in the positive-context than no-context (\nAs examples of distribution patterns, participants’ mean valence ratings for slightly negative, neutral, and slightly positive faces across the relevant contexts are shown in (Fig.\n\nValence ratings by context and AQ group for slightly negative, neutral and slightly positive valence categories. The y-axis represents valence ratings for (\nIn this study, we explored the differences between individuals with higher and lower autistic traits in how they apply contextual priors when processing immediate sensory information during evaluation of emotional valence from facial expressions. Their lower-order, more automatic eye-gaze behaviour was assessed through fixation duration on the eyes and mouth, while their higher-order, cognitive-evaluative behaviour was inferred from their valence ratings. To investigate the influence of top-down information, participants completed a valence rating task in three distinct contexts: first, simply observing (no-context), then observing while imagining a dream-job offer scenario (positive-context), and lastly observing while imagining a dream-job rejection scenario (negative-context), with the order of the latter two contexts randomised. Findings showed that participants consistently fixated more on the eyes than the mouth across conditions, with the largest differences observed in the no-context condition compared to the positive- or negative-context conditions. Individuals with higher autistic traits exhibited similar or greater eye fixation durations compared to those with lower autistic traits, although with greater variability. Furthermore, the effect of context on valence ratings was observed in the lower autistic traits group but not in the higher autistic traits group. By recognising the diversity within these groups and the potential for shared characteristics, we aim to offer explanations to deepen our understanding of how individuals with different levels of autistic traits interpret and navigate social and emotional cues.\nBoth the higher and lower autistic traits groups showed longer fixation on the eyes than the mouth across valence categories and contexts, consistent with research showing that the eyes are a primary source of emotional information, especially for decoding negative emotions such as fear and anger\nDespite the general trend of reduced eye contact reported in autism literature\nAlthough longer fixation on the eyes than the mouth was a consistent pattern across both groups, valence categories and contexts, the largest fixation duration differences emerged in the no-context condition. This suggests that prior contextual information plays a role in shaping fixation behaviour, highlighting a dynamic interplay between sensory input and prior expectations in guiding attention. The absence of contextual information in the no-context condition likely increased ambiguity around emotion recognition. Greater informational ambiguity would have more strongly engaged the neural and cognitive mechanisms involved in emotion understanding, thereby facilitating interpretation. In particular, sensorimotor cortical activity, thought to reflect the brain’s internal mirroring of observed facial expressions to infer emotional meaning, has been shown to increase when categorising ambiguous neutral faces compared to easily recognisable happy or sad expressions\nThe influence of prior contextual information on fixation behaviour aligns with evidence that visual attention is often guided by visual expectation\nImportantly, the finding that both groups showed the greatest attention to the eyes in the no-context condition suggests that individuals with higher autistic traits, like those with lower traits, were influenced by contextual priors. One interpretation is that the explicit nature of the priors provided in the positive- and negative-context conditions reduced ambiguity and made it easier for both groups to integrate contextual cues in a way that influenced their eye gaze behaviour. Supporting this view, previous research has shown that individuals with varying levels of autistic traits tend to exhibit more similar decision-making behaviours when prior information is presented explicitly. This has been observed across various tasks involving visual cues predicting motion direction\nIn contrast to gaze behaviour, valence ratings differed between the autistic groups across contexts. Consistent with the hypothesis, only the lower autistic traits group exhibited context-sensitive valence ratings, perceiving both negatively- and positively-valenced faces as more negative when contextual information was provided than when it was absent. This pattern may reflect how contextual cues shaped emotional interpretation. In the negative-context (job rejection), alignment between the scenario and the facial expressions likely amplified perceived negativity, while in the positive-context (dream job offer), a mismatch between facial expressions and heightened expectations of happiness may have reduced perceived positivity, leading to lower ratings compared to the no-context condition. In contrast, the higher autistic traits group showed no significant differences in valence ratings across contexts. This finding aligns with predictive processing accounts of autism\nAnother noteworthy finding from our study was the high AQ scores in our sample, with 38% of participants scoring at or above 26. This may reflect broader societal shifts that have altered common patterns of socialising and increased acceptance of a more diverse range of behaviours, or it may be influenced by a biased population (e.g., psychology students). The causes of this trend were beyond the scope of the present study and warrant further investigation. The relatively small sample size, drawn primarily from a university student population, also limited the generalisability of the findings to broader populations. Another limitation was that individuals likely varied in their levels of empathy and emotional engagement with the imagined scenarios, which were not assessed in the current study. Previous research has shown that higher autistic traits are associated with higher alexithymic traits, which can impair emotional awareness and the ability to identify with emotional situations\nIt is essential to recognise that while many autistic traits may represent natural variations in behaviour that do not necessitate intervention, there are instances where these traits can lead to challenges in specific areas and require targeted support. Acknowledging and addressing the experiences of those who face significant difficulties due to their autism, or undiagnosed but impairing autistic traits, is crucial to fostering a more inclusive and understanding approach in autism research, clinical practice, and the wider society.\n62 participants were recruited using the University of Adelaide research participant pool and flyers posted around the campus. Eligible students received course credit for completing the study and other volunteers did not receive any compensation. Inclusion criteria included not having a previous mental illness diagnosis or history of neurological impairment, and being fluent in English. All participants except one were between the ages of 18 and 27. Data from the older participant were retained in the overall sample (\nAutistic trait levels were assessed using the 50-item autism spectrum quotient (AQ;\nThe AQ is based on the idea that autism spectrum conditions exist at the extreme end of a continuum of socio-communicative traits within the general population. It has been widely used in both clinical and non-clinical groups, demonstrating strong psychometric properties, including reliability\nFace stimuli were taken from the Amsterdam Dynamic Facial Expression Set - Bath Intensity Variations (ADFES-BIV;\nThe valence rating task began with a practice block containing four example trials to ensure task familiarity. The experimental task consisted of three blocks, each accompanied by different task instructions, with short breaks permitted between blocks. In Block A, participants received neutral contextual instructions: “You will see a series of faces showing positive or negative emotions. Look at each face carefully and rate the intensity of positive or negative emotion as accurately as possible”. Block A included 94 trials, consisting of 12 faces from each emotional valence category (i.e., very negative, negative, slightly negative, slightly positive, positive, very positive) and 22 neutral faces, thus covering the full valence scale. In Block B, participants were presented with negative contextual instructions: “Imagine that the person you will see on screen just got turned down from their dream job. Look at the faces carefully and rate the intensity of negative emotion as accurately as possible.” Block B consisted of 58 trials, presenting only negatively-valenced faces (very negative, negative, slightly negative) and neutral faces (12 from each negative valence category and 22 neutral). In Block C, participants were given positive contextual instructions: “Imagine that the person you will see on screen just received an offer for their dream job. Look at the faces carefully and rate the intensity of positive emotion as accurately as possible.” Block C also included 58 trials, presenting only positively-valenced faces (i.e., very positive, positive, slightly positive) and neutral faces (12 from each positive valence category and 22 neutral). Participants always completed Block A first, followed by Blocks B and C in randomised order. While the faces were drawn from the same stimulus set, only the emotional valence categories relevant to each block, along with neutral faces, were presented.\nEach trial started with a 2-second fixation cross, followed by the image of a face (image size 7338 × 4973; see Fig.\n\nSchematic representation of the valence rating task procedure. Each trial started with a fixation cross displayed for 2 s, followed by the presentation of a face image which remained on screen until the participant clicked on a valence rating. The arrow indicates the sequence of events over time. Face images are not shown here due to copyright restrictions.\nTobii Pro Eye Tracker software version 1.232 with a sampling frequency of 1200 Hz was used to track participants’ eye movements and fixations to the AOIs. Facial AOIs were created for each face by utilising the AOI drawing tool within Tobii Pro Lab. The AOIs analysed in this study were the eye area and the mouth. All AOIs were created following the same parameters, as described in Supplementary File 1 Fig. S3.\nPotential participants who emailed the researchers to express interest in the study were provided with a copy of the participant information sheet, which detailed the study and outlined the inclusion criteria. Following this, a suitable time slot for data collection was arranged, and participants attended the laboratory at the University of Adelaide at their designated time. Upon arrival, participants were assigned participant numbers to ensure de-identification. Electronic informed consent was obtained using the online survey platform Qualtrics. Participants then completed short demographics (i.e., gender and age) and the AQ\nData preparation and analyses were conducted using RStudio version 4.4.1\nAny remaining missing ratings were excluded as necessary during the analyses. Valence ratings from\nFor the fixation analysis, a fixation duration difference score was calculated for each trial as the time spent looking at the eyes minus the time spent looking at the mouth. This approach quantifies relative gaze preference between socially salient features while also minimising the need for multiple statistical comparisons and accounting for individual differences in overall fixation duration. Positive values indicated longer fixation on the eyes compared to the mouth, while negative values reflected longer fixation on the mouth than the eyes. To address skewness and reduce the influence of outliers in the data, a signed log transformation was applied. The resulting log-transformed mean fixation duration difference scores were then used as the outcome variable in the analyses.\nThe analyses investigated the influence of context (no-context, negative-context, positive-context) and AQ group (higher, lower) on valence ratings (0 = very negative to 6 = very positive) and fixation duration difference scores for different intensities (neutral, low, medium, high) of joyful and angry facial expressions (i.e., valence categories). In order to capture the effects of context and AQ group in each valence category, we fit separate models when conducting valence rating and fixation duration analyses. This way, we were able to understand the nuanced effects that could vary by specific emotions (positive, negative, neutral) and intensities (from very negative to very positive). In the valence rating analysis, for each valence category, a cumulative link mixed model (CLMM) was fitted to assess the interaction between context and AQ group on valence ratings. The Laplace approximation was used to estimate the parameters. CLMM was employed as it appropriately accounts for the ordinal nature of the valence rating variable and is robust to violations of parametric assumptions\nAll models included context, AQ group, and their interaction as fixed effects, with a random intercept for participants to account for repeated measures. Significant or close-to-significant interaction effects were followed up by Bonferroni-corrected post-hoc contrasts to evaluate any differences between the AQ groups. We conducted analyses both including and excluding the outlier participants to gain better insights into any influence of the outliers on the results. This approach leveraged the full dataset for comparison. In each analysis, outlier participants were identified based on their mean valence ratings or mean log-transformed fixation duration difference scores within each combination of context and AQ group (i.e., > 1.5 times of the interquartile range). Results are reported for both cases, using “incl.” for results including outliers and “excl.” for those excluding outliers (e.g.,\nBelow is the link to the electronic supplementary material.\n\nSupplementary Material 1\n\nSupplementary Material 2\n\nSupplementary Material 3", "topic": "Neurodevelopmental_disorder"}
{"pmid": "38682611", "pmcid": "12303959", "title": "Executive function and neural oscillations in adults with attention-deficit/hyperactivity disorder: a systematic review", "publication_year": "N/A", "abstract": "Attention-deficit/hyperactivity disorder (ADHD) is a childhood-onset neurobiological disorder that often persists into adulthood. Adult ADHD is an important public health concern due to its great social damage and challenges in clinical recognition, resulting in a significant disease burden. Nonetheless, the diagnosis of adult ADHD remains challenging due to the absence of specific symptoms and biological markers. The aims of this systematic review were as follows: (1) To discern whether there were any differences in resting-state electroencephalogram (EEG) and event related potential (ERP) between adult ADHD and healthy controls (HCs). (2) To ascertain whether ERP specific manifestations associated with executive function (EF) deficiencies. (3) To conduct an exploration into the mechanisms of specific electrophysiologic alterations. This review was conducted in PubMed-Medline and Web-of-Science from 1971 to August 15th, 2024 to summarize the EEG changes of adult ADHD. We focused on resting-state EEG to report spectral power across different frequency bands and ERPs under different experimental tasks, 68 studies were finally included. When studying the characteristics of resting-state EEG in adult ADHD patients, we observed that theta power exhibits a consistent upward trend. Congruous reduction Pe, P3, and N2 amplitudes during response inhibition tasks, with a further decrease in P3 and N2 amplitudes in sustained attention tasks. These EEG changes may stem from impairments in error detection, cognitive control, and attention allocation, meaning that core EFs are affected in adults with ADHD. Overall, consistent changes in resting-state EEG and ERPs could provide insight for the identification of ADHD in adults.", "full_text": "Attention-deficit/hyperactivity disorder (ADHD) is a prevalent childhood-onset neurobiological disorder, nearly 60% of patients diagnosed in childhood continue to exhibit symptoms in adulthood (\nThe clinical presentation of ADHD tends to evolve and diminish across the developmental course (\nAssessment of ADHD has been largely relayed on subjective reports from patients and clinical observations. Whether EEG could be utilized in clinical practice as a diagnostic aid to assist diagnosis or not, it would provide a potentially non-invasive and economical method with which to objectify the assessment process. There are a considerable number of studies for the use of electroencephalogram (EEG) in adult ADHD. In 2014 one published review (\nBased on the background above, this systematic review focused on adult ADHD, innovatively categorized ERP studies according to the EFs domains, which adding conceptual clarity and enhanced clinical relevance. We included both resting-state EEG and event related potential (ERP) studies, providing a broad and integrated perspective on electrophysiological correlates of EF deficits. Objectives of this systematic review are as followed: (1) To discern whether there were any differences in resting state EEG and ERP between adult ADHD and healthy population. (2) To ascertain whether ERP specific manifestations associated with EF deficiencies. (3) To conduct an initial exploration into the mechanisms of specific electrophysiologic alterations.\nWe conducted a comprehensive search of English-language literature from 1971 to August 15th, 2024, in publicly available datasets PubMed and Web of Science, there was no limitation on publication date in search strategy. The current review was performed in compliance with the Preferred Reported Items for Systematic Reviews and Meta Analyses (PRISMA) 2021 guidelines (\nThe objectives and the inclusion criteria of this study were structured based on the elements of the PICOS model (Population of interest, Interventions, Comparators, Outcomes, and Study design), The specific items of inclusion and exclusion criteria have been listed in\nInclusion and exclusion criteria of studies.\nData extractions were conducted in duplicate by two independent reviewers, and discrepancies were resolved through discussion and consultation with a third reviewer. We roughly classify ERPs into five categories according to EFs, which are: Response Inhibition, Working Memory, Self-regulation of affects, Sustained Attention and others. From each included article was extracted and entered into tables, the extracted data included the following information: (1) authors and year of publication, (2) demographic characteristics (sample size, sex, age), (3) recording condition (eyes closed or eyes open), measures of frequency bands and range, spectral power type utilized (for resting state EEG), (4) Experimental task (for ERPs), (5) main findings. The selected articles and their data have been shown in the data extraction (\nMain finding of the resting-state EEG studies included in the review.\n↑, Frequency band power of ADHD higher than HC; ↓, Frequency band power of ADHD lower than HC; NS, Not significant change; NA, Not assessed. Absolute, absolute power of frequency band; Relative, relative power of frequency band; Time-1, Resting state before a 1.5-h cognitive task; Time-2, Resting state after a 1.5-h cognitive task.\nEvent-related potential characterization of response inhibition.\nPe, error positivity; ERN, error-related negativity; CNV, contingent negative variation.\nEvent-related potential characterization of sustained attention.\nCPT, Continuous Performance Task; TOVA, Test of Variables of Attention; SAT: Sustained attention task.\nEvent-related potential characterization of working memory.\nWM: working memory; CDA: Contralateral Delay Activity.\nEvent-related potential characterization of Self- regulation of affect.\nLPP, Late positive potential.\nEvent-related potential characterization of other Executive Function.\nCRT, Choice Reaction Time; RON/late negative: reorienting negativity; EPN, Early Posterior Negativity.\nCharacteristics of the resting-state EEG studies included in the review.\nF, Female; M, Male; HC, Health Control; EC, Eyes Close; EO, Eyes Open; ADHD-C, ADHD combined type; ADHD-I, ADHD inattentive type; ADHD-H, ADHD hyperactive/impulsive type; MPH, Methylphenidate.\nCharacteristics of the event-related studies included in the review.\nTwo raters independently assessed study quality using the modified Newcastle Ottawa Scale (NOS). The detailed criteria of modified NOS in\nA total of 443 articles were initially identified from Pub-Med and Web-of-Science databases using our search terms (\nPreferred reporting items for systematic reviews and meta-analyses (PRISMA) flow diagram of study selection.\nIn the resting state (\nThe number of different frequency bands among included studies (resting state).\nThe changes of different frequencies in included studies (resting state).\nThe least studied frequency band was gamma, with only 4 studies involved, among which 3 showed no significant difference between adult ADHD and HC, while one study suggested a decrease in gamma band power in right centroparietal region (\nThe measurement results of delta, alpha, and beta frequency bands are not consistent. For delta frequency band of adult ADHD, 4 included studies indicated increases delta power compared to HCs, whereas 2 articles indicated decreased delta activities (\nFor alpha band of adult ADHD, 4 studies showed an increase in band power, 3 studies suggested that adult ADHD has lower alpha power than HCs. 8 studies showed no significant difference in alpha power between ADHD and HC in adults. Kiiski and Bennett in 2020 drew conclusions that theta power of adult ADHD was increased in centro-parietal region (\nThe results of researches in beta waves are most heterogeneous among all frequencies, 7 articles showed an increase in band power, while 5 studies indicated decreased beta activities. Interestingly, one study found that beta power (13–16 Hz) increased in frontal region, and beta activities (16–20 Hz) became higher in parietal region in adult ADHD (\nIt is worth noticing that the classification of five main frequency bands have subtle differences, and some articles further divided them into sub-bands (Fig. 3 indicated the frequency bands ranges and changes of each study). Among them, 3 studies indicated sub-component of specific frequency band in patients with ADHD were consistent (\nNumber of included studies by experimental tasks. The chart summarizes the experimental tasks used during EEG recording in the included studies. (Tasks that are performed less than 3 times are not included).\nNumber of included studies by EFs.\nAs demonstrated in\nIn addition, working memory tasks were adopted in 4 studies. In these tasks, participants temporarily store and manipulate visual (e.g., shapes, colors) and spatial (e.g., locations, movements) information (The describe and related EFs of paradigms of ERPs see\nAs illustrated in\nNumber of included studies by EEG measurements. (measurements that are recorded less than 3 times are not included).\nThis systematic review sought to explore EEG alterations in ADHD adults across both resting and event-related states. We are the first to categorize the ERP results in ADHD patients based on their EF performance across diverse tasks. Our goal is to identify neuro-electrophysiological markers associated with specific dimensions of EF deficits and to explore potential neuropathological mechanisms behind these changes. The findings indicate that ADHD adults tend to demonstrate a consistent increase in theta band power compared to HCs when in a resting state. Additionally, during response inhibition tasks, the amplitudes of ERP components such as Pe, P3, and N2 were consistently lower in ADHD patients. During sustained attention tasks, there were more pronounced reductions of P3 and N2 amplitudes in ADHD patients than in controls.\nThe outcomes of literatures included in this review indicate that ADHD adults exhibit heightened theta band power relative to HCs. Although the specific mechanism remains unclear, two hypotheses—the maturational lag hypothesis and the cortical hypo-arousal hypothesis—may provide insight into this manifestation (\nSome scholars have interpreted the increased slow-wave activities like delta and theta bands as indicative of a cortical low arousal state (\nClinical studies have shown that impulsivity and inattention symptoms are still prevalent in adults with ADHD, although hyperactivity symptoms tend to diminish with age (\nIn the included articles, 10 out of 17 studies reported an increase in theta band power, while 7 researches indicated no significant change in this frequency band of adult ADHD patients when compared to HCs. We noticed that the participants’ age in unchanged studies are higher than elevated theta studies. For the ages of participants in the included literature, ADHD patients was greater than 18 years, and there was no upper limit. Herrmann and his colleges divided the adult ADHD into two subgroup, youngster subgroup and elderly subgroup, the mean age of youngster group is 25 and for elderly is 40. EEG outcomes changes in youngster group but not in elderly samples (\nIn addition, the classification of ADHD exerts certain influences on EEG results. This disease typically categorized into inattentive, predominantly hyperactive/impulsive, and combined subtypes based on clinical manifestations. In a systematic review published recently, researcher indicated that resting state and task-related modulation of EEG and ERPs are different among ADHD subtypes (\nFurthermore, gender, intelligence quotient (IQ), and recording context may further influence the results of studies. Several studies have found that male adults with ADHD are more likely to exhibit elevated theta band power (\nIn the included studies of this systematic review, adult ADHD patients consistently exhibited a decrease in the amplitude of Pe, P3, and N2 components compared to HCs during tasks related to inhibition function. This suggests that adult ADHD patients may have deficiencies in inhibitory control. Pe typically reaches peak at centro-parietal sites around 200–450 ms after the occurrence of the erroneous response, which is thought to be an ERP that associated with erroneous responses, signifying conscious recognition of error (\nThe P3 typically peaks at 300–600 ms after stimulation (\nN2 is a negative potential located in the frontal-central region, typically measured at 200–400 ms, and is thought to be associated with conflict monitoring, response inhibition and selection (\nAdult ADHD patients consistently show reductions in the amplitude of P3 and N2 components compared to HCs when completing sustained attention related tasks. The decreased amplitude of P3 component may reflect deficits in attention, stimulus processing, and evaluation abilities, or an inappropriate attentional resources allocation (\nHowever, current studies on the resting-state alpha and beta oscillations in adult ADHD have not reached a consistent conclusion. Some investigators have found that alpha power is higher in adult ADHD patients compared to HCs (\nIn addition, some studies have found that beta band power in adults with ADHD is higher than that in HCs. Researchers hypothesize that this increase in beta band activity may be associated with heightened cerebral cortex activity and impaired emotion control (\nBased on a comprehensive analysis of the included literatures, we observed that adult patients with ADHD demonstrated consistent EEG characteristics and changes in ERP components in the context of specific EFs compared to HCs. However, there were significant inconsistencies results across studies. These differences may be attributed to various confounding factors,\nFirstly, in term of general demographic characters, several studies have reported divergent EEG changes due to differences in gender, age, IQ. and subtype. Other than that, ADHD patients have high frequency of co-morbidities, this condition is unavoidable. Some studies have recorded combination with other psychiatric disorders (see\nSecondly, the subgroup of particular component of ERPs and its correlation with cognitive domains has been inconsistent across studies (see\nIn summary, resting-state EEG of adult ADHD patients is characterized by an increase in theta band power, which may be consistent with the cortical low arousal model. During functional tasks, especially the response inhibition tasks, ADHD patients tend to exhibit a significant reduction in the amplitude of ERP components such as Pe, N2, and P3. These reductions may reflect deficiencies in error detection and control functions. Additionally, reduction in P3 and N2 components during sustained attention tasks suggests that ADHD patients may have difficulties in effectively allocating attentional resources. However, these findings should be interpreted with caution due to the presence of numerous confounding factors in the studies. Of note, this systematic review did not perform a meta- analysis, primarily because of heterogeneous protocols, inconsistent reporting and clinical diversity. To advance the field, future research should standardize methodologies, comprehensive clinical documentation and control confounders. Through these efforts, the field can establish robust electrophysiological biomarkers for ADHD, ultimately improving diagnostic precision and effective interventions.", "content_for_embedding": "Attention-deficit/hyperactivity disorder (ADHD) is a prevalent childhood-onset neurobiological disorder, nearly 60% of patients diagnosed in childhood continue to exhibit symptoms in adulthood (\nThe clinical presentation of ADHD tends to evolve and diminish across the developmental course (\nAssessment of ADHD has been largely relayed on subjective reports from patients and clinical observations. Whether EEG could be utilized in clinical practice as a diagnostic aid to assist diagnosis or not, it would provide a potentially non-invasive and economical method with which to objectify the assessment process. There are a considerable number of studies for the use of electroencephalogram (EEG) in adult ADHD. In 2014 one published review (\nBased on the background above, this systematic review focused on adult ADHD, innovatively categorized ERP studies according to the EFs domains, which adding conceptual clarity and enhanced clinical relevance. We included both resting-state EEG and event related potential (ERP) studies, providing a broad and integrated perspective on electrophysiological correlates of EF deficits. Objectives of this systematic review are as followed: (1) To discern whether there were any differences in resting state EEG and ERP between adult ADHD and healthy population. (2) To ascertain whether ERP specific manifestations associated with EF deficiencies. (3) To conduct an initial exploration into the mechanisms of specific electrophysiologic alterations.\nWe conducted a comprehensive search of English-language literature from 1971 to August 15th, 2024, in publicly available datasets PubMed and Web of Science, there was no limitation on publication date in search strategy. The current review was performed in compliance with the Preferred Reported Items for Systematic Reviews and Meta Analyses (PRISMA) 2021 guidelines (\nThe objectives and the inclusion criteria of this study were structured based on the elements of the PICOS model (Population of interest, Interventions, Comparators, Outcomes, and Study design), The specific items of inclusion and exclusion criteria have been listed in\nInclusion and exclusion criteria of studies.\nData extractions were conducted in duplicate by two independent reviewers, and discrepancies were resolved through discussion and consultation with a third reviewer. We roughly classify ERPs into five categories according to EFs, which are: Response Inhibition, Working Memory, Self-regulation of affects, Sustained Attention and others. From each included article was extracted and entered into tables, the extracted data included the following information: (1) authors and year of publication, (2) demographic characteristics (sample size, sex, age), (3) recording condition (eyes closed or eyes open), measures of frequency bands and range, spectral power type utilized (for resting state EEG), (4) Experimental task (for ERPs), (5) main findings. The selected articles and their data have been shown in the data extraction (\nMain finding of the resting-state EEG studies included in the review.\n↑, Frequency band power of ADHD higher than HC; ↓, Frequency band power of ADHD lower than HC; NS, Not significant change; NA, Not assessed. Absolute, absolute power of frequency band; Relative, relative power of frequency band; Time-1, Resting state before a 1.5-h cognitive task; Time-2, Resting state after a 1.5-h cognitive task.\nEvent-related potential characterization of response inhibition.\nPe, error positivity; ERN, error-related negativity; CNV, contingent negative variation.\nEvent-related potential characterization of sustained attention.\nCPT, Continuous Performance Task; TOVA, Test of Variables of Attention; SAT: Sustained attention task.\nEvent-related potential characterization of working memory.\nWM: working memory; CDA: Contralateral Delay Activity.\nEvent-related potential characterization of Self- regulation of affect.\nLPP, Late positive potential.\nEvent-related potential characterization of other Executive Function.\nCRT, Choice Reaction Time; RON/late negative: reorienting negativity; EPN, Early Posterior Negativity.\nCharacteristics of the resting-state EEG studies included in the review.\nF, Female; M, Male; HC, Health Control; EC, Eyes Close; EO, Eyes Open; ADHD-C, ADHD combined type; ADHD-I, ADHD inattentive type; ADHD-H, ADHD hyperactive/impulsive type; MPH, Methylphenidate.\nCharacteristics of the event-related studies included in the review.\nTwo raters independently assessed study quality using the modified Newcastle Ottawa Scale (NOS). The detailed criteria of modified NOS in\nA total of 443 articles were initially identified from Pub-Med and Web-of-Science databases using our search terms (\nPreferred reporting items for systematic reviews and meta-analyses (PRISMA) flow diagram of study selection.\nIn the resting state (\nThe number of different frequency bands among included studies (resting state).\nThe changes of different frequencies in included studies (resting state).\nThe least studied frequency band was gamma, with only 4 studies involved, among which 3 showed no significant difference between adult ADHD and HC, while one study suggested a decrease in gamma band power in right centroparietal region (\nThe measurement results of delta, alpha, and beta frequency bands are not consistent. For delta frequency band of adult ADHD, 4 included studies indicated increases delta power compared to HCs, whereas 2 articles indicated decreased delta activities (\nFor alpha band of adult ADHD, 4 studies showed an increase in band power, 3 studies suggested that adult ADHD has lower alpha power than HCs. 8 studies showed no significant difference in alpha power between ADHD and HC in adults. Kiiski and Bennett in 2020 drew conclusions that theta power of adult ADHD was increased in centro-parietal region (\nThe results of researches in beta waves are most heterogeneous among all frequencies, 7 articles showed an increase in band power, while 5 studies indicated decreased beta activities. Interestingly, one study found that beta power (13–16 Hz) increased in frontal region, and beta activities (16–20 Hz) became higher in parietal region in adult ADHD (\nIt is worth noticing that the classification of five main frequency bands have subtle differences, and some articles further divided them into sub-bands (Fig. 3 indicated the frequency bands ranges and changes of each study). Among them, 3 studies indicated sub-component of specific frequency band in patients with ADHD were consistent (\nNumber of included studies by experimental tasks. The chart summarizes the experimental tasks used during EEG recording in the included studies. (Tasks that are performed less than 3 times are not included).\nNumber of included studies by EFs.\nAs demonstrated in\nIn addition, working memory tasks were adopted in 4 studies. In these tasks, participants temporarily store and manipulate visual (e.g., shapes, colors) and spatial (e.g., locations, movements) information (The describe and related EFs of paradigms of ERPs see\nAs illustrated in\nNumber of included studies by EEG measurements. (measurements that are recorded less than 3 times are not included).\nThis systematic review sought to explore EEG alterations in ADHD adults across both resting and event-related states. We are the first to categorize the ERP results in ADHD patients based on their EF performance across diverse tasks. Our goal is to identify neuro-electrophysiological markers associated with specific dimensions of EF deficits and to explore potential neuropathological mechanisms behind these changes. The findings indicate that ADHD adults tend to demonstrate a consistent increase in theta band power compared to HCs when in a resting state. Additionally, during response inhibition tasks, the amplitudes of ERP components such as Pe, P3, and N2 were consistently lower in ADHD patients. During sustained attention tasks, there were more pronounced reductions of P3 and N2 amplitudes in ADHD patients than in controls.\nThe outcomes of literatures included in this review indicate that ADHD adults exhibit heightened theta band power relative to HCs. Although the specific mechanism remains unclear, two hypotheses—the maturational lag hypothesis and the cortical hypo-arousal hypothesis—may provide insight into this manifestation (\nSome scholars have interpreted the increased slow-wave activities like delta and theta bands as indicative of a cortical low arousal state (\nClinical studies have shown that impulsivity and inattention symptoms are still prevalent in adults with ADHD, although hyperactivity symptoms tend to diminish with age (\nIn the included articles, 10 out of 17 studies reported an increase in theta band power, while 7 researches indicated no significant change in this frequency band of adult ADHD patients when compared to HCs. We noticed that the participants’ age in unchanged studies are higher than elevated theta studies. For the ages of participants in the included literature, ADHD patients was greater than 18 years, and there was no upper limit. Herrmann and his colleges divided the adult ADHD into two subgroup, youngster subgroup and elderly subgroup, the mean age of youngster group is 25 and for elderly is 40. EEG outcomes changes in youngster group but not in elderly samples (\nIn addition, the classification of ADHD exerts certain influences on EEG results. This disease typically categorized into inattentive, predominantly hyperactive/impulsive, and combined subtypes based on clinical manifestations. In a systematic review published recently, researcher indicated that resting state and task-related modulation of EEG and ERPs are different among ADHD subtypes (\nFurthermore, gender, intelligence quotient (IQ), and recording context may further influence the results of studies. Several studies have found that male adults with ADHD are more likely to exhibit elevated theta band power (\nIn the included studies of this systematic review, adult ADHD patients consistently exhibited a decrease in the amplitude of Pe, P3, and N2 components compared to HCs during tasks related to inhibition function. This suggests that adult ADHD patients may have deficiencies in inhibitory control. Pe typically reaches peak at centro-parietal sites around 200–450 ms after the occurrence of the erroneous response, which is thought to be an ERP that associated with erroneous responses, signifying conscious recognition of error (\nThe P3 typically peaks at 300–600 ms after stimulation (\nN2 is a negative potential located in the frontal-central region, typically measured at 200–400 ms, and is thought to be associated with conflict monitoring, response inhibition and selection (\nAdult ADHD patients consistently show reductions in the amplitude of P3 and N2 components compared to HCs when completing sustained attention related tasks. The decreased amplitude of P3 component may reflect deficits in attention, stimulus processing, and evaluation abilities, or an inappropriate attentional resources allocation (\nHowever, current studies on the resting-state alpha and beta oscillations in adult ADHD have not reached a consistent conclusion. Some investigators have found that alpha power is higher in adult ADHD patients compared to HCs (\nIn addition, some studies have found that beta band power in adults with ADHD is higher than that in HCs. Researchers hypothesize that this increase in beta band activity may be associated with heightened cerebral cortex activity and impaired emotion control (\nBased on a comprehensive analysis of the included literatures, we observed that adult patients with ADHD demonstrated consistent EEG characteristics and changes in ERP components in the context of specific EFs compared to HCs. However, there were significant inconsistencies results across studies. These differences may be attributed to various confounding factors,\nFirstly, in term of general demographic characters, several studies have reported divergent EEG changes due to differences in gender, age, IQ. and subtype. Other than that, ADHD patients have high frequency of co-morbidities, this condition is unavoidable. Some studies have recorded combination with other psychiatric disorders (see\nSecondly, the subgroup of particular component of ERPs and its correlation with cognitive domains has been inconsistent across studies (see\nIn summary, resting-state EEG of adult ADHD patients is characterized by an increase in theta band power, which may be consistent with the cortical low arousal model. During functional tasks, especially the response inhibition tasks, ADHD patients tend to exhibit a significant reduction in the amplitude of ERP components such as Pe, N2, and P3. These reductions may reflect deficiencies in error detection and control functions. Additionally, reduction in P3 and N2 components during sustained attention tasks suggests that ADHD patients may have difficulties in effectively allocating attentional resources. However, these findings should be interpreted with caution due to the presence of numerous confounding factors in the studies. Of note, this systematic review did not perform a meta- analysis, primarily because of heterogeneous protocols, inconsistent reporting and clinical diversity. To advance the field, future research should standardize methodologies, comprehensive clinical documentation and control confounders. Through these efforts, the field can establish robust electrophysiological biomarkers for ADHD, ultimately improving diagnostic precision and effective interventions.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "38633780", "pmcid": "12309824", "title": "Emergency department pain management in special populations", "publication_year": "N/A", "abstract": "Pain is a leading cause of emergency department (ED) visits globally, yet certain patient populations experience persistent disparities in their pain management due to physiological complexities, comorbidities, and gaps in evidence-based guidelines. This clinical review focuses on individualized, evidence-based approaches to ED pain management in four vulnerable groups: pregnant and breastfeeding patients, patients with sickle cell disease, geriatric populations, and patients with cancer pain and requiring palliative care. The practical recommendations presented in this review for optimal ED pain management in these special populations call for timely, effective, and multimodal analgesia; prioritization of nonpharmacologic and pain syndrome-targeted techniques; awareness of drug-disease and drug-drug interactions; interdisciplinary coordination; and education to mitigate ED clinicians’ biases. This review emphasizes the importance of tailoring pain strategies to population-specific needs to improve outcomes, reduce harm, and advance equity in emergency care delivery.", "full_text": "Pain is a common presenting complaint in emergency departments (EDs) worldwide, with up to 78% of ED visits involving pain as a primary or secondary symptom.[\nThe management of pain in these special populations is complicated due to altered pharmacokinetics, comorbidities, physiological vulnerabilities, refractoriness to conventional therapeutic approaches, and concerns about medication safety that frequently translate into inadequate pain control in the ED. This focused clinical review aims to provide emergency physicians with evidence-based approaches to pain management in these challenging populations.\nAcute pain is common in pregnancy, with analgesics being the third-most-prescribed medication class after antiemetics and antibiotics.[\nED clinicians must assess the risks of untreated illness and potential adverse effects of pharmacotherapy on pregnancy and breastfeeding and unfavorable perinatal and infant outcomes such as miscarriage, major congenital disabilities, preterm birth, stillbirth, neonatal adaptation signs, and behavioral and developmental effects.[\nCommonly used analgesics in pregnancy and lactation\nRID: Relative infant dose, NSAIDs: Nonsteroidal anti-inflammatory drugs, PO: Oral, PR: Rectal, IV: Intravenous, IN: Intranasal, IM: Intramuscular, SQ: Subcutaneous, NOWS: Neonatal opioid withdrawal syndrome, IUGR: Intrauterine growth retardation, CNS: Central nervous system, OUD: Opioid use disorder, SL: Sublingual, SGA: Small for gestational age, INH: Inhalation\nAcetaminophen is used in 40%–70% of pregnancies and is the only pain medication considered safe during pregnancy and compatible with breastfeeding.[\nNSAIDs, including their parenteral, oral, and topical forms, are generally considered safe in pregnant and lactating women and are commonly used for musculoskeletal (MSK) pain, headaches, and renal colic.[\nBeyond 20 weeks, NSAID use has been linked to fetal nephrotoxicity and oligohydramnios, prompting FDA recommendations to minimize use after 20 weeks and avoid it entirely after 30 weeks.[\nOpioids are widely used for pain management during pregnancy via IV, oral (PO), sublingual (SL), and intranasal (IN) routes. Frequent titration and the use of the lowest effective dose for the shortest duration are recommended to minimize complications.[\nPregnant women with opioid use disorder (OUD) face higher risks of inadequate prenatal care, fetal growth restriction, preterm labor, and NOWS.[\nDespite the relative infant dose of opioids in breast milk being in the range of 1%–5% of the mother’s therapeutic dose, there are significant risks associated with continued breastfeeding while on opioids.[\nCorticosteroids administered as a short course orally, topically, or intravenously are generally considered safe for treating radicular back pain, joint pain, and inflammatory pain during pregnancy.[\nMagnesium is commonly used in obstetrics and has been well tolerated by both the mother and baby in the treatment of acute and chronic painful syndromes.[\nGabapentin and pregabalin are commonly used for postherpetic neuralgia, diabetic neuropathy, and radicular back pain in pregnant patients and are generally safe in breastfeeding. A large population-based study of 4642 pregnancies with early gabapentin exposure did not demonstrate an association with major congenital malformations. However, maternal gabapentin use in late pregnancy was associated with a 20%–30% increased risk of preterm birth, a 30%–40% increased risk of small-for-gestational-age infants, and a 35% increased likelihood of neonatal intensive care unit admission.[\nTargeted analgesic techniques such as topical, local, and regional anesthesia offer rapid pain relief with minimal systemic effects to pregnant and lactating patients.[\nAntidopaminergics (metoclopramide, prochlorperazine, droperidol, and haloperidol) are frequently used for the management of intractable nausea/vomiting, primary headache, and intractable abdominal pain in the ED. While generally safe in pregnancy and breastfeeding, the use of metoclopramide might be associated with maternal extrapyramidal symptoms. The use of phenothiazines rarely leads to the development of cleft palate, skeletal, limb, and cardiac abnormalities, as well as neonatal respiratory depression during pregnancy. The administration of droperidol or haloperidol is often avoided due to concerns about maternal prolonged QTc.[\nThe use of central muscle relaxants such as baclofen, methocarbamol, chlorzoxazone, cyclobenzaprine, tizanidine, and thiocolchicoside should be generally avoided in pregnant patients as numerous animal studies demonstrated teratogenicity of such medications and human data is severely limited.[\nThe use of nitrous oxide during pregnancy, particularly for short-term procedures and labor pain management, appears to be safe with no significant adverse effects on the fetus. However, long-term exposure to high concentrations of nitrous oxide, such as in occupational or recreational settings, may negatively impact fertility and fetal outcomes. Additionally, there are concerns regarding its use in the first trimester, where the inactivation of Vitamin B12 disrupts the folate metabolism.[\nKetamine is frequently used in the ED for procedural sedation and analgesia, intubation, and pain management. Ketamine readily crosses the placenta and preferentially distributes in neuronal tissue, raising concerns about its neurotoxic effects in the developing brain.[\nExercise and physical therapy have been associated with reduced pain intensity, decreased disability, and improved quality of life in pregnancy-related MSK and back pain.[\nBreastfeeding-all drugs under 1000 kDa transfer into breast milk. A quantitative estimate of how much medication is transferred to the nursing infant is expressed as a relative infant dose (RID). For most drugs, a RID of 10% or less is considered relatively safe; caution is required for drugs excreted in dosages of 10%–25% of the maternal dosage; and those few drugs excreted in dosages over 25% of the maternal dosage are considered unacceptable.[\n\nPrescribe at the lowest effective dose, quantity, and duration of treatment to minimize in utero exposure to medications\nPrioritize topicals and nonpharmacological therapies over systemic treatments\nUse targeted analgesia whenever possible\nCollaborate with patients to establish treatment goals.\nSCD is an autosomal recessive disorder characterized by disrupted morphology (sickling) that affects close to 8 million people globally and results in painful crises, hemolytic anemia, splenic sequestration, infections, and stroke.[\nThe best practice guidelines by the American Society of Hematology (ASH) and the American College of Emergency Physicians recommend assessing all patients presenting with acute VOC to the ED as high-risk, administering appropriate analgesia within 1 h of arrival with pain reassessment every 30–60 min, and individualizing the plans of care for each patient based on their history of analgesic use and effective dosage and route for pain relief in the past. The goal of analgesia in VOC is to provide appropriate relief for patient discomfort in a safe and effective manner while evaluating patients for underlying complications of SCD.[\nSummary of analgesic options in the treatment of acute pain in vaso-occlusive crisis in sickle-cell disease patients\nIV: Intravenous, PO: Oral, PR: Rectal, IN: Intranasal, IM: Intramuscular, SL: Sublingual, SQ: Subcutaneous, NEB: Nebulized, NMDA: N-methyl-D-aspartate, NSAIDs: Nonsteroidal anti-inflammatory drugs, APAP: Acetaminophen, Paracetamol (N-acetyl-p-aminophenol), MSIR: Morphine sulfate immediate release\nParacetamol’s mechanism of action for pain reduction seems to primarily involve its central inhibition of cyclooxygenase (COX), without a significant anti-inflammatory effect. The use of IV acetaminophen (with its debatable analgesic superiority over oral form[\nTo date, no published RCTs have examined IV APAP’s clinical efficacy, either as a single agent or as an adjunct to opioids for VOC treatment in adults. Recommended dosing is 10–15 mg/kg per dose in children (500–1000 mg per dose in adults), with a maximum dose of 75 mg/kg/day in children (4 g in adults). Adverse effects include nausea and vomiting, with hepatic insufficiency being one of the major contraindications and lack of titratability as a major limitation.\nNonsteroidal antiinflammatory drugs (NSAIDs) act by reducing both pain and inflammation through the inhibition of COX enzymes, thereby decreasing prostaglandin production. As a part of multimodal analgesia, ibuprofen, ketorolac, diclofenac, ketoprofen, and dexketoprofen were found to be beneficial in reducing pain and overall opioid consumption.[\nOpioids remain the cornerstone of management of pain in VOC. Commonly used mu-receptor agonists (morphine, hydromorphone, and fentanyl) decrease afferent nociceptive signals, thereby reducing pain sensation. Parenteral formulations must be titrated to optimal analgesic effect, and only immediate-release and short-acting opioids should be used in the ED for VOC treatment. Opioid administration should target achievement of a “therapeutic window,’ where optimal analgesia is achieved with the least amount of side effects, which could include nausea/vomiting, itching, dizziness, somnolence, and even respiratory depression. The factors affecting this “therapeutic window” in patients with VOC include renal and hepatic function, drug metabolism, prior pain events, and amount and duration of opioid use in the past.[\nNumerous clinical trials support the use of IN administration of hydromorphone and fentanyl for sickle cell patients in the ED, demonstrating similar analgesic efficacy to their parenteral counterparts. Similarly, SL administration of fentanyl, sufentanil, and buprenorphine resulted in significant pain relief of acute pain of VOC.[\nOnce optimal analgesia is achieved, those patients admitted for subsequent pain management could benefit from patient-controlled analgesia (PCA) infusions or intermittent boluses. The use of PCA in the ED may also have a positive impact on patient satisfaction and reduced need for additional analgesics, provided adequate training and experience with this modality is maintained amongst ED providers.[\nOpioid tolerance, which is associated with a reduction in analgesic effect following repeated or prolonged opioid use, and opioid-induced hyperalgesia (OIH)-a paradoxical nociceptive sensitization leading to a hyper response to acute noxious stimuli in the setting of opioid therapy-are frequently present in sickle cell patients.[\nFinally, the metabolism of tramadol and codeine is dependent on the hepatic CYP2D6 enzyme, which affects the amount of available active metabolite due to gene polymorphism in sickle-cell patients, thus warranting avoidance of these opioids in these patients.[\nKetamine is a noncompetitive antagonist of N-methyl-D-aspartate and plays a role in the reduction of pain through central sensitization. Two RCTs demonstrated similar analgesic efficacy of sub-dissociative dose ketamine to opioid-based therapy and opioid-sparing effect, illustrating its potential as an adjunct in pain management for VOC.[\nSystemic IV administration of lidocaine, an amide local anesthetic, has been found to reduce pain and provide opioid-sparing in patients with VOC. However, the data is based on retrospective case series and reports showing a variability in outcome measures and dosing. In general, both ketamine and lidocaine, while limited by current evidence, still hold potential benefits as adjuncts to opioid medication, potentially reducing the amount of opioids used to effectively manage acute pain in SCD patients.[\nA review of nonpharmacologic options for pain relief in sickle cell patients, including distraction therapy, cognitive–behavioral therapy, hypnosis, biofeedback, and massage, demonstrated significant reduction in pain and anxiety and improvements in patients’ satisfaction.[\nFrequent use of high dosages of opioids in patients with SCD is frequently met with negative provider attitude and bias as well as fear of dependence and/or addiction, leading to delayed and ineffective pain management.[\n\nED clinicians should attempt to create and utilize patient-specific pain management pathways that improve pain management and throughput in the ED\nED clinicians should use opioids in a safe and effective manner by frequent titration and balancing pain relief and adverse effects\nED clinicians should utilize nonopioid analgesics and adjuncts in a judicious and effective manner for the control of acute pain\nED clinicians should collaborate with an interdisciplinary team to ensure effective pain management in the ED and continuation of care upon discharge from the ED.\nED’s visits of cancer patients for breakthrough pain, inadequate baseline analgesia, or serious complications are challenging due to limited initial clinical information.[\nGeneral approach to cancer pain in the emergency department\nOIH: Opioid-induced hyperalgesia, ED: Emergency department\nCommonly used analgesics with routes and dosing regimens in the emergency department\nAll initial doses should be titrated based on patient response and tolerability. The doses listed are general starting points for opioid-naïve adults. For breakthrough Pain: Prescribe 10%–15% of the 24-h opioid dose as needed. Reduce doses and extend intervals for patients with renal/hepatic impairment. Start with lower doses (approximately 25%–50% of the standard dose) in elderly patients. Consider concurrent use of adjuvant analgesics (NSAIDs, anticonvulsants, antidepressants) to improve pain control. When using opioids, consider implementing a bowel regimen to prevent constipation. IV: Intravenous, SL: Sublingual, IN: Intranasal, IM: Intramuscular, INH: Inhalation, PO: Oral, PR: Rectal, SQ: Subcutaneous, SL: Sublingual, TD: Transdermal, TM: Transmucosal, IR: Immediate release, ER: Extended release, CNS: Central nervous system, NSAID: Nonsteroidal anti-inflammatory drug, GI: Gastrointestinal\nCommunication and shared decision-making with patients and their families regarding pain management goals, expectations, and adverse effects are essential for timely and effective pain, stress, and anxiety control in the ED.[\nOpioids are the most studied analgesics for cancer pain. Most cancer patients with breakthrough pain develop tolerance, requiring higher doses for satisfactory analgesia.[\nHydromorphone administered in parenteral, oral, and rectal forms is equally effective for managing chronic cancer pain, but its metabolites may accumulate in patients with renal or hepatic impairment.[\nTramadol’s opioid activity is dependent on CYP2D6 metabolism, leading to significant variability in humans and a less favorable safety profile.[\nA Cochrane review demonstrated equal or even superior efficacy of transdermal buprenorphine in comparison to other opioids in cancer patients.[\nOral and parenteral equivalent doses of opioids and conversion ratios\nConversions should consider potential complex interactions with other medications and potential patient variability. It is recommended to titrate slowly and monitor for side effects, IV: Intravenous\nParacetamol (acetaminophen) is not considered a first-line therapy for cancer pain.[\nNSAIDs are found to be effective in managing cancer pain in the ED when administered alone or in combination with opioids, enhancing analgesic efficacy and reducing the need for opioids.[\nSub-dissociative doses of ketamine can be helpful in the treatment of opioid-tolerant and refractory cancer pain.[\nA single-phase II study supported the efficacy and safety of IV lidocaine in refractory cancer pain.[\nAlthough benzodiazepines do not have a direct analgesic effect, small boluses of midazolam (1–2 mg IV) are effective in reducing anxiety and muscle spasms.[\nCorticosteroids, despite limited efficacy, are commonly used as adjuvant analgesics in cancer pain management, particularly for neuropathic pain, bone metastasis, and pain associated with inflammation or edema.[\nAnticonvulsants such as gabapentin and pregabalin can be helpful adjuncts for neuropathic types of cancer pain. The initiation of gabapentin or pregabalin in the ED for compression or chemotherapy-induced neuropathies may be considered, although these therapeutics are not expected to provide immediate relief[\nThere is strong evidence from several RCT that antiemetics should be considered early for co-administration with opioids to prevent nausea/vomiting.[\nUltrasound-guided nerve blocks are an excellent therapeutic modality for cancer patients who present to the ED with properly localized acute pain.[\nAlthough the list of potential pitfalls in cancer pain management is vast, they can be categorized into assessment issues, treatment-related issues, opioid-related pitfalls, system gaps, and psychosocial and patient-related factors [\nCommon pitfalls in cancer pain management in the emergency department\n\nConsider acute cancer/treatment complications and comorbidities as potential causes of pain and avoid “cancer pain bias”\nCommunicate goals and expectations with patients and their families and utilize a multimodal approach of nonpharmacologic and pharmacologic treatment modalities\nCalculate opioid requirements based on home regimens and use careful titration in renal/hepatic dysfunction. Use short-acting opioids for breakthrough pain. If the patient is discharged, provide a discharge analgesic rescue plan\nUse NSAIDs (with caution), ketamine (for opioid-tolerant patients), and adjuncts (anticonvulsants for neuropathic pain, antiemetics) for pain control\nConsider ultrasound-guided nerve blocks\nAcknowledge anxiety, depression, stress, and distress. Exercise empathy and consider anxiolytics if appropriate\nWhen in doubt, consult: Do not hesitate to seek guidance from palliative care specialists and/or pain management experts.\nManaging acute pain in elderly patients (>64 years) in the ED requires a nuanced approach. Older patients are often more sensitive to medication effects and side effects. They tend to have more comorbid conditions, higher rates of polypharmacy, and reduced physiological reserves. The primary focus of pain management in geriatric patients is to minimize potential harm while providing effective, multi-modal analgesia.\nOlder adults often present to the ED with acute pain, yet they consistently receive less adequate pain management compared to younger patients.[\nChallenges to safely managing pain in older adult patients\nIn patients able to communicate, pain can be assessed via different tools and pain scales, such as a numeric scale or Visual Analog Scale.[\nA useful framework for managing pain in older adults is to use a patient-centered, holistic, and diverse therapeutic approach that considers potential drug-patient, drug-disease, and drug-drug factors and interactions.\nPutting patients’ desires and interests at the center of conversation by asking what matters the most to them will align clinicians’ care with the patient’s goals. Incorporating what matters to the patient is a cornerstone of the Age-Friendly Health Systems’ “5 Ms” framework that includes: mentation, mobility, medications, multi-complexity, and what matters most.[\nPain and the experience of suffering are multifactorial and personal, and can be exacerbated by emotional distress and other unmet needs. Identifying whether pain is acute or chronic, neuropathic or nociceptive, visceral or somatic can help guide treatment selection. In addition, it is important to address the patient’s other needs, such as food, hydration, and physical comfort.[\nWhen selecting a medication and dose, consider potential interactions between the drug and the patient, such as the patient’s baseline level of frailty or physiologic reserves, their underlying fall risk, and whether they have physiologic tolerance or are naïve to a given class of medications.[\nRenal, hepatic, or cardiac dysfunction; peptic ulcer disease; orthostatic hypotension; and delirium may necessitate medication adjustments. For example, NSAIDs can cause acute renal failure, particularly in the setting of chronic kidney disease (CKD). NSAIDs can also worsen gastritis and peptic ulcer disease. They can also interact with ACE inhibitors, diuretics, steroids, and warfarin, potentially increasing INR for patients on warfarin.\nRenally-cleared opioids such as oxycodone, hydrocodone, and morphine should be used cautiously in patients with chronic kidney disease or end-stage kidney disease, as the medication or its metabolites can have prolonged or more severe adverse effects or sedation.[\nWhen prescribing medications for use over time, as well as a single dose in the ED, it is important to review the patient’s home medication list to look for potential medication interactions. For pain management, high-risk combinations to avoid to prevent oversedation, respiratory depression, or other side effects include opioids with gabapentinoids, muscle relaxants, or benzodiazepines.[\nAfter assessing the patient’s source, severity, and chronicity of pain, aligning with patient goals, and reviewing the underlying drug-patient, drug-drug, and drug-disease factors, emergency clinicians should employ a tiered approach to safely managing their pain. Commonly used analgesics with their starting doses and routes of administration are summarized in\nCommon analgesics with routes of administration and starting doses\nIV: Intravenous, PO: Oral, BID: Twice a day, TID: Three times per day, QHS: Once at night, Q-every, NSAIDs: Nonsteroidal anti-inflammatory drugs, GI: Gastrointestinal, IR: Immediate release\nAddressing unmet physical or emotional needs can help reduce the experience of suffering. Simple interventions such as adjusting the bed or chair for physical comfort, providing warm blankets, and addressing hunger, thirst, or toileting needs. Heating pads, distraction, or reassurance can be useful as well.[\nCertain types of pain are particularly amenable to targeted approaches. For example, femoral or fascia iliaca nerve blocks offer effective analgesia for hip fractures, reducing opioidconsumption.[\nTopical agents, such as diclofenac, can be used alone or as adjuvants for many painful MSK disorders, such as sprains and strains. Topical diclofenac is effective, well-absorbed locally, has little systemic absorption, and reduced side effects.[\nAcetaminophen is a common first-line medication for mild or moderate pain in older adults, as there are few side effects and medication interactions, and it can be used in patients with renal disease. It can be given orally or intravenously and can be used in conjunction with other pain medications for a multi-modal approach.[\nNSAIDs administered orally or parenterally are effective for pain control in the elderly in the ED, with caution in patients with gastric ulcers or renal impairment. NSAIDs are particularly effective for renal colic and other nociceptive (rather than neuropathic) pain.[\nKetamine, when used for acute pain in the ED, provides analgesia comparable to morphine but caries a higher risk of psycho-perceptual side effects such as dizziness, light sedation, or feelings of unreality,[\nGabapentin or pregabalin can be effective for neuropathic pain, but their dosing requires titration. Combinations with benzodiazepines or opioids should be avoided or used with extreme caution.[\nOpioids can be used alone or in conjunction with other treatment modalities for acute moderate or severe pain. Opioid medications carry the risk of sedation, urinary retention, and respiratory depression acutely, as well as tolerance and addiction with chronic use. It is generally wise to begin with a lower initial dose, monitoring, and frequent titration as needed to avoid respiratory depression or sedation.[\nOpioids should also be used for the shortest duration necessary to avoid the risk of addiction or dependence. Tramadol is a weak mu-opioid agonist that is commonly prescribed in the outpatient setting. However, it has significant potential side effects for older adults, including hypoglycemia, hyponatremia, lower seizure threshold, and higher mortality, so it should generally be avoided in favor of safer alternatives.[\nWhen prescribing opioids on discharge, it is important to also prescribe a bowel regimen. A combination of stimulant laxatives, such as senna, and/or an osmotic laxative such as polyethylene glycol, is effective.[\nEffective pain management for older adult patients in the ED requires a comprehensive approach that balances efficacy with safety. By understanding and addressing the unique challenges faced by this population, clinicians can improve patient safety and enhance the quality of care for elderly patients experiencing acute pain. Clinicians should take a patient-centered, holistic approach and consider drug-patient, drug-disease, and drug-drug interactions to help ensure they are selecting the best medication, dose, and duration for each patient.\n\nThorough assessment: Use a holistic approach to assessing a patient’s pain, their desires, and what matters most to them. Both verbal and non-verbal indicators are important, especially in patients with cognitive impairment\nIndividualized treatment plans: Develop treatment plans that consider the patient’s overall health, current medications, and personal preferences. Incorporate both pharmacologic and nonpharmacologic approaches\nDosing strategy: Start with the lowest effective dose, particularly with opioids and sedatives. Reassess or monitor patients frequently and avoid long-term prescriptions when possible\nEducation and communication: Ensure that patients and caregivers understand the treatment plan, potential adverse effects, and the importance of follow-up. On discharge, communicate potential adverse effects and dosing adjustments with the patient and caregiver, such as the risk of dizziness or falls\nDischarge management: For patients who are prescribed an opioid, it is important to also prescribe a stimulant bowel regimen.\nWhile each of the unique and challenging populations requires an individualized treatment plan at discharge from the ED, several important concepts are uniformly applicable to all of them. At discharge, ED clinicians should engage patients in shared decision-making about the nature of their painful syndromes and their expectations with respect to pain relief and functional improvement; commonly used analgesic modalities and their alternatives, as well as short- and long-term adverse effects; and the importance of outpatient follow-up with the specialists (obstetricians and gynecologists, hematologists and sickle-cell specialists, oncologists and palliative care specialists, geriatricians, and pain management specialists with expertise in pain management of these vulnerable groups). In addition, ED clinicians should emphasize the need to return to the ED for re-evaluation in the absence of acceptable pain relief and/or development of severe adverse effects related to prescribed analgesics.\nEffective pain management in special populations requires emergency physicians to adopt tailored approaches that acknowledge the unique physiological, pharmacological, and psychosocial factors affecting these vulnerable groups. For pregnant patients, SCD patients, geriatric individuals, and those requiring cancer or palliative care, standard pain management protocols often prove insufficient or potentially harmful. Implementation of population-specific pain management strategies, early multimodal analgesia, appropriate utilization of non-pharmacological interventions, and interdisciplinary collaboration are essential components of optimal care.\nAs emergency medicine continues to evolve, further research focusing on these special populations will be critical to developing more refined, evidence-based pain management strategies that would improve patient outcomes, minimize adverse effects, and address the persistent disparities in pain management that these populations frequently encounter.\nNone Declared.", "content_for_embedding": "Pain is a common presenting complaint in emergency departments (EDs) worldwide, with up to 78% of ED visits involving pain as a primary or secondary symptom.[\nThe management of pain in these special populations is complicated due to altered pharmacokinetics, comorbidities, physiological vulnerabilities, refractoriness to conventional therapeutic approaches, and concerns about medication safety that frequently translate into inadequate pain control in the ED. This focused clinical review aims to provide emergency physicians with evidence-based approaches to pain management in these challenging populations.\nAcute pain is common in pregnancy, with analgesics being the third-most-prescribed medication class after antiemetics and antibiotics.[\nED clinicians must assess the risks of untreated illness and potential adverse effects of pharmacotherapy on pregnancy and breastfeeding and unfavorable perinatal and infant outcomes such as miscarriage, major congenital disabilities, preterm birth, stillbirth, neonatal adaptation signs, and behavioral and developmental effects.[\nCommonly used analgesics in pregnancy and lactation\nRID: Relative infant dose, NSAIDs: Nonsteroidal anti-inflammatory drugs, PO: Oral, PR: Rectal, IV: Intravenous, IN: Intranasal, IM: Intramuscular, SQ: Subcutaneous, NOWS: Neonatal opioid withdrawal syndrome, IUGR: Intrauterine growth retardation, CNS: Central nervous system, OUD: Opioid use disorder, SL: Sublingual, SGA: Small for gestational age, INH: Inhalation\nAcetaminophen is used in 40%–70% of pregnancies and is the only pain medication considered safe during pregnancy and compatible with breastfeeding.[\nNSAIDs, including their parenteral, oral, and topical forms, are generally considered safe in pregnant and lactating women and are commonly used for musculoskeletal (MSK) pain, headaches, and renal colic.[\nBeyond 20 weeks, NSAID use has been linked to fetal nephrotoxicity and oligohydramnios, prompting FDA recommendations to minimize use after 20 weeks and avoid it entirely after 30 weeks.[\nOpioids are widely used for pain management during pregnancy via IV, oral (PO), sublingual (SL), and intranasal (IN) routes. Frequent titration and the use of the lowest effective dose for the shortest duration are recommended to minimize complications.[\nPregnant women with opioid use disorder (OUD) face higher risks of inadequate prenatal care, fetal growth restriction, preterm labor, and NOWS.[\nDespite the relative infant dose of opioids in breast milk being in the range of 1%–5% of the mother’s therapeutic dose, there are significant risks associated with continued breastfeeding while on opioids.[\nCorticosteroids administered as a short course orally, topically, or intravenously are generally considered safe for treating radicular back pain, joint pain, and inflammatory pain during pregnancy.[\nMagnesium is commonly used in obstetrics and has been well tolerated by both the mother and baby in the treatment of acute and chronic painful syndromes.[\nGabapentin and pregabalin are commonly used for postherpetic neuralgia, diabetic neuropathy, and radicular back pain in pregnant patients and are generally safe in breastfeeding. A large population-based study of 4642 pregnancies with early gabapentin exposure did not demonstrate an association with major congenital malformations. However, maternal gabapentin use in late pregnancy was associated with a 20%–30% increased risk of preterm birth, a 30%–40% increased risk of small-for-gestational-age infants, and a 35% increased likelihood of neonatal intensive care unit admission.[\nTargeted analgesic techniques such as topical, local, and regional anesthesia offer rapid pain relief with minimal systemic effects to pregnant and lactating patients.[\nAntidopaminergics (metoclopramide, prochlorperazine, droperidol, and haloperidol) are frequently used for the management of intractable nausea/vomiting, primary headache, and intractable abdominal pain in the ED. While generally safe in pregnancy and breastfeeding, the use of metoclopramide might be associated with maternal extrapyramidal symptoms. The use of phenothiazines rarely leads to the development of cleft palate, skeletal, limb, and cardiac abnormalities, as well as neonatal respiratory depression during pregnancy. The administration of droperidol or haloperidol is often avoided due to concerns about maternal prolonged QTc.[\nThe use of central muscle relaxants such as baclofen, methocarbamol, chlorzoxazone, cyclobenzaprine, tizanidine, and thiocolchicoside should be generally avoided in pregnant patients as numerous animal studies demonstrated teratogenicity of such medications and human data is severely limited.[\nThe use of nitrous oxide during pregnancy, particularly for short-term procedures and labor pain management, appears to be safe with no significant adverse effects on the fetus. However, long-term exposure to high concentrations of nitrous oxide, such as in occupational or recreational settings, may negatively impact fertility and fetal outcomes. Additionally, there are concerns regarding its use in the first trimester, where the inactivation of Vitamin B12 disrupts the folate metabolism.[\nKetamine is frequently used in the ED for procedural sedation and analgesia, intubation, and pain management. Ketamine readily crosses the placenta and preferentially distributes in neuronal tissue, raising concerns about its neurotoxic effects in the developing brain.[\nExercise and physical therapy have been associated with reduced pain intensity, decreased disability, and improved quality of life in pregnancy-related MSK and back pain.[\nBreastfeeding-all drugs under 1000 kDa transfer into breast milk. A quantitative estimate of how much medication is transferred to the nursing infant is expressed as a relative infant dose (RID). For most drugs, a RID of 10% or less is considered relatively safe; caution is required for drugs excreted in dosages of 10%–25% of the maternal dosage; and those few drugs excreted in dosages over 25% of the maternal dosage are considered unacceptable.[\n\nPrescribe at the lowest effective dose, quantity, and duration of treatment to minimize in utero exposure to medications\nPrioritize topicals and nonpharmacological therapies over systemic treatments\nUse targeted analgesia whenever possible\nCollaborate with patients to establish treatment goals.\nSCD is an autosomal recessive disorder characterized by disrupted morphology (sickling) that affects close to 8 million people globally and results in painful crises, hemolytic anemia, splenic sequestration, infections, and stroke.[\nThe best practice guidelines by the American Society of Hematology (ASH) and the American College of Emergency Physicians recommend assessing all patients presenting with acute VOC to the ED as high-risk, administering appropriate analgesia within 1 h of arrival with pain reassessment every 30–60 min, and individualizing the plans of care for each patient based on their history of analgesic use and effective dosage and route for pain relief in the past. The goal of analgesia in VOC is to provide appropriate relief for patient discomfort in a safe and effective manner while evaluating patients for underlying complications of SCD.[\nSummary of analgesic options in the treatment of acute pain in vaso-occlusive crisis in sickle-cell disease patients\nIV: Intravenous, PO: Oral, PR: Rectal, IN: Intranasal, IM: Intramuscular, SL: Sublingual, SQ: Subcutaneous, NEB: Nebulized, NMDA: N-methyl-D-aspartate, NSAIDs: Nonsteroidal anti-inflammatory drugs, APAP: Acetaminophen, Paracetamol (N-acetyl-p-aminophenol), MSIR: Morphine sulfate immediate release\nParacetamol’s mechanism of action for pain reduction seems to primarily involve its central inhibition of cyclooxygenase (COX), without a significant anti-inflammatory effect. The use of IV acetaminophen (with its debatable analgesic superiority over oral form[\nTo date, no published RCTs have examined IV APAP’s clinical efficacy, either as a single agent or as an adjunct to opioids for VOC treatment in adults. Recommended dosing is 10–15 mg/kg per dose in children (500–1000 mg per dose in adults), with a maximum dose of 75 mg/kg/day in children (4 g in adults). Adverse effects include nausea and vomiting, with hepatic insufficiency being one of the major contraindications and lack of titratability as a major limitation.\nNonsteroidal antiinflammatory drugs (NSAIDs) act by reducing both pain and inflammation through the inhibition of COX enzymes, thereby decreasing prostaglandin production. As a part of multimodal analgesia, ibuprofen, ketorolac, diclofenac, ketoprofen, and dexketoprofen were found to be beneficial in reducing pain and overall opioid consumption.[\nOpioids remain the cornerstone of management of pain in VOC. Commonly used mu-receptor agonists (morphine, hydromorphone, and fentanyl) decrease afferent nociceptive signals, thereby reducing pain sensation. Parenteral formulations must be titrated to optimal analgesic effect, and only immediate-release and short-acting opioids should be used in the ED for VOC treatment. Opioid administration should target achievement of a “therapeutic window,’ where optimal analgesia is achieved with the least amount of side effects, which could include nausea/vomiting, itching, dizziness, somnolence, and even respiratory depression. The factors affecting this “therapeutic window” in patients with VOC include renal and hepatic function, drug metabolism, prior pain events, and amount and duration of opioid use in the past.[\nNumerous clinical trials support the use of IN administration of hydromorphone and fentanyl for sickle cell patients in the ED, demonstrating similar analgesic efficacy to their parenteral counterparts. Similarly, SL administration of fentanyl, sufentanil, and buprenorphine resulted in significant pain relief of acute pain of VOC.[\nOnce optimal analgesia is achieved, those patients admitted for subsequent pain management could benefit from patient-controlled analgesia (PCA) infusions or intermittent boluses. The use of PCA in the ED may also have a positive impact on patient satisfaction and reduced need for additional analgesics, provided adequate training and experience with this modality is maintained amongst ED providers.[\nOpioid tolerance, which is associated with a reduction in analgesic effect following repeated or prolonged opioid use, and opioid-induced hyperalgesia (OIH)-a paradoxical nociceptive sensitization leading to a hyper response to acute noxious stimuli in the setting of opioid therapy-are frequently present in sickle cell patients.[\nFinally, the metabolism of tramadol and codeine is dependent on the hepatic CYP2D6 enzyme, which affects the amount of available active metabolite due to gene polymorphism in sickle-cell patients, thus warranting avoidance of these opioids in these patients.[\nKetamine is a noncompetitive antagonist of N-methyl-D-aspartate and plays a role in the reduction of pain through central sensitization. Two RCTs demonstrated similar analgesic efficacy of sub-dissociative dose ketamine to opioid-based therapy and opioid-sparing effect, illustrating its potential as an adjunct in pain management for VOC.[\nSystemic IV administration of lidocaine, an amide local anesthetic, has been found to reduce pain and provide opioid-sparing in patients with VOC. However, the data is based on retrospective case series and reports showing a variability in outcome measures and dosing. In general, both ketamine and lidocaine, while limited by current evidence, still hold potential benefits as adjuncts to opioid medication, potentially reducing the amount of opioids used to effectively manage acute pain in SCD patients.[\nA review of nonpharmacologic options for pain relief in sickle cell patients, including distraction therapy, cognitive–behavioral therapy, hypnosis, biofeedback, and massage, demonstrated significant reduction in pain and anxiety and improvements in patients’ satisfaction.[\nFrequent use of high dosages of opioids in patients with SCD is frequently met with negative provider attitude and bias as well as fear of dependence and/or addiction, leading to delayed and ineffective pain management.[\n\nED clinicians should attempt to create and utilize patient-specific pain management pathways that improve pain management and throughput in the ED\nED clinicians should use opioids in a safe and effective manner by frequent titration and balancing pain relief and adverse effects\nED clinicians should utilize nonopioid analgesics and adjuncts in a judicious and effective manner for the control of acute pain\nED clinicians should collaborate with an interdisciplinary team to ensure effective pain management in the ED and continuation of care upon discharge from the ED.\nED’s visits of cancer patients for breakthrough pain, inadequate baseline analgesia, or serious complications are challenging due to limited initial clinical information.[\nGeneral approach to cancer pain in the emergency department\nOIH: Opioid-induced hyperalgesia, ED: Emergency department\nCommonly used analgesics with routes and dosing regimens in the emergency department\nAll initial doses should be titrated based on patient response and tolerability. The doses listed are general starting points for opioid-naïve adults. For breakthrough Pain: Prescribe 10%–15% of the 24-h opioid dose as needed. Reduce doses and extend intervals for patients with renal/hepatic impairment. Start with lower doses (approximately 25%–50% of the standard dose) in elderly patients. Consider concurrent use of adjuvant analgesics (NSAIDs, anticonvulsants, antidepressants) to improve pain control. When using opioids, consider implementing a bowel regimen to prevent constipation. IV: Intravenous, SL: Sublingual, IN: Intranasal, IM: Intramuscular, INH: Inhalation, PO: Oral, PR: Rectal, SQ: Subcutaneous, SL: Sublingual, TD: Transdermal, TM: Transmucosal, IR: Immediate release, ER: Extended release, CNS: Central nervous system, NSAID: Nonsteroidal anti-inflammatory drug, GI: Gastrointestinal\nCommunication and shared decision-making with patients and their families regarding pain management goals, expectations, and adverse effects are essential for timely and effective pain, stress, and anxiety control in the ED.[\nOpioids are the most studied analgesics for cancer pain. Most cancer patients with breakthrough pain develop tolerance, requiring higher doses for satisfactory analgesia.[\nHydromorphone administered in parenteral, oral, and rectal forms is equally effective for managing chronic cancer pain, but its metabolites may accumulate in patients with renal or hepatic impairment.[\nTramadol’s opioid activity is dependent on CYP2D6 metabolism, leading to significant variability in humans and a less favorable safety profile.[\nA Cochrane review demonstrated equal or even superior efficacy of transdermal buprenorphine in comparison to other opioids in cancer patients.[\nOral and parenteral equivalent doses of opioids and conversion ratios\nConversions should consider potential complex interactions with other medications and potential patient variability. It is recommended to titrate slowly and monitor for side effects, IV: Intravenous\nParacetamol (acetaminophen) is not considered a first-line therapy for cancer pain.[\nNSAIDs are found to be effective in managing cancer pain in the ED when administered alone or in combination with opioids, enhancing analgesic efficacy and reducing the need for opioids.[\nSub-dissociative doses of ketamine can be helpful in the treatment of opioid-tolerant and refractory cancer pain.[\nA single-phase II study supported the efficacy and safety of IV lidocaine in refractory cancer pain.[\nAlthough benzodiazepines do not have a direct analgesic effect, small boluses of midazolam (1–2 mg IV) are effective in reducing anxiety and muscle spasms.[\nCorticosteroids, despite limited efficacy, are commonly used as adjuvant analgesics in cancer pain management, particularly for neuropathic pain, bone metastasis, and pain associated with inflammation or edema.[\nAnticonvulsants such as gabapentin and pregabalin can be helpful adjuncts for neuropathic types of cancer pain. The initiation of gabapentin or pregabalin in the ED for compression or chemotherapy-induced neuropathies may be considered, although these therapeutics are not expected to provide immediate relief[\nThere is strong evidence from several RCT that antiemetics should be considered early for co-administration with opioids to prevent nausea/vomiting.[\nUltrasound-guided nerve blocks are an excellent therapeutic modality for cancer patients who present to the ED with properly localized acute pain.[\nAlthough the list of potential pitfalls in cancer pain management is vast, they can be categorized into assessment issues, treatment-related issues, opioid-related pitfalls, system gaps, and psychosocial and patient-related factors [\nCommon pitfalls in cancer pain management in the emergency department\n\nConsider acute cancer/treatment complications and comorbidities as potential causes of pain and avoid “cancer pain bias”\nCommunicate goals and expectations with patients and their families and utilize a multimodal approach of nonpharmacologic and pharmacologic treatment modalities\nCalculate opioid requirements based on home regimens and use careful titration in renal/hepatic dysfunction. Use short-acting opioids for breakthrough pain. If the patient is discharged, provide a discharge analgesic rescue plan\nUse NSAIDs (with caution), ketamine (for opioid-tolerant patients), and adjuncts (anticonvulsants for neuropathic pain, antiemetics) for pain control\nConsider ultrasound-guided nerve blocks\nAcknowledge anxiety, depression, stress, and distress. Exercise empathy and consider anxiolytics if appropriate\nWhen in doubt, consult: Do not hesitate to seek guidance from palliative care specialists and/or pain management experts.\nManaging acute pain in elderly patients (>64 years) in the ED requires a nuanced approach. Older patients are often more sensitive to medication effects and side effects. They tend to have more comorbid conditions, higher rates of polypharmacy, and reduced physiological reserves. The primary focus of pain management in geriatric patients is to minimize potential harm while providing effective, multi-modal analgesia.\nOlder adults often present to the ED with acute pain, yet they consistently receive less adequate pain management compared to younger patients.[\nChallenges to safely managing pain in older adult patients\nIn patients able to communicate, pain can be assessed via different tools and pain scales, such as a numeric scale or Visual Analog Scale.[\nA useful framework for managing pain in older adults is to use a patient-centered, holistic, and diverse therapeutic approach that considers potential drug-patient, drug-disease, and drug-drug factors and interactions.\nPutting patients’ desires and interests at the center of conversation by asking what matters the most to them will align clinicians’ care with the patient’s goals. Incorporating what matters to the patient is a cornerstone of the Age-Friendly Health Systems’ “5 Ms” framework that includes: mentation, mobility, medications, multi-complexity, and what matters most.[\nPain and the experience of suffering are multifactorial and personal, and can be exacerbated by emotional distress and other unmet needs. Identifying whether pain is acute or chronic, neuropathic or nociceptive, visceral or somatic can help guide treatment selection. In addition, it is important to address the patient’s other needs, such as food, hydration, and physical comfort.[\nWhen selecting a medication and dose, consider potential interactions between the drug and the patient, such as the patient’s baseline level of frailty or physiologic reserves, their underlying fall risk, and whether they have physiologic tolerance or are naïve to a given class of medications.[\nRenal, hepatic, or cardiac dysfunction; peptic ulcer disease; orthostatic hypotension; and delirium may necessitate medication adjustments. For example, NSAIDs can cause acute renal failure, particularly in the setting of chronic kidney disease (CKD). NSAIDs can also worsen gastritis and peptic ulcer disease. They can also interact with ACE inhibitors, diuretics, steroids, and warfarin, potentially increasing INR for patients on warfarin.\nRenally-cleared opioids such as oxycodone, hydrocodone, and morphine should be used cautiously in patients with chronic kidney disease or end-stage kidney disease, as the medication or its metabolites can have prolonged or more severe adverse effects or sedation.[\nWhen prescribing medications for use over time, as well as a single dose in the ED, it is important to review the patient’s home medication list to look for potential medication interactions. For pain management, high-risk combinations to avoid to prevent oversedation, respiratory depression, or other side effects include opioids with gabapentinoids, muscle relaxants, or benzodiazepines.[\nAfter assessing the patient’s source, severity, and chronicity of pain, aligning with patient goals, and reviewing the underlying drug-patient, drug-drug, and drug-disease factors, emergency clinicians should employ a tiered approach to safely managing their pain. Commonly used analgesics with their starting doses and routes of administration are summarized in\nCommon analgesics with routes of administration and starting doses\nIV: Intravenous, PO: Oral, BID: Twice a day, TID: Three times per day, QHS: Once at night, Q-every, NSAIDs: Nonsteroidal anti-inflammatory drugs, GI: Gastrointestinal, IR: Immediate release\nAddressing unmet physical or emotional needs can help reduce the experience of suffering. Simple interventions such as adjusting the bed or chair for physical comfort, providing warm blankets, and addressing hunger, thirst, or toileting needs. Heating pads, distraction, or reassurance can be useful as well.[\nCertain types of pain are particularly amenable to targeted approaches. For example, femoral or fascia iliaca nerve blocks offer effective analgesia for hip fractures, reducing opioidconsumption.[\nTopical agents, such as diclofenac, can be used alone or as adjuvants for many painful MSK disorders, such as sprains and strains. Topical diclofenac is effective, well-absorbed locally, has little systemic absorption, and reduced side effects.[\nAcetaminophen is a common first-line medication for mild or moderate pain in older adults, as there are few side effects and medication interactions, and it can be used in patients with renal disease. It can be given orally or intravenously and can be used in conjunction with other pain medications for a multi-modal approach.[\nNSAIDs administered orally or parenterally are effective for pain control in the elderly in the ED, with caution in patients with gastric ulcers or renal impairment. NSAIDs are particularly effective for renal colic and other nociceptive (rather than neuropathic) pain.[\nKetamine, when used for acute pain in the ED, provides analgesia comparable to morphine but caries a higher risk of psycho-perceptual side effects such as dizziness, light sedation, or feelings of unreality,[\nGabapentin or pregabalin can be effective for neuropathic pain, but their dosing requires titration. Combinations with benzodiazepines or opioids should be avoided or used with extreme caution.[\nOpioids can be used alone or in conjunction with other treatment modalities for acute moderate or severe pain. Opioid medications carry the risk of sedation, urinary retention, and respiratory depression acutely, as well as tolerance and addiction with chronic use. It is generally wise to begin with a lower initial dose, monitoring, and frequent titration as needed to avoid respiratory depression or sedation.[\nOpioids should also be used for the shortest duration necessary to avoid the risk of addiction or dependence. Tramadol is a weak mu-opioid agonist that is commonly prescribed in the outpatient setting. However, it has significant potential side effects for older adults, including hypoglycemia, hyponatremia, lower seizure threshold, and higher mortality, so it should generally be avoided in favor of safer alternatives.[\nWhen prescribing opioids on discharge, it is important to also prescribe a bowel regimen. A combination of stimulant laxatives, such as senna, and/or an osmotic laxative such as polyethylene glycol, is effective.[\nEffective pain management for older adult patients in the ED requires a comprehensive approach that balances efficacy with safety. By understanding and addressing the unique challenges faced by this population, clinicians can improve patient safety and enhance the quality of care for elderly patients experiencing acute pain. Clinicians should take a patient-centered, holistic approach and consider drug-patient, drug-disease, and drug-drug interactions to help ensure they are selecting the best medication, dose, and duration for each patient.\n\nThorough assessment: Use a holistic approach to assessing a patient’s pain, their desires, and what matters most to them. Both verbal and non-verbal indicators are important, especially in patients with cognitive impairment\nIndividualized treatment plans: Develop treatment plans that consider the patient’s overall health, current medications, and personal preferences. Incorporate both pharmacologic and nonpharmacologic approaches\nDosing strategy: Start with the lowest effective dose, particularly with opioids and sedatives. Reassess or monitor patients frequently and avoid long-term prescriptions when possible\nEducation and communication: Ensure that patients and caregivers understand the treatment plan, potential adverse effects, and the importance of follow-up. On discharge, communicate potential adverse effects and dosing adjustments with the patient and caregiver, such as the risk of dizziness or falls\nDischarge management: For patients who are prescribed an opioid, it is important to also prescribe a stimulant bowel regimen.\nWhile each of the unique and challenging populations requires an individualized treatment plan at discharge from the ED, several important concepts are uniformly applicable to all of them. At discharge, ED clinicians should engage patients in shared decision-making about the nature of their painful syndromes and their expectations with respect to pain relief and functional improvement; commonly used analgesic modalities and their alternatives, as well as short- and long-term adverse effects; and the importance of outpatient follow-up with the specialists (obstetricians and gynecologists, hematologists and sickle-cell specialists, oncologists and palliative care specialists, geriatricians, and pain management specialists with expertise in pain management of these vulnerable groups). In addition, ED clinicians should emphasize the need to return to the ED for re-evaluation in the absence of acceptable pain relief and/or development of severe adverse effects related to prescribed analgesics.\nEffective pain management in special populations requires emergency physicians to adopt tailored approaches that acknowledge the unique physiological, pharmacological, and psychosocial factors affecting these vulnerable groups. For pregnant patients, SCD patients, geriatric individuals, and those requiring cancer or palliative care, standard pain management protocols often prove insufficient or potentially harmful. Implementation of population-specific pain management strategies, early multimodal analgesia, appropriate utilization of non-pharmacological interventions, and interdisciplinary collaboration are essential components of optimal care.\nAs emergency medicine continues to evolve, further research focusing on these special populations will be critical to developing more refined, evidence-based pain management strategies that would improve patient outcomes, minimize adverse effects, and address the persistent disparities in pain management that these populations frequently encounter.\nNone Declared.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "38533351", "pmcid": "12308010", "title": "ISR Modulators in Neurological Diseases", "publication_year": "N/A", "abstract": "The dysfunction of different cells lies in the pathogenesis of neurological diseases and is usually associated with cellular stress. Various stressors trigger the integrated stress response (ISR) signaling, whose highly conserved mechanism is primarily aimed at protecting a stress-exposed cell to cope as safely as possible with such stressful conditions. On the contrary, if a cell is unable to cope with excessive stress, the ISR can induce apoptosis. The ISR mechanism, whose main stage is the inhibition of translation machinery in favor of the synthesis of specific proteins, including the transcription factors ATF3, ATF4, CEBPA, and CEBPB, which function only as dimers and determine the uniqueness of the ISR response in each individual case, thus ensures different outcomes of the ISR. Inhibition of global protein synthesis is achieved through phosphorylation of eIF2α by PERK, HRI, PKR, or GCN2. To date, a number of compounds have been developed that modulate the ISR, including activators and inhibitors of the abovementioned ISR kinases as well as modulators of p-eIF2α dephosphorylation. They target different ISR stages, allowing a broad ISR modulation strategy. At the same time, there are no drugs that are both exceptionally safe and effective for the treatment of several neurological diseases, so there is an urgent need for new approaches to the treatment of these disorders. In this review, we represent ISR signaling as an important participant in the pathogenesis of neurological diseases. We also describe how various ISR modulators may become a part of future therapies for these diseases.", "full_text": "", "content_for_embedding": "The dysfunction of different cells lies in the pathogenesis of neurological diseases and is usually associated with cellular stress. Various stressors trigger the integrated stress response (ISR) signaling, whose highly conserved mechanism is primarily aimed at protecting a stress-exposed cell to cope as safely as possible with such stressful conditions. On the contrary, if a cell is unable to cope with excessive stress, the ISR can induce apoptosis. The ISR mechanism, whose main stage is the inhibition of translation machinery in favor of the synthesis of specific proteins, including the transcription factors ATF3, ATF4, CEBPA, and CEBPB, which function only as dimers and determine the uniqueness of the ISR response in each individual case, thus ensures different outcomes of the ISR. Inhibition of global protein synthesis is achieved through phosphorylation of eIF2α by PERK, HRI, PKR, or GCN2. To date, a number of compounds have been developed that modulate the ISR, including activators and inhibitors of the abovementioned ISR kinases as well as modulators of p-eIF2α dephosphorylation. They target different ISR stages, allowing a broad ISR modulation strategy. At the same time, there are no drugs that are both exceptionally safe and effective for the treatment of several neurological diseases, so there is an urgent need for new approaches to the treatment of these disorders. In this review, we represent ISR signaling as an important participant in the pathogenesis of neurological diseases. We also describe how various ISR modulators may become a part of future therapies for these diseases.", "topic": "Neurodevelopmental_disorder"}
{"pmid": "38434359", "pmcid": "12309153", "title": "Understanding Capabilities, Opportunities, and Motivations of Walking for Physical Activity Among Adults With Intellectual Disabilities: A Qualitative Theory‐Based Study", "publication_year": "N/A", "abstract": "", "full_text": "\n\nThe COM‐B model is a theoretical framework used to understand capabilities, opportunities, and motivations for a behaviour.\nThis study used interviews, photo‐based methods, and a focus group with adults with learning disabilities to apply the COM‐B to walking for physical activity.\nThere are many different capabilities, opportunities, and sources of motivation identified that impact on walking for adults with learning disabilities.\nFrom the perspective of adults with learning disabilities, the important findings were that walking is better when walking in a group, walking should have a purpose (e.g., walking to the shops), that everyone has individual needs, and everyone needs to feel included.\nWalking is a free form of physical activity associated with reduced risk for all‐cause mortality, obesity, diabetes, and major depressive disorder (Kelly et al.\nPrevious interventions to increase walking and physical activity of adults with intellectual disabilities have reported limited effectiveness (Melville et al.\nTestable theoretical frameworks can help to understand how to improve physical activity and walking. The most frequently used theories in lifestyle change interventions with adults with intellectual disabilities are the Transtheoretical Model, Social Cognitive Theory, and Theory of Planned Behaviour (Rana et al.\nIn recent years, researchers have been using a specific theoretical framework called the COM‐B model to understand the social support caregivers provide for physical activity for adults with intellectual disabilities (Bossink et al.\nSummary of COM‐B model.\n\nAt the centre of a wider framework called the Behaviour Change Wheel, which is used to guide intervention development (BCW; Michie et al.\nEthical approval was provided by the University of Glasgow College of Medical, Veterinary, and Life Sciences ethics committee. Additional procedures were in place to facilitate informed consent, such as producing\nAll research team members have expertise in working with adults with intellectual disabilities and/or lifestyle modification. The team included a representative from the non‐profit organisation Values into Action Scotland (VIAS) which supports adults with intellectual disabilities to achieve their goals. Involvement of VIAS helped to ensure the research was relevant and accessible for people with intellectual disabilities.\nThe researcher primarily responsible for data collection and analysis aligns with the philosophical stance of critical realism. Critical realism argues that reality exists independent of the researcher and understanding is shaped by human experiences; however, this understanding can be improved by rigorous research (Lyons and Coyle\nThe qualitative study design enabled understanding of the capabilities, opportunities and motivations for walking from the perspective of adults with intellectual disabilities. As the COM‐B is used in the context of behaviour change interventions, the use of qualitative methods ensured the influences of walking identified reflected people's lived experiences (O'Cathain et al.\nThe study included two data collection pathways, both adopting photo‐elicitation methods. Pathway one: semi‐structured interviews (in‐person or using remote methods) were conducted with researcher‐directed photo‐elicitation methods. Pathway two: participant‐directed photo‐elicitation methods followed by a focus group to discuss the photographs taken. Throughout the process, a reflexive approach to data collection and analysis ensured the process was inclusive and accessible.\nPurposive sampling sought adults (≥ 18 years) who identified as having mild to moderate intellectual disabilities and lived in the Greater Glasgow area. Recruitment and data collection took place between August 2022 and May 2023. Based on the recommendation of VIAS, a small financial incentive of a £20 gift voucher was used.\nFor pathway one, a provisional sample of\nFor pathway two, the tentative sample was\nA demographic questionnaire collected data on participant age, gender identity, residential setting, and post code to calculate the Scottish Index of Multiple Deprivation (SIMD; Scottish Government\nThe interviews involved an initial photo‐elicitation activity and then followed a semi‐structured interview schedule reflecting the COM‐B behavioural diagnosis (see SI File\nThe images represented environmental influences of walking outlined in previous literature (e.g., dogs, weather, green spaces, roads, the dark); three example images are provided in Figure\nExample photographs used to facilitate discussion.\nThe interviews could be conducted in person or remotely using Zoom (a video conferencing platform). The audio of the in‐person interviews was recorded with a Dictaphone, and the remote interviews were recorded over Zoom. The audio recordings allowed the researcher to transcribe the audio verbatim and enabled the transcriptions to be checked for accuracy against the initial recordings. A reflexive approach to data collection allowed for adaptations to the methods. These adaptations included the provision of more context to the questions and greater explanation for the photo elicitation activity.\nIn situ data were gathered during a walk using photograph‐based methods to support adults with intellectual disabilities to be involved in the data collection process (Overmars‐Marx et al.\nData were analysed using the framework approach to thematic analysis as the goal was to map influences of walking onto the existing framework of the COM‐B (Gale et al.\nThe categorisation onto the COM‐B involved reference to the Theoretical Domains Framework (TDF). The TDF is based on the synthesis of existing theories relating to behaviours and behaviour change, and is often used alongside the COM‐B to expand the influences (Cane et al.\nOnce the coding framework was applied to the remaining interview transcripts, a framework matrix was produced using NVIVO. The influences identified for capabilities, opportunities, and motivations to go on a walk were presented by cases (by each participant included in the study). The framework matrix helped to explore the important participant characteristics, such as gender, age, and SIMD. An example excerpt from the matrix for ‘physical opportunities’ has been provided in Appendix\nThe focus group data were analysed using the coding framework developed for the interviews as a guide. The data was treated as separate but complementary to the data collected during the interviews. Therefore, new codes were generated when analysing this data, and not all the existing codes were relevant.\nThroughout the research process there was close collaboration with Values into Action Scotland (VIAS), with a member of VIAS attending all team meetings and involved in all decisions made. There was a separate patient and public involvement (PPI) meeting with people with lived experiences once there were preliminary findings from both the interviews and focus group. This was held in May 2023 at the lead researcher's University, with financial compensation provided for the participants' time. PPI consisted of three adults with intellectual disabilities, with one person attending to provide additional support. The researcher produced easy read slides which were approved in advance by VIAS. Feedback was given on the initial interpretation of the findings, which were integrated into the results.\nA total of 12 adults with mild to moderate intellectual disabilities were interviewed, and nine participants had a source of support present. As can be seen in Table\nDemographic characteristics of interview participants.\nTwo participants requested to support each other.\nParticipant did not disclose postcode.\nPsychological capabilities relate to knowledge, psychological skills, and mental processes (Michie et al.\nI know I'm quite vulnerable, even though I hate that word, I am classed as vulnerable. So like if a stranger come up to me and say do you want to come to my place or do you want to come see my dog …I might tend to go with a stranger if they asked me. [Participant 8]\nWalking influences mapped under Capabilities.\n\nPhysical capabilities in the COM‐B are defined as relating to physical skills, strength, and stamina (Michie et al.\nPhysical opportunities relate to the physical resources people have access to, and more conceptual resources, such as time (Michie et al.\nThere's a wee park up beside me you know, so I walk there and then I walk back down. You know, and just kind of sit about a wee while and then say right. It's not even just that, the fresh air gives you…makes you feel good. [Participant 4]\nWalking influences mapped under Opportunities.\n\nWalking in the dark was seen as either peaceful or unsafe because of poor visibility or due to other people. Gender differences in perceptions of walking in the dark became evident during the analysis. Although two men taking part did appraise the dark as unsafe, the other men participating reported no safety concerns or felt the dark made walking peaceful and relaxing: ‘Really good, I like going out for a walk at night‐time…because it's quiet and nobody's around’. [Participant 10, Man]. Importantly, one of the men felt that walking in the dark was unsafe, but these risks were attributed to women:\n…especially if you were a lady. I've known so many ladies that sadly has walked home by themself at night through like dark allies… The dark ally or the darks path and sadly they've been sexually assaulted, or they've been… it's been all over the Glasgow live [Participant 5, Man]\nReflecting this, all of the women taking part appraised walking in the dark as unsafe with this predominantly linked to other people being dangerous: ‘It's kinda… because it is getting frightening now when you go out, if you understand. You know because you're afraid to go out at night now because you don't know what's going to happen anymore.’ [Participant 4, Woman] Women also described wider safety concerns when walking in isolated areas and on ‘lonely roads’:\nI know, but it's an empty street as well remember. [Participant 6, attending support] ‘Nope. It's a one in five chance that you get attacked and have you read the reports today? There's been more attacks on Glasgow than there was like ten years ago’. [Participant 6, Woman]\nWhile describing physical opportunities, participants also referred to tangible resources, in the form of suitable clothes and water. With participants also referencing the need for wider funding and organisational support, which related to walking groups. However, the need for tangible resources highlighted accessibility concerns, with not everyone having access to the same opportunities and previously available options closing due to the COVID‐19 pandemic: ‘Well, it's just where everything was closed due to COVID’. [Participant 6].\nSocial opportunities are defined as relating to interpersonal influences, cultural and social norms (Michie et al.\nAll participants reported the negative impact of other people, as participants described experiencing harassment and discrimination by members of the public and within the wider perceptions of society: ‘See soon as you get diagnosed with a learning disability you're supposed to go inside, out the road because you're no’ supposed to have the common sense or the way to speak or whatever…’ [Participant 4]\nHaving a dog, or knowing someone with a dog, facilitated walking; however, dogs can pull and make walking difficult. Walking was also facilitated by the presence of walking groups and organisations providing support for people with intellectual disabilities. However, these groups were not available to everyone and many groups closed during the COVID‐19 pandemic.\n… it's nice to walk in a…we enjoyed that again walking in a crowd? Because you heard everybody chatting and so it was nice to chat to the other people as well. No just me. Isn't it, you enjoyed that? [[Participant 6], Attending support]\nAdditionally, level of deprivation contributed to variations in access to these resources. One participant lived in an area classified as ‘least deprived’. Compared to the other participants, the participant had more opportunities through access to football clubs, voluntary working positions, dance classes, youth clubs and walking clubs. Emphasising the impact of financial resources and support availability contributing to disparities in opportunities for walking.\nReflective motivation relates to reflective processes, such as making plans (Michie et al.\nAdditionally, reflective motivation was increased when there was a purpose or a goal, with the most reported being walking to the shops. Another recurrent influence was the impact of walking on physical health benefits, with walking described as being ‘good’ for you, contributing to weight loss and being a form of exercise. ‘Well… when you're sitting you've just got your belly, it's just sitting, but when you're walking you're burning the muscles in your belly and it burns all the fat away. All the fat away… I'll need to start again.’ [Participant 11]\nWalking influences mapped under Motivation.\n\nAutomatic motivation is defined as ‘automatic processes’, which includes emotional reactions (Michie et al.\nSeven participants also described the impact of fear and anxiety on their walking, with fear tied to bad experiences with members of the public that made them feel unsafe, anxiety over catching COVID‐19, and fear of falling and becoming injured.\nSo and then I get feared [scared] to go out if that happens. I mean, being honest with you, I fall in the house so I do. I'm just… I'm clumsy in the house do you know what I mean, because sometimes you trip over your own feet. [Participant 4]\nParticipants involved in this pathway were not involved in pathway two. Five participants took part during this stage which included four men and one woman, aged between 24 and 40 years old. All participants were part of a walking group facilitated by a non‐profit organisation for people with intellectual disabilities. One of the participants was non‐ambulatory and used a wheel chair. During data collection, a source of support was present with each participant along with the organiser of the walking group. Participants had difficulties completing the full demographic questionnaire, so only gender and age were recorded.\nThe focus group described physical capabilities that impacted on capacity to go on a walk. Participants described that some people had visual impairments and emphasised that walking routes need to be accessible, with one member of the walking group trained to identify potential hazards (Table\nExample photographs and illustrative quotes.\n‘I would also… I would also need to know the routes, emm the safety aspects. [Focus group, Participant 1]\n… Keep people safe. [Focus group, Participant 4]’\n‘It was really shaky, and… It was really shaky… but that day, that was really risky.’ [Focus group, Participant 1]\n‘Especially [Focus group, Participant 1], that's your mode for you being able to use your hands to wheel yourself, isn't it? And that's taking away your independence’. [Walking group organiser]\n‘I liked it because em… I liked pretty much all of it really’ [Focus group, Participant 1]\n‘It was good that the weather was nice as well’. [Focus group support]\n‘Well this was a hazard the police shouldn't have been parked in the middle of the pedestrian highway because there was spaces where they could have parked their car and they wouldn't have had to park in the middle of the highway’. [Focus group, Participant 1]\n‘No one's…\n‘When you were on the walk, how did seeing flowers make you feel? [Researcher]\nHappy. I like gold. [Focus group, Participant 4]’\n‘Happy’. [Focus group, Participant 4]\n‘And why is that?’ [Researcher]\n‘Because the colours… Nature’ [Focus group, Participant 4]\n‘All the pink stuff and then it falls on the grass. Oh the pink stuff …the blooms’. [Focus group, Participant 2]\n‘Being together’. [Focus group, Participant 4]\n‘[Focus group, Participant 2] looks forward to it. Before it even starts, he likes talking about it before he goes’. [Focus group, support]\n‘Seeing everyone’. [Focus group, Participant 5]\nParks were considered by participants to be good places to walk, and on the day of the walk, the weather was pleasant, which facilitated walking (Table\nDuring the walk, there were police in the park and the presence of police cars was seen as a potential hazard but the police were described as helping to keep people safe (Table\nThe walk took place during the spring when flowers were in bloom. The researcher was directed to take photographs of the cherry blossoms and other flowers as the sight made the participant ‘happy’ (Table\nThe PPI group agreed with the findings and felt like it captured their experiences of walking. They emphasised that walking in a group helps improve the walking experience, and that there should also be a reason for a walk, such as walking to the shops. The involvement group stressed that everyone has individual needs, and that it is important that everyone feels included.\nThis study was the first to use the COM‐B model to develop a behavioural diagnosis of walking among adults with mild to moderate intellectual disabilities. The findings emphasise the complexity of understanding influences of walking for adults with intellectual disabilities and the need for a flexible theoretical framework. The multiple capabilities, opportunities, and motivations were interacting, with many of the influences identified as unique to the experience of having an intellectual disability.\nPeople involved in the study described how limitations in adaptive skills impacted on their psychological capability to independently walk outdoors. Reduced autonomy, safety concerns, and a reliance on social support can ultimately restrict the opportunities people with intellectual disabilities have for walks (Brooker et al.\nWalking opportunities may also be impacted by gender, with women participants more likely to perceive walking in the dark or on ‘lonely roads’ as unsafe. In research involving people without intellectual disabilities, women and girls feel less safe walking alone in the dark and in greenspaces like parks (Office of National Statistics\nFor all participants, walking was tied to the social opportunity of having consistent social support. However, receiving social support relies on the capabilities, opportunities, and motivation of support providers, along with the wider financial resources available to access meaningful support (Bossink et al.\nNevertheless, opportunities for meeting other people were a main source of reflective motivation and identified as a key priority by the PPI group of people with lived experiences. These findings have important implications as adults with intellectual disabilities are at increased risk of experiencing loneliness and have reduced social connections (Alexandra et al.\nThe reflective motivation of walking with a purpose or reason for a walk was also appraised as an important finding by the PPI group. These findings taken within the wider context of behaviour change could indicate the benefit of behaviour change techniques, such as ‘goal setting’ or ‘action planning’. Goal setting and action planning have been adopted in interventions with people with intellectual disabilities (Rana et al.\nThe PPI group emphasised that everyone has individual needs and that everyone should feel included. Involvement of people with intellectual disabilities in behaviour change research ensures the interventions are accessible and reflect individual needs (Westrop et al.\nThe findings were bound to the specific experiences of adults with mild to moderate intellectual disabilities living in Greater Glasgow, limiting the transferability of the findings. Further research is required to confirm the capabilities, opportunities, and motivations for walking among adults with intellectual disabilities in different contexts. Although a potential intersection between gender and having a disability was observed, the data did not allow for consideration of other intersecting identities such as racial and ethnic identity or level of intellectual disability. The focus group also only included one woman, which reflected the ratio within the walking group.\nThe main implication and strength of this study relates to the application of the COM‐B to understand walking among adults with intellectual disabilities. Specificity is considered important when applying the COM‐B to a behaviour (Michie et al.\nA major strength and implication of this study relates to the involvement of people with lived experiences in the research. Having this involvement helped to ensure the study was accessible and helped to prioritise findings important to people with intellectual disabilities. The use of qualitative methodology further facilitated meaningful involvement and ensured there was flexibility to reflect individual preferences (e.g., option of remote or in‐person interviews).\nThere is a need to adopt accessible methods to facilitate understanding of walking among people with severe and profound intellectual disabilities who were excluded from this study. Researchers must consider the impact of intersecting identities on walking experiences. It is essential for researchers to involve people with lived experiences throughout the research process to ensure findings best reflect the needs and ensure that everyone feels included. More research is required in exploring the applications of the COM‐B in a behaviour change context for adults with intellectual disabilities.\nThe COM‐B is a flexible framework that can be applied to understanding walking for adults with intellectual disabilities. The findings emphasise the complexity of behaviour change in this population, due to many interacting capabilities, opportunities, and motivations. Involvement of people with lived experiences helps to identify the key findings important to people with intellectual disabilities. Future researchers should ensure that all experiences are captured by involving the people experiencing multiple intersecting sources of disadvantage.\nThe authors declare no conflicts of interest.\n\n", "content_for_embedding": "\n\nThe COM‐B model is a theoretical framework used to understand capabilities, opportunities, and motivations for a behaviour.\nThis study used interviews, photo‐based methods, and a focus group with adults with learning disabilities to apply the COM‐B to walking for physical activity.\nThere are many different capabilities, opportunities, and sources of motivation identified that impact on walking for adults with learning disabilities.\nFrom the perspective of adults with learning disabilities, the important findings were that walking is better when walking in a group, walking should have a purpose (e.g., walking to the shops), that everyone has individual needs, and everyone needs to feel included.\nWalking is a free form of physical activity associated with reduced risk for all‐cause mortality, obesity, diabetes, and major depressive disorder (Kelly et al.\nPrevious interventions to increase walking and physical activity of adults with intellectual disabilities have reported limited effectiveness (Melville et al.\nTestable theoretical frameworks can help to understand how to improve physical activity and walking. The most frequently used theories in lifestyle change interventions with adults with intellectual disabilities are the Transtheoretical Model, Social Cognitive Theory, and Theory of Planned Behaviour (Rana et al.\nIn recent years, researchers have been using a specific theoretical framework called the COM‐B model to understand the social support caregivers provide for physical activity for adults with intellectual disabilities (Bossink et al.\nSummary of COM‐B model.\n\nAt the centre of a wider framework called the Behaviour Change Wheel, which is used to guide intervention development (BCW; Michie et al.\nEthical approval was provided by the University of Glasgow College of Medical, Veterinary, and Life Sciences ethics committee. Additional procedures were in place to facilitate informed consent, such as producing\nAll research team members have expertise in working with adults with intellectual disabilities and/or lifestyle modification. The team included a representative from the non‐profit organisation Values into Action Scotland (VIAS) which supports adults with intellectual disabilities to achieve their goals. Involvement of VIAS helped to ensure the research was relevant and accessible for people with intellectual disabilities.\nThe researcher primarily responsible for data collection and analysis aligns with the philosophical stance of critical realism. Critical realism argues that reality exists independent of the researcher and understanding is shaped by human experiences; however, this understanding can be improved by rigorous research (Lyons and Coyle\nThe qualitative study design enabled understanding of the capabilities, opportunities and motivations for walking from the perspective of adults with intellectual disabilities. As the COM‐B is used in the context of behaviour change interventions, the use of qualitative methods ensured the influences of walking identified reflected people's lived experiences (O'Cathain et al.\nThe study included two data collection pathways, both adopting photo‐elicitation methods. Pathway one: semi‐structured interviews (in‐person or using remote methods) were conducted with researcher‐directed photo‐elicitation methods. Pathway two: participant‐directed photo‐elicitation methods followed by a focus group to discuss the photographs taken. Throughout the process, a reflexive approach to data collection and analysis ensured the process was inclusive and accessible.\nPurposive sampling sought adults (≥ 18 years) who identified as having mild to moderate intellectual disabilities and lived in the Greater Glasgow area. Recruitment and data collection took place between August 2022 and May 2023. Based on the recommendation of VIAS, a small financial incentive of a £20 gift voucher was used.\nFor pathway one, a provisional sample of\nFor pathway two, the tentative sample was\nA demographic questionnaire collected data on participant age, gender identity, residential setting, and post code to calculate the Scottish Index of Multiple Deprivation (SIMD; Scottish Government\nThe interviews involved an initial photo‐elicitation activity and then followed a semi‐structured interview schedule reflecting the COM‐B behavioural diagnosis (see SI File\nThe images represented environmental influences of walking outlined in previous literature (e.g., dogs, weather, green spaces, roads, the dark); three example images are provided in Figure\nExample photographs used to facilitate discussion.\nThe interviews could be conducted in person or remotely using Zoom (a video conferencing platform). The audio of the in‐person interviews was recorded with a Dictaphone, and the remote interviews were recorded over Zoom. The audio recordings allowed the researcher to transcribe the audio verbatim and enabled the transcriptions to be checked for accuracy against the initial recordings. A reflexive approach to data collection allowed for adaptations to the methods. These adaptations included the provision of more context to the questions and greater explanation for the photo elicitation activity.\nIn situ data were gathered during a walk using photograph‐based methods to support adults with intellectual disabilities to be involved in the data collection process (Overmars‐Marx et al.\nData were analysed using the framework approach to thematic analysis as the goal was to map influences of walking onto the existing framework of the COM‐B (Gale et al.\nThe categorisation onto the COM‐B involved reference to the Theoretical Domains Framework (TDF). The TDF is based on the synthesis of existing theories relating to behaviours and behaviour change, and is often used alongside the COM‐B to expand the influences (Cane et al.\nOnce the coding framework was applied to the remaining interview transcripts, a framework matrix was produced using NVIVO. The influences identified for capabilities, opportunities, and motivations to go on a walk were presented by cases (by each participant included in the study). The framework matrix helped to explore the important participant characteristics, such as gender, age, and SIMD. An example excerpt from the matrix for ‘physical opportunities’ has been provided in Appendix\nThe focus group data were analysed using the coding framework developed for the interviews as a guide. The data was treated as separate but complementary to the data collected during the interviews. Therefore, new codes were generated when analysing this data, and not all the existing codes were relevant.\nThroughout the research process there was close collaboration with Values into Action Scotland (VIAS), with a member of VIAS attending all team meetings and involved in all decisions made. There was a separate patient and public involvement (PPI) meeting with people with lived experiences once there were preliminary findings from both the interviews and focus group. This was held in May 2023 at the lead researcher's University, with financial compensation provided for the participants' time. PPI consisted of three adults with intellectual disabilities, with one person attending to provide additional support. The researcher produced easy read slides which were approved in advance by VIAS. Feedback was given on the initial interpretation of the findings, which were integrated into the results.\nA total of 12 adults with mild to moderate intellectual disabilities were interviewed, and nine participants had a source of support present. As can be seen in Table\nDemographic characteristics of interview participants.\nTwo participants requested to support each other.\nParticipant did not disclose postcode.\nPsychological capabilities relate to knowledge, psychological skills, and mental processes (Michie et al.\nI know I'm quite vulnerable, even though I hate that word, I am classed as vulnerable. So like if a stranger come up to me and say do you want to come to my place or do you want to come see my dog …I might tend to go with a stranger if they asked me. [Participant 8]\nWalking influences mapped under Capabilities.\n\nPhysical capabilities in the COM‐B are defined as relating to physical skills, strength, and stamina (Michie et al.\nPhysical opportunities relate to the physical resources people have access to, and more conceptual resources, such as time (Michie et al.\nThere's a wee park up beside me you know, so I walk there and then I walk back down. You know, and just kind of sit about a wee while and then say right. It's not even just that, the fresh air gives you…makes you feel good. [Participant 4]\nWalking influences mapped under Opportunities.\n\nWalking in the dark was seen as either peaceful or unsafe because of poor visibility or due to other people. Gender differences in perceptions of walking in the dark became evident during the analysis. Although two men taking part did appraise the dark as unsafe, the other men participating reported no safety concerns or felt the dark made walking peaceful and relaxing: ‘Really good, I like going out for a walk at night‐time…because it's quiet and nobody's around’. [Participant 10, Man]. Importantly, one of the men felt that walking in the dark was unsafe, but these risks were attributed to women:\n…especially if you were a lady. I've known so many ladies that sadly has walked home by themself at night through like dark allies… The dark ally or the darks path and sadly they've been sexually assaulted, or they've been… it's been all over the Glasgow live [Participant 5, Man]\nReflecting this, all of the women taking part appraised walking in the dark as unsafe with this predominantly linked to other people being dangerous: ‘It's kinda… because it is getting frightening now when you go out, if you understand. You know because you're afraid to go out at night now because you don't know what's going to happen anymore.’ [Participant 4, Woman] Women also described wider safety concerns when walking in isolated areas and on ‘lonely roads’:\nI know, but it's an empty street as well remember. [Participant 6, attending support] ‘Nope. It's a one in five chance that you get attacked and have you read the reports today? There's been more attacks on Glasgow than there was like ten years ago’. [Participant 6, Woman]\nWhile describing physical opportunities, participants also referred to tangible resources, in the form of suitable clothes and water. With participants also referencing the need for wider funding and organisational support, which related to walking groups. However, the need for tangible resources highlighted accessibility concerns, with not everyone having access to the same opportunities and previously available options closing due to the COVID‐19 pandemic: ‘Well, it's just where everything was closed due to COVID’. [Participant 6].\nSocial opportunities are defined as relating to interpersonal influences, cultural and social norms (Michie et al.\nAll participants reported the negative impact of other people, as participants described experiencing harassment and discrimination by members of the public and within the wider perceptions of society: ‘See soon as you get diagnosed with a learning disability you're supposed to go inside, out the road because you're no’ supposed to have the common sense or the way to speak or whatever…’ [Participant 4]\nHaving a dog, or knowing someone with a dog, facilitated walking; however, dogs can pull and make walking difficult. Walking was also facilitated by the presence of walking groups and organisations providing support for people with intellectual disabilities. However, these groups were not available to everyone and many groups closed during the COVID‐19 pandemic.\n… it's nice to walk in a…we enjoyed that again walking in a crowd? Because you heard everybody chatting and so it was nice to chat to the other people as well. No just me. Isn't it, you enjoyed that? [[Participant 6], Attending support]\nAdditionally, level of deprivation contributed to variations in access to these resources. One participant lived in an area classified as ‘least deprived’. Compared to the other participants, the participant had more opportunities through access to football clubs, voluntary working positions, dance classes, youth clubs and walking clubs. Emphasising the impact of financial resources and support availability contributing to disparities in opportunities for walking.\nReflective motivation relates to reflective processes, such as making plans (Michie et al.\nAdditionally, reflective motivation was increased when there was a purpose or a goal, with the most reported being walking to the shops. Another recurrent influence was the impact of walking on physical health benefits, with walking described as being ‘good’ for you, contributing to weight loss and being a form of exercise. ‘Well… when you're sitting you've just got your belly, it's just sitting, but when you're walking you're burning the muscles in your belly and it burns all the fat away. All the fat away… I'll need to start again.’ [Participant 11]\nWalking influences mapped under Motivation.\n\nAutomatic motivation is defined as ‘automatic processes’, which includes emotional reactions (Michie et al.\nSeven participants also described the impact of fear and anxiety on their walking, with fear tied to bad experiences with members of the public that made them feel unsafe, anxiety over catching COVID‐19, and fear of falling and becoming injured.\nSo and then I get feared [scared] to go out if that happens. I mean, being honest with you, I fall in the house so I do. I'm just… I'm clumsy in the house do you know what I mean, because sometimes you trip over your own feet. [Participant 4]\nParticipants involved in this pathway were not involved in pathway two. Five participants took part during this stage which included four men and one woman, aged between 24 and 40 years old. All participants were part of a walking group facilitated by a non‐profit organisation for people with intellectual disabilities. One of the participants was non‐ambulatory and used a wheel chair. During data collection, a source of support was present with each participant along with the organiser of the walking group. Participants had difficulties completing the full demographic questionnaire, so only gender and age were recorded.\nThe focus group described physical capabilities that impacted on capacity to go on a walk. Participants described that some people had visual impairments and emphasised that walking routes need to be accessible, with one member of the walking group trained to identify potential hazards (Table\nExample photographs and illustrative quotes.\n‘I would also… I would also need to know the routes, emm the safety aspects. [Focus group, Participant 1]\n… Keep people safe. [Focus group, Participant 4]’\n‘It was really shaky, and… It was really shaky… but that day, that was really risky.’ [Focus group, Participant 1]\n‘Especially [Focus group, Participant 1], that's your mode for you being able to use your hands to wheel yourself, isn't it? And that's taking away your independence’. [Walking group organiser]\n‘I liked it because em… I liked pretty much all of it really’ [Focus group, Participant 1]\n‘It was good that the weather was nice as well’. [Focus group support]\n‘Well this was a hazard the police shouldn't have been parked in the middle of the pedestrian highway because there was spaces where they could have parked their car and they wouldn't have had to park in the middle of the highway’. [Focus group, Participant 1]\n‘No one's…\n‘When you were on the walk, how did seeing flowers make you feel? [Researcher]\nHappy. I like gold. [Focus group, Participant 4]’\n‘Happy’. [Focus group, Participant 4]\n‘And why is that?’ [Researcher]\n‘Because the colours… Nature’ [Focus group, Participant 4]\n‘All the pink stuff and then it falls on the grass. Oh the pink stuff …the blooms’. [Focus group, Participant 2]\n‘Being together’. [Focus group, Participant 4]\n‘[Focus group, Participant 2] looks forward to it. Before it even starts, he likes talking about it before he goes’. [Focus group, support]\n‘Seeing everyone’. [Focus group, Participant 5]\nParks were considered by participants to be good places to walk, and on the day of the walk, the weather was pleasant, which facilitated walking (Table\nDuring the walk, there were police in the park and the presence of police cars was seen as a potential hazard but the police were described as helping to keep people safe (Table\nThe walk took place during the spring when flowers were in bloom. The researcher was directed to take photographs of the cherry blossoms and other flowers as the sight made the participant ‘happy’ (Table\nThe PPI group agreed with the findings and felt like it captured their experiences of walking. They emphasised that walking in a group helps improve the walking experience, and that there should also be a reason for a walk, such as walking to the shops. The involvement group stressed that everyone has individual needs, and that it is important that everyone feels included.\nThis study was the first to use the COM‐B model to develop a behavioural diagnosis of walking among adults with mild to moderate intellectual disabilities. The findings emphasise the complexity of understanding influences of walking for adults with intellectual disabilities and the need for a flexible theoretical framework. The multiple capabilities, opportunities, and motivations were interacting, with many of the influences identified as unique to the experience of having an intellectual disability.\nPeople involved in the study described how limitations in adaptive skills impacted on their psychological capability to independently walk outdoors. Reduced autonomy, safety concerns, and a reliance on social support can ultimately restrict the opportunities people with intellectual disabilities have for walks (Brooker et al.\nWalking opportunities may also be impacted by gender, with women participants more likely to perceive walking in the dark or on ‘lonely roads’ as unsafe. In research involving people without intellectual disabilities, women and girls feel less safe walking alone in the dark and in greenspaces like parks (Office of National Statistics\nFor all participants, walking was tied to the social opportunity of having consistent social support. However, receiving social support relies on the capabilities, opportunities, and motivation of support providers, along with the wider financial resources available to access meaningful support (Bossink et al.\nNevertheless, opportunities for meeting other people were a main source of reflective motivation and identified as a key priority by the PPI group of people with lived experiences. These findings have important implications as adults with intellectual disabilities are at increased risk of experiencing loneliness and have reduced social connections (Alexandra et al.\nThe reflective motivation of walking with a purpose or reason for a walk was also appraised as an important finding by the PPI group. These findings taken within the wider context of behaviour change could indicate the benefit of behaviour change techniques, such as ‘goal setting’ or ‘action planning’. Goal setting and action planning have been adopted in interventions with people with intellectual disabilities (Rana et al.\nThe PPI group emphasised that everyone has individual needs and that everyone should feel included. Involvement of people with intellectual disabilities in behaviour change research ensures the interventions are accessible and reflect individual needs (Westrop et al.\nThe findings were bound to the specific experiences of adults with mild to moderate intellectual disabilities living in Greater Glasgow, limiting the transferability of the findings. Further research is required to confirm the capabilities, opportunities, and motivations for walking among adults with intellectual disabilities in different contexts. Although a potential intersection between gender and having a disability was observed, the data did not allow for consideration of other intersecting identities such as racial and ethnic identity or level of intellectual disability. The focus group also only included one woman, which reflected the ratio within the walking group.\nThe main implication and strength of this study relates to the application of the COM‐B to understand walking among adults with intellectual disabilities. Specificity is considered important when applying the COM‐B to a behaviour (Michie et al.\nA major strength and implication of this study relates to the involvement of people with lived experiences in the research. Having this involvement helped to ensure the study was accessible and helped to prioritise findings important to people with intellectual disabilities. The use of qualitative methodology further facilitated meaningful involvement and ensured there was flexibility to reflect individual preferences (e.g., option of remote or in‐person interviews).\nThere is a need to adopt accessible methods to facilitate understanding of walking among people with severe and profound intellectual disabilities who were excluded from this study. Researchers must consider the impact of intersecting identities on walking experiences. It is essential for researchers to involve people with lived experiences throughout the research process to ensure findings best reflect the needs and ensure that everyone feels included. More research is required in exploring the applications of the COM‐B in a behaviour change context for adults with intellectual disabilities.\nThe COM‐B is a flexible framework that can be applied to understanding walking for adults with intellectual disabilities. The findings emphasise the complexity of behaviour change in this population, due to many interacting capabilities, opportunities, and motivations. Involvement of people with lived experiences helps to identify the key findings important to people with intellectual disabilities. Future researchers should ensure that all experiences are captured by involving the people experiencing multiple intersecting sources of disadvantage.\nThe authors declare no conflicts of interest.\n\n", "topic": "Neurodevelopmental_disorder"}