{"pmid": "40736876", "pmcid": "12309640", "title": "Dose‐Response Association of Handgrip Strength With Alzheimer's Disease: A Longitudinal Study Involving 85,979 Adults", "publication_year": "N/A", "abstract": "", "full_text": "Alzheimer's disease (AD) is a neurodegenerative disorder characterised by global cognitive decline, personality changes and progressive memory loss [\nPeople with AD, even at an early stage, have a higher prevalence of sarcopenia than cognitively intact people of the same age [\nIn this regard, handgrip strength is a reliable marker of general muscle strength in adults [\nA growing number of studies suggest that a low level of handgrip strength is associated with increased incidence of all‐cause dementia and AD in middle‐aged men and women [\nThe present study included data from waves 1, 2, 4, 5, 6, 7 and 8 from the Survey of Health, Ageing and Retirement in Europe (SHARE) [\nStudy profile.\nTrained interviewers measured handgrip strength twice for each hand using a handheld dynamometer (Smedley, S Dynamometer, TTM, Tokyo, 100 kg). In accordance with the SHARE protocol, participants were instructed to either stand or sit with the elbow flexed at a 90° angle, maintaining a neutral wrist position and the upper arm perpendicular to the trunk. The interviewers used standardised verbal instructions to encourage participants to squeeze the dynamometer with maximum effort for a few seconds. The device was calibrated according to SHARE protocol. Handgrip strength was considered as the maximum value of either hand, regardless of hand dominance.\nParticipants were followed throughout the study period to determine whether they developed AD. This was determined through the following question that participants responded to in each SHARE wave: ‘\nThe possible responses were ‘\nAccording to a previous literature review [\nWe conducted all statistical analyses in Stata version 16.1 (StataCorp, Texas, USA). We used a Cox regression to estimate the hazard ratios (HRs) for AD while accounting for repeated measures of handgrip strength. Participants were censored at either final follow‐up or date of death. Time‐on‐study in months was used as the timescale. We examined the proportional hazards assumption by testing interactions with log(time) and found no evidence of assumption violation. Because we detected an interaction between handgrip strength and age using a Wald test, we conducted all the analyses stratified by age. Thus, age was categorised into two subgroups using the cut‐off point of 65 years, which is considered as a critical age in longitudinal studies on AD [\nTo check consistency of the estimates, we conducted a complete‐case analysis, which showed. Moreover, to minimise the potential influence of reverse causality, we excluded 2 years of follow‐up from the analyses. To depict the progression of AD over time, we plotted a Kaplan‐Meier survival function plot by handgrip strength category.\nOverall, 85,979 participants were followed‐up during a median of 9.3 years (Interquartile range 5.7–10.0) (484,151 persons/years), in which 3324 (3.9%) developed AD. At study entry, average age was 66.9 (SD 9.9) of whom 55.8% were women. Table\nCharacteristics of participants at study entry (\n\nBased on ISCED 1997 classification.\nFigure\nProspective associations between handgrip strength (kg) and Alzheimer's disease (Crude model). Models adjusted for age and sex. Missing values were imputed.\nProspective associations between handgrip strength (kg) and Alzheimer's disease (Adjusted model). Model adjusted for age, sex, country, education, body mass index, smoking habit, alcohol consumption, physical inactivity, fruits and vegetables consumption, and number of chronic conditions. Missing values were imputed.\nThe spline model determined that the minimum and optimal doses of handgrip strength for a significant reduction in the risk of AD for those aged < 65 years were 54 kg (HR = 0.99; 95% CI: 0.08–0.99) and 56 kg (HR = 0.27; 95% CI: 0.08–0.91), respectively (Figure\n(A) Dose–response association (Adjusted hazard ratios and associated 95% confidence interval band) between handgrip strength (kg) and Alzheimer's disease in men aged between 50 and 64 years. (B) Dose–response association (Adjusted hazard ratios and associated 95% confidence interval band) between handgrip strength (kg) and Alzheimer's disease in women aged 65 years or over. Adjusted for Model B (age, country, education, body mass index, smoking habit, alcohol consumption, physical inactivity, fruits and vegetables consumption, and number of chronic conditions.). Missing values were imputed. Reference 20 kg hr = hazard ratio lb/ub = lower boundary/upper boundary.\nSensitivity analyses showed scarce variations with regards to the main analyses. Complete‐case analysis exhibited particularly higher risk reductions for the upper third in participants aged < 65 years (Figure\nOur study examined the longitudinal association between handgrip strength and the development of AD using repeated measures in a relatively large and representative sample of middle‐aged and older adults in Europe. A significant association was identified between having higher handgrip strength and a lower risk of developing AD in both middle‐aged and older adults. These results are consistent with published studies that included participants from the UK Biobank [\nThe risk of progression depends on several modulating factors (e.g. increasing age, frailty, cognitive reserve, copathology, presence of neurodegeneration markers and protective genes, among others) [\nConsistent with our findings, a recent prospective cohort study from the UK Biobank showed that lower hand grip strength was significantly associated with an increased risk of early onset dementia [\nOne of the main neuropathological features of AD is the extracellular accumulation of senile plaques around neurons and glia due to the accumulation of insoluble β‐amyloid protein [\nA recent meta‐analysis of longitudinal cohort studies showed that people with lower strength were more likely to develop AD [\nFinally, several mechanisms have been proposed to explain the association between handgrip strength and a reduced risk of developing AD. Handgrip strength is a measure of overall muscle strength [\nThis study used a large representative cohort of European adults providing objectively measured handgrip strength. Our analyses accounted for time‐varying confounding of a wide set of covariates and attempted to address potential reversal causation. On the other hand, the present study should be considered in the light of several limitations. First, although we used relevant potential time‐varying confounders to adjust our models, there is a possibility for both residual and time‐varying confounding. Second, the diagnosis of AD was based on self‐report of medical diagnosis recorded in the SHARE survey. Since the outcome was obtained through a proxy‐relative, there is still a chance for a certain degree of misclassification bias. This limitation should be considered when interpreting the results. Third, the estimations obtained in this study are limited to the range of values assessed within the participants. Fourth, since SHARE survey only collects data from participants aged 50 years and older, generalisations over younger populations are not adequate. Thus, studies examining higher handgrip strength values might add more knowledge to this issue. Fourthly, owing to the lower number of AD cases on participants aged lower than 65 years, the uncertainty of the estimates for this category is higher than for older adults and thus less accurate. Furthermore, it is important to recognize the potential bidirectional relationship between hand grip strength and cognitive impairment, whereby lower muscle strength may contribute to cognitive impairment and, conversely, early cognitive impairment may result in decreased physical function and strength [\nThis longitudinal study found a strong association between higher levels of handgrip strength and a lower risk of developing AD. However, the dose‐response relationship is limited to specific ranges according to age group. We identified a range between 54 and 56 kg years and a range between 31 and 49 kg as suitable to prevent AD in adults aged 50–64 and ≥ 65 years, respectively. These findings may provide information on appropriate levels of handgrip strength in middle‐aged and older adults to guide tailored treatment and prevention strategies. In addition, incorporating routine assessment of hand grip strength into clinical practice could help healthcare professionals identify individuals at increased risk of AD. Early interventions aimed at improving or maintaining muscle strength, especially through structured strength training programmes, may be an accessible and low‐cost approach to support cognitive health and reduce the risk of dementia in middle‐aged and older populations.\nThe authors declare no conflicts of interest.\nFigure S1\nFigure S2\nFigure S3", "content_for_embedding": "Alzheimer's disease (AD) is a neurodegenerative disorder characterised by global cognitive decline, personality changes and progressive memory loss [\nPeople with AD, even at an early stage, have a higher prevalence of sarcopenia than cognitively intact people of the same age [\nIn this regard, handgrip strength is a reliable marker of general muscle strength in adults [\nA growing number of studies suggest that a low level of handgrip strength is associated with increased incidence of all‐cause dementia and AD in middle‐aged men and women [\nThe present study included data from waves 1, 2, 4, 5, 6, 7 and 8 from the Survey of Health, Ageing and Retirement in Europe (SHARE) [\nStudy profile.\nTrained interviewers measured handgrip strength twice for each hand using a handheld dynamometer (Smedley, S Dynamometer, TTM, Tokyo, 100 kg). In accordance with the SHARE protocol, participants were instructed to either stand or sit with the elbow flexed at a 90° angle, maintaining a neutral wrist position and the upper arm perpendicular to the trunk. The interviewers used standardised verbal instructions to encourage participants to squeeze the dynamometer with maximum effort for a few seconds. The device was calibrated according to SHARE protocol. Handgrip strength was considered as the maximum value of either hand, regardless of hand dominance.\nParticipants were followed throughout the study period to determine whether they developed AD. This was determined through the following question that participants responded to in each SHARE wave: ‘\nThe possible responses were ‘\nAccording to a previous literature review [\nWe conducted all statistical analyses in Stata version 16.1 (StataCorp, Texas, USA). We used a Cox regression to estimate the hazard ratios (HRs) for AD while accounting for repeated measures of handgrip strength. Participants were censored at either final follow‐up or date of death. Time‐on‐study in months was used as the timescale. We examined the proportional hazards assumption by testing interactions with log(time) and found no evidence of assumption violation. Because we detected an interaction between handgrip strength and age using a Wald test, we conducted all the analyses stratified by age. Thus, age was categorised into two subgroups using the cut‐off point of 65 years, which is considered as a critical age in longitudinal studies on AD [\nTo check consistency of the estimates, we conducted a complete‐case analysis, which showed. Moreover, to minimise the potential influence of reverse causality, we excluded 2 years of follow‐up from the analyses. To depict the progression of AD over time, we plotted a Kaplan‐Meier survival function plot by handgrip strength category.\nOverall, 85,979 participants were followed‐up during a median of 9.3 years (Interquartile range 5.7–10.0) (484,151 persons/years), in which 3324 (3.9%) developed AD. At study entry, average age was 66.9 (SD 9.9) of whom 55.8% were women. Table\nCharacteristics of participants at study entry (\n\nBased on ISCED 1997 classification.\nFigure\nProspective associations between handgrip strength (kg) and Alzheimer's disease (Crude model). Models adjusted for age and sex. Missing values were imputed.\nProspective associations between handgrip strength (kg) and Alzheimer's disease (Adjusted model). Model adjusted for age, sex, country, education, body mass index, smoking habit, alcohol consumption, physical inactivity, fruits and vegetables consumption, and number of chronic conditions. Missing values were imputed.\nThe spline model determined that the minimum and optimal doses of handgrip strength for a significant reduction in the risk of AD for those aged < 65 years were 54 kg (HR = 0.99; 95% CI: 0.08–0.99) and 56 kg (HR = 0.27; 95% CI: 0.08–0.91), respectively (Figure\n(A) Dose–response association (Adjusted hazard ratios and associated 95% confidence interval band) between handgrip strength (kg) and Alzheimer's disease in men aged between 50 and 64 years. (B) Dose–response association (Adjusted hazard ratios and associated 95% confidence interval band) between handgrip strength (kg) and Alzheimer's disease in women aged 65 years or over. Adjusted for Model B (age, country, education, body mass index, smoking habit, alcohol consumption, physical inactivity, fruits and vegetables consumption, and number of chronic conditions.). Missing values were imputed. Reference 20 kg hr = hazard ratio lb/ub = lower boundary/upper boundary.\nSensitivity analyses showed scarce variations with regards to the main analyses. Complete‐case analysis exhibited particularly higher risk reductions for the upper third in participants aged < 65 years (Figure\nOur study examined the longitudinal association between handgrip strength and the development of AD using repeated measures in a relatively large and representative sample of middle‐aged and older adults in Europe. A significant association was identified between having higher handgrip strength and a lower risk of developing AD in both middle‐aged and older adults. These results are consistent with published studies that included participants from the UK Biobank [\nThe risk of progression depends on several modulating factors (e.g. increasing age, frailty, cognitive reserve, copathology, presence of neurodegeneration markers and protective genes, among others) [\nConsistent with our findings, a recent prospective cohort study from the UK Biobank showed that lower hand grip strength was significantly associated with an increased risk of early onset dementia [\nOne of the main neuropathological features of AD is the extracellular accumulation of senile plaques around neurons and glia due to the accumulation of insoluble β‐amyloid protein [\nA recent meta‐analysis of longitudinal cohort studies showed that people with lower strength were more likely to develop AD [\nFinally, several mechanisms have been proposed to explain the association between handgrip strength and a reduced risk of developing AD. Handgrip strength is a measure of overall muscle strength [\nThis study used a large representative cohort of European adults providing objectively measured handgrip strength. Our analyses accounted for time‐varying confounding of a wide set of covariates and attempted to address potential reversal causation. On the other hand, the present study should be considered in the light of several limitations. First, although we used relevant potential time‐varying confounders to adjust our models, there is a possibility for both residual and time‐varying confounding. Second, the diagnosis of AD was based on self‐report of medical diagnosis recorded in the SHARE survey. Since the outcome was obtained through a proxy‐relative, there is still a chance for a certain degree of misclassification bias. This limitation should be considered when interpreting the results. Third, the estimations obtained in this study are limited to the range of values assessed within the participants. Fourth, since SHARE survey only collects data from participants aged 50 years and older, generalisations over younger populations are not adequate. Thus, studies examining higher handgrip strength values might add more knowledge to this issue. Fourthly, owing to the lower number of AD cases on participants aged lower than 65 years, the uncertainty of the estimates for this category is higher than for older adults and thus less accurate. Furthermore, it is important to recognize the potential bidirectional relationship between hand grip strength and cognitive impairment, whereby lower muscle strength may contribute to cognitive impairment and, conversely, early cognitive impairment may result in decreased physical function and strength [\nThis longitudinal study found a strong association between higher levels of handgrip strength and a lower risk of developing AD. However, the dose‐response relationship is limited to specific ranges according to age group. We identified a range between 54 and 56 kg years and a range between 31 and 49 kg as suitable to prevent AD in adults aged 50–64 and ≥ 65 years, respectively. These findings may provide information on appropriate levels of handgrip strength in middle‐aged and older adults to guide tailored treatment and prevention strategies. In addition, incorporating routine assessment of hand grip strength into clinical practice could help healthcare professionals identify individuals at increased risk of AD. Early interventions aimed at improving or maintaining muscle strength, especially through structured strength training programmes, may be an accessible and low‐cost approach to support cognitive health and reduce the risk of dementia in middle‐aged and older populations.\nThe authors declare no conflicts of interest.\nFigure S1\nFigure S2\nFigure S3", "topic": "Diagnostic"}
{"pmid": "37848293", "pmcid": "12302809", "title": "Exploring Characteristics, Services And Outcome Indicators Of Global Functioning In Adults With Autism Spectrum Disorders: Insights From A Group Of 503 Patients", "publication_year": "2025", "abstract": "", "full_text": "Autism Spectrum Disorders (ASD) are broad neurodevelopmental disorders characterized by lifelong difficulties in communicative-relational abilities and patterns of restricted and repetitive interests and activities (DSM-5;\nAs with other clinical situations, ASD also involves factors that influence life outcomes and developmental trajectories: the severity of the symptoms can affect a person's functioning to a greater or lesser extent across all stages of life while also being influenced by various external contextual variables, thereby impacting global functioning (\nThe term \"Global Functioning” covers an individual's psychological, social, and occupational functioning, irrespective of any disorder (\nEvaluating global functioning allows for identifying the impact of the disorders and their symptoms on the patient’s life, suggesting interventions and/or treatment plans while verifying their effectiveness in terms of outcomes (\nAccording to literature, outcomes, life trajectories, and global functioning for individuals with ASD can vary significantly depending on various external factors, including the age of diagnosis, early interventions, family support, community services and resources, and access to rehabilitation, educational, and training programs (\nFurthermore, ASD people may encounter various challenges in their lives due to individual factors such as differences in sensory processing, neuropsychological features, and the degree of impairment in linguistic and communicative abilities − which can vary significantly from one individual to another − (Howlin & Magiati, 2017;\nBoth external and individual factors can strongly influence the outcomes and life trajectories of subjects with ASD.\nSubjects with ASD may require varying degrees of support to address environmental challenges, seemingly irrespective of intelligence level. Indeed, the cognitive profile of ASD individuals varies from extreme intellectual disability to profiles well above average (\nAs recently highlighted, ASD adults may present comorbid symptoms such as psychopathological symptoms, personality disorders, psychosis, mood and anxiety disorders, obsessive-compulsive disorder, and other neurodevelopmental disorders in co-occurrence such as ADHD and Specific Learning Disorders (\nSeveral interventions are implemented, both pharmacological and non-pharmacological, with varying levels of evidence (see\nSocial and affective relationships impact physical and mental health in subjects with ASD (\nFamily and social support are often crucial for subjects with ASD in adulthood. Access to family and community support networks can play a fundamental role in defining outcomes for adult subjects with ASD, significantly influencing quality of life (\nSubjects with ASD often exhibit atypical sensory processing modalities (APA, 2013), which can significantly influence their interactions with the surrounding world and their daily experiences. These atypicalities may involve different sensory modalities and vary among individuals (\nSensory difficulties can impact the quality of life and developmental trajectories by reducing opportunities for community participation and employment opportunities (\nAdults with ASD may achieve various occupational outcomes, including high levels of education and significant employment positions. However, some may face challenges in finding and maintaining stable employment. Support programs, guidance, and vocational training are among the various variables that can affect the occupational outcomes of subjects with ASD (\nIndividuals with ASD may demonstrate variable levels of autonomy and independence in managing daily life. Some may live relatively independently, managing their personal needs and finances, working autonomously, and residing independently. In contrast, others may require significant support and live in group housing (\nAt the medical level, a higher prevalence of pathologies is identified in individuals with ASD compared to the general population, and it increases with age (\nAll these aspects strongly impact functional adaptation in various life domains and also affect the quality of life of ASD people and their families.\nAs Howlin and Magiati (2017) highlighted, the literature lacks studies examining outcomes for adult individuals with autism.\nAttention has recently been focused on the transition into adulthood and across the lifespan for ASD. This has led to a lack of implementation of personalized interventions (\nThe primary purpose of this study is to conduct a survey and investigate the main characteristics and types of functioning, as well as the types of services and interventions that subjects with ASD in adulthood have utilized or are currently utilizing at the Adult Autism Center in Turin. Additionally, we used the collected data to preliminarily analyze and identify internal and external factors that enhance outcomes for individuals with autism and their impact on global functioning.\nBetween January and October 2022, a total of 503 subjects with ASD in adulthood (mean age = 27.8, SD = 8.62) participated in the research.\nAll participants provided their informed consent to take part in the study and all procedures performed in the study were conducted in compliance with privacy regulations, ethical standards and in accordance with the 1964 Helsinki Declaration and its later amendments or comparable ethical standards.\nThe sample included 123 females (24.45%; mean age = 29.8, SD = 8.30) and 380 males (75.55%; mean age = 27.2, SD = 8.64). The female/male ratio is 1:4. All participants received ASD diagnosis from the Regional Center for Autism Spectrum Disorder in Turin according to Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition (DSM-5) (APA, 2013) criteria following a structured diagnostic pathway (Multistep Network Model-\nMean and SD of age and educational level of the entire sample (n=503)\nThe participants' mean age at diagnosis is 14.00 years (SD = 12.54), and the mean number of years under the Adult Autism Service is 3.88 (SD = 2.63).\nGlobal Assessment of Functioning. The Global Assessment of Functioning Scale (GAF;\nTo guide the interview and data collection, licensed psychologists and clinicians of the Adult Autism Center built and filled out an ad hoc checklist to assign the GAF score. Clinical records and telephonic interviews with participants, caregivers, and therapists were the primary sources of information. Several variables were collected on the checklist to define functioning profiles (see\nDescriptive analysis of the investigated variables\nCategorical variables are expressed as absolute numbers, percentages, and means and standard deviation for continuous data.\nUnivariate and multiple Linear regression models were performed to identify factors independently associated with GAF in the overall sample. The correlation between variables was checked. Multivariate analyses were adjusted for all variables in the model. Results with a p-value < 0.05 were considered statistically significant; all p-values were two-tailed.\nAll statistical analyses were performed using STATA software (Stata Corporation, College Station, TX, USA).\nThe results of the information gathered using the checklist to complete the GAF are summarized in the\nTo conduct an appropriate multivariate analysis, we selected variables that the literature has shown to impact global functioning significantly. Specifically, we included internal (education, level of diagnosis, level of communication, comorbidity, use of psychotropic medications, type of challenging behaviours, co-occurrence with neurodevelopmental disorders, peer relationships) and external (living environment, family composition and partners, work and job training, sport, habilitative interventions, age at first diagnosis) variables.\nWe set a reference level for each variable, which was considered the most significant outcome. The significance was not intended to be the best or most positive outcome per se. Still, it was set considering the evidence in the literature to measure the impact of certain variables on the outcomes.\nIn\nMultivariate analysis results\n°= Reference level; Significant at * p < .05, ** p < .001.\nSeveral variables have demonstrated a statistically significant impact on the outcomes of ASD adults as measured by clinicians' scoring on the Global Assessment of Functioning (GAF) scale. As previously indicated, based on the literature, we established a reference level considered the most significant outcome. We assessed the influence of each variable on the total assigned GAF score.\nAt a significance level of\nThe impact of communication skills on the Global Assessment of Functioning scale is significant. Specifically, minimal meaningful communication can result in a decrease of -15.99 points on the GAF scale.\nOn the other hand, the ability to communicate about a restricted number of topics results in a more minor but still statistically significant decrease of -6.66 points on the GAF scale.\nNot taking psychotropic drugs is associated with a decrease in GAF scores by -4.69 points.\nThe presence of comorbidities significantly and negatively impacts the outcome, leading to a decrease in GAF scores by -4.51 points.\nThe co-occurrence with other neurodevelopmental disorders worsens GAF scores by -4.51 points. Not having a partner worsens GAF scores by -7.81 points.\nNot having a social network negatively impacts GAF scores: having no friends worsens the outcome by -13.87 points, and having only one friend worsens it by -9.37 points.\nAt a significance level of\nLiving in a group home provided by social services significantly worsens the outcome by -17.72 points.\nNot having a job decreases GAF scores by -4.64 points, and not being enrolled in training courses decreases GAF scores by 3.79.\nFurthermore, self-injurious and hetero-injurious behaviours adversely affect functioning, decreasing GAF scores by -5.18 points (self-injurious) and 4.79 points (hetero-injurious).\nPsychotherapy in adulthood appears to have a positive impact, as those who did not undergo such treatment experienced a decrease in GAF scores by -8.92 points: this data should be carefully interpreted, considering that only a few subjects had access to psychotherapy.\nConversely, in our analysis, we did not find a significant impact on the scores assigned to GAF for certain variables, including gender, age, years of schooling, age at first diagnosis, some living arrangements (alone, with partner/roommates/family), attending sports, presence of medical conditions. Similarly, we did not observe effects on the outcomes of specific treatments such as speech therapy in childhood, educational interventions in childhood, psychological counselling in adulthood or psychomotor therapy in childhood.\nOur study collected various information related to demographic variables, functioning profiles, diagnostic characteristics, comorbidities, and interventions and services in 503 patients with ASD in adulthood.\n75.5% of the participants are male: this highlights the need to further investigate the female population with autism, which is generally underrepresented not only in clinical settings but also in research (\nIn terms of needed support over half of the individuals received a diagnosis of level 1 autism (56.6%) according to DSM 5 (APA, 2013). A significant variability in global functioning among adults with ASD, was measured by the GAF scale. Levels of required support demonstrated a profound impact on GAF scores, with individuals diagnosed with Level 3 ASD (20.68%) showing a decrease of -25.05 points and those with Level 2 ASD (23.26%) a decrease of -8.74 points compared to Level 1. This finding emphasizes the critical role of tailored interventions to address the needs of individuals requiring higher support, consistent with previous studies highlighting the heterogeneity of functional outcomes in ASD populations (Howlin & Magiati, 2017).\nAs mentioned earlier, we did not find significant effects of gender, age, and education level on the scores obtained on the GAF, contrary to what was observed for the level of support needed. For example, regarding gender, this data can be interpreted by highlighting that, contrary to common belief, autistic females may exhibit difficulties in adapting to daily life contexts and require support just like males, despite the belief that women display more subtle symptomatology. Another consideration is that autistic individuals require guaranteed support from a lifelong perspective, regardless of age or the level of education achieved.\nIn addition to the autism diagnosis, approximately half of the participants exhibit physical illnesses (42.74%) that are often associated with autism diagnosis (including epilepsy, gastrointestinal disorders, and celiac disease) (\nThese findings open new avenues for research into the structural and systemic health challenges that may coexist with autism. Given the complexity of autism and its associated conditions, the importance of personalized assessment of subjects with autism in adulthood needs becomes evident for designing effective and targeted interventions (\nPsychological comorbidities and/or those related to other neurodevelopmental disorders are present in the majority of cases. Regarding psychiatric comorbidities, 63.0% of participants reported at least one co-occurring psychopathological or neurodevelopmental disorder, which was associated with a decrease of -4.51 points in GAF scores.\nThese results are in line with the existing literature. In fact,\nPsychotic spectrum disorders, including schizotypal and schizoid traits, are similarly prevalent, further underscoring the complexity of clinical presentations in this population. Recent studies have reported a high prevalence of autistic traits and autism spectrum disorder among individuals with psychosis, with significantly higher rates compared to the general population (\nThese findings emphasize the importance of a comprehensive evaluation of psychological and neurodevelopmental disorders during the diagnosis and management of autism, ensuring that comorbid conditions are identified and addressed to improve functional outcomes and overall quality of life.\nLocation of residence varies within the sample; most individuals live in urban settings (56.86%) and reside with their born family (80.2%). Conversely, 25.25% inhabit apartments in towns surrounding the capital. A smaller portion, 3.98%, reside in standalone houses within the capital city, while 6.16% live in standalone houses in rural areas. Additionally, 6.76% of the sample reside in therapeutic communities, and approximately 1% reside in apartment complexes provided by the National Health System or City Council.\nAdditionally, 5.17% live within therapeutic communities, 3.38% have roommates or live with a friend, and 4.17% live with their partner.\nContrary to the goals of life planning and intervention programs, only a very tiny minority of subjects with ASD in adulthood live independently (6.69% of the sample) and less than half of the patients (37.75%) can independently complete tasks or activities related to self-care and managing the domestic environment.\nThe same results are observed concerning work-life: only a minimal percentage (18.89%) is currently employed or enrolled in vocational training or upgrading (in a training course).\nEmployment status further influenced functioning, with unemployed individuals showing a decrease of -4.64 points in GAF scores and those not enrolled in any vocational training or upgrading courses experiencing a decrease of -3.79 points.\nOnly 21.47% of participants had been employed in the past, and 83.90% had not participated in any professional training after completing their schooling.\nRegarding the composition of the family, 30.42% of subjects are only child, 52.68% have only one sibling, 12.92% have two siblings, 2.78% have three siblings, while 0.80% and 0.40% respectively have 4 or 5 siblings. Among these, 34.00% are firstborn, 32.42% are second-born, 4.37% are third-born, 1.99% are fourth-born, and 0.20% are fifth-born.\nCommunication abilities also emerged as a factor influencing global functioning of subjects with ASD. Participants with minimal communication skills exhibited a significant decrease in GAF scores by -15.99 points compared to those able to discuss a wide variety of topics, while those with restricted communication abilities showed a decrease of -6.66 points. However, only 2.58% of participants who did not use spoken language employed an alternative communication system, revealing a substantial gap in the availability and use of assistive communication tools. Integrating a personalized communication system is crucial to facilitate effective communication for individuals with ASD who may have difficulty with verbal communication (\nBehavioral problems and challenging behaviors are present in about half of the participants (48.71%). Moreover, the presence of challenging behaviors further impacted functioning, with self-injurious behaviors leading to a decrease of -5.18 points and hetero-injurious behaviors a decrease of -4.79 points. These findings align with the literature documenting the significant burden of comorbid conditions on the daily lives and clinical outcomes of individuals with ASD (\nThe analysis also highlighted the impact of social variables on global functioning. A lack of peer relationships was strongly associated with reduced GAF scores, with individuals reporting no peer contacts (58.85%) experiencing a decrease of -13.87 points and those with only one peer contact (14.31%) showing a decrease of -9.37 points. Similarly, the absence of a partner (88.87%) was associated with a decrease of -7.81 points; only 11.13% of the sample having a partner(s). These findings underline the critical importance of fostering social connections and promoting opportunities for community engagement to enhance functional outcomes and quality of life. Interventions aimed at social participation should focus on helping ASD individuals develop skills necessary to participate actively in the community. These interventions should include social skills training programs, social support sessions, group activities or recreational opportunities.\nMost individuals have participated or are participating in sports activities or associations: participation in sports activities was reported by 69.98% of participants, with 44.93% currently engaged in structured physical activities. While the analysis did not identify a significant direct impact of sports on GAF scores, the broader benefits of physical activities, such as reducing anxiety and fostering social inclusion, are well-documented in the literature (\nStructured physical activity programs, including sports, have been shown to enhance quality of life and foster social inclusion for individuals with ASD. Beyond physical health benefits, evidence highlights that activities like swimming, martial arts, or hiking can foster social connections, reduce isolation, and address comorbid issues such as anxiety and depression (\nThe type of interventions and services provided to patients appears to be varied. This includes interventions offered by the National Health System's educational or social services and non-professional individualized education support.\n22.86% of individuals receive non-professional individualized educational support (daily and recreational foster care), while 5.15% receive educational support in facilities (SSER), 7.55% receive support within therapeutic communities, and 2.19% receive support in rehabilitation (CAD or CADD) or in day care centers (16.10%). Additionally, 4.77% receive or received educational intervention, 44.93% undergo or underwent speech therapy, and 43.94% undergo or underwent psychomotricity. Mental health services are involved in the care of individuals in 45.53% of cases.\nOnly 3.98% of participants had access to individual psychotherapy in adulthood, and less than 5% received psychological counseling.\nAccess to interventions based on Applied Behavior Analysis (ABA) was extremely limited during childhood (2.98%), contradicting established guidelines advocating for early and intensive behavioral interventions (\nSummarizing, our study examined the relationship between various internal and external factors and Global Functioning in adults with Autism Spectrum Disorder (ASD).\nPrevious literature has shown that the examined variables significantly influence Global Functioning in different psychological, social, and occupational domains.\nWe highlighted several factors that significantly impact the functioning of adults with ASD, assessed with the Global Assessment of Functioning Scale (GAF; DSM 4 -TR;\nAccording to the literature (Howlin & Magiati, 2017;\nOne limitation of our study is that GAF is a clinician-report rating scale and, therefore, has limitations regarding its objectivity.\nThe GAF scale is widely used in clinical and research settings to assess individual functioning, making it a valuable tool for our study. However, we believe it is essential to consider the characteristics and needs of individuals on the autism spectrum to accurately capture their complexity. Individuals with autism often have comorbidities or concurrent conditions, including medical ones, that can impact their functioning.\nFurthermore, the support needs and requirements of autistic individuals can vary significantly depending on different life contexts. So, the data sources used to complete the GAF varied (patients, family members, caregivers, clinicians, etc.) and to address these possible issues, we used a specially design structured checklist to guide the completion process.\nOur results suggest the importance of personalized assessment of ASD adults' needs for designing effective and targeted interventions. Identifying effective interventions and investigating comorbidity and co-occurrence impacts offer valuable insight for intervention design and service planning, enabling healthcare providers and professionals to allocate resources more effectively. This can lead to personalized and high-quality care for individuals with ASD and comorbidities.\nConsidering the significant impact of comorbidities with psychopathology and/or other neurodevelopmental disorders on the global functioning of ASD adults, close collaboration with Mental Health Services is crucial to ensure effective pharmacological treatment.\nThe results' analysis reveals that designing social and vocational interventions is crucial to ensuring meaningful life and social participation opportunities.\nInterventions aimed at social participation should focus on helping ASD individuals develop the skills necessary to participate actively in the community. These interventions should include social skills training programs, social support sessions, group activities, and volunteer/recreational opportunities.\nIntegrating a personalized communication system is essential to facilitate effective communication for individuals with ASD who may have difficulty with verbal communication (\nSimilarly, interventions aimed at occupational inclusion should be designed to support individuals with ASD in finding, maintaining, and succeeding in paid employment. These interventions should include vocational training, workplace coaching, adaptation of tasks and work environment to the individual's needs, and support in interacting with colleagues and managing work-related challenges (\nThe results we have obtained further reinforce the need to define the support of autistic individuals across different life contexts, ensuring lifetime continuity of interventions through an individualized life-project. This should include an assessment of the person’s preferences and expectations, a definition of methodologies, strategies, and intervention procedures − including in healthcare, pharmacological, social-health, educational, and care settings − based on scientific evidence. This should be guaranteed for all autistic individuals.\nBased on the results obtained, several recommendations emerge for future research directions and clinical interventions. First, it is essential to address the gaps in the literature regarding personalized treatment for adults with ASD, particularly concerning comorbidities. Additionally, the development of more sensitive diagnostic tools in order to more sensitively identify both autism spectrum disorders and the comorbidities -that may exhibit unique clinical manifestations- and interventions grounded in robust evidence represents a critical priority. This study highlights the importance of interdisciplinary collaborations among mental health services, families, and caregivers to provide holistic support and improve life outcomes.\nPreliminary data suggest that interventions aimed at enhancing personal autonomy, social participation, and employment integration can have a significant impact on the overall well-being of individuals with ASD. Investigating the effectiveness of these interventions through longitudinal and randomized studies is a crucial step toward improving health and social policies in this field. In conclusion, designing targeted and personalized interventions requires a focus on the specific needs, abilities, and challenges of each individual with ASD. This study represents an initial exploratory investigation into these issues. However, further research is needed to better understand the effectiveness of specific interventions and to more comprehensively assess the impact of both internal and external factors examined.", "content_for_embedding": "Autism Spectrum Disorders (ASD) are broad neurodevelopmental disorders characterized by lifelong difficulties in communicative-relational abilities and patterns of restricted and repetitive interests and activities (DSM-5;\nAs with other clinical situations, ASD also involves factors that influence life outcomes and developmental trajectories: the severity of the symptoms can affect a person's functioning to a greater or lesser extent across all stages of life while also being influenced by various external contextual variables, thereby impacting global functioning (\nThe term \"Global Functioning” covers an individual's psychological, social, and occupational functioning, irrespective of any disorder (\nEvaluating global functioning allows for identifying the impact of the disorders and their symptoms on the patient’s life, suggesting interventions and/or treatment plans while verifying their effectiveness in terms of outcomes (\nAccording to literature, outcomes, life trajectories, and global functioning for individuals with ASD can vary significantly depending on various external factors, including the age of diagnosis, early interventions, family support, community services and resources, and access to rehabilitation, educational, and training programs (\nFurthermore, ASD people may encounter various challenges in their lives due to individual factors such as differences in sensory processing, neuropsychological features, and the degree of impairment in linguistic and communicative abilities − which can vary significantly from one individual to another − (Howlin & Magiati, 2017;\nBoth external and individual factors can strongly influence the outcomes and life trajectories of subjects with ASD.\nSubjects with ASD may require varying degrees of support to address environmental challenges, seemingly irrespective of intelligence level. Indeed, the cognitive profile of ASD individuals varies from extreme intellectual disability to profiles well above average (\nAs recently highlighted, ASD adults may present comorbid symptoms such as psychopathological symptoms, personality disorders, psychosis, mood and anxiety disorders, obsessive-compulsive disorder, and other neurodevelopmental disorders in co-occurrence such as ADHD and Specific Learning Disorders (\nSeveral interventions are implemented, both pharmacological and non-pharmacological, with varying levels of evidence (see\nSocial and affective relationships impact physical and mental health in subjects with ASD (\nFamily and social support are often crucial for subjects with ASD in adulthood. Access to family and community support networks can play a fundamental role in defining outcomes for adult subjects with ASD, significantly influencing quality of life (\nSubjects with ASD often exhibit atypical sensory processing modalities (APA, 2013), which can significantly influence their interactions with the surrounding world and their daily experiences. These atypicalities may involve different sensory modalities and vary among individuals (\nSensory difficulties can impact the quality of life and developmental trajectories by reducing opportunities for community participation and employment opportunities (\nAdults with ASD may achieve various occupational outcomes, including high levels of education and significant employment positions. However, some may face challenges in finding and maintaining stable employment. Support programs, guidance, and vocational training are among the various variables that can affect the occupational outcomes of subjects with ASD (\nIndividuals with ASD may demonstrate variable levels of autonomy and independence in managing daily life. Some may live relatively independently, managing their personal needs and finances, working autonomously, and residing independently. In contrast, others may require significant support and live in group housing (\nAt the medical level, a higher prevalence of pathologies is identified in individuals with ASD compared to the general population, and it increases with age (\nAll these aspects strongly impact functional adaptation in various life domains and also affect the quality of life of ASD people and their families.\nAs Howlin and Magiati (2017) highlighted, the literature lacks studies examining outcomes for adult individuals with autism.\nAttention has recently been focused on the transition into adulthood and across the lifespan for ASD. This has led to a lack of implementation of personalized interventions (\nThe primary purpose of this study is to conduct a survey and investigate the main characteristics and types of functioning, as well as the types of services and interventions that subjects with ASD in adulthood have utilized or are currently utilizing at the Adult Autism Center in Turin. Additionally, we used the collected data to preliminarily analyze and identify internal and external factors that enhance outcomes for individuals with autism and their impact on global functioning.\nBetween January and October 2022, a total of 503 subjects with ASD in adulthood (mean age = 27.8, SD = 8.62) participated in the research.\nAll participants provided their informed consent to take part in the study and all procedures performed in the study were conducted in compliance with privacy regulations, ethical standards and in accordance with the 1964 Helsinki Declaration and its later amendments or comparable ethical standards.\nThe sample included 123 females (24.45%; mean age = 29.8, SD = 8.30) and 380 males (75.55%; mean age = 27.2, SD = 8.64). The female/male ratio is 1:4. All participants received ASD diagnosis from the Regional Center for Autism Spectrum Disorder in Turin according to Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition (DSM-5) (APA, 2013) criteria following a structured diagnostic pathway (Multistep Network Model-\nMean and SD of age and educational level of the entire sample (n=503)\nThe participants' mean age at diagnosis is 14.00 years (SD = 12.54), and the mean number of years under the Adult Autism Service is 3.88 (SD = 2.63).\nGlobal Assessment of Functioning. The Global Assessment of Functioning Scale (GAF;\nTo guide the interview and data collection, licensed psychologists and clinicians of the Adult Autism Center built and filled out an ad hoc checklist to assign the GAF score. Clinical records and telephonic interviews with participants, caregivers, and therapists were the primary sources of information. Several variables were collected on the checklist to define functioning profiles (see\nDescriptive analysis of the investigated variables\nCategorical variables are expressed as absolute numbers, percentages, and means and standard deviation for continuous data.\nUnivariate and multiple Linear regression models were performed to identify factors independently associated with GAF in the overall sample. The correlation between variables was checked. Multivariate analyses were adjusted for all variables in the model. Results with a p-value < 0.05 were considered statistically significant; all p-values were two-tailed.\nAll statistical analyses were performed using STATA software (Stata Corporation, College Station, TX, USA).\nThe results of the information gathered using the checklist to complete the GAF are summarized in the\nTo conduct an appropriate multivariate analysis, we selected variables that the literature has shown to impact global functioning significantly. Specifically, we included internal (education, level of diagnosis, level of communication, comorbidity, use of psychotropic medications, type of challenging behaviours, co-occurrence with neurodevelopmental disorders, peer relationships) and external (living environment, family composition and partners, work and job training, sport, habilitative interventions, age at first diagnosis) variables.\nWe set a reference level for each variable, which was considered the most significant outcome. The significance was not intended to be the best or most positive outcome per se. Still, it was set considering the evidence in the literature to measure the impact of certain variables on the outcomes.\nIn\nMultivariate analysis results\n°= Reference level; Significant at * p < .05, ** p < .001.\nSeveral variables have demonstrated a statistically significant impact on the outcomes of ASD adults as measured by clinicians' scoring on the Global Assessment of Functioning (GAF) scale. As previously indicated, based on the literature, we established a reference level considered the most significant outcome. We assessed the influence of each variable on the total assigned GAF score.\nAt a significance level of\nThe impact of communication skills on the Global Assessment of Functioning scale is significant. Specifically, minimal meaningful communication can result in a decrease of -15.99 points on the GAF scale.\nOn the other hand, the ability to communicate about a restricted number of topics results in a more minor but still statistically significant decrease of -6.66 points on the GAF scale.\nNot taking psychotropic drugs is associated with a decrease in GAF scores by -4.69 points.\nThe presence of comorbidities significantly and negatively impacts the outcome, leading to a decrease in GAF scores by -4.51 points.\nThe co-occurrence with other neurodevelopmental disorders worsens GAF scores by -4.51 points. Not having a partner worsens GAF scores by -7.81 points.\nNot having a social network negatively impacts GAF scores: having no friends worsens the outcome by -13.87 points, and having only one friend worsens it by -9.37 points.\nAt a significance level of\nLiving in a group home provided by social services significantly worsens the outcome by -17.72 points.\nNot having a job decreases GAF scores by -4.64 points, and not being enrolled in training courses decreases GAF scores by 3.79.\nFurthermore, self-injurious and hetero-injurious behaviours adversely affect functioning, decreasing GAF scores by -5.18 points (self-injurious) and 4.79 points (hetero-injurious).\nPsychotherapy in adulthood appears to have a positive impact, as those who did not undergo such treatment experienced a decrease in GAF scores by -8.92 points: this data should be carefully interpreted, considering that only a few subjects had access to psychotherapy.\nConversely, in our analysis, we did not find a significant impact on the scores assigned to GAF for certain variables, including gender, age, years of schooling, age at first diagnosis, some living arrangements (alone, with partner/roommates/family), attending sports, presence of medical conditions. Similarly, we did not observe effects on the outcomes of specific treatments such as speech therapy in childhood, educational interventions in childhood, psychological counselling in adulthood or psychomotor therapy in childhood.\nOur study collected various information related to demographic variables, functioning profiles, diagnostic characteristics, comorbidities, and interventions and services in 503 patients with ASD in adulthood.\n75.5% of the participants are male: this highlights the need to further investigate the female population with autism, which is generally underrepresented not only in clinical settings but also in research (\nIn terms of needed support over half of the individuals received a diagnosis of level 1 autism (56.6%) according to DSM 5 (APA, 2013). A significant variability in global functioning among adults with ASD, was measured by the GAF scale. Levels of required support demonstrated a profound impact on GAF scores, with individuals diagnosed with Level 3 ASD (20.68%) showing a decrease of -25.05 points and those with Level 2 ASD (23.26%) a decrease of -8.74 points compared to Level 1. This finding emphasizes the critical role of tailored interventions to address the needs of individuals requiring higher support, consistent with previous studies highlighting the heterogeneity of functional outcomes in ASD populations (Howlin & Magiati, 2017).\nAs mentioned earlier, we did not find significant effects of gender, age, and education level on the scores obtained on the GAF, contrary to what was observed for the level of support needed. For example, regarding gender, this data can be interpreted by highlighting that, contrary to common belief, autistic females may exhibit difficulties in adapting to daily life contexts and require support just like males, despite the belief that women display more subtle symptomatology. Another consideration is that autistic individuals require guaranteed support from a lifelong perspective, regardless of age or the level of education achieved.\nIn addition to the autism diagnosis, approximately half of the participants exhibit physical illnesses (42.74%) that are often associated with autism diagnosis (including epilepsy, gastrointestinal disorders, and celiac disease) (\nThese findings open new avenues for research into the structural and systemic health challenges that may coexist with autism. Given the complexity of autism and its associated conditions, the importance of personalized assessment of subjects with autism in adulthood needs becomes evident for designing effective and targeted interventions (\nPsychological comorbidities and/or those related to other neurodevelopmental disorders are present in the majority of cases. Regarding psychiatric comorbidities, 63.0% of participants reported at least one co-occurring psychopathological or neurodevelopmental disorder, which was associated with a decrease of -4.51 points in GAF scores.\nThese results are in line with the existing literature. In fact,\nPsychotic spectrum disorders, including schizotypal and schizoid traits, are similarly prevalent, further underscoring the complexity of clinical presentations in this population. Recent studies have reported a high prevalence of autistic traits and autism spectrum disorder among individuals with psychosis, with significantly higher rates compared to the general population (\nThese findings emphasize the importance of a comprehensive evaluation of psychological and neurodevelopmental disorders during the diagnosis and management of autism, ensuring that comorbid conditions are identified and addressed to improve functional outcomes and overall quality of life.\nLocation of residence varies within the sample; most individuals live in urban settings (56.86%) and reside with their born family (80.2%). Conversely, 25.25% inhabit apartments in towns surrounding the capital. A smaller portion, 3.98%, reside in standalone houses within the capital city, while 6.16% live in standalone houses in rural areas. Additionally, 6.76% of the sample reside in therapeutic communities, and approximately 1% reside in apartment complexes provided by the National Health System or City Council.\nAdditionally, 5.17% live within therapeutic communities, 3.38% have roommates or live with a friend, and 4.17% live with their partner.\nContrary to the goals of life planning and intervention programs, only a very tiny minority of subjects with ASD in adulthood live independently (6.69% of the sample) and less than half of the patients (37.75%) can independently complete tasks or activities related to self-care and managing the domestic environment.\nThe same results are observed concerning work-life: only a minimal percentage (18.89%) is currently employed or enrolled in vocational training or upgrading (in a training course).\nEmployment status further influenced functioning, with unemployed individuals showing a decrease of -4.64 points in GAF scores and those not enrolled in any vocational training or upgrading courses experiencing a decrease of -3.79 points.\nOnly 21.47% of participants had been employed in the past, and 83.90% had not participated in any professional training after completing their schooling.\nRegarding the composition of the family, 30.42% of subjects are only child, 52.68% have only one sibling, 12.92% have two siblings, 2.78% have three siblings, while 0.80% and 0.40% respectively have 4 or 5 siblings. Among these, 34.00% are firstborn, 32.42% are second-born, 4.37% are third-born, 1.99% are fourth-born, and 0.20% are fifth-born.\nCommunication abilities also emerged as a factor influencing global functioning of subjects with ASD. Participants with minimal communication skills exhibited a significant decrease in GAF scores by -15.99 points compared to those able to discuss a wide variety of topics, while those with restricted communication abilities showed a decrease of -6.66 points. However, only 2.58% of participants who did not use spoken language employed an alternative communication system, revealing a substantial gap in the availability and use of assistive communication tools. Integrating a personalized communication system is crucial to facilitate effective communication for individuals with ASD who may have difficulty with verbal communication (\nBehavioral problems and challenging behaviors are present in about half of the participants (48.71%). Moreover, the presence of challenging behaviors further impacted functioning, with self-injurious behaviors leading to a decrease of -5.18 points and hetero-injurious behaviors a decrease of -4.79 points. These findings align with the literature documenting the significant burden of comorbid conditions on the daily lives and clinical outcomes of individuals with ASD (\nThe analysis also highlighted the impact of social variables on global functioning. A lack of peer relationships was strongly associated with reduced GAF scores, with individuals reporting no peer contacts (58.85%) experiencing a decrease of -13.87 points and those with only one peer contact (14.31%) showing a decrease of -9.37 points. Similarly, the absence of a partner (88.87%) was associated with a decrease of -7.81 points; only 11.13% of the sample having a partner(s). These findings underline the critical importance of fostering social connections and promoting opportunities for community engagement to enhance functional outcomes and quality of life. Interventions aimed at social participation should focus on helping ASD individuals develop skills necessary to participate actively in the community. These interventions should include social skills training programs, social support sessions, group activities or recreational opportunities.\nMost individuals have participated or are participating in sports activities or associations: participation in sports activities was reported by 69.98% of participants, with 44.93% currently engaged in structured physical activities. While the analysis did not identify a significant direct impact of sports on GAF scores, the broader benefits of physical activities, such as reducing anxiety and fostering social inclusion, are well-documented in the literature (\nStructured physical activity programs, including sports, have been shown to enhance quality of life and foster social inclusion for individuals with ASD. Beyond physical health benefits, evidence highlights that activities like swimming, martial arts, or hiking can foster social connections, reduce isolation, and address comorbid issues such as anxiety and depression (\nThe type of interventions and services provided to patients appears to be varied. This includes interventions offered by the National Health System's educational or social services and non-professional individualized education support.\n22.86% of individuals receive non-professional individualized educational support (daily and recreational foster care), while 5.15% receive educational support in facilities (SSER), 7.55% receive support within therapeutic communities, and 2.19% receive support in rehabilitation (CAD or CADD) or in day care centers (16.10%). Additionally, 4.77% receive or received educational intervention, 44.93% undergo or underwent speech therapy, and 43.94% undergo or underwent psychomotricity. Mental health services are involved in the care of individuals in 45.53% of cases.\nOnly 3.98% of participants had access to individual psychotherapy in adulthood, and less than 5% received psychological counseling.\nAccess to interventions based on Applied Behavior Analysis (ABA) was extremely limited during childhood (2.98%), contradicting established guidelines advocating for early and intensive behavioral interventions (\nSummarizing, our study examined the relationship between various internal and external factors and Global Functioning in adults with Autism Spectrum Disorder (ASD).\nPrevious literature has shown that the examined variables significantly influence Global Functioning in different psychological, social, and occupational domains.\nWe highlighted several factors that significantly impact the functioning of adults with ASD, assessed with the Global Assessment of Functioning Scale (GAF; DSM 4 -TR;\nAccording to the literature (Howlin & Magiati, 2017;\nOne limitation of our study is that GAF is a clinician-report rating scale and, therefore, has limitations regarding its objectivity.\nThe GAF scale is widely used in clinical and research settings to assess individual functioning, making it a valuable tool for our study. However, we believe it is essential to consider the characteristics and needs of individuals on the autism spectrum to accurately capture their complexity. Individuals with autism often have comorbidities or concurrent conditions, including medical ones, that can impact their functioning.\nFurthermore, the support needs and requirements of autistic individuals can vary significantly depending on different life contexts. So, the data sources used to complete the GAF varied (patients, family members, caregivers, clinicians, etc.) and to address these possible issues, we used a specially design structured checklist to guide the completion process.\nOur results suggest the importance of personalized assessment of ASD adults' needs for designing effective and targeted interventions. Identifying effective interventions and investigating comorbidity and co-occurrence impacts offer valuable insight for intervention design and service planning, enabling healthcare providers and professionals to allocate resources more effectively. This can lead to personalized and high-quality care for individuals with ASD and comorbidities.\nConsidering the significant impact of comorbidities with psychopathology and/or other neurodevelopmental disorders on the global functioning of ASD adults, close collaboration with Mental Health Services is crucial to ensure effective pharmacological treatment.\nThe results' analysis reveals that designing social and vocational interventions is crucial to ensuring meaningful life and social participation opportunities.\nInterventions aimed at social participation should focus on helping ASD individuals develop the skills necessary to participate actively in the community. These interventions should include social skills training programs, social support sessions, group activities, and volunteer/recreational opportunities.\nIntegrating a personalized communication system is essential to facilitate effective communication for individuals with ASD who may have difficulty with verbal communication (\nSimilarly, interventions aimed at occupational inclusion should be designed to support individuals with ASD in finding, maintaining, and succeeding in paid employment. These interventions should include vocational training, workplace coaching, adaptation of tasks and work environment to the individual's needs, and support in interacting with colleagues and managing work-related challenges (\nThe results we have obtained further reinforce the need to define the support of autistic individuals across different life contexts, ensuring lifetime continuity of interventions through an individualized life-project. This should include an assessment of the person’s preferences and expectations, a definition of methodologies, strategies, and intervention procedures − including in healthcare, pharmacological, social-health, educational, and care settings − based on scientific evidence. This should be guaranteed for all autistic individuals.\nBased on the results obtained, several recommendations emerge for future research directions and clinical interventions. First, it is essential to address the gaps in the literature regarding personalized treatment for adults with ASD, particularly concerning comorbidities. Additionally, the development of more sensitive diagnostic tools in order to more sensitively identify both autism spectrum disorders and the comorbidities -that may exhibit unique clinical manifestations- and interventions grounded in robust evidence represents a critical priority. This study highlights the importance of interdisciplinary collaborations among mental health services, families, and caregivers to provide holistic support and improve life outcomes.\nPreliminary data suggest that interventions aimed at enhancing personal autonomy, social participation, and employment integration can have a significant impact on the overall well-being of individuals with ASD. Investigating the effectiveness of these interventions through longitudinal and randomized studies is a crucial step toward improving health and social policies in this field. In conclusion, designing targeted and personalized interventions requires a focus on the specific needs, abilities, and challenges of each individual with ASD. This study represents an initial exploratory investigation into these issues. However, further research is needed to better understand the effectiveness of specific interventions and to more comprehensively assess the impact of both internal and external factors examined.", "topic": "Diagnostic"}
{"pmid": "37767431", "pmcid": "12306948", "title": "Results of Long-Term Therapy with a Biosimilar of Eculizumab in Patients with Paroxysmal Nocturnal Hemoglobinuria", "publication_year": "N/A", "abstract": "", "full_text": "Paroxysmal nocturnal hemoglobinuria (PNH) is a rare clonal hematopoietic stem cell disease that presents with hemolytic anemia, thrombosis, and smooth muscle dystonias, and in some cases is associated with bone marrow failure [\nThe inhibition of MAC formation using eculizumab, a humanized anticomplement component C5 antibody, remains the mainstay of treatment for PNH [\nElizaria\nAn open-label, prospective, multicenter study of the long-term safety, immunogenicity, PKs, PDs, and efficacy of eculizumab biosimilar in patients who had previously completed the ECU-PNH-III and ECU-PNH-Ib clinical trials was conducted at 8 study sites (\nPatients with hypersensitivity to the investigational product and its components, as well as active ingredients and components of the meningococcal vaccine, patients with a history of infectious diseases caused by\nA patient could be excluded during the study for the following reasons: ≥2 events of grade 3 toxicity, or ≥1 event of grade 4 toxicity according to the CTCAE 4.03, which the investigator considered as associated with the investigational product; diagnosis of cancer; meningococcal infection; treatment with immunosuppressants, except for eculizumab, glucocorticosteroids, androgens, erythropoietin products, or adjusted-dose warfarin; refusal to participate or noncompliance with study procedures; significant deviations from the protocol (ver. 4.0 dated 13.07.2018). Any outcome data were collected for participants who could discontinue or deviate from intervention protocols.\nThe open-label, prospective, multicenter study included the following periods: the end of study visit of previous trials (Switching Visit), which was the first visit of this study; the treatment period (up to 104 weeks); and the follow-up period (2 weeks). If the product became commercially available to an individual patient, the patient would withdraw from the study.\nThe patients received the biosimilar at a maintenance dose of 900 mg every 2 weeks. The maximum duration of treatment was 104 weeks. During the study, patients received from 18 to 44 injections of the biosimilar, the average number of injections was 32.33 ± 6.74). In previous clinical trials, all patients were immunized with a meningococcal vaccine at least 14 days before the first eculizumab infusion or received preventive antibacterial therapy for at least 2 weeks after vaccination. Re-immunization during the clinical study was possible, if necessary.\nThe study procedures included physical examination, anthropometry, assessment of vital signs, electrocardiography, and Doppler echocardiography with an assessment of the mean pulmonary artery pressure and the degree of pulmonary hypertension. Blood samples were taken for red blood cell/granulocyte PNH clone tests (according to the high-sensitivity flow cytometry protocol [\nThe PK analysis (C\nThe therapy safety was assessed by the incidence and severity of adverse reactions (ARs) according to symptoms, physical examination, assessment of vital signs, electrocardiography, laboratory and instrumental findings, and patient diaries. All adverse events (AEs) reported in the study were analyzed by their association with the investigational products (definite, probable, or possible), system organ classes, preferred terms, and treatment groups. The AEs and ARs were coded using the Medical Dictionary for Regulatory Activities (MedDRA), version 21.0, and presented with the aggregation of preferred terms by System Organ Classes.\nImmunogenicity was determined by the level of antidrug antibodies (ADAs), including the neutralizing activity of antibodies to eculizumab, by bridging enzyme-linked immunosorbent assay. The assay was carried out at Weeks 12, 24, 36, 48, 60, 72, 84, and 102 during the treatment period. The immunogenicity analysis was performed considering the total duration of therapy, including the results of previous studies. The analysis results before the first dose of the product in previous clinical studies (ECU-PNH-Ib and ECU-PNH-III) were considered as baseline.\nEfficacy variables included changes in the levels of lactate dehydrogenase (LDH), hemoglobin, reticulocytes, and red blood cell/granulocyte PNH clone. In addition, the number of patients requiring blood transfusions was evaluated.\nR 4.0.3 [\nQualitative attributes were described using the absolute number of observations, percentages, and two-sided 95% CIs for percentages. Nonparametric Mann-Whitney and Friedman tests were used to compare quantitative parameters between groups and changes in these parameters between visits in each group, respectively, since all study populations and groups were represented by small subsets.\nThe study enrolled 30 patients, of which 25 (83%) and 5 (17%) previously received biosimilar (group A) and originator (group B), respectively. All patients completed the study according to the protocol when the biosimilar became commercially available, each at their own visit. As a result, the data at the end of study visit were actually collected at several different time points. The PK/PD population accounted for 16.67% of the FAS population (5 patients) and included only patients from group B.\nThe median age of patients was 37 years (39 years in group A and 33 years in group B). The study included 12 male and 18 female patients. Patients in groups A and B were comparable in terms of all baseline characteristics (shown in\nBaseline characteristics of enrolled patients\nMAC, membrane attack complex; C\n\n\nThe most common concomitant diseases in the study subjects were vascular diseases (50% of patients) and cardiac disorders (36.7% of patients). There were no significant differences in the manifestations of PNH and incidence of various comorbidities between the groups (\nIn group B, where patients switched from the originator to the biosimilar prior to enrollment in this study, the mean serum concentration of eculizumab was 127.77 ± 63.33 μg/mL at visit 1, 128.62 ± 57.96 μg/mL at visit 2, 112.54 ± 48.84 μg/mL at visit 3, and 126.54 ± 62.73 μg/mL at visit 4. High variability in the product concentration was observed at all time points; the coefficient of variation was close to 50% but did not exceed this value (shown in\nMinimum product concentration at the end of the dosing interval and membrane attack complex concentration at first study visits. PK population (\nAt the end of each dosing interval, the mean eculizumab concentration 5 min pre-dose at all visits exceeded 35 μg/mL, which is the minimum concentration sufficient for complete inhibition of intravascular hemolysis in patients with PNH [\nThe median LDH activity ranged from 226 (197.8; 300) U/L to 320 (235.8; 377.5) U/L, and median changes in LDH activity from baseline (visit 1) ranged from −3.5 (−84.3; 130.8) U/L to −98.5 (−128.3; −68.8) U/L. The analysis of changes in LDH activity showed that the median LDH activity in the FAS population was stable throughout the study (\nChanges in serum LDH activity during the study (median with interquartile range).\nBoth groups demonstrated comparable positive mean changes in the hemoglobin level at the end of the study, which were 3.7 ± 13.6 g/L in group A and 1 ± 2.5 g/L in group B (\nResults of comparative assessment of efficacy endpoints\nThe reticulocyte count in the general population was stable throughout the study; there were no significant changes compared to visit 1 (\nWith regard to changes in PNH type II + III red blood cells and granulocytes compared to baseline values at screening, similar changes in mean values were observed in both groups. At the end of the study, groups A and B demonstrated an insignificant decrease in type II + III red blood cells, which was −3.2 ± 18.42% and −1.08 ± 16.73%, respectively (\nBreakthrough hemolysis was recorded in 4 patients in group A (shown in\nEight (27%) patients received red blood cell transfusions from the start of therapy to the end of the study, with no significant differences between groups A (28%) and B (20%). No new thrombotic events were reported in the study.\nDuring the study period, none of the patients developed a meningococcal infection or other infections potentially associated with long-term terminal complement inhibition. None of the evaluated patients had SAEs associated with hemolysis.\nAmong the reported 362 AEs, only two episodes in two patients had at least a possible association with the investigational product: alopecia in group A (4%) and elevated aspartate aminotransferase in Group B (20%) (shown in online suppl.\nThroughout the study, binding ADAs were detected in 7/30 (23.3%) patients: 6/25 (24%) in group A and 1/5 (20%) in group B. According to the immunogenicity analysis, there were no significant differences between the groups with regard to the frequency of ADA detection at any study visit (\nCurrently, data on the efficacy and safety of new biosimilars of eculizumab in PNH are being actively published [\nThe stable LDH activity and hemoglobin levels observed in this study indicate long-term treatment efficacy due to a decrease in hemolytic activity. The persistent need for RBC transfusions is consistent with previously published data on the long-term use of the originator product Soliris (18–29%), including the population of Russian patients [\nAccording to the PK/PD analysis, mean eculizumab concentration 5 min pre-dose at all visits exceeded 35 μg/mL, which is the minimum concentration sufficient for complete inhibition of intravascular hemolysis in patients with PNH. At the same time, a persistent decrease in the mean serum MAC concentration confirms the efficacy of terminal complement activation control [\nThe overall safety profile of the investigational product was consistent with the findings of previous studies of originator [\nThe main limitation of this clinical study was the low number of PNH patients, as well as the orphan status of eculizumab, which made it difficult to include more patients in the study, and especially in group B, given the decreased use of the originator. In addition, the study did not implement the recently proposed criteria for response to complement inhibitor therapy [\nThe anti-C5 monoclonal antibody eculizumab has been used in the treatment of PNH for 20 years. Eculizumab has revolutionized treatment, controlling intravascular hemolysis and thrombosis occurrence, with improved long-term survival [\nTherefore, this clinical study demonstrates that long-term use of biosimilar of eculizumab in the treatment of PNH patients ensures successful control of hemolytic activity of the complement system, which is the main pathogenetic mechanism of the disease. The study also confirms the safety of biosimilar in long-term treatment of PNH patients, with a low percentage of ARs and cases of ADA formation. The findings of the ECU-PNH-III-X clinical study conducted as part of the clinical development of the biosimilar confirm its efficacy and safety for long-term use in patients with PNH.\nThis clinical study was approved by the Ministry of Health of Russia, Approval No. 205 dated 08.05.2018. The study protocol was reviewed and approved by Ethics Council at the Ministry of Health of the Russia; meeting number 165 dated 13.03.2018. This study protocol was reviewed and approved by Ethics Committees at each of the participating sites. This full list of participating site and Ethics Committees can be found at\nThe study was conducted in accordance with the ethical principles of the World Medical Association (WMA) Declaration of Helsinki (last revised in 2013) and the standards of the Good Clinical Practice (GCP) Guidelines of the International Conference on Harmonization of technical requirements for registration of pharmaceuticals for human use (ICH), designed to monitor compliance with the interests and safety of the patients. Personal information about potential and enrolled participants was collected and kept in strict confidence before, during and after the study. Written informed consent to participate in the study was obtained by the investigators from all participants before their participation in the study.\nAlexander D. Kulagin: Alexion Pharmaceuticals, Inc: consultancy, research funding; JSC GENERIUM: consultancy, honoraria, research funding. Vadim V. Ptushkin: Alexion Pharmaceuticals, Inc: consultancy, research funding; JSC GENERIUM: research funding; Janssen: consultancy; AbbVie: consultancy; Roche: consultancy. Elena A. Lukina: JSC GENERIUM: research funding; Sanofi Genzyme: honoraria, membership on an entity’s Board of Directors or advisory committees; Shire: Honoraria, Membership on an entity’s Board of Directors or advisory committees. Other: travel reimbursement, research funding. Oksana А. Markova: JSC GENERIUM: employment. Eugene V. Zuev: JSC GENERIUM: employment.\nThe study was organized and conducted with the support of GENERIUM JSC.\nContribution: AD.K., V.V.P., and E.A.L. recruited patients, collected data, analyzed and interpreted the data, contributed to the manuscript, and approved the final version; I.L.D., A.V.K., T.S.K., E.Yu.K., N.V.M., T.A.M., O.U.К., E.G.A., and V.D.L. recruited patients, collected data, contributed to the manuscript, and approved the final version; O.A.M. and E.V.Z. developed the protocol, analyzed and interpreted the data, contributed to the manuscript, and approved the final version.", "content_for_embedding": "Paroxysmal nocturnal hemoglobinuria (PNH) is a rare clonal hematopoietic stem cell disease that presents with hemolytic anemia, thrombosis, and smooth muscle dystonias, and in some cases is associated with bone marrow failure [\nThe inhibition of MAC formation using eculizumab, a humanized anticomplement component C5 antibody, remains the mainstay of treatment for PNH [\nElizaria\nAn open-label, prospective, multicenter study of the long-term safety, immunogenicity, PKs, PDs, and efficacy of eculizumab biosimilar in patients who had previously completed the ECU-PNH-III and ECU-PNH-Ib clinical trials was conducted at 8 study sites (\nPatients with hypersensitivity to the investigational product and its components, as well as active ingredients and components of the meningococcal vaccine, patients with a history of infectious diseases caused by\nA patient could be excluded during the study for the following reasons: ≥2 events of grade 3 toxicity, or ≥1 event of grade 4 toxicity according to the CTCAE 4.03, which the investigator considered as associated with the investigational product; diagnosis of cancer; meningococcal infection; treatment with immunosuppressants, except for eculizumab, glucocorticosteroids, androgens, erythropoietin products, or adjusted-dose warfarin; refusal to participate or noncompliance with study procedures; significant deviations from the protocol (ver. 4.0 dated 13.07.2018). Any outcome data were collected for participants who could discontinue or deviate from intervention protocols.\nThe open-label, prospective, multicenter study included the following periods: the end of study visit of previous trials (Switching Visit), which was the first visit of this study; the treatment period (up to 104 weeks); and the follow-up period (2 weeks). If the product became commercially available to an individual patient, the patient would withdraw from the study.\nThe patients received the biosimilar at a maintenance dose of 900 mg every 2 weeks. The maximum duration of treatment was 104 weeks. During the study, patients received from 18 to 44 injections of the biosimilar, the average number of injections was 32.33 ± 6.74). In previous clinical trials, all patients were immunized with a meningococcal vaccine at least 14 days before the first eculizumab infusion or received preventive antibacterial therapy for at least 2 weeks after vaccination. Re-immunization during the clinical study was possible, if necessary.\nThe study procedures included physical examination, anthropometry, assessment of vital signs, electrocardiography, and Doppler echocardiography with an assessment of the mean pulmonary artery pressure and the degree of pulmonary hypertension. Blood samples were taken for red blood cell/granulocyte PNH clone tests (according to the high-sensitivity flow cytometry protocol [\nThe PK analysis (C\nThe therapy safety was assessed by the incidence and severity of adverse reactions (ARs) according to symptoms, physical examination, assessment of vital signs, electrocardiography, laboratory and instrumental findings, and patient diaries. All adverse events (AEs) reported in the study were analyzed by their association with the investigational products (definite, probable, or possible), system organ classes, preferred terms, and treatment groups. The AEs and ARs were coded using the Medical Dictionary for Regulatory Activities (MedDRA), version 21.0, and presented with the aggregation of preferred terms by System Organ Classes.\nImmunogenicity was determined by the level of antidrug antibodies (ADAs), including the neutralizing activity of antibodies to eculizumab, by bridging enzyme-linked immunosorbent assay. The assay was carried out at Weeks 12, 24, 36, 48, 60, 72, 84, and 102 during the treatment period. The immunogenicity analysis was performed considering the total duration of therapy, including the results of previous studies. The analysis results before the first dose of the product in previous clinical studies (ECU-PNH-Ib and ECU-PNH-III) were considered as baseline.\nEfficacy variables included changes in the levels of lactate dehydrogenase (LDH), hemoglobin, reticulocytes, and red blood cell/granulocyte PNH clone. In addition, the number of patients requiring blood transfusions was evaluated.\nR 4.0.3 [\nQualitative attributes were described using the absolute number of observations, percentages, and two-sided 95% CIs for percentages. Nonparametric Mann-Whitney and Friedman tests were used to compare quantitative parameters between groups and changes in these parameters between visits in each group, respectively, since all study populations and groups were represented by small subsets.\nThe study enrolled 30 patients, of which 25 (83%) and 5 (17%) previously received biosimilar (group A) and originator (group B), respectively. All patients completed the study according to the protocol when the biosimilar became commercially available, each at their own visit. As a result, the data at the end of study visit were actually collected at several different time points. The PK/PD population accounted for 16.67% of the FAS population (5 patients) and included only patients from group B.\nThe median age of patients was 37 years (39 years in group A and 33 years in group B). The study included 12 male and 18 female patients. Patients in groups A and B were comparable in terms of all baseline characteristics (shown in\nBaseline characteristics of enrolled patients\nMAC, membrane attack complex; C\n\n\nThe most common concomitant diseases in the study subjects were vascular diseases (50% of patients) and cardiac disorders (36.7% of patients). There were no significant differences in the manifestations of PNH and incidence of various comorbidities between the groups (\nIn group B, where patients switched from the originator to the biosimilar prior to enrollment in this study, the mean serum concentration of eculizumab was 127.77 ± 63.33 μg/mL at visit 1, 128.62 ± 57.96 μg/mL at visit 2, 112.54 ± 48.84 μg/mL at visit 3, and 126.54 ± 62.73 μg/mL at visit 4. High variability in the product concentration was observed at all time points; the coefficient of variation was close to 50% but did not exceed this value (shown in\nMinimum product concentration at the end of the dosing interval and membrane attack complex concentration at first study visits. PK population (\nAt the end of each dosing interval, the mean eculizumab concentration 5 min pre-dose at all visits exceeded 35 μg/mL, which is the minimum concentration sufficient for complete inhibition of intravascular hemolysis in patients with PNH [\nThe median LDH activity ranged from 226 (197.8; 300) U/L to 320 (235.8; 377.5) U/L, and median changes in LDH activity from baseline (visit 1) ranged from −3.5 (−84.3; 130.8) U/L to −98.5 (−128.3; −68.8) U/L. The analysis of changes in LDH activity showed that the median LDH activity in the FAS population was stable throughout the study (\nChanges in serum LDH activity during the study (median with interquartile range).\nBoth groups demonstrated comparable positive mean changes in the hemoglobin level at the end of the study, which were 3.7 ± 13.6 g/L in group A and 1 ± 2.5 g/L in group B (\nResults of comparative assessment of efficacy endpoints\nThe reticulocyte count in the general population was stable throughout the study; there were no significant changes compared to visit 1 (\nWith regard to changes in PNH type II + III red blood cells and granulocytes compared to baseline values at screening, similar changes in mean values were observed in both groups. At the end of the study, groups A and B demonstrated an insignificant decrease in type II + III red blood cells, which was −3.2 ± 18.42% and −1.08 ± 16.73%, respectively (\nBreakthrough hemolysis was recorded in 4 patients in group A (shown in\nEight (27%) patients received red blood cell transfusions from the start of therapy to the end of the study, with no significant differences between groups A (28%) and B (20%). No new thrombotic events were reported in the study.\nDuring the study period, none of the patients developed a meningococcal infection or other infections potentially associated with long-term terminal complement inhibition. None of the evaluated patients had SAEs associated with hemolysis.\nAmong the reported 362 AEs, only two episodes in two patients had at least a possible association with the investigational product: alopecia in group A (4%) and elevated aspartate aminotransferase in Group B (20%) (shown in online suppl.\nThroughout the study, binding ADAs were detected in 7/30 (23.3%) patients: 6/25 (24%) in group A and 1/5 (20%) in group B. According to the immunogenicity analysis, there were no significant differences between the groups with regard to the frequency of ADA detection at any study visit (\nCurrently, data on the efficacy and safety of new biosimilars of eculizumab in PNH are being actively published [\nThe stable LDH activity and hemoglobin levels observed in this study indicate long-term treatment efficacy due to a decrease in hemolytic activity. The persistent need for RBC transfusions is consistent with previously published data on the long-term use of the originator product Soliris (18–29%), including the population of Russian patients [\nAccording to the PK/PD analysis, mean eculizumab concentration 5 min pre-dose at all visits exceeded 35 μg/mL, which is the minimum concentration sufficient for complete inhibition of intravascular hemolysis in patients with PNH. At the same time, a persistent decrease in the mean serum MAC concentration confirms the efficacy of terminal complement activation control [\nThe overall safety profile of the investigational product was consistent with the findings of previous studies of originator [\nThe main limitation of this clinical study was the low number of PNH patients, as well as the orphan status of eculizumab, which made it difficult to include more patients in the study, and especially in group B, given the decreased use of the originator. In addition, the study did not implement the recently proposed criteria for response to complement inhibitor therapy [\nThe anti-C5 monoclonal antibody eculizumab has been used in the treatment of PNH for 20 years. Eculizumab has revolutionized treatment, controlling intravascular hemolysis and thrombosis occurrence, with improved long-term survival [\nTherefore, this clinical study demonstrates that long-term use of biosimilar of eculizumab in the treatment of PNH patients ensures successful control of hemolytic activity of the complement system, which is the main pathogenetic mechanism of the disease. The study also confirms the safety of biosimilar in long-term treatment of PNH patients, with a low percentage of ARs and cases of ADA formation. The findings of the ECU-PNH-III-X clinical study conducted as part of the clinical development of the biosimilar confirm its efficacy and safety for long-term use in patients with PNH.\nThis clinical study was approved by the Ministry of Health of Russia, Approval No. 205 dated 08.05.2018. The study protocol was reviewed and approved by Ethics Council at the Ministry of Health of the Russia; meeting number 165 dated 13.03.2018. This study protocol was reviewed and approved by Ethics Committees at each of the participating sites. This full list of participating site and Ethics Committees can be found at\nThe study was conducted in accordance with the ethical principles of the World Medical Association (WMA) Declaration of Helsinki (last revised in 2013) and the standards of the Good Clinical Practice (GCP) Guidelines of the International Conference on Harmonization of technical requirements for registration of pharmaceuticals for human use (ICH), designed to monitor compliance with the interests and safety of the patients. Personal information about potential and enrolled participants was collected and kept in strict confidence before, during and after the study. Written informed consent to participate in the study was obtained by the investigators from all participants before their participation in the study.\nAlexander D. Kulagin: Alexion Pharmaceuticals, Inc: consultancy, research funding; JSC GENERIUM: consultancy, honoraria, research funding. Vadim V. Ptushkin: Alexion Pharmaceuticals, Inc: consultancy, research funding; JSC GENERIUM: research funding; Janssen: consultancy; AbbVie: consultancy; Roche: consultancy. Elena A. Lukina: JSC GENERIUM: research funding; Sanofi Genzyme: honoraria, membership on an entity’s Board of Directors or advisory committees; Shire: Honoraria, Membership on an entity’s Board of Directors or advisory committees. Other: travel reimbursement, research funding. Oksana А. Markova: JSC GENERIUM: employment. Eugene V. Zuev: JSC GENERIUM: employment.\nThe study was organized and conducted with the support of GENERIUM JSC.\nContribution: AD.K., V.V.P., and E.A.L. recruited patients, collected data, analyzed and interpreted the data, contributed to the manuscript, and approved the final version; I.L.D., A.V.K., T.S.K., E.Yu.K., N.V.M., T.A.M., O.U.К., E.G.A., and V.D.L. recruited patients, collected data, contributed to the manuscript, and approved the final version; O.A.M. and E.V.Z. developed the protocol, analyzed and interpreted the data, contributed to the manuscript, and approved the final version.", "topic": "Diagnostic"}
{"pmid": "37456436", "pmcid": "12308542", "title": "Cost impact of Bruton’s tyrosine kinase inhibitor selection in Medicare patients with chronic lymphocytic leukemia", "publication_year": "2025", "abstract": "", "full_text": "Chronic lymphocytic leukemia (CLL) is a hematologic malignancy characterized by abnormal lymphocyte proliferation [\nCovalent Bruton’s tyrosine kinase inhibitors (cBTKis) – including ibrutinib, acalabrutinib and zanubrutinib – have significantly improved progression-free survival and overall survival over standard chemoimmunotherapy [\nBeyond efficacy, choice of cBTKi often relies on patient- and drug-specific factors such as comorbidities, cost and safety profiles [\nAssessing the implications of cBTKi treatment choice for CLL is essential to optimize both patient outcomes and the sustainability of cancer care systems. While physicians must tailor treatments to the unique needs and preferences of individual patients, the broader impact of treatment decisions on healthcare expenditures cannot be overlooked, particularly by payers such as the Centers for Medicare and Medicaid Services (CMS). Given the high prevalence of CLL among older adults, Medicare reimbursement policies will significantly influence access to these therapies. This highlights the need for value-based prescribing that considers not only patient outcomes but also the economic implications of safety profiles and treatment costs. To address these considerations, this study utilized economic modeling to assess the potential cost savings associated with choice of cBTKi across TN and RR patients with CLL, focusing on the impact of safety-related differences on health and economic outcomes from a Medicare perspective.\nAn economic model was constructed to simulate economic outcomes among patients with CLL initiating cBTKi therapy with ibrutinib, acalabrutinib, or zanubrutinib. A US payer perspective – specifically CMS – was used. The modeled population included both patients with TN and RR CLL from a Medicare perspective [\nTreatment with acalabrutinib was compared with ibrutinib and to zanubrutinib individually. Dosing and duration of therapy was modeled per current US FDA labeling information, which states all three cBTKis may be given indefinitely until disease progression or unacceptable toxicity [\nA Markov model approach simulated transitions between four treatment pathway health states in 28-day monthly cycles: cBTKi, venetoclax + rituximab, subsequent treatment (pooled pirtobrutinib, chimeric antigen receptor [CAR] T cell therapy with lisocabtagene maraleucel, and best supportive care [BSC]) and death (\nSubsequent treatment state consisted of a pool of pirtobrutinib, lisocabtagene maraleucel and best supportive care, weighted by real-world US distribution.\ncBTKi: Covalent Bruton’s tyrosine kinase inhibitors; CLL: Chronic lymphocytic leukemia.\nKey model inputs included safety, clinical, cost and epidemiology. (\nCost inputs shown in table are prior to adjustment for Medicare reimbursement using commercial-to-Medicare reimbursement ratios.\nAE: Adverse event; cBTKi: Covalent Bruton’s Tyrosine kinase inhibitor; CLL: Chronic lymphocytic leukemia; Pts: Patients; RR: Relapsed/refractory; TN: Treatment-naive; USD: United States dollar.\nClinical parameters were used to populate transition probabilities between health states. Clinical parameters included discontinuation rates for cBTKi and venetoclax + rituximab; uptake distribution of pirtobrutinib, CAR T cell therapy or BSC following discontinuation of venetoclax + rituximab; and mortality rates for cBTKi, venetoclax + rituximab, pirtobrutinib, CAR T cell therapy and BSC. No differences in efficacy among the three cBTKis were modeled; cost differences were driven by differences in treatment cost and cBTKi safety profiles. cBTKi discontinuation and mortality rates were based on real-world data and assumed equal across ibrutinib, acalabrutinib and zanubrutinib [\nCost parameters were used to estimate direct costs per monthly cycle in each health state. Costs in the cBTKi health state were calculated by adjusting the total cost of CLL care for the differential cost impact of different cBTKis AE rates and drug costs. A baseline estimate of total medical care costs (inpatient stays, emergency department [ED] visits, office visits and other outpatient and ancillary care) on targeted CLL therapy exclusive of AE costs [\nEpidemiology parameters were used to construct real-world estimates of expected costs in patients with CLL covered by Medicare who are eligible to start cBTKi, per-patient and nationwide. The real-world annual relative distribution of TN versus RR in CLL, where RR included patients in 2L–3L, was obtained from literature to weight cost estimates per TN and RR patient to derive an overall estimate of cost per patient with CLL [\nModeled patients with CLL were assumed to meet 2023 National Comprehensive Cancer Network (NCCN) criteria for cBTKi therapy [\nThe parameters were incorporated into a Microsoft Excel calculator model to estimate costs associated with cBTKi treatment choice over 1, 3 and 5 years. Separate Markov chain simulations were constructed for TN and RR populations using 28-day cycles and applying a 3% annual discount rate [\nA subgroup analysis was conducted to examine outcomes in special subpopulations of patients with CLL in Medicare including the disabled, terminally ill and patients with ESRD [\nUse of observed grade ≥3 AE rates from extended follow-up of pivotal cBTKi clinical trials with similar durations in the base case is transparent and avoids assumptions or extrapolation of trial data. However, when cBTKis are not compared head-to-head, differences in trial populations may impact AE rates and limit comparability. To address this concern, a scenario analysis was conducted using MAIC results to inform AE rates for cBTKi comparisons in TN and RR not available from head-to-head clinical trials. MAIC-adjusted grade ≥3 AE rates for ibrutinib in TN and zanubrutinib in TN and RR were derived by applying the relative differences in AE rates from acalabrutinib estimated in the available published MAICs to the acalabrutinib clinical trial rates used in the base case [\nUncertainty was tested through deterministic sensitivity analysis and probabilistic analysis (DSA, PA). DSA varied key individual safety, clinical and cost parameters +/-20%. PA was performed via Monte Carlo simulations over 5000 iterated scenarios using Microsoft Excel visual basic code. Costs were represented by γ distributions and probabilities by\nA cohort of 13,726 patients with CLL (44% TN, 56% RR) was modeled to reflect a real-world population with CLL covered by Medicare who are eligible to start cBTKi therapy. Infection was the most common grade ≥3 AE across cBTKis in TN (20.6% ibrutinib, 16.2% acalabrutinib, 23.8% zanubrutinib) and RR (30.0%, 31.0%, 35.5%) patients, followed by neutropenia (TN: 12.6%, 11.2%, 12.5%; RR: 23.0%, 20.0%, 22.2%). Overall, acalabrutinib had the lowest aggregate grade ≥3 AE rate, with reductions of 25.8%-points versus ibrutinib (35.8% vs 61.6%) and 20.6%-points versus zanubrutinib (35.8% vs 56.4%) in TN patients, and reductions of and 8.0%-points versus ibrutinib (75.0% vs 83.0%) and 11.1%-points versus zanubrutinib (75.0% vs 86.1%) in RR patients. Key differences for acalabrutinib included lower rates of grade ≥3 hypertension (2.8% vs 8.1% for ibrutinib and 9.2% for zanubrutinib), infections and atrial fibrillation (1.1% vs 5.2% for ibrutinib) in TN patients, and lower rates of grade ≥3 hypertension (4.0% vs 9.0% for ibrutinib and 16.4% for zanubrutinib), thrombocytopenia (10.0% vs 7.0% for ibrutinib and 3.7% for zanubrutinib) and diarrhea (1.0% acalabrutinib vs 5.0% ibrutinib) in RR patients. Ibrutinib, acalabrutinib and zanubrutinib annual WACs were $213,677, $186,979 and $183,303, respectively.\nCombining drug cost and grade ≥3 AE differences, acalabrutinib showed cost savings of $15,478 per patient versus ibrutinib over the first year of treatment, driven by lower treatment cost ($12,076 decrease) and lower AE cost ($3402 decrease) (\nTotal cost is the sum of direct medical care costs, including cost of AE management, and pharmacy costs associated with the cBTKi therapy. Positive numbers indicate cost saving with acalabrutinib; negative numbers indicate increased cost with acalabrutinib.\nAE: Adverse event; cBTKi: Covalent Bruton’s tyrosine kinase inhibitor; CLL: Chronic lymphocytic leukemia; USD: United States dollar.\nAcross all patients with CLL in Medicare, estimated cost savings with acalabrutinib over 1, 3 and 5 years, respectively, were $212 million, $326 million and $351 million versus ibrutinib, and $26 million, $10 million and $7 million versus zanubrutinib (\nTotal cost is the sum of direct medical care costs, including cost of AE management and pharmacy costs associated with the cBTKi therapy. Positive numbers indicate cost saving with acalabrutinib; negative numbers indicate increased cost with acalabrutinib.\ncBTKi: Covalent Bruton’s tyrosine kinase inhibitor; CLL: Chronic lymphocytic leukemia; USD: United States dollar.\nAmong the modeled cohort of 13,726 patients with CLL, 4875 were estimated to be disabled, 560 with ESRD and 1849 terminally ill. Compared with ibrutinib, acalabrutinib was associated with 1186 fewer, 95 fewer and 292 fewer grade ≥3 AEs across disabled, ESRD, terminally ill patients with CLL, respectively, over 1 year (\n*Annualized cost calculated as an average of annual costs weighted by the real-world distributions of TN versus RR and years since cBTKi therapy start across CMS special subpopulation (2024 USD, discounted).\nAE: Adverse event; cBTKi: Covalent Bruton’s tyrosine kinase inhibitor; CLL: Chronic lymphocytic leukemia; CMS: Centers for Medicare and Medicaid Services; ESRD: End stage renal disease; RR: Relapsed/refractory; TN: Treatment-naive; USD: United States dollar.\nMAIC informed aggregate grade ≥3 AE rates for acalabrutinib were 22.9% points less than ibrutinib and 5.0% points less than zanubrutinib in TN, and 8.0% points less than ibrutinib and 20.1% points less than zanubrutinib in RR. Differences in MAIC-informed AE rates resulted in cost savings with acalabrutinib over 1 year of $15,142 per patient versus ibrutinib and $1501 per patient versus zanubrutinib. In both alternate population scenarios, acalabrutinib resulted in cost savings compared with ibrutinib and zanubrutinib. Savings versus ibrutinib over 1 year were $16,919 per patient, totaling $138 million across all patients in scenario 1 and $313 million in scenario 2. Savings versus zanubrutinib over 1 year were $2529 per patient, totaling $21 million across all patients in scenario 1 and $47 million in scenario 2. Varying cBTKi discontinuation showed 1-year savings of $19,872 and $2267 per patient with acalabrutinib versus ibrutinib and zanubrutinib, respectively. Cost savings were generally maintained over 3 and 5 years (\nDifference in adverse event costs versus difference in pharmacy costs over 1 year between\nAE: Adverse event.\nUse of acalabrutinib among patients with TN and RR CLL yielded cost savings in comparison to other cBTKis from a CMS payer perspective. Results were driven by current cBTKi drug prices and reduced AE costs over short-term (1 year since cBTKi initiation) and longer-term (3 and 5 years). Acalabrutinib had both lower drug cost and lower grade ≥3 AEs rates than ibrutinib, making acalabrutinib a clear choice over ibrutinib. Although annual acalabrutinib WAC was $3676 more than zanubrutinib, this treatment cost difference was entirely offset by cost savings from lower grade ≥3 AEs rates with acalabrutinib.\nThis study is not only useful for payer decision-making in general, it can also help inform CMS decision-making under Inflation Reduction Act (IRA)-mandated ‘maximum fair price’ negotiations for select drugs covered under Medicare [\nStrengths of this study include modeling separate cohorts for TN and RR patients with CLL and use of safety data from pivotal phase III clinical trials. A pooled estimate across TN and RR patients with CLL was used to inform the cost impact of cBTKis because it is straightforward to interpret and aligns with CMS’s approach of negotiating drug prices at the drug level rather than indication level, considering the cost impact across all users in Medicare. However, this study was subject to limitations. Model health states represented treatment pathways rather than disease progression, and the model structure represented only one possible treatment pathway for both TN and RR CLL [\nAcalabrutinib yielded cost savings compared with ibrutinib and zanubrutinib for patients with CLL from a Medicare perspective due to lower treatment cost than ibrutinib and fewer grade ≥3 AEs than both ibrutinib and zanubrutinib.\nChronic lymphocytic leukemia (CLL) affects over 200,000 individuals in the US, with approximately 20,700 new cases, of which 70% aged 65 years or older at diagnosis, and 4500 deaths in 2024.\nCLL has had a number of recent clinical advancements including US FDA approved covalent Bruton’s tyrosine kinase inhibitors (cBKTis) ibrutinib, acalabrutinib and zanubrutinib.\nIbrutinib is limited by cardiovascular toxicities such as atrial fibrillation and hypertension, while acalabrutinib and zanubrutinib have improved selectivity, demonstrating reduced rates of cardiovascular adverse events (AEs) compared with ibrutinib in clinical trials.\nWhile there are no head-to-head clinical trials of acalabrutinib and zanubrutinib, matching-adjusted indirect comparisons (MAICs) have estimated significantly lower risk of hypertension, hemorrhage, serious AE and AE leading to dose reduction with acalabrutinib than zanubrutinib.\nThis study constructed an economic model to estimate potential cost impact to Medicare in choice of cBTKi based on differences in safety profiles for treatment of treatment-naive (TN) and relapsed/refractory (RR) patients with CLL.\nCompared with ibrutinib, acalabrutinib was associated with cost savings of $15,478 per patient over the first year of treatment, driven by lower treatment cost ($12,076 decrease) and lower AE cost ($3402 decrease).\nCompared with zanubrutinib, acalabrutinib was associated with cost savings of $1901 per patient over the first year of treatment, as higher acalabrutinib treatment cost ($1663 increase) was offset by lower AE cost ($3563 decrease).\nCost savings with acalabrutinib versus ibrutinib and zanubrutinib persisted over 3 ($25,615; $1331) and 5 ($27,635; $1053) years.\nAt current drug prices, the CLL population-level annualized cost savings to CMS with acalabrutinib would be $64 million versus ibrutinib and $2 million versus zanubrutinib.\nFindings of this study can be used to inform Medicare national coverage determinations, reimbursement policies and value-based contracts such as through drug price negotiations under the Inflation Reduction Act, which will have significant implications for access to these cBTKi treatments for the majority of patients with CLL.", "content_for_embedding": "Chronic lymphocytic leukemia (CLL) is a hematologic malignancy characterized by abnormal lymphocyte proliferation [\nCovalent Bruton’s tyrosine kinase inhibitors (cBTKis) – including ibrutinib, acalabrutinib and zanubrutinib – have significantly improved progression-free survival and overall survival over standard chemoimmunotherapy [\nBeyond efficacy, choice of cBTKi often relies on patient- and drug-specific factors such as comorbidities, cost and safety profiles [\nAssessing the implications of cBTKi treatment choice for CLL is essential to optimize both patient outcomes and the sustainability of cancer care systems. While physicians must tailor treatments to the unique needs and preferences of individual patients, the broader impact of treatment decisions on healthcare expenditures cannot be overlooked, particularly by payers such as the Centers for Medicare and Medicaid Services (CMS). Given the high prevalence of CLL among older adults, Medicare reimbursement policies will significantly influence access to these therapies. This highlights the need for value-based prescribing that considers not only patient outcomes but also the economic implications of safety profiles and treatment costs. To address these considerations, this study utilized economic modeling to assess the potential cost savings associated with choice of cBTKi across TN and RR patients with CLL, focusing on the impact of safety-related differences on health and economic outcomes from a Medicare perspective.\nAn economic model was constructed to simulate economic outcomes among patients with CLL initiating cBTKi therapy with ibrutinib, acalabrutinib, or zanubrutinib. A US payer perspective – specifically CMS – was used. The modeled population included both patients with TN and RR CLL from a Medicare perspective [\nTreatment with acalabrutinib was compared with ibrutinib and to zanubrutinib individually. Dosing and duration of therapy was modeled per current US FDA labeling information, which states all three cBTKis may be given indefinitely until disease progression or unacceptable toxicity [\nA Markov model approach simulated transitions between four treatment pathway health states in 28-day monthly cycles: cBTKi, venetoclax + rituximab, subsequent treatment (pooled pirtobrutinib, chimeric antigen receptor [CAR] T cell therapy with lisocabtagene maraleucel, and best supportive care [BSC]) and death (\nSubsequent treatment state consisted of a pool of pirtobrutinib, lisocabtagene maraleucel and best supportive care, weighted by real-world US distribution.\ncBTKi: Covalent Bruton’s tyrosine kinase inhibitors; CLL: Chronic lymphocytic leukemia.\nKey model inputs included safety, clinical, cost and epidemiology. (\nCost inputs shown in table are prior to adjustment for Medicare reimbursement using commercial-to-Medicare reimbursement ratios.\nAE: Adverse event; cBTKi: Covalent Bruton’s Tyrosine kinase inhibitor; CLL: Chronic lymphocytic leukemia; Pts: Patients; RR: Relapsed/refractory; TN: Treatment-naive; USD: United States dollar.\nClinical parameters were used to populate transition probabilities between health states. Clinical parameters included discontinuation rates for cBTKi and venetoclax + rituximab; uptake distribution of pirtobrutinib, CAR T cell therapy or BSC following discontinuation of venetoclax + rituximab; and mortality rates for cBTKi, venetoclax + rituximab, pirtobrutinib, CAR T cell therapy and BSC. No differences in efficacy among the three cBTKis were modeled; cost differences were driven by differences in treatment cost and cBTKi safety profiles. cBTKi discontinuation and mortality rates were based on real-world data and assumed equal across ibrutinib, acalabrutinib and zanubrutinib [\nCost parameters were used to estimate direct costs per monthly cycle in each health state. Costs in the cBTKi health state were calculated by adjusting the total cost of CLL care for the differential cost impact of different cBTKis AE rates and drug costs. A baseline estimate of total medical care costs (inpatient stays, emergency department [ED] visits, office visits and other outpatient and ancillary care) on targeted CLL therapy exclusive of AE costs [\nEpidemiology parameters were used to construct real-world estimates of expected costs in patients with CLL covered by Medicare who are eligible to start cBTKi, per-patient and nationwide. The real-world annual relative distribution of TN versus RR in CLL, where RR included patients in 2L–3L, was obtained from literature to weight cost estimates per TN and RR patient to derive an overall estimate of cost per patient with CLL [\nModeled patients with CLL were assumed to meet 2023 National Comprehensive Cancer Network (NCCN) criteria for cBTKi therapy [\nThe parameters were incorporated into a Microsoft Excel calculator model to estimate costs associated with cBTKi treatment choice over 1, 3 and 5 years. Separate Markov chain simulations were constructed for TN and RR populations using 28-day cycles and applying a 3% annual discount rate [\nA subgroup analysis was conducted to examine outcomes in special subpopulations of patients with CLL in Medicare including the disabled, terminally ill and patients with ESRD [\nUse of observed grade ≥3 AE rates from extended follow-up of pivotal cBTKi clinical trials with similar durations in the base case is transparent and avoids assumptions or extrapolation of trial data. However, when cBTKis are not compared head-to-head, differences in trial populations may impact AE rates and limit comparability. To address this concern, a scenario analysis was conducted using MAIC results to inform AE rates for cBTKi comparisons in TN and RR not available from head-to-head clinical trials. MAIC-adjusted grade ≥3 AE rates for ibrutinib in TN and zanubrutinib in TN and RR were derived by applying the relative differences in AE rates from acalabrutinib estimated in the available published MAICs to the acalabrutinib clinical trial rates used in the base case [\nUncertainty was tested through deterministic sensitivity analysis and probabilistic analysis (DSA, PA). DSA varied key individual safety, clinical and cost parameters +/-20%. PA was performed via Monte Carlo simulations over 5000 iterated scenarios using Microsoft Excel visual basic code. Costs were represented by γ distributions and probabilities by\nA cohort of 13,726 patients with CLL (44% TN, 56% RR) was modeled to reflect a real-world population with CLL covered by Medicare who are eligible to start cBTKi therapy. Infection was the most common grade ≥3 AE across cBTKis in TN (20.6% ibrutinib, 16.2% acalabrutinib, 23.8% zanubrutinib) and RR (30.0%, 31.0%, 35.5%) patients, followed by neutropenia (TN: 12.6%, 11.2%, 12.5%; RR: 23.0%, 20.0%, 22.2%). Overall, acalabrutinib had the lowest aggregate grade ≥3 AE rate, with reductions of 25.8%-points versus ibrutinib (35.8% vs 61.6%) and 20.6%-points versus zanubrutinib (35.8% vs 56.4%) in TN patients, and reductions of and 8.0%-points versus ibrutinib (75.0% vs 83.0%) and 11.1%-points versus zanubrutinib (75.0% vs 86.1%) in RR patients. Key differences for acalabrutinib included lower rates of grade ≥3 hypertension (2.8% vs 8.1% for ibrutinib and 9.2% for zanubrutinib), infections and atrial fibrillation (1.1% vs 5.2% for ibrutinib) in TN patients, and lower rates of grade ≥3 hypertension (4.0% vs 9.0% for ibrutinib and 16.4% for zanubrutinib), thrombocytopenia (10.0% vs 7.0% for ibrutinib and 3.7% for zanubrutinib) and diarrhea (1.0% acalabrutinib vs 5.0% ibrutinib) in RR patients. Ibrutinib, acalabrutinib and zanubrutinib annual WACs were $213,677, $186,979 and $183,303, respectively.\nCombining drug cost and grade ≥3 AE differences, acalabrutinib showed cost savings of $15,478 per patient versus ibrutinib over the first year of treatment, driven by lower treatment cost ($12,076 decrease) and lower AE cost ($3402 decrease) (\nTotal cost is the sum of direct medical care costs, including cost of AE management, and pharmacy costs associated with the cBTKi therapy. Positive numbers indicate cost saving with acalabrutinib; negative numbers indicate increased cost with acalabrutinib.\nAE: Adverse event; cBTKi: Covalent Bruton’s tyrosine kinase inhibitor; CLL: Chronic lymphocytic leukemia; USD: United States dollar.\nAcross all patients with CLL in Medicare, estimated cost savings with acalabrutinib over 1, 3 and 5 years, respectively, were $212 million, $326 million and $351 million versus ibrutinib, and $26 million, $10 million and $7 million versus zanubrutinib (\nTotal cost is the sum of direct medical care costs, including cost of AE management and pharmacy costs associated with the cBTKi therapy. Positive numbers indicate cost saving with acalabrutinib; negative numbers indicate increased cost with acalabrutinib.\ncBTKi: Covalent Bruton’s tyrosine kinase inhibitor; CLL: Chronic lymphocytic leukemia; USD: United States dollar.\nAmong the modeled cohort of 13,726 patients with CLL, 4875 were estimated to be disabled, 560 with ESRD and 1849 terminally ill. Compared with ibrutinib, acalabrutinib was associated with 1186 fewer, 95 fewer and 292 fewer grade ≥3 AEs across disabled, ESRD, terminally ill patients with CLL, respectively, over 1 year (\n*Annualized cost calculated as an average of annual costs weighted by the real-world distributions of TN versus RR and years since cBTKi therapy start across CMS special subpopulation (2024 USD, discounted).\nAE: Adverse event; cBTKi: Covalent Bruton’s tyrosine kinase inhibitor; CLL: Chronic lymphocytic leukemia; CMS: Centers for Medicare and Medicaid Services; ESRD: End stage renal disease; RR: Relapsed/refractory; TN: Treatment-naive; USD: United States dollar.\nMAIC informed aggregate grade ≥3 AE rates for acalabrutinib were 22.9% points less than ibrutinib and 5.0% points less than zanubrutinib in TN, and 8.0% points less than ibrutinib and 20.1% points less than zanubrutinib in RR. Differences in MAIC-informed AE rates resulted in cost savings with acalabrutinib over 1 year of $15,142 per patient versus ibrutinib and $1501 per patient versus zanubrutinib. In both alternate population scenarios, acalabrutinib resulted in cost savings compared with ibrutinib and zanubrutinib. Savings versus ibrutinib over 1 year were $16,919 per patient, totaling $138 million across all patients in scenario 1 and $313 million in scenario 2. Savings versus zanubrutinib over 1 year were $2529 per patient, totaling $21 million across all patients in scenario 1 and $47 million in scenario 2. Varying cBTKi discontinuation showed 1-year savings of $19,872 and $2267 per patient with acalabrutinib versus ibrutinib and zanubrutinib, respectively. Cost savings were generally maintained over 3 and 5 years (\nDifference in adverse event costs versus difference in pharmacy costs over 1 year between\nAE: Adverse event.\nUse of acalabrutinib among patients with TN and RR CLL yielded cost savings in comparison to other cBTKis from a CMS payer perspective. Results were driven by current cBTKi drug prices and reduced AE costs over short-term (1 year since cBTKi initiation) and longer-term (3 and 5 years). Acalabrutinib had both lower drug cost and lower grade ≥3 AEs rates than ibrutinib, making acalabrutinib a clear choice over ibrutinib. Although annual acalabrutinib WAC was $3676 more than zanubrutinib, this treatment cost difference was entirely offset by cost savings from lower grade ≥3 AEs rates with acalabrutinib.\nThis study is not only useful for payer decision-making in general, it can also help inform CMS decision-making under Inflation Reduction Act (IRA)-mandated ‘maximum fair price’ negotiations for select drugs covered under Medicare [\nStrengths of this study include modeling separate cohorts for TN and RR patients with CLL and use of safety data from pivotal phase III clinical trials. A pooled estimate across TN and RR patients with CLL was used to inform the cost impact of cBTKis because it is straightforward to interpret and aligns with CMS’s approach of negotiating drug prices at the drug level rather than indication level, considering the cost impact across all users in Medicare. However, this study was subject to limitations. Model health states represented treatment pathways rather than disease progression, and the model structure represented only one possible treatment pathway for both TN and RR CLL [\nAcalabrutinib yielded cost savings compared with ibrutinib and zanubrutinib for patients with CLL from a Medicare perspective due to lower treatment cost than ibrutinib and fewer grade ≥3 AEs than both ibrutinib and zanubrutinib.\nChronic lymphocytic leukemia (CLL) affects over 200,000 individuals in the US, with approximately 20,700 new cases, of which 70% aged 65 years or older at diagnosis, and 4500 deaths in 2024.\nCLL has had a number of recent clinical advancements including US FDA approved covalent Bruton’s tyrosine kinase inhibitors (cBKTis) ibrutinib, acalabrutinib and zanubrutinib.\nIbrutinib is limited by cardiovascular toxicities such as atrial fibrillation and hypertension, while acalabrutinib and zanubrutinib have improved selectivity, demonstrating reduced rates of cardiovascular adverse events (AEs) compared with ibrutinib in clinical trials.\nWhile there are no head-to-head clinical trials of acalabrutinib and zanubrutinib, matching-adjusted indirect comparisons (MAICs) have estimated significantly lower risk of hypertension, hemorrhage, serious AE and AE leading to dose reduction with acalabrutinib than zanubrutinib.\nThis study constructed an economic model to estimate potential cost impact to Medicare in choice of cBTKi based on differences in safety profiles for treatment of treatment-naive (TN) and relapsed/refractory (RR) patients with CLL.\nCompared with ibrutinib, acalabrutinib was associated with cost savings of $15,478 per patient over the first year of treatment, driven by lower treatment cost ($12,076 decrease) and lower AE cost ($3402 decrease).\nCompared with zanubrutinib, acalabrutinib was associated with cost savings of $1901 per patient over the first year of treatment, as higher acalabrutinib treatment cost ($1663 increase) was offset by lower AE cost ($3563 decrease).\nCost savings with acalabrutinib versus ibrutinib and zanubrutinib persisted over 3 ($25,615; $1331) and 5 ($27,635; $1053) years.\nAt current drug prices, the CLL population-level annualized cost savings to CMS with acalabrutinib would be $64 million versus ibrutinib and $2 million versus zanubrutinib.\nFindings of this study can be used to inform Medicare national coverage determinations, reimbursement policies and value-based contracts such as through drug price negotiations under the Inflation Reduction Act, which will have significant implications for access to these cBTKi treatments for the majority of patients with CLL.", "topic": "Diagnostic"}

{"pmid": "40729485", "pmcid": "12306926", "title": "Associations of Plasma p‐tau181 With Age, Adjusted for Kidney Function and Sociodemographic Factors", "publication_year": "N/A", "abstract": "", "full_text": "Alzheimer’s disease\nAlzheimer’s Disease Neuroimaging Initiative\nAmyloid‐PET positive\nAmyloid‐PET negative\nCognitively unimpaired\nCognitively impaired non‐AD\n95% Confidence Intervals\nInterquartile range\nMild cognitive impairment\nPresenilin 1 gene\nNational Institute on Ageing and Alzheimer’s Association\nstandard deviation\nStandardised uptake value\nWashington Heights‐Inwood Columbia Ageing Project\nIncreased\nPositive\nnegative\nPlasma phosphorylated (p‐tau) proteins are among the leading blood biomarkers for the detection of AD pathology [\nFollowing recent marketing approvals in the U.S. for amyloid‐lowering therapies, the Alzheimer's Association have proposed updated criteria for the biological definition of Alzheimer's disease [\nA PubMed literature search using the terms (plasma AND p‐tau AND tau) identified studies exploring associations between p‐tau and age, with inclusion criteria of peer‐reviewed, published studies in English. Included studies reported on plasma p‐tau217 or plasma p‐tau181 levels using an ultra‐sensitive immunoassay, as well as age. Seven cohort studies reported on the association of plasma p‐tau levels with age, with characteristics and main findings are summarised in Table\nHowever, the association between p‐tau181 and age is inconsistent, particularly in amyloid‐negative individuals, and its interaction with amyloid status remains underexplored. Bouteloup et al. found age as a primary driver of AD biomarker variance in cognitively unimpaired cohorts [\nThis study investigates the influence of age, renal function, BMI, ethnicity, sex and amyloid pathology on plasma p‐tau181 levels using the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, informed by the literature search, to contribute to blood biomarker reference ranges for AD diagnosis in community settings.\nWe used anonymised data available from ADNI (ADNI‐LONI [\nWe analysed a subset of an ADNI cohort, comprising 1111 observations from 706 participants in a previous study [\nStudy flow diagram of data inclusion and statistical analyses. 1 AD Group: Amyloid‐PET 18F‐florbetapir Standardised Uptake Value Ratio (SUVR) ≥ 1.11 and Clinical Dementia Rating Sum of Boxes (CDR‐SB) global scores > 0. 2 Control group: Amyloid‐PET 18F‐florbetapir SUVR < 1.11 and CDR‐SB = 0.\nParticipants were stratified by amyloid‐PET (18F‐florbetapir), Standardised Uptake Value Ratio (SUVR) ≥ 1.11 and Clinical Dementia Rating Sum of Boxes (CDR‐SB) global scores [\nPredictors, identified from the literature search, included age, creatinine Nightingale Health's NMR metabolomics platform [\nBMI was recorded at the baseline visit, and ethnicity was comprised of two categories: White or ‘minority ethnic group’, which included American Indian or Alaskan Native, Asian, Black or African American, Native Hawaiian or Other Pacific Islander and More Than One Race groups. We chose to combine these minority ethnic groups as individual groups were relatively small (range\nMissingness tests, specifically Little's MCAR test, indicated that data were Missing Completely at Random (MCAR) for p‐tau181 (\nModel assumptions (linearity, homoscedasticity, no multicollinearity [variance inflation factors (VIFs) < 1.3]) were assessed using residual plots for linearity and homoscedasticity, VIFs for multicollinearity, and the Shapiro‐Wilk test (\nAge, creatinine, BMI, sex and ethnicity were identified as factors that could also potentially influence plasma p‐tau181 concentration from relevant studies during the literature search.\nWe first used a mixed‐effects multivariable linear regression model (the ‘fully adjusted model’) to estimate effects of age on plasma p‐tau181 concentration adjusting for group status (Controls vs. AD), sex, creatinine, BMI and ethnicity, with a random intercept for participant ID. Mixed‐effects models can account for both fixed effects and random effects associated with intra‐individual variation with repeated measures.\nNext we used separate single‐variable LMMs with a random intercept for participant ID to evaluate the fixed effects of age, creatinine, BMI, sex, and ethnicity on plasma p‐tau181 levels in the ADNI cohort, incorporating interaction terms with Group status (Control vs. AD) to assess whether these effects vary by group (e.g., Age × Group (Control vs. AD), BMI × Group (Control vs. AD)).\nAll analyses were performed using\nThe study sample included 581 unique participants, with 357 AD (amyloid‐PET SUVR ≥ 1.11, CDR‐SB > 0) and 224 Control (SUVR < 1.11, CDR‐SB = 0) participants. Demographic characteristics (Table\nA summary of study characteristics and main findings.\nThis model was employed to assess the impact of age on plasma p‐tau181 levels while adjusting for multiple covariates, including creatinine, BMI, sex, group status, and ethnicity, with a random intercept for participant ID to account for within‐subject correlations. The model revealed a non‐significant effect of age on p‐tau181 (\nMixed effects regression analyses examining the association between p‐tau181 levels and group, age, creatinine, BMI, sex, and minority ethnic group.\n\n\n\n*\nSerum Creatinine (μmol/L).\nMale reference value.\nWhite reference value.\nInteraction terms (e.g., Age: Group) represent the additional effect of the covariate across Group levels (Control vs. AD), calculated as the product of the variables.\nTo explore group‐specific effects, separate LMMs were fitted for each covariate with an interaction term for group status (Control vs. AD).\nThe interaction between age and disease status was not significant (\nFor the ADNI data, the mean duration between creatinine and p‐tau blood draw dates was 29.6 (SD 44.9) days. There was no significant interaction between creatinine and group status (\nThe interaction between BMI and group status was significant (−0.39 pg/mL per kg/m\nThe interaction with group status was not significant (\nSex did not demonstrate a significant interaction with group status (\nThis study used linear mixed models (LMMs) within the ADNI cohort to examine the effects of age on p‐tau181 while adjusting for creatinine, BMI, sex, ethnicity, and group status (Control vs. AD) as identified from a literature search. We also assessed whether there was a group effect on any association between each individual variable and p‐tau181.\nIn the fully adjusted LLM, AD group status and creatinine showed a significant positive association with plasma p‐tau181 levels, and BMI showed a significant negative association with p‐tau181. Group status may have obscured the total effect of age on p‐tau181, as its removal from the model resulted in a significant age effect. Single‐variable models showed that the positive association between either age or creatinine and plasma p‐tau did not differ between control and AD groups. The negative association between BMI and plasma p‐tau was stronger in AD versus control groups.\nOur findings align with prior studies on plasma p‐tau181 associations. Seven studies reported on p‐tau181 and age, with five finding a positive association in cognitively impaired participants [\nIn terms of methods used, four studies performed a regression analysis of age on plasma p‐tau levels [\nOnly two studies examined age‐related differences in plasma p‐tau by amyloid‐PET status [\nThere were key differences between these studies in terms of participant characteristics and methods (Table\nFurther work in other independent datasets is needed to establish if there is a clinically important association, and if specific age‐related reference ranges are required. Age‐specific reference ranges have been produced for another blood‐based biomarker, serum neurofilament light, where levels have been positively associated with age [\nThe molecular pathways associated with plasma p‐tau and increasing age have not been fully explained. Age‐related amyloid‐β accumulation is associated with increased plasma p‐tau, particularly p‐tau217 and p‐tau231 [\nThe significant creatinine p‐tau181 association in our study is consistent with reports of higher p‐tau181 in chronic kidney disease (CKD). Impaired renal function is believed to affect plasma p‐tau levels via reduced clearance of p‐tau from the blood, resulting in elevated levels [\nBMI may also affect plasma p‐tau levels [\nThis negative BMI association aligns with Brickman et al. who reported that increased BMI was associated with lower plasma p‐tau181 and p‐tau217 levels [\nMinority ethnic group did not show a significant association with plasma p‐tau181 levels. Brickman et al. selected a cohort with equal proportion of ethnic groups, which included non‐Hispanic White (White), Hispanic, and non‐Hispanic Black/African American participants. They reported similar p‐tau levels amongst the three ethnic groups [\nMielke et al. reported that there were no significant differences in plasma p‐tau181 levels by sex in the entire cohort [\nSeveral medical comorbidities may influence plasma p‐tau levels as they are risk factors for AD or affect physiological processes [\nThese findings highlight the interplay of renal, metabolic, and demographic factors in p‐tau181 variability, necessitating tailored clinical guidelines for AD biomarker use in diverse, ageing populations.\nThe literature search was limited by requiring both ‘plasma’ and ‘p‐tau’ as search terms and focussing on studies reporting associations with age. The combined ‘plasma p‐tau’ term may have excluded studies using alternative terms, while the association focus, chosen for comparability with our linear mixed‐effects model analyses, may have omitted null findings or non‐associational designs, introducing publication bias and restricting contextual evidence. Using serum creatinine instead of eGFR as a kidney function marker avoids multicollinearity with age and sex but has limitations. eGFR, preferred clinically for standardised adjustments [\nLimitations in the ADNI data analyses were that the participants' BMI values were only included at baseline visit, with an average of 603 days between the baseline BMI visit and p‐tau measure. The time difference between creatinine and p‐tau181 measurements was constrained to ≤ 365 days (mean = 29.6, SD = 44.9 days), and observations with missing serum creatinine (55, ∼5%) or BMI (6, ∼0.5%) values were omitted to ensure complete and temporally relevant data for linear mixed modelling. However, even this shorter creatinine–p‐tau gap may affect associations due to potential renal function changes with the passage of time, given the possible renal clearance of p‐tau181 [\nFurther research is needed to study the age‐adjusted effect of co‐morbidities such as high BMI, poor renal function, cardiac conditions and prior stroke, on plasma p‐tau levels. No studies recorded the disease duration of participants. This may have an important influence of plasma p‐tau levels. A limitation of this study was the reliance on a single database, albeit one that provides data from a global, large, and diverse cohort. Prospective longitudinal cohort studies using real‐world populations with data on disease duration, co‐morbidities, sociodemographic factors, and amyloid status may more robustly address knowledge gaps on the association between p‐tau and age.\nThis study provides insights into the factors that may influence plasma p‐tau181 levels. The results may help refine reference ranges and interpretation guidelines, though further validation is needed. A considered approach is required to effectively prepare clinicians to interpret plasma p‐tau in a clinical setting, where most patients seen are in the older age category, are ethnically diverse and have multiple medical co‐morbidities. This is to ensure that the blood biomarker level is interpreted holistically in the context of the clinical picture. There are currently limitations in their application with further prospective validation work to confirm the association of co‐variates on plasma p‐tau levels. The use of educational tools to accompany biomarker results and provide information on the context and limitations of p‐tau values will be essential.\nAll authors contributed to the conception and design of the review. JH wrote the first draft and all authors revised and approved the article for publication.\nHZ has served at scientific advisory boards and/or as a consultant for Abbvie, Acumen, Alector, Alzinova, ALZPath, Amylyx, Annexon, Apellis, Artery Therapeutics, AZTherapies, Cognito Therapeutics, CogRx, Denali, Eisai, Merry Life, Nervgen, Novo Nordisk, Optoceutics, Passage Bio, Pinteon Therapeutics, Prothena, Red Abbey Labs, reMYND, Roche, Samumed, Siemens Healthineers, Triplet Therapeutics, and Wave, has given lectures in symposia sponsored by Alzecure, Biogen, Cellectricon, Fujirebio, Lilly, Novo Nordisk, and Roche, and is a co‐founder of Brain Biomarker Solutions in Gothenburg AB (BBS), which is a part of the GU Ventures Incubator Programme (outside submitted work). NF has served at scientific advisory boards and/or as a consultant for Biogen, Eisai, Ionis, Lilly, Roche/Genentech, and Siemens.\nTable S1\nTable S2", "content_for_embedding": "Alzheimer’s disease\nAlzheimer’s Disease Neuroimaging Initiative\nAmyloid‐PET positive\nAmyloid‐PET negative\nCognitively unimpaired\nCognitively impaired non‐AD\n95% Confidence Intervals\nInterquartile range\nMild cognitive impairment\nPresenilin 1 gene\nNational Institute on Ageing and Alzheimer’s Association\nstandard deviation\nStandardised uptake value\nWashington Heights‐Inwood Columbia Ageing Project\nIncreased\nPositive\nnegative\nPlasma phosphorylated (p‐tau) proteins are among the leading blood biomarkers for the detection of AD pathology [\nFollowing recent marketing approvals in the U.S. for amyloid‐lowering therapies, the Alzheimer's Association have proposed updated criteria for the biological definition of Alzheimer's disease [\nA PubMed literature search using the terms (plasma AND p‐tau AND tau) identified studies exploring associations between p‐tau and age, with inclusion criteria of peer‐reviewed, published studies in English. Included studies reported on plasma p‐tau217 or plasma p‐tau181 levels using an ultra‐sensitive immunoassay, as well as age. Seven cohort studies reported on the association of plasma p‐tau levels with age, with characteristics and main findings are summarised in Table\nHowever, the association between p‐tau181 and age is inconsistent, particularly in amyloid‐negative individuals, and its interaction with amyloid status remains underexplored. Bouteloup et al. found age as a primary driver of AD biomarker variance in cognitively unimpaired cohorts [\nThis study investigates the influence of age, renal function, BMI, ethnicity, sex and amyloid pathology on plasma p‐tau181 levels using the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, informed by the literature search, to contribute to blood biomarker reference ranges for AD diagnosis in community settings.\nWe used anonymised data available from ADNI (ADNI‐LONI [\nWe analysed a subset of an ADNI cohort, comprising 1111 observations from 706 participants in a previous study [\nStudy flow diagram of data inclusion and statistical analyses. 1 AD Group: Amyloid‐PET 18F‐florbetapir Standardised Uptake Value Ratio (SUVR) ≥ 1.11 and Clinical Dementia Rating Sum of Boxes (CDR‐SB) global scores > 0. 2 Control group: Amyloid‐PET 18F‐florbetapir SUVR < 1.11 and CDR‐SB = 0.\nParticipants were stratified by amyloid‐PET (18F‐florbetapir), Standardised Uptake Value Ratio (SUVR) ≥ 1.11 and Clinical Dementia Rating Sum of Boxes (CDR‐SB) global scores [\nPredictors, identified from the literature search, included age, creatinine Nightingale Health's NMR metabolomics platform [\nBMI was recorded at the baseline visit, and ethnicity was comprised of two categories: White or ‘minority ethnic group’, which included American Indian or Alaskan Native, Asian, Black or African American, Native Hawaiian or Other Pacific Islander and More Than One Race groups. We chose to combine these minority ethnic groups as individual groups were relatively small (range\nMissingness tests, specifically Little's MCAR test, indicated that data were Missing Completely at Random (MCAR) for p‐tau181 (\nModel assumptions (linearity, homoscedasticity, no multicollinearity [variance inflation factors (VIFs) < 1.3]) were assessed using residual plots for linearity and homoscedasticity, VIFs for multicollinearity, and the Shapiro‐Wilk test (\nAge, creatinine, BMI, sex and ethnicity were identified as factors that could also potentially influence plasma p‐tau181 concentration from relevant studies during the literature search.\nWe first used a mixed‐effects multivariable linear regression model (the ‘fully adjusted model’) to estimate effects of age on plasma p‐tau181 concentration adjusting for group status (Controls vs. AD), sex, creatinine, BMI and ethnicity, with a random intercept for participant ID. Mixed‐effects models can account for both fixed effects and random effects associated with intra‐individual variation with repeated measures.\nNext we used separate single‐variable LMMs with a random intercept for participant ID to evaluate the fixed effects of age, creatinine, BMI, sex, and ethnicity on plasma p‐tau181 levels in the ADNI cohort, incorporating interaction terms with Group status (Control vs. AD) to assess whether these effects vary by group (e.g., Age × Group (Control vs. AD), BMI × Group (Control vs. AD)).\nAll analyses were performed using\nThe study sample included 581 unique participants, with 357 AD (amyloid‐PET SUVR ≥ 1.11, CDR‐SB > 0) and 224 Control (SUVR < 1.11, CDR‐SB = 0) participants. Demographic characteristics (Table\nA summary of study characteristics and main findings.\nThis model was employed to assess the impact of age on plasma p‐tau181 levels while adjusting for multiple covariates, including creatinine, BMI, sex, group status, and ethnicity, with a random intercept for participant ID to account for within‐subject correlations. The model revealed a non‐significant effect of age on p‐tau181 (\nMixed effects regression analyses examining the association between p‐tau181 levels and group, age, creatinine, BMI, sex, and minority ethnic group.\n\n\n\n*\nSerum Creatinine (μmol/L).\nMale reference value.\nWhite reference value.\nInteraction terms (e.g., Age: Group) represent the additional effect of the covariate across Group levels (Control vs. AD), calculated as the product of the variables.\nTo explore group‐specific effects, separate LMMs were fitted for each covariate with an interaction term for group status (Control vs. AD).\nThe interaction between age and disease status was not significant (\nFor the ADNI data, the mean duration between creatinine and p‐tau blood draw dates was 29.6 (SD 44.9) days. There was no significant interaction between creatinine and group status (\nThe interaction between BMI and group status was significant (−0.39 pg/mL per kg/m\nThe interaction with group status was not significant (\nSex did not demonstrate a significant interaction with group status (\nThis study used linear mixed models (LMMs) within the ADNI cohort to examine the effects of age on p‐tau181 while adjusting for creatinine, BMI, sex, ethnicity, and group status (Control vs. AD) as identified from a literature search. We also assessed whether there was a group effect on any association between each individual variable and p‐tau181.\nIn the fully adjusted LLM, AD group status and creatinine showed a significant positive association with plasma p‐tau181 levels, and BMI showed a significant negative association with p‐tau181. Group status may have obscured the total effect of age on p‐tau181, as its removal from the model resulted in a significant age effect. Single‐variable models showed that the positive association between either age or creatinine and plasma p‐tau did not differ between control and AD groups. The negative association between BMI and plasma p‐tau was stronger in AD versus control groups.\nOur findings align with prior studies on plasma p‐tau181 associations. Seven studies reported on p‐tau181 and age, with five finding a positive association in cognitively impaired participants [\nIn terms of methods used, four studies performed a regression analysis of age on plasma p‐tau levels [\nOnly two studies examined age‐related differences in plasma p‐tau by amyloid‐PET status [\nThere were key differences between these studies in terms of participant characteristics and methods (Table\nFurther work in other independent datasets is needed to establish if there is a clinically important association, and if specific age‐related reference ranges are required. Age‐specific reference ranges have been produced for another blood‐based biomarker, serum neurofilament light, where levels have been positively associated with age [\nThe molecular pathways associated with plasma p‐tau and increasing age have not been fully explained. Age‐related amyloid‐β accumulation is associated with increased plasma p‐tau, particularly p‐tau217 and p‐tau231 [\nThe significant creatinine p‐tau181 association in our study is consistent with reports of higher p‐tau181 in chronic kidney disease (CKD). Impaired renal function is believed to affect plasma p‐tau levels via reduced clearance of p‐tau from the blood, resulting in elevated levels [\nBMI may also affect plasma p‐tau levels [\nThis negative BMI association aligns with Brickman et al. who reported that increased BMI was associated with lower plasma p‐tau181 and p‐tau217 levels [\nMinority ethnic group did not show a significant association with plasma p‐tau181 levels. Brickman et al. selected a cohort with equal proportion of ethnic groups, which included non‐Hispanic White (White), Hispanic, and non‐Hispanic Black/African American participants. They reported similar p‐tau levels amongst the three ethnic groups [\nMielke et al. reported that there were no significant differences in plasma p‐tau181 levels by sex in the entire cohort [\nSeveral medical comorbidities may influence plasma p‐tau levels as they are risk factors for AD or affect physiological processes [\nThese findings highlight the interplay of renal, metabolic, and demographic factors in p‐tau181 variability, necessitating tailored clinical guidelines for AD biomarker use in diverse, ageing populations.\nThe literature search was limited by requiring both ‘plasma’ and ‘p‐tau’ as search terms and focussing on studies reporting associations with age. The combined ‘plasma p‐tau’ term may have excluded studies using alternative terms, while the association focus, chosen for comparability with our linear mixed‐effects model analyses, may have omitted null findings or non‐associational designs, introducing publication bias and restricting contextual evidence. Using serum creatinine instead of eGFR as a kidney function marker avoids multicollinearity with age and sex but has limitations. eGFR, preferred clinically for standardised adjustments [\nLimitations in the ADNI data analyses were that the participants' BMI values were only included at baseline visit, with an average of 603 days between the baseline BMI visit and p‐tau measure. The time difference between creatinine and p‐tau181 measurements was constrained to ≤ 365 days (mean = 29.6, SD = 44.9 days), and observations with missing serum creatinine (55, ∼5%) or BMI (6, ∼0.5%) values were omitted to ensure complete and temporally relevant data for linear mixed modelling. However, even this shorter creatinine–p‐tau gap may affect associations due to potential renal function changes with the passage of time, given the possible renal clearance of p‐tau181 [\nFurther research is needed to study the age‐adjusted effect of co‐morbidities such as high BMI, poor renal function, cardiac conditions and prior stroke, on plasma p‐tau levels. No studies recorded the disease duration of participants. This may have an important influence of plasma p‐tau levels. A limitation of this study was the reliance on a single database, albeit one that provides data from a global, large, and diverse cohort. Prospective longitudinal cohort studies using real‐world populations with data on disease duration, co‐morbidities, sociodemographic factors, and amyloid status may more robustly address knowledge gaps on the association between p‐tau and age.\nThis study provides insights into the factors that may influence plasma p‐tau181 levels. The results may help refine reference ranges and interpretation guidelines, though further validation is needed. A considered approach is required to effectively prepare clinicians to interpret plasma p‐tau in a clinical setting, where most patients seen are in the older age category, are ethnically diverse and have multiple medical co‐morbidities. This is to ensure that the blood biomarker level is interpreted holistically in the context of the clinical picture. There are currently limitations in their application with further prospective validation work to confirm the association of co‐variates on plasma p‐tau levels. The use of educational tools to accompany biomarker results and provide information on the context and limitations of p‐tau values will be essential.\nAll authors contributed to the conception and design of the review. JH wrote the first draft and all authors revised and approved the article for publication.\nHZ has served at scientific advisory boards and/or as a consultant for Abbvie, Acumen, Alector, Alzinova, ALZPath, Amylyx, Annexon, Apellis, Artery Therapeutics, AZTherapies, Cognito Therapeutics, CogRx, Denali, Eisai, Merry Life, Nervgen, Novo Nordisk, Optoceutics, Passage Bio, Pinteon Therapeutics, Prothena, Red Abbey Labs, reMYND, Roche, Samumed, Siemens Healthineers, Triplet Therapeutics, and Wave, has given lectures in symposia sponsored by Alzecure, Biogen, Cellectricon, Fujirebio, Lilly, Novo Nordisk, and Roche, and is a co‐founder of Brain Biomarker Solutions in Gothenburg AB (BBS), which is a part of the GU Ventures Incubator Programme (outside submitted work). NF has served at scientific advisory boards and/or as a consultant for Biogen, Eisai, Ionis, Lilly, Roche/Genentech, and Siemens.\nTable S1\nTable S2", "topic": "Diagnostic"}
{"pmid": "40713476", "pmcid": "12290490", "title": "Distinct inflammatory profiles in young‐onset versus late‐onset Alzheimer's disease", "publication_year": "N/A", "abstract": "", "full_text": "Alzheimer's disease (AD) is a neurodegenerative disease characterized by progressive cognitive impairment and neuropathological hallmarks, that is, the deposition of amyloid β (Aβ) plaques and tau‐containing neurofibrillary tangles (NFTs).\nNumerous pathological, positron emission tomography (PET), and biofluid studies have reported microglial activation and astrogliosis in AD.\nA limited number of pathological studies has characterized neuroinflammation in YOAD patients. In a post‐mortem analysis of AD brains at similar Braak stages, Yin et al. 2017 revealed an increase in Aβ plaque‐associated hyperreactive microglia, with higher expression of phagocytic genes, in YOAD compared to LOAD.\nHere we hypothesize that neuroinflammation, a central player in AD pathogenesis, could contribute differentially to the pathophysiology of YOAD and LOAD.\nAll patients presenting with cognitive impairment who underwent a lumbar puncture for research purposes at the University Health Network (UHN) Memory Clinic (Toronto, Ontario, CA) between 2013–2023 were considered for inclusion. Final inclusion was based on AD biomarker positivity (Aβ‐PET‐or CSF) and a clinical diagnosis of typical or atypical AD. Clinical diagnoses included AD dementia, mild cognitive impairment (MCI), logopenic variant (lvPPA), and nonfluent variant (nfvPPA) primary progressive aphasia, frontal variant AD (fvAD), posterior cortical atrophy (PCA), and corticobasal syndrome (CBS) (See Table\nDemographics, clinical characteristics, and CSF biomarkers of the cohort used in this study\nYOAD\n\nLOAD\n\nHC\n\nKruskal‐Wallis test.\nChi‐squared test of independence without continuity correction.\nWilcoxon Rank Sum test.\nANCOVA with age as covariate.\nNo difference between YOAD and HC.\nNo difference between YOAD and LOAD.\n\nAbbreviations: AD, Alzheimer's disease; aMCI, amnestic mild cognitive impairment; Aβ42, β‐amyloid 1‐42; CBS, corticobasal syndrome; LOAD, late‐onset Alzheimer's disease; lvPPA, logopenic variant primary progressive aphasia; MCI, mild cognitive impairment; NfL, neurofilament light‐chain; nfvPPA, nonfluent variant primary progressive aphasia; ns, not significant; PPA, primary progressive aphasia; p‐tau181, phosphorylated tau at threonine 181; SD, standard deviation; YOAD, young‐onset Alzheimer's disease.\nCSF collection and pre‐analytical processing was performed as previously described.\nCognitive assessments of AD patients included the Montreal Cognitive Assessment (MoCA) (\nThe levels of 737 inflammatory markers (Olink Explore Inflammation panels I and II) were measured using PEA technology (Olink Proteomics, Boston, USA) at Hamilton Health Sciences (Hamilton, ON, Canada).\n\n\n\n\nFor participants recruited at UHN, sandwich enzyme‐linked immunosorbent assays (ELISAs) were used to measure concentrations of Aβ42 (Innotest β‐amyloid (1‐42), Fujirebio, USA), phosphorylated tau (p‐tau) 181 (p‐tau181) (Innotest phospho‐tau (181p), Fujirebio), and t‐tau (Innotest hTAU‐Ag, Fujirebio). AD biomarker positivity was defined as: p‐tau181 > 68 pg/mL and Aβ42 to tau Index (ATI) < 0.8 (ATI being defined as: Aβ42/(240+1.18*t‐tau).\nNeurofilament light‐chain (NfL) levels were measured using a commercially available NF‐light SIMOA Assay Advantage kit or the Neurology 2‐Plex B assay kit (Quanterix, USA) on a single molecule array (Simoa) SR‐X analyzer according to manufacturer's instructions.\nAll data processing and analyses were conducted in R (4.2.2). We ran analyses of covariance (ANCOVAs) with diagnosis (YOAD, LOAD or HC) as independent variables, NPX as the outcome variable, and age and sex as covariates.\nPathway enrichment analysis was done using the integrated pathway database pathDIP (\nTo investigate the effect of AD subtype (YOAD versus LOAD) on the relationship between NPX and NfL (or cognitive scores) we ran multivariable linear regressions incorporating an interaction of AD subtype with NPX (or cognitive scores) on NfL. We also performed mediation analyses with the package mediation\nFalse discovery rate (FDR) correction was applied, and the level of statistical significance was set at FDR‐adjusted p‐value (q‐value) < 0.05. Effect sizes were calculated with emmeans (\nNinety AD‐positive patients (57 YOAD, 33 LOAD) and 26 AD‐negative HC were included (Table\nCompared to LOAD patients, YOAD patients had significantly lower CSF Aβ42 levels (\nAcross the 116 samples, more than 75% data were missing for seven markers (BCL2L11, BID, EP300, FGF3, ADIPOQ, FUOM, MGLL), which were removed from the analysis.\nEighteen inflammatory markers significantly differed across groups (q < 0.05), and were further analyzed in post‐host tests with a Bonferroni correction for pairwise comparisons. Compared to HC, YOAD showed higher levels of 18 markers: SCRN1 (d = 1.88,\nDifferences in inflammatory profiles between young‐onset Alzheimer's disease (YOAD), late‐onset AD (LOAD), and healthy controls (HC). (A‐C) Volcano plots showing differences in Normalized Protein eXpression (NPX) between (A) YOAD and HC, (B) LOAD and HC, and (C) YOAD and LOAD. Estimated mean differences in NPX are plotted on the x‐axis and ‐log\nDifferentially expressed CSF proteins among YOAD, LOAD, and HC\n\nAbbreviations: CI, confidence interval; CSF, cerebrospinal fluid; HC, healthy control; LOAD, late‐onset Alzheimer's disease; YOAD, young‐onset Alzheimer's disease.\nThere were diagnosis‐specific sex differences in NPX (Table\nA comprehensive pathway enrichment analysis across all source databases showed that the most important differences between YOAD and LOAD were for the immune system category (\nMultivariable linear regressions adjusting for age and sex showed that 46 inflammatory markers were associated with NfL in AD patients (q < 0.05; Table\nWe then ran multivariable linear regressions with an interaction term of AD subtype and NPX as the independent variable, and the following dependent variables (in separate models, all adjusted for age and sex): NfL, Aβ42, p‐tau181 or t‐tau (all log‐transformed). There was a significant interaction of GIT1 (β ± SE: 0.33 ± .08, q < 0.05) and KLRD1 (β ± SE:.33 ± .08, q < 0.05) with AD subtype on NfL levels. Slope visualization suggested a stronger positive relationship of GIT1 and KLDR1 with NfL in LOAD compared to YOAD. There was no significant interaction of any inflammatory marker with AD subtype on AD markers.\nWilcoxon‐rank sum found that LOAD patients had higher z‐scores than YOAD patients (‐5.7 ± 3.6 and ‐8.5 ± 4.3, respectively), indicating better performance relative to age‐ and sex‐matched HC (\nWe examined whether AD biomarkers in YOAD and LOAD mediated the association of the 18 differentially expressed inflammatory markers on neurodegeneration. This was carried out through mediation analyses adjusted for age and sex, with NPX as the independent variable, AD biomarkers as the mediator, and logged NfL as the dependent variable.\nIn YOAD, a positive total association (direct effect plus mediation effect of p‐tau181) was found for eight markers and was mediated by p‐tau181 (Figure\nThe association of the differentially regulated inflammatory markers with neurofilament light‐chain (NfL) is mediated by phosphorylated tau 181 (p‐tau181). In young‐onset Alzheimer's disease (YOAD), p‐tau181 significantly mediates the association of (A) SCRN1, (B) MMP10, (C) SPART, (D) NGRN, (E) MDH1, (F) LHPP, (G) GNPDA2, and (H) ATP5IF1 with NfL levels. In each plot, “a” is the effect of the inflammatory marker on the mediator, p‐tau181; “b” is the effect of mediator p‐tau181 on NfL; “Total effect” indicates the total effect that a given inflammatory marker has on NfL, which is the sum of the “Direct effect” with the “Mediation effect;” “Proportion” is the proportion of the association of the inflammatory marker with NfL that is mediated by p‐tau181.\nWe observed a similar pattern for CSF t‐tau, which mediated the effect of eight markers on NfL in YOAD but not LOAD: SCRN1 (mediation effect: 0.10; q < 0.05), MDH1 (0.15; q < 0.001), NGRN (0.14; q < 0.001), SPART (0.10; q < 0.05), LHPP (0.11; q < 0.001), GNPDA2 (0.12; q < 0.01), ATP5IF1 (0.10; q < 0.05), and HGF (0.08; q < 0.05) (Figure\nThe association of the differentially regulated inflammatory marker with neurofilament light‐chain (NfL) is mediated by total tau (t‐tau). T‐tau significantly mediates the association of (A) SCRN1, (B) MDH1, (C) NRGN, (D) SPART, (E) LHPP, (F) GNPDA2, (G) HGF, and (H) ATP5IF1 with NfL.\nAβ42 was not a mediator of the association between differentially expressed markers and NfL in either YOAD or LOAD.\nIn the subset of individuals with APOE status, which included 23 HC (5 APOE4‐positive), 15 LOAD (8 APOE4‐positive), and 47 YOAD (21 APOE4‐positive) participants, we found no association between AD subtype and APOE4 positivity per the chi‐squared test (\nLikely due to sample size, we could not reproduce all the findings in the subset of participants with APOE status. We found no significant difference in YOAD versus HC for ATP5IF, and of LOAD versus HC for MMP10. The other significant differences reported in the full dataset could be reproduced in this subset. This remained the case after adding APOE4 status as a covariate in the model (q < 0.05). Similarly, the mediation effects reported in Figure\nIn this study, we used the Olink PEA technology\nElevated levels of the matrix metalloproteinase MMP10 and of SCRN1 were detected in both YOAD and LOAD. Matrix metalloproteinases, expressed in neurons and secreted by microglia and astrocytes, contribute to protein degradation in the extracellular matrix. Increased CSF MMP10 levels in particular are thought to reflect disruption of the blood‐brain‐barrier,\nSixteen inflammatory markers were significantly increased in YOAD, but not LOAD, compared to HC: GPI, MDH1, NRGN, SPART, CRKL, GSR, GLOD4, ADD1, FLT3LG, LHPP, GNPDA2, TBCA, ATP5IF1, DTD1, HGF, and BTD. Of these, seven (GPI, MDH1, CRKL, GSR, GLOD4, HGF, and BTD) were significantly higher in YOAD than LOAD. Previous studies had linked NRGN, SPART, CRKL, GSR, GLOD4, TBCA, MDH1, and ATP5IF1 to MCI due to AD but did not report any age‐related differences.\nThis study also aimed to characterize the relationship between neuroinflammation and AD‐related neurodegeneration. In our AD cohort, 47 inflammatory markers were associated with NfL, a marker of neuroaxonal damage, but none with Aβ42, p‐tau181, or t‐tau. However, p‐tau181 and t‐tau partially mediated the relationship between inflammatory markers with NfL in YOAD and not in LOAD. Consistent with these findings, a PET study showed a stronger correlation of neuroinflammation with tau than Aβ in MCI.\nSeveral studies point toward a sexual dimorphism in the neuroinflammatory processes implicated in AD, likely exacerbated in females compared to males.\nOther study limitations include a small sample size relative to the large number of inflammatory markers measured, which may limit statistical power, especially in the smaller LOAD group. We observed no association between the normalized cognitive scores and the different biomarkers after controlling for age and sex, which likely reflects the size and heterogeneity of our cohort as well as differences in data collection context and the cognitive scores used. The inclusion of samples collected at a different center may also be a source of variability in our results. Secondly, for the pathway analysis, we defined differentially expressed proteins in the input based on uncorrected\nIn summary, our exploratory proteomic analysis reveals that the inflammatory profile and the relationship between inflammation and neurodegeneration differs in YOAD versus LOAD. Further characterization of the inflammatory markers differentially implicated in these two populations may lead to important insights on the pathophysiology of AD. This work also provides potential targets for the development of biomarker‐based patient classification and disease‐modifying treatments.\nI.J. serves on the scientific advisory board (SAB) of Ankarys Therapeutics, YetiWare, Human Exposome Assessment Platform (HEAP) project. He is on a scientific advisory board for Honeywell Healthcare, Lenovo, Arthritis Society Canada, is a co‐founder and CSO for LumiNet Bio Incorporated, and is under the Horizon 2020 Framework Program for Research and Innovation. He has received a server donation from Lenovo and licensed access to the mirDIP database from Cardiatec. B.H. owns stock in Novartis; he serves on the SAB of Dewpoint and has an option for stock. He serves on a scientific advisory board or is a consultant for AbbVie, Alexion, Ambagon, Aprinoia Therapeutics, Arvinas, Avrobio, AstraZenica, Biogen, Bioinsights, BMS, Cure Alz Fund, Cell Signaling, Dewpoint, Latus, Merck, Novartis, Pfizer, Sanofi, Sofinnova, Takeda, TD Cowen, Vigil, Violet, Voyager, WaveBreak. SEA is a paid consultant for Allyx Therapeutics, BioVie, Bob's Last Marathon, Merck, Jocasta Neuroscience, Sage Therapeutics, Sanofi, and Vandria. He has received payments for expert testimony from Foster & Eldredge and ProSelect Insurance Co, and has received grants or contracts from Abbvie, AC Immune, Alzheimer's Association, Athira, Challenger Foundation, Novartis, Seer Biosciences, Venture Well, Chromadex, Ionis Pharmaceuticals, Janssen Pharmaceuticals, the John Sperling Foundation, the NIH, Gatehouse Bio, Eli Lilly/Fortrea, and SuperFluid Dx. M.I. is a paid consultant for BioArctic AB and Eisai Pharmaceuticals. AML receives consulting fees from Abbott, Boston Scientific, Insightec, Medtronic, and Functional Neuromodulation (Scientific Director). MCT has received in‐kind funding from Roche. She conducts clinical trials for Biogen, Anavex, Janssen, Novo Nordisk, Merck, Green Valley, UCB. Author disclosures are available in the\nThe study was conducted in accordance with the revised Declaration of Helsinki and Good Clinical Practice guidelines and was approved by the Research Ethics Board of the Toronto Western Hospital (University Health Network) and the Mass General Brigham Institutional Review Board (2018P001989). Informed consent was obtained from subjects included in the study.\nThis study included 90 patients with Alzheimer's disease and 26 healthy controls. The population was diverse in regard to gender, with approximately 50% of female subjects in both Alzheimer's disease and healthy control groups. To account for potential differences in socioeconomic status (specifically, differences in education level) and to account for the large age range covered in this study, we used z‐scores for the comparison of cognitive impairment. Detailed demographics are reported in Table\nSupporting Information\nSupporting Information\nSupporting Information", "content_for_embedding": "Alzheimer's disease (AD) is a neurodegenerative disease characterized by progressive cognitive impairment and neuropathological hallmarks, that is, the deposition of amyloid β (Aβ) plaques and tau‐containing neurofibrillary tangles (NFTs).\nNumerous pathological, positron emission tomography (PET), and biofluid studies have reported microglial activation and astrogliosis in AD.\nA limited number of pathological studies has characterized neuroinflammation in YOAD patients. In a post‐mortem analysis of AD brains at similar Braak stages, Yin et al. 2017 revealed an increase in Aβ plaque‐associated hyperreactive microglia, with higher expression of phagocytic genes, in YOAD compared to LOAD.\nHere we hypothesize that neuroinflammation, a central player in AD pathogenesis, could contribute differentially to the pathophysiology of YOAD and LOAD.\nAll patients presenting with cognitive impairment who underwent a lumbar puncture for research purposes at the University Health Network (UHN) Memory Clinic (Toronto, Ontario, CA) between 2013–2023 were considered for inclusion. Final inclusion was based on AD biomarker positivity (Aβ‐PET‐or CSF) and a clinical diagnosis of typical or atypical AD. Clinical diagnoses included AD dementia, mild cognitive impairment (MCI), logopenic variant (lvPPA), and nonfluent variant (nfvPPA) primary progressive aphasia, frontal variant AD (fvAD), posterior cortical atrophy (PCA), and corticobasal syndrome (CBS) (See Table\nDemographics, clinical characteristics, and CSF biomarkers of the cohort used in this study\nYOAD\n\nLOAD\n\nHC\n\nKruskal‐Wallis test.\nChi‐squared test of independence without continuity correction.\nWilcoxon Rank Sum test.\nANCOVA with age as covariate.\nNo difference between YOAD and HC.\nNo difference between YOAD and LOAD.\n\nAbbreviations: AD, Alzheimer's disease; aMCI, amnestic mild cognitive impairment; Aβ42, β‐amyloid 1‐42; CBS, corticobasal syndrome; LOAD, late‐onset Alzheimer's disease; lvPPA, logopenic variant primary progressive aphasia; MCI, mild cognitive impairment; NfL, neurofilament light‐chain; nfvPPA, nonfluent variant primary progressive aphasia; ns, not significant; PPA, primary progressive aphasia; p‐tau181, phosphorylated tau at threonine 181; SD, standard deviation; YOAD, young‐onset Alzheimer's disease.\nCSF collection and pre‐analytical processing was performed as previously described.\nCognitive assessments of AD patients included the Montreal Cognitive Assessment (MoCA) (\nThe levels of 737 inflammatory markers (Olink Explore Inflammation panels I and II) were measured using PEA technology (Olink Proteomics, Boston, USA) at Hamilton Health Sciences (Hamilton, ON, Canada).\n\n\n\n\nFor participants recruited at UHN, sandwich enzyme‐linked immunosorbent assays (ELISAs) were used to measure concentrations of Aβ42 (Innotest β‐amyloid (1‐42), Fujirebio, USA), phosphorylated tau (p‐tau) 181 (p‐tau181) (Innotest phospho‐tau (181p), Fujirebio), and t‐tau (Innotest hTAU‐Ag, Fujirebio). AD biomarker positivity was defined as: p‐tau181 > 68 pg/mL and Aβ42 to tau Index (ATI) < 0.8 (ATI being defined as: Aβ42/(240+1.18*t‐tau).\nNeurofilament light‐chain (NfL) levels were measured using a commercially available NF‐light SIMOA Assay Advantage kit or the Neurology 2‐Plex B assay kit (Quanterix, USA) on a single molecule array (Simoa) SR‐X analyzer according to manufacturer's instructions.\nAll data processing and analyses were conducted in R (4.2.2). We ran analyses of covariance (ANCOVAs) with diagnosis (YOAD, LOAD or HC) as independent variables, NPX as the outcome variable, and age and sex as covariates.\nPathway enrichment analysis was done using the integrated pathway database pathDIP (\nTo investigate the effect of AD subtype (YOAD versus LOAD) on the relationship between NPX and NfL (or cognitive scores) we ran multivariable linear regressions incorporating an interaction of AD subtype with NPX (or cognitive scores) on NfL. We also performed mediation analyses with the package mediation\nFalse discovery rate (FDR) correction was applied, and the level of statistical significance was set at FDR‐adjusted p‐value (q‐value) < 0.05. Effect sizes were calculated with emmeans (\nNinety AD‐positive patients (57 YOAD, 33 LOAD) and 26 AD‐negative HC were included (Table\nCompared to LOAD patients, YOAD patients had significantly lower CSF Aβ42 levels (\nAcross the 116 samples, more than 75% data were missing for seven markers (BCL2L11, BID, EP300, FGF3, ADIPOQ, FUOM, MGLL), which were removed from the analysis.\nEighteen inflammatory markers significantly differed across groups (q < 0.05), and were further analyzed in post‐host tests with a Bonferroni correction for pairwise comparisons. Compared to HC, YOAD showed higher levels of 18 markers: SCRN1 (d = 1.88,\nDifferences in inflammatory profiles between young‐onset Alzheimer's disease (YOAD), late‐onset AD (LOAD), and healthy controls (HC). (A‐C) Volcano plots showing differences in Normalized Protein eXpression (NPX) between (A) YOAD and HC, (B) LOAD and HC, and (C) YOAD and LOAD. Estimated mean differences in NPX are plotted on the x‐axis and ‐log\nDifferentially expressed CSF proteins among YOAD, LOAD, and HC\n\nAbbreviations: CI, confidence interval; CSF, cerebrospinal fluid; HC, healthy control; LOAD, late‐onset Alzheimer's disease; YOAD, young‐onset Alzheimer's disease.\nThere were diagnosis‐specific sex differences in NPX (Table\nA comprehensive pathway enrichment analysis across all source databases showed that the most important differences between YOAD and LOAD were for the immune system category (\nMultivariable linear regressions adjusting for age and sex showed that 46 inflammatory markers were associated with NfL in AD patients (q < 0.05; Table\nWe then ran multivariable linear regressions with an interaction term of AD subtype and NPX as the independent variable, and the following dependent variables (in separate models, all adjusted for age and sex): NfL, Aβ42, p‐tau181 or t‐tau (all log‐transformed). There was a significant interaction of GIT1 (β ± SE: 0.33 ± .08, q < 0.05) and KLRD1 (β ± SE:.33 ± .08, q < 0.05) with AD subtype on NfL levels. Slope visualization suggested a stronger positive relationship of GIT1 and KLDR1 with NfL in LOAD compared to YOAD. There was no significant interaction of any inflammatory marker with AD subtype on AD markers.\nWilcoxon‐rank sum found that LOAD patients had higher z‐scores than YOAD patients (‐5.7 ± 3.6 and ‐8.5 ± 4.3, respectively), indicating better performance relative to age‐ and sex‐matched HC (\nWe examined whether AD biomarkers in YOAD and LOAD mediated the association of the 18 differentially expressed inflammatory markers on neurodegeneration. This was carried out through mediation analyses adjusted for age and sex, with NPX as the independent variable, AD biomarkers as the mediator, and logged NfL as the dependent variable.\nIn YOAD, a positive total association (direct effect plus mediation effect of p‐tau181) was found for eight markers and was mediated by p‐tau181 (Figure\nThe association of the differentially regulated inflammatory markers with neurofilament light‐chain (NfL) is mediated by phosphorylated tau 181 (p‐tau181). In young‐onset Alzheimer's disease (YOAD), p‐tau181 significantly mediates the association of (A) SCRN1, (B) MMP10, (C) SPART, (D) NGRN, (E) MDH1, (F) LHPP, (G) GNPDA2, and (H) ATP5IF1 with NfL levels. In each plot, “a” is the effect of the inflammatory marker on the mediator, p‐tau181; “b” is the effect of mediator p‐tau181 on NfL; “Total effect” indicates the total effect that a given inflammatory marker has on NfL, which is the sum of the “Direct effect” with the “Mediation effect;” “Proportion” is the proportion of the association of the inflammatory marker with NfL that is mediated by p‐tau181.\nWe observed a similar pattern for CSF t‐tau, which mediated the effect of eight markers on NfL in YOAD but not LOAD: SCRN1 (mediation effect: 0.10; q < 0.05), MDH1 (0.15; q < 0.001), NGRN (0.14; q < 0.001), SPART (0.10; q < 0.05), LHPP (0.11; q < 0.001), GNPDA2 (0.12; q < 0.01), ATP5IF1 (0.10; q < 0.05), and HGF (0.08; q < 0.05) (Figure\nThe association of the differentially regulated inflammatory marker with neurofilament light‐chain (NfL) is mediated by total tau (t‐tau). T‐tau significantly mediates the association of (A) SCRN1, (B) MDH1, (C) NRGN, (D) SPART, (E) LHPP, (F) GNPDA2, (G) HGF, and (H) ATP5IF1 with NfL.\nAβ42 was not a mediator of the association between differentially expressed markers and NfL in either YOAD or LOAD.\nIn the subset of individuals with APOE status, which included 23 HC (5 APOE4‐positive), 15 LOAD (8 APOE4‐positive), and 47 YOAD (21 APOE4‐positive) participants, we found no association between AD subtype and APOE4 positivity per the chi‐squared test (\nLikely due to sample size, we could not reproduce all the findings in the subset of participants with APOE status. We found no significant difference in YOAD versus HC for ATP5IF, and of LOAD versus HC for MMP10. The other significant differences reported in the full dataset could be reproduced in this subset. This remained the case after adding APOE4 status as a covariate in the model (q < 0.05). Similarly, the mediation effects reported in Figure\nIn this study, we used the Olink PEA technology\nElevated levels of the matrix metalloproteinase MMP10 and of SCRN1 were detected in both YOAD and LOAD. Matrix metalloproteinases, expressed in neurons and secreted by microglia and astrocytes, contribute to protein degradation in the extracellular matrix. Increased CSF MMP10 levels in particular are thought to reflect disruption of the blood‐brain‐barrier,\nSixteen inflammatory markers were significantly increased in YOAD, but not LOAD, compared to HC: GPI, MDH1, NRGN, SPART, CRKL, GSR, GLOD4, ADD1, FLT3LG, LHPP, GNPDA2, TBCA, ATP5IF1, DTD1, HGF, and BTD. Of these, seven (GPI, MDH1, CRKL, GSR, GLOD4, HGF, and BTD) were significantly higher in YOAD than LOAD. Previous studies had linked NRGN, SPART, CRKL, GSR, GLOD4, TBCA, MDH1, and ATP5IF1 to MCI due to AD but did not report any age‐related differences.\nThis study also aimed to characterize the relationship between neuroinflammation and AD‐related neurodegeneration. In our AD cohort, 47 inflammatory markers were associated with NfL, a marker of neuroaxonal damage, but none with Aβ42, p‐tau181, or t‐tau. However, p‐tau181 and t‐tau partially mediated the relationship between inflammatory markers with NfL in YOAD and not in LOAD. Consistent with these findings, a PET study showed a stronger correlation of neuroinflammation with tau than Aβ in MCI.\nSeveral studies point toward a sexual dimorphism in the neuroinflammatory processes implicated in AD, likely exacerbated in females compared to males.\nOther study limitations include a small sample size relative to the large number of inflammatory markers measured, which may limit statistical power, especially in the smaller LOAD group. We observed no association between the normalized cognitive scores and the different biomarkers after controlling for age and sex, which likely reflects the size and heterogeneity of our cohort as well as differences in data collection context and the cognitive scores used. The inclusion of samples collected at a different center may also be a source of variability in our results. Secondly, for the pathway analysis, we defined differentially expressed proteins in the input based on uncorrected\nIn summary, our exploratory proteomic analysis reveals that the inflammatory profile and the relationship between inflammation and neurodegeneration differs in YOAD versus LOAD. Further characterization of the inflammatory markers differentially implicated in these two populations may lead to important insights on the pathophysiology of AD. This work also provides potential targets for the development of biomarker‐based patient classification and disease‐modifying treatments.\nI.J. serves on the scientific advisory board (SAB) of Ankarys Therapeutics, YetiWare, Human Exposome Assessment Platform (HEAP) project. He is on a scientific advisory board for Honeywell Healthcare, Lenovo, Arthritis Society Canada, is a co‐founder and CSO for LumiNet Bio Incorporated, and is under the Horizon 2020 Framework Program for Research and Innovation. He has received a server donation from Lenovo and licensed access to the mirDIP database from Cardiatec. B.H. owns stock in Novartis; he serves on the SAB of Dewpoint and has an option for stock. He serves on a scientific advisory board or is a consultant for AbbVie, Alexion, Ambagon, Aprinoia Therapeutics, Arvinas, Avrobio, AstraZenica, Biogen, Bioinsights, BMS, Cure Alz Fund, Cell Signaling, Dewpoint, Latus, Merck, Novartis, Pfizer, Sanofi, Sofinnova, Takeda, TD Cowen, Vigil, Violet, Voyager, WaveBreak. SEA is a paid consultant for Allyx Therapeutics, BioVie, Bob's Last Marathon, Merck, Jocasta Neuroscience, Sage Therapeutics, Sanofi, and Vandria. He has received payments for expert testimony from Foster & Eldredge and ProSelect Insurance Co, and has received grants or contracts from Abbvie, AC Immune, Alzheimer's Association, Athira, Challenger Foundation, Novartis, Seer Biosciences, Venture Well, Chromadex, Ionis Pharmaceuticals, Janssen Pharmaceuticals, the John Sperling Foundation, the NIH, Gatehouse Bio, Eli Lilly/Fortrea, and SuperFluid Dx. M.I. is a paid consultant for BioArctic AB and Eisai Pharmaceuticals. AML receives consulting fees from Abbott, Boston Scientific, Insightec, Medtronic, and Functional Neuromodulation (Scientific Director). MCT has received in‐kind funding from Roche. She conducts clinical trials for Biogen, Anavex, Janssen, Novo Nordisk, Merck, Green Valley, UCB. Author disclosures are available in the\nThe study was conducted in accordance with the revised Declaration of Helsinki and Good Clinical Practice guidelines and was approved by the Research Ethics Board of the Toronto Western Hospital (University Health Network) and the Mass General Brigham Institutional Review Board (2018P001989). Informed consent was obtained from subjects included in the study.\nThis study included 90 patients with Alzheimer's disease and 26 healthy controls. The population was diverse in regard to gender, with approximately 50% of female subjects in both Alzheimer's disease and healthy control groups. To account for potential differences in socioeconomic status (specifically, differences in education level) and to account for the large age range covered in this study, we used z‐scores for the comparison of cognitive impairment. Detailed demographics are reported in Table\nSupporting Information\nSupporting Information\nSupporting Information", "topic": "Diagnostic"}
{"pmid": "40624544", "pmcid": "12255577", "title": "Rethinking MRI as a measurement device through modular and portable pipelines", "publication_year": "N/A", "abstract": "The premise of MRI as a reliable measurement device is limited by proprietary barriers and inconsistent implementations, which prevent the establishment of measurement uncertainties. As a result, biomedical studies that rely on these methods are plagued by systematic variance, undermining the perceived promise of quantitative imaging biomarkers (QIBs) and hindering their clinical translation. This review explores the added value of open-source measurement pipelines in minimizing variability sources that would otherwise remain unknown. First, we introduce a tiered benchmarking framework (from black-box to glass-box) that exposes how opacity at different workflow stages propagates measurement uncertainty. Second, we provide a concise glossary to promote consistent terminology for strategies that enhance reproducibility before acquisition or enable valid post-hoc pooling of QIBs. Building on this foundation, we present two illustrative measurement workflows that decouple workflow logic from the orchestration of computational processes in an MRI measurement pipeline, rooted in the core principles of modularity and portability. Designed as accessible entry points for implementation, these examples serve as practical guides, helping users adapt the frameworks to their specific needs and facilitating collaboration. Through critical evaluation of existing approaches, we discuss how standardized workflows can help identify outstanding challenges in translating glass-box frameworks into clinical scanner environments. Ultimately, achieving this goal will require coordinated efforts from QIB developers, regulators, industry partners, and clinicians alike.", "full_text": "\n\nBasics of measurement technology—Part 2: Terms for measuring instruments [\nWhen evaluated against this standard, MRI scanners are not considered true measurement systems. Their intended use lacks the metrological rigor required for quantitative applications in clinical settings [\nQuantitative imaging biomarkers (QIBs) are numerical characteristics derived from quantitative imaging techniques [\nOn the other hand, the measurement concept goes beyond purely quantitative frameworks, incorporating quantifiable features extracted from morphological characteristics in imaging data. These\nAll of these measurement procedures ultimately boil down to three main methodological steps: pulse sequence implementations (\nSetting aside the impact of inevitable variations in experimental conditions (e.g., hardware differences) and random factors, the generalizability of these three primary steps (\nFor example, a recent editorial on radiomics identified this issue as the elephant in the scanner room that must be addressed for data-driven QIBs [\nNevertheless, this drawback is not unique to data-driven QIBs. For nearly 50 years, physics-based QIBs have been suggested as a powerful alternative to improve the consistency of qualitative pattern recognition (e.g., using T2 to eliminate inter-site contrast variations in T2-weighted images due to protocol differences [\nThe past two decades in MRI research have seen synergistic forces to lift QIBs from the swamp of variability: grassroots open-source development [\nThe momentum of open-source community initiatives is a powerful driver in advancing QIBs. To leverage this momentum effectively, we must implement overarching strategies throughout the development process. In doing so, respecting the boundaries of regulatory requirements and commercial interests is key to landing innovations in clinical practice. Playfully captured in the ISMRM 2024 Lauterbur Lecture by Andrew Webb [\nBenchmarking of MRI measurement workflows based on the openness of their key steps: acquisition (\nInfographic defining MRI measurement terms used consistently throughout this review. The horizontal axis separates terms based on their relevance before or after acquisition (k-space sampling), while the vertical axis indicates whether their use is geared towards physics-based parameter quantification (i.e., qMRI) or data-driven insights (i.e., radiomics). The continuum of methodological similarity in MRI measurement workflows, based on the definitions by [\nMRI workflows can be categorized into four benchmarks distributed across three zones of transparency:\nOpaque zone: When the internal implementations of MRI workflows (\nBlack-box benchmark: No visibility into any key step.\nGray-box benchmark: Provides access to\nSemi-Transparent zone (Fig.\nFrosted-box benchmark: This partial transparency allows limited modifications to on-site steps of an MRI measurement.\nTransparent zone: (Fig.\nGlass-box benchmark: Represents the ideal case of full visibility and control over MRI workflows.\nFreed from the complexity of setting up third-party execution environments and dependencies at the scanner site, black-box workflows are often the most user-friendly choice (Fig.\nOther common examples of commercially available quantification packages are fraction measurement methods, typically used for investigating musculoskeletal and hepatic anomalies [\nThis shortcoming remains evident across a spectrum of measurements, from the most fundamental T1 mapping methods [\nUnder more carefully controlled multi-site conditions managed by the same research group, the reproducibility of gray-box workflows can be improved. A notable example is proton-density fat fraction, where each major vendor’s implementation of chemical-shift encoded spoiled gradient echo was used, followed by a standardized\nAnother common roadblock researchers encounter is the challenge posed by proprietary system upgrades. These upgrades may introduce variability that is difficult to account for, even within the same site on the same MRI system [\nCorrecting for the non-biological variance commonly observed in MRI measurements is a non-trivial effort—one that has taken on a life of its own, giving rise to a nomenclature that is increasingly intricate and sometimes difficult to parse. Therefore, we provide a glossary of terms (Fig.\nIt is important to note that both QIBA and the International Vocabulary of Metrology (VIM) offer comprehensive terminology relevant to measurements [\nThe terms standardization and harmonization are used rather loosely by MRI and neuroimaging researchers to refer to the process of “removing scanner effects” either before or after data collection. Even though these two terms are closely related, they actually represent distinct concepts. In the field of metrology, harmonization is an overarching term used to describe ensuring consistency of values measured by different methods [\nThe definitions outlined in Fig.\nIn earlier sections, we presented two examples—Case-1 for cardiac T1 mapping and Case-2 for brain T2 mapping—that highlight the challenges of operating in the opaque zone of MRI measurements. In this section, we introduce two approaches taken by independent research groups to address these challenges and highlight additional efforts that tackle this issue at various levels.\nStandardizing MRI measurement workflows through glass-box implementations provides the state-of-the-art approach for systematically comparing measurement procedures across different systems. This standardization can even be leveraged to evaluate the performance of systems expected to operate identically. Keenan et al. (2025) demonstrated this by deploying a standardized relaxometry workflow on both a commercial low-field 0.55 T system and a prototype system ramped down from 1.5 T to 0.55 T [\nIn addition to enabling multi-center collaboration and providing generalizable templates that help MRI researchers build on each other’s work [\nSimilarly, Rowley et al. (2021) developed a simulation framework that models the impact of magnetization transfer pulses, which vary between vendors, for sequence-informed removal of B1 effects from the MTsat maps [\nBeyond the domain of MRI physics,\nThe ComBat has been successfully applied to enhance the statistical power of a mega-analysis using MRI data from 33 sites and 6000 subjects to distinguish healthy participants from schizophrenia patients [\nIn addition to statistics-driven harmonization methods, recent literature has seen a growing number of deep learning-based approaches, such as DeepHarmony [\nA key consideration in QIB development is balancing complexity and modularity. As summarized in Fig.\nTo address Webb’s chicken-egg dilemma, a good starting point is to\nNextflow combines a declarative domain-specific language (DSL) with a reactive dataflow model. The reactive model enables Nextflow to dynamically manage data flow in response to changing data streams, eliminating the need for explicit callbacks to handle updates. For instance, a Nextflow pipeline can be linked to the raw data stream of an MRI scanner, automatically triggering reconstruction processes based on predefined patterns.\nIts declarative nature enables users to define what their pipeline should achieve rather than how to execute it. Nextflow manages parallel execution, error recovery, and workflow dependencies, allowing users to focus on data transformations and file-naming conventions. This abstraction ensures seamless scalability across diverse platforms—including any operating system, cloud environments, or high-performance computing clusters—without requiring changes to the pipeline's logic.\nNextflow can be installed on any POSIX-compatible system with a single command. Pipelines are defined in scripts using Nextflow’s DSL in scripts with the.nf extension. Comprehensive documentation on DSL is available at\nTo build a Nextflow pipeline, users define tasks as\nBy default, Nextflow delegates command execution to the underlying environment, meaning external packages like PyDeface [\nFinally, running Nextflow on a pipeline (e.g.,\nA simple update to the pipeline configuration file,\nNextflow’s original DSL constrained pipelines to monolithic scripts, requiring error-prone code duplication or complex channel logic to reuse components. With the introduction of DSL2, Nextflow revolutionized workflow design by enabling native modularity: processes, subworkflows, and functions can now be encapsulated in separate, reusable files. This paradigm shift is particularly transformative for MRI measurement pipelines, where evolving tools and analyses demand adaptable, compartmentalized workflows.\nDSL2 allows critical pipeline components—such as preprocessing steps, quality control checks, or analysis modules—to be stored in dedicated files (e.g.,\nThese advancements are pivotal for MRI measurement pipelines, where evolving open-source reconstruction tools, quality control checks, and analysis steps demand adaptable, compartmentalized workflows. Unlike Snakemake [\nAlthough most of Nextflow’s advantages come out of the box, there is a need to establish a set of principles to fully leverage its potential in QIB development:\nApply one process to one container mapping for modular dependency management at ease\nEach process in a Nextflow pipeline can be linked to a Docker or Singularity container either by specifying the container directly within the process (Fig.\nExample Nextflow snippets demonstrating how different processes—FSL (red,\nWhen combined with the modularity introduced by DSL2, the following example outlines the high-level steps of this principle from the user’s perspective:\nInclude\nPull\nEdit\nRepeat 1–3 for\nRepeat 1–3 for\nDefine the dataflow between these processes to define the pipeline\nExecute the pipeline\nInstead of consolidating all these tools into a single monolithic container, the modular approach offers several advantages:\nSimplified dependency management: Users can seamlessly pull pre-configured images maintained by their developers, allowing Nextflow to orchestrate them effortlessly.\nConflict-free dependencies: Isolating processes within dedicated containers eliminates dependency conflicts.\nDeveloper autonomy: Each development team can focus exclusively on their specific runtime environment.\nAvoidance of excessive wrappers: This methodology discourages the common but inefficient practice of layering academic software packages with too many wrappers.\nUse data standards to enable declarative interlinking of the workflow processes\nNextflow’s reactive dataflow model relies on file patterns to dynamically populate channels. Therefore, community standards like ISMRM-RD [\nDeclarative routing: Naming conventions (e.g., BIDS\nInterface contracts: Standards define clear input/output relationship between workflow stages. For example, a BIDS derivatives rule that segmentation masks follow\nSwap modules, do not reinvent them\nOnce data standards and containerization are established, pipeline modules become interchangeable “LEGO blocks”. Figure\nThis approach can drastically reduce code complexity, particularly when the pipeline description includes all steps. Figure\nThis illustration captures one of many possible (3\nqMRFlow is a suite of container-mediated, data-driven and transparent qMRI pipelines, ideally starting with a vendor-neutral\nPowered by Nextflow, qMRFlow adapts the principles outlined in this review to enable reproducible and modular measurements. Its modules are developed to work primarily with qMRLab [\nWhile qMRLab offers core functionality for processing quantitative MRI data, qMRFlow enhances this by seamlessly integrating with nearly all\nThe\nThere are two main pipeline descriptions that make use of these modules:\nThe\nSince the pipeline follows qMRI-BIDS, data channels can be structured using standardized patterns, simplifying the integration of processes and ensuring seamless workflow connectivity.\nTo repeat the\nA more recent demonstration of qMRFlow’s glass-box compatibility is shown through its integration with Pulseq [\nThe TractoFlow pipeline processes dMRI dataset from the raw data to the tractography as a modular entity. Tractoflow was quickly adopted by researchers outside of the immediate network of developers. Powered by Nextflow DSL1 and containerization, here are the five main highlights of Tractoflow (Fig.\nEfficient diffusion MRI processing pipeline from raw (i.e., vendor-reconstructed) diffusion data to tractography, which has allowed processing of the HCP [\nThe stochastic nature of the Tractoflow tractography pipeline makes reproducible results particularly challenging. Efforts are made to reduce variability when relaunching Tractoflow to ensure reproducible and replicable results today, tomorrow, and over time [\nTractoflow provides a tradeoff between customization and curation of configuration files, making it easy-to-use for non-technical and clinician users. Profiles are provided to adapt to different use cases (aging, development, white matter hyperintensities, amongst others [\nLittle to no installation steps and compatibility with High-Performance Computing thanks to containers and Nextflow executors (e.g. SLURM, AWS).\nSupport for multiple vendors through BIDS.\nThis figure represents the TractoFlow pipeline, designed as a gray-box workflow: it uses BIDS-formatted inputs from scanner reconstructions. It outputs a variety of files, ensuring reproducibility when inputs are identical. Each box in the diagram denotes a modular step, capable of saving outputs and configured for durability using dedicated Docker containers. Parameters are fully accessible and customizable through a comprehensive configuration file, allowing users to adapt the pipeline for diverse applications (e.g., healthy brain, tumor analysis, aging studies). Steps like tissue segmentation can be reconfigured to use tools like FreeSurfer, aligning with the gray-box principles\nTractoflow includes more than 20 steps that are automatically distributed depending on their dependencies and requirements and grouped into two main blocks of processes (see Fig.\nFrom the Tractoflow output tree, there are a series of optional flows available to automatically extract the main white matter bundles (rbx_flow) [\nHowever, Tractoflow does not address completely the\nNextflow DSL2 enabled the creation of\nIn the section titled “Opening up the implementations, that’s how the light gets in,” we reviewed recent QIB studies that use glass-box workflows as an effective approach to tackle variability at its source, all while staying true to the first-principles foundation of MRI acquisitions. This title purposefully draws inspiration from Leonard Cohen’s famous lyrics, “There’s a crack in everything, that’s how the light gets in”. While glass-box workflows are designed for transparency, their increasing complexity introduces fractures where dependencies accumulate (Fig.\nNearly half a century of efforts have fallen short in giving a generalizable answer to this question. MRI research silos answer it by championing a particular QIB attached to a fitting clinical use case (and even some de-facto standards) to make it reproducible across scanners [\nThe idea that the future of MRI is quantitative emerges, fades, and resurfaces as the tagline of annual conferences on MRI methods development. Meanwhile, applied research studies leveraging MRI measurements to test biomedical hypotheses continue to proliferate, spawning new subfields and career trajectories. However, the widening gap between the ever-expanding body of rejected null hypotheses and the scarcity of QIBs that have led to changes in patient management has raised concerns among clinicians about the validity of research priorities and their practical impact on patient care.\nOpening quotes from two articles by MDs Weinberger and Radulescu [\nFollowing these staggering opening quotes in their articles on structural MRI, the authors warn against overinterpreting data-driven QIBs and emphasize that such findings should be framed strictly as “differences in MRI measurements” rather than definitive neurobiological conclusions such as “cortical thinning”. They further argue that the ongoing overinterpretation of confounded MRI measurements is not only problematic but also a disservice to patients and their families, potentially by misdirecting valuable taxpayer dollars—funds that could be used more effectively to improve patient care, such as by better staffing hospitals and enhancing clinical services.\nGiven the unresolved translational gap, it remains too soon to determine whether numerical metrics derived from MRI offer clear clinical advantages over visual assessment alone. However, significant efforts are being made to improve the utility of QIBs, and we briefly discuss their potential benefits and challenges below.\nMRI does not directly measure anatomy; apparent tissue boundaries are influenced by systematic biases and biophysical confounders. Most data-driven QIBSs rely on these boundaries, which may reflect secondary physiological effects rather than true morphology [\nCan we dispense with the differences in k-space encoding within the latent space of deep learning models? For example, CALAMITI claims to disentangle anatomy and contrast into distinct latent representations [\nSimulation-based bias correction strategies targeting the opaque zone (Fig.\nAn interesting avenue for further exploration is examining inter-site effects starting from the k-space data acquired using vendor-native sequences. In the context of data-driven QIBs, variability in the reconstruction of images from multi-channel receive coils is a notable source of inconsistency [\nIt is crucial to recognize that even the simplest QIB in MRI involves far more degrees of freedom in its calculation than the Hounsfield Unit in CT. The final form of an MR image is influenced by a complex interplay of factors, including spin dynamics, coil sensitivities, gradient nonlinearities, B0 inhomogeneities, eddy currents, susceptibility effects, RF field distortions, and physiological noise, among others. This complexity underscores the importance of returning to the first principles of MRI measurements for conscious reduction of scanner effects. We argue that taking a step back and striving for standardization in a metrological framework is a leap toward unlocking the true clinical potential of QIBs, and adopting glass-box workflows can show the way forward.\nThe consideration of user-friendliness is still in its early stages for deploying vendor-neutral acquisition platforms coupled with glass-box workflows. Nevertheless, exciting developments are underway both by open-source developers and vendors.\nCurrently, only the RTHawk proprietary platform [\nThe modular and portable approach to creating a comprehensive measurement pipeline presented in this review has great potential to complement these efforts, facilitate collaboration, and lower the barriers to standardizing QIB implementations. Once we standardize MRI measurement procedures through efficient use of reference objects [\nUnlike standardized biochemical assays which have universally accepted calibration standards across laboratories, MRI measurements remain highly variable across scanners and sites. This variability stems from the complex interplay of factors in MRI signal generation and site-specific differences in the measurement chain. Rather than constructing a Rube Goldberg machine of harmonization methods and normative modeling, we argue for returning to the first principles of MRI measurements, using standardization within a metrological framework. By embracing workflows that strive for standardization, we can bridge the gap between research innovations and clinical applications [", "content_for_embedding": "\n\nBasics of measurement technology—Part 2: Terms for measuring instruments [\nWhen evaluated against this standard, MRI scanners are not considered true measurement systems. Their intended use lacks the metrological rigor required for quantitative applications in clinical settings [\nQuantitative imaging biomarkers (QIBs) are numerical characteristics derived from quantitative imaging techniques [\nOn the other hand, the measurement concept goes beyond purely quantitative frameworks, incorporating quantifiable features extracted from morphological characteristics in imaging data. These\nAll of these measurement procedures ultimately boil down to three main methodological steps: pulse sequence implementations (\nSetting aside the impact of inevitable variations in experimental conditions (e.g., hardware differences) and random factors, the generalizability of these three primary steps (\nFor example, a recent editorial on radiomics identified this issue as the elephant in the scanner room that must be addressed for data-driven QIBs [\nNevertheless, this drawback is not unique to data-driven QIBs. For nearly 50 years, physics-based QIBs have been suggested as a powerful alternative to improve the consistency of qualitative pattern recognition (e.g., using T2 to eliminate inter-site contrast variations in T2-weighted images due to protocol differences [\nThe past two decades in MRI research have seen synergistic forces to lift QIBs from the swamp of variability: grassroots open-source development [\nThe momentum of open-source community initiatives is a powerful driver in advancing QIBs. To leverage this momentum effectively, we must implement overarching strategies throughout the development process. In doing so, respecting the boundaries of regulatory requirements and commercial interests is key to landing innovations in clinical practice. Playfully captured in the ISMRM 2024 Lauterbur Lecture by Andrew Webb [\nBenchmarking of MRI measurement workflows based on the openness of their key steps: acquisition (\nInfographic defining MRI measurement terms used consistently throughout this review. The horizontal axis separates terms based on their relevance before or after acquisition (k-space sampling), while the vertical axis indicates whether their use is geared towards physics-based parameter quantification (i.e., qMRI) or data-driven insights (i.e., radiomics). The continuum of methodological similarity in MRI measurement workflows, based on the definitions by [\nMRI workflows can be categorized into four benchmarks distributed across three zones of transparency:\nOpaque zone: When the internal implementations of MRI workflows (\nBlack-box benchmark: No visibility into any key step.\nGray-box benchmark: Provides access to\nSemi-Transparent zone (Fig.\nFrosted-box benchmark: This partial transparency allows limited modifications to on-site steps of an MRI measurement.\nTransparent zone: (Fig.\nGlass-box benchmark: Represents the ideal case of full visibility and control over MRI workflows.\nFreed from the complexity of setting up third-party execution environments and dependencies at the scanner site, black-box workflows are often the most user-friendly choice (Fig.\nOther common examples of commercially available quantification packages are fraction measurement methods, typically used for investigating musculoskeletal and hepatic anomalies [\nThis shortcoming remains evident across a spectrum of measurements, from the most fundamental T1 mapping methods [\nUnder more carefully controlled multi-site conditions managed by the same research group, the reproducibility of gray-box workflows can be improved. A notable example is proton-density fat fraction, where each major vendor’s implementation of chemical-shift encoded spoiled gradient echo was used, followed by a standardized\nAnother common roadblock researchers encounter is the challenge posed by proprietary system upgrades. These upgrades may introduce variability that is difficult to account for, even within the same site on the same MRI system [\nCorrecting for the non-biological variance commonly observed in MRI measurements is a non-trivial effort—one that has taken on a life of its own, giving rise to a nomenclature that is increasingly intricate and sometimes difficult to parse. Therefore, we provide a glossary of terms (Fig.\nIt is important to note that both QIBA and the International Vocabulary of Metrology (VIM) offer comprehensive terminology relevant to measurements [\nThe terms standardization and harmonization are used rather loosely by MRI and neuroimaging researchers to refer to the process of “removing scanner effects” either before or after data collection. Even though these two terms are closely related, they actually represent distinct concepts. In the field of metrology, harmonization is an overarching term used to describe ensuring consistency of values measured by different methods [\nThe definitions outlined in Fig.\nIn earlier sections, we presented two examples—Case-1 for cardiac T1 mapping and Case-2 for brain T2 mapping—that highlight the challenges of operating in the opaque zone of MRI measurements. In this section, we introduce two approaches taken by independent research groups to address these challenges and highlight additional efforts that tackle this issue at various levels.\nStandardizing MRI measurement workflows through glass-box implementations provides the state-of-the-art approach for systematically comparing measurement procedures across different systems. This standardization can even be leveraged to evaluate the performance of systems expected to operate identically. Keenan et al. (2025) demonstrated this by deploying a standardized relaxometry workflow on both a commercial low-field 0.55 T system and a prototype system ramped down from 1.5 T to 0.55 T [\nIn addition to enabling multi-center collaboration and providing generalizable templates that help MRI researchers build on each other’s work [\nSimilarly, Rowley et al. (2021) developed a simulation framework that models the impact of magnetization transfer pulses, which vary between vendors, for sequence-informed removal of B1 effects from the MTsat maps [\nBeyond the domain of MRI physics,\nThe ComBat has been successfully applied to enhance the statistical power of a mega-analysis using MRI data from 33 sites and 6000 subjects to distinguish healthy participants from schizophrenia patients [\nIn addition to statistics-driven harmonization methods, recent literature has seen a growing number of deep learning-based approaches, such as DeepHarmony [\nA key consideration in QIB development is balancing complexity and modularity. As summarized in Fig.\nTo address Webb’s chicken-egg dilemma, a good starting point is to\nNextflow combines a declarative domain-specific language (DSL) with a reactive dataflow model. The reactive model enables Nextflow to dynamically manage data flow in response to changing data streams, eliminating the need for explicit callbacks to handle updates. For instance, a Nextflow pipeline can be linked to the raw data stream of an MRI scanner, automatically triggering reconstruction processes based on predefined patterns.\nIts declarative nature enables users to define what their pipeline should achieve rather than how to execute it. Nextflow manages parallel execution, error recovery, and workflow dependencies, allowing users to focus on data transformations and file-naming conventions. This abstraction ensures seamless scalability across diverse platforms—including any operating system, cloud environments, or high-performance computing clusters—without requiring changes to the pipeline's logic.\nNextflow can be installed on any POSIX-compatible system with a single command. Pipelines are defined in scripts using Nextflow’s DSL in scripts with the.nf extension. Comprehensive documentation on DSL is available at\nTo build a Nextflow pipeline, users define tasks as\nBy default, Nextflow delegates command execution to the underlying environment, meaning external packages like PyDeface [\nFinally, running Nextflow on a pipeline (e.g.,\nA simple update to the pipeline configuration file,\nNextflow’s original DSL constrained pipelines to monolithic scripts, requiring error-prone code duplication or complex channel logic to reuse components. With the introduction of DSL2, Nextflow revolutionized workflow design by enabling native modularity: processes, subworkflows, and functions can now be encapsulated in separate, reusable files. This paradigm shift is particularly transformative for MRI measurement pipelines, where evolving tools and analyses demand adaptable, compartmentalized workflows.\nDSL2 allows critical pipeline components—such as preprocessing steps, quality control checks, or analysis modules—to be stored in dedicated files (e.g.,\nThese advancements are pivotal for MRI measurement pipelines, where evolving open-source reconstruction tools, quality control checks, and analysis steps demand adaptable, compartmentalized workflows. Unlike Snakemake [\nAlthough most of Nextflow’s advantages come out of the box, there is a need to establish a set of principles to fully leverage its potential in QIB development:\nApply one process to one container mapping for modular dependency management at ease\nEach process in a Nextflow pipeline can be linked to a Docker or Singularity container either by specifying the container directly within the process (Fig.\nExample Nextflow snippets demonstrating how different processes—FSL (red,\nWhen combined with the modularity introduced by DSL2, the following example outlines the high-level steps of this principle from the user’s perspective:\nInclude\nPull\nEdit\nRepeat 1–3 for\nRepeat 1–3 for\nDefine the dataflow between these processes to define the pipeline\nExecute the pipeline\nInstead of consolidating all these tools into a single monolithic container, the modular approach offers several advantages:\nSimplified dependency management: Users can seamlessly pull pre-configured images maintained by their developers, allowing Nextflow to orchestrate them effortlessly.\nConflict-free dependencies: Isolating processes within dedicated containers eliminates dependency conflicts.\nDeveloper autonomy: Each development team can focus exclusively on their specific runtime environment.\nAvoidance of excessive wrappers: This methodology discourages the common but inefficient practice of layering academic software packages with too many wrappers.\nUse data standards to enable declarative interlinking of the workflow processes\nNextflow’s reactive dataflow model relies on file patterns to dynamically populate channels. Therefore, community standards like ISMRM-RD [\nDeclarative routing: Naming conventions (e.g., BIDS\nInterface contracts: Standards define clear input/output relationship between workflow stages. For example, a BIDS derivatives rule that segmentation masks follow\nSwap modules, do not reinvent them\nOnce data standards and containerization are established, pipeline modules become interchangeable “LEGO blocks”. Figure\nThis approach can drastically reduce code complexity, particularly when the pipeline description includes all steps. Figure\nThis illustration captures one of many possible (3\nqMRFlow is a suite of container-mediated, data-driven and transparent qMRI pipelines, ideally starting with a vendor-neutral\nPowered by Nextflow, qMRFlow adapts the principles outlined in this review to enable reproducible and modular measurements. Its modules are developed to work primarily with qMRLab [\nWhile qMRLab offers core functionality for processing quantitative MRI data, qMRFlow enhances this by seamlessly integrating with nearly all\nThe\nThere are two main pipeline descriptions that make use of these modules:\nThe\nSince the pipeline follows qMRI-BIDS, data channels can be structured using standardized patterns, simplifying the integration of processes and ensuring seamless workflow connectivity.\nTo repeat the\nA more recent demonstration of qMRFlow’s glass-box compatibility is shown through its integration with Pulseq [\nThe TractoFlow pipeline processes dMRI dataset from the raw data to the tractography as a modular entity. Tractoflow was quickly adopted by researchers outside of the immediate network of developers. Powered by Nextflow DSL1 and containerization, here are the five main highlights of Tractoflow (Fig.\nEfficient diffusion MRI processing pipeline from raw (i.e., vendor-reconstructed) diffusion data to tractography, which has allowed processing of the HCP [\nThe stochastic nature of the Tractoflow tractography pipeline makes reproducible results particularly challenging. Efforts are made to reduce variability when relaunching Tractoflow to ensure reproducible and replicable results today, tomorrow, and over time [\nTractoflow provides a tradeoff between customization and curation of configuration files, making it easy-to-use for non-technical and clinician users. Profiles are provided to adapt to different use cases (aging, development, white matter hyperintensities, amongst others [\nLittle to no installation steps and compatibility with High-Performance Computing thanks to containers and Nextflow executors (e.g. SLURM, AWS).\nSupport for multiple vendors through BIDS.\nThis figure represents the TractoFlow pipeline, designed as a gray-box workflow: it uses BIDS-formatted inputs from scanner reconstructions. It outputs a variety of files, ensuring reproducibility when inputs are identical. Each box in the diagram denotes a modular step, capable of saving outputs and configured for durability using dedicated Docker containers. Parameters are fully accessible and customizable through a comprehensive configuration file, allowing users to adapt the pipeline for diverse applications (e.g., healthy brain, tumor analysis, aging studies). Steps like tissue segmentation can be reconfigured to use tools like FreeSurfer, aligning with the gray-box principles\nTractoflow includes more than 20 steps that are automatically distributed depending on their dependencies and requirements and grouped into two main blocks of processes (see Fig.\nFrom the Tractoflow output tree, there are a series of optional flows available to automatically extract the main white matter bundles (rbx_flow) [\nHowever, Tractoflow does not address completely the\nNextflow DSL2 enabled the creation of\nIn the section titled “Opening up the implementations, that’s how the light gets in,” we reviewed recent QIB studies that use glass-box workflows as an effective approach to tackle variability at its source, all while staying true to the first-principles foundation of MRI acquisitions. This title purposefully draws inspiration from Leonard Cohen’s famous lyrics, “There’s a crack in everything, that’s how the light gets in”. While glass-box workflows are designed for transparency, their increasing complexity introduces fractures where dependencies accumulate (Fig.\nNearly half a century of efforts have fallen short in giving a generalizable answer to this question. MRI research silos answer it by championing a particular QIB attached to a fitting clinical use case (and even some de-facto standards) to make it reproducible across scanners [\nThe idea that the future of MRI is quantitative emerges, fades, and resurfaces as the tagline of annual conferences on MRI methods development. Meanwhile, applied research studies leveraging MRI measurements to test biomedical hypotheses continue to proliferate, spawning new subfields and career trajectories. However, the widening gap between the ever-expanding body of rejected null hypotheses and the scarcity of QIBs that have led to changes in patient management has raised concerns among clinicians about the validity of research priorities and their practical impact on patient care.\nOpening quotes from two articles by MDs Weinberger and Radulescu [\nFollowing these staggering opening quotes in their articles on structural MRI, the authors warn against overinterpreting data-driven QIBs and emphasize that such findings should be framed strictly as “differences in MRI measurements” rather than definitive neurobiological conclusions such as “cortical thinning”. They further argue that the ongoing overinterpretation of confounded MRI measurements is not only problematic but also a disservice to patients and their families, potentially by misdirecting valuable taxpayer dollars—funds that could be used more effectively to improve patient care, such as by better staffing hospitals and enhancing clinical services.\nGiven the unresolved translational gap, it remains too soon to determine whether numerical metrics derived from MRI offer clear clinical advantages over visual assessment alone. However, significant efforts are being made to improve the utility of QIBs, and we briefly discuss their potential benefits and challenges below.\nMRI does not directly measure anatomy; apparent tissue boundaries are influenced by systematic biases and biophysical confounders. Most data-driven QIBSs rely on these boundaries, which may reflect secondary physiological effects rather than true morphology [\nCan we dispense with the differences in k-space encoding within the latent space of deep learning models? For example, CALAMITI claims to disentangle anatomy and contrast into distinct latent representations [\nSimulation-based bias correction strategies targeting the opaque zone (Fig.\nAn interesting avenue for further exploration is examining inter-site effects starting from the k-space data acquired using vendor-native sequences. In the context of data-driven QIBs, variability in the reconstruction of images from multi-channel receive coils is a notable source of inconsistency [\nIt is crucial to recognize that even the simplest QIB in MRI involves far more degrees of freedom in its calculation than the Hounsfield Unit in CT. The final form of an MR image is influenced by a complex interplay of factors, including spin dynamics, coil sensitivities, gradient nonlinearities, B0 inhomogeneities, eddy currents, susceptibility effects, RF field distortions, and physiological noise, among others. This complexity underscores the importance of returning to the first principles of MRI measurements for conscious reduction of scanner effects. We argue that taking a step back and striving for standardization in a metrological framework is a leap toward unlocking the true clinical potential of QIBs, and adopting glass-box workflows can show the way forward.\nThe consideration of user-friendliness is still in its early stages for deploying vendor-neutral acquisition platforms coupled with glass-box workflows. Nevertheless, exciting developments are underway both by open-source developers and vendors.\nCurrently, only the RTHawk proprietary platform [\nThe modular and portable approach to creating a comprehensive measurement pipeline presented in this review has great potential to complement these efforts, facilitate collaboration, and lower the barriers to standardizing QIB implementations. Once we standardize MRI measurement procedures through efficient use of reference objects [\nUnlike standardized biochemical assays which have universally accepted calibration standards across laboratories, MRI measurements remain highly variable across scanners and sites. This variability stems from the complex interplay of factors in MRI signal generation and site-specific differences in the measurement chain. Rather than constructing a Rube Goldberg machine of harmonization methods and normative modeling, we argue for returning to the first principles of MRI measurements, using standardization within a metrological framework. By embracing workflows that strive for standardization, we can bridge the gap between research innovations and clinical applications [", "topic": "Diagnostic"}
{"pmid": "40685338", "pmcid": "12278571", "title": "Circulating miRNAs correlate with clinical evaluation of activity in ANCA-associated glomerulonephritis", "publication_year": "N/A", "abstract": "", "full_text": "ANCA-associated vasculitis (AAV) comprises a group of systemic autoimmune disorders characterized by necrotizing small vessel vasculitis. Renal involvement in the form of AAV-GN is a prevalent and severe manifestation of AAV that significantly impacts disease prognosis and management strategies as a major contributor to both morbidity and mortality. Precise noninvasive detection and monitoring of active AAV-GN remain a clinical challenge. Currently, circulating ANCAs serve as a principal biomarker for diagnosis and disease monitoring. However, the ANCA-based approach has several limitations, including the presence of ANCAs in diseases other than AAV-GN and the discordance between ANCA titers and clinical manifestations. Specifically, patients may exhibit persistent ANCA positivity despite clinical remission or, conversely, active disease in the absence of titer elevation [\nMicroRNAs (miRNAs), a class of small noncoding RNAs that regulate gene expression post-transcriptionally, have emerged as promising biomarkers across a range of autoimmune diseases, including systemic lupus erythematosus, psoriasis, and rheumatoid arthritis [\nThis was a prospective follow-up study on serum samples of 60 consecutive cases of AAV after biopsy-proven renal involvement in the form of AAV-GN. The serum samples were collected at renal biopsy (initial diagnosis samples) and at 3-, 6-, 12-, and 24-month intervals post renal biopsy during clinical check-ups (follow-up samples). All serum samples were snap-frozen and stored at −80 °C within 72 h of collection.\nIn every case, the follow-up period terminated with one of the following predefined clinical events: last clinical follow-up at study closure, relapse, death, or need for kidney replacement therapy. Patient enrollment began in January 2018, and follow-up continued until December 2024.\nVariables recorded for each case (and time point) included age, sex, estimated glomerular filtration rate (eGFR in ml/min/1.73 m2, calculated using the CKD-EPI 2021 equation), measured daily proteinuria (24 h urine total protein excretion in grams), ANCA titers, type of immunosuppressive therapy, and Birmingham Vasculitis Activity Score version 3 (BVAS) [\nANCA specificity and titers were determined using enzyme-linked immunosorbent assay (ELISA, Wieslab AB, Malmö, Sweden) at the Institute of Pathology, Medical Faculty of Ljubljana. The positive cutoff levels were 8 IU/ml for MPO-ANCA and 6 IU/ml for PR3-ANCA. Additional routine laboratory parameters, such as C-reactive protein (CRP), were analyzed at the Department of Clinical Chemistry, University Medical Centre Ljubljana.\nDisease activity was assessed by the treating nephrologist based on clinical judgment at the time of treatment and subsequently supplemented by a retrospective review of medical records by the study investigator using the BVAS.\nComplete remission was defined as a BVAS3 score of 0. Standard remission criteria included the absence of clinical symptoms and signs of active vasculitis in any organ system, as confirmed by both the treating physician and the study investigator, no requirement for escalation of immunosuppressive therapy, and normalization of inflammatory markers (CRP).\nFor the purposes of this study, patients who were deemed to be in clinical remission by both the treating physician and the study investigator—based on a comprehensive review of clinical and laboratory data—but who nevertheless exhibited a BVAS3 score between > 0 and ≤ 2 solely due to persistent but progressively improving proteinuria, were classified as being in partial remission. These patients demonstrated negative inflammatory markers, complete resolution of extra renal manifestations, and continuous improvement in renal function.\nAll other patients who did not meet the criteria for complete or partial remission were considered to have active disease.\nRelapse was defined as the recurrence of disease after achieving complete remission, in patients who had completed induction immunosuppressive therapy. Relapse required the presence of new or worsening clinical symptoms and signs of vasculitis, a BVAS3 score > 2, and the need to intensify immunosuppressive therapy.\nWe aimed to include initial disease presentations only but subsequently enrolled five relapse cases after a sustained remission period without immunosuppressive therapy to increase sample size.\nNine miRNAs (\nFor total RNA isolation, 200 µl of stored serum was processed with miRNeasy Serum/Plasma Advanced Kit (Qiagen, Hilden, Germany) following the manufacturer’s protocol. Elution was performed in 20 µL of nuclease-free water and the eluate was stored at −80 °C. Spike-in RNAs, namely UniSp2, UniSp4 and UniSp5 (Qiagen, Hilden, Germany), were used to verify the technical success of the isolation procedure.\nReverse transcription (RT) was performed according to the manufacturer’s instructions. For RT, miRCURY LNA RT Kit (Qiagen, Hilden, Germany) was used with 2 μl of isolated RNA in 10 μl reaction master mix. For RT quality control, UniSp6 was spiked into the RT. The reaction was run at 42 °C for 60 min and 85 °C for 5 min.\nThe obtained RT was diluted 30-fold and 3 μl was used in 10 μl qPCR reaction master mix containing 5 µl of 2X miRCURY SYBR Green Master Mix and 1 µl of appropriate 10X miRCURY LNA miRNA PCR Assay. All qPCR reactions were performed in duplicate on the QuantStudio 7 Pro platform (Thermo Fisher Scientific, Foster City, CA, USA) according to the manufacturer’s instructions. The signal was collected at the endpoint of every cycle. To ascertain the specificity of the qPCR products, melting curve analysis was conducted using a ramping rate of 0.075 °C/1 s in the 60–95 °C range.\nBefore analysis, successful RT was tested using expression analysis of UniSp6 spike-in during RT reaction. Further, successful RNA isolation from serum was evaluated by expression analysis of spike-in RNAs during isolation, namely UniSp2, UniSp4 and UniSp5\nThe geometric mean of expression of reference genes for each sample was subtracted from the expression of analyzed miRNAs (ΔCq) [\nWe included all cases with at least one technically adequate follow-up sample for correlation analyses in unpaired independent samples. The initial sample served as expression normalization reference and therefore was a prerequisite for paired analyses, but not for unpaired independent analyses.\nThirty-eight out of 60 cases initially considered eligible were ultimately selected after sample quality control. Twenty-two cases (19 MPO- and 3 PR3-positive) with technically adequate initial and at least one follow-up sample were included in both unpaired (global) and paired analyses. Sixteen additional cases (11 MPO- and 5 PR3-positive) without a technically adequate initial sample but with at least one follow-up sample were included in unpaired (global) analyses only.\nThe patients were followed up for a median of 38 months (range 3–73 months) up to the occurrence of a predefined clinical event as described in Materials & Methods. Selected clinicopathologic characteristics of the cohort are presented in Table\nCore clinicopathologic characteristics of the study cohort\nDisease activity was negatively correlated to eGFR (Rho = −0.435,\nCorrelation between eGFR and disease activity.\nExpression of miRNAs in independent follow-up samples was correlated to disease activity, eGFR, ANCA titer and BVAS (both compounded and scored as persistent or new/worse). To disease activity, we observed a weak negative correlation with the expression of\nTo eGFR, we observed a weak positive correlation with the expression of\nCorrelations of miRNA expressions with markers of disease activity and miRNA expression differences between disease activity groups\nRho = −0.381\nRho = −0.212\nRho = −0.312\nRho = −0.514\nRho = 0.444\nRho = 0.291\nRho = −0.215\nRho = −0.344\nRho = −0.197\nRho = −0.381\nRho = −0.432\nRho = −0.238\nRho = −0.341\nRho = −0.576\nRho = −0.228\nRho = −0.480\nRho = −0–375\nRho = −0.667\nRho = −0.241\nRho = −0.384\nRho = −0.221\nRho = 0.533\nRho = 0.248\nRho = 0.446\nRho = 0.364\nRho = 0.526\nRho = 0.315\nWe compared the expression of miRNAs in follow-up samples (3-, 6-, 12-, and 24-month intervals months post initial samples) relative to the initial serum sample. We observed statistically significant differential expression of\nSince we observed differential expressions between paired serum samples (follow-up in comparison to initial serum sample), we normalized the expression of investigated miRNAs in follow-up serum samples to the initial one (ΔΔCq) and the normalized expression was again analyzed for correlation to disease activity.\nWith disease activity, we observed a weak negative correlation to expressions of\nSpecifically, a significant differential expression of\nCorrelations of normalized miRNA expressions with disease activity.\nCorrelation of\nAdditionally, negative correlations with the expression of\nCorrelation of\nIn this prospective study, we sought to evaluate the utility of a circulating miRNA signature as a noninvasive biomarker for monitoring disease activity in AAV-GN. We identified a distinct circulating miRNA signature associated with active AAV-GN by preceding comprehensive screening [\nThe most important findings include correlations between the disease activity, BVAS, eGFR and ANCA titers, and the differential expressions of\nOur study also confirmed the inverse relationship between disease activity and eGFR, underscoring the detrimental impact of active vasculitis on renal function. These findings align with previous reports that have demonstrated a significant association between higher disease activity scores and decreased eGFR [\nCurrent knowledge of circulating miRNAs in AAV-GN is minimal and inconsistent. Of note, the existent studies did not stem from comprehensive tissue-based screening with subsequent validation and employed a limited screening panel or analyzed pre-selected miRNAs in serum or urine samples [\nAmong the most promising biomarker miRNAs,\nWe also included three out of five miRNAs belonging to\nWe also observed a down-regulation of\nTwo additional miRNAs (\nAn interesting finding relates to\nAlthough clinical application remains distant, functional annotations of the studied miRNAs to biological pathways and target genes relevant to AAV pathogenesis also support attractive therapeutic avenues by miRNA ago-/antagomirs and miRNA sponges.\nAs a limitation, it is important to acknowledge that our actual study cohort was small due to challenging technical aspects of biofluid-based miRNA expression analysis, resulting in constrained statistical power for subgroup comparisons and correlation analyses.\nCollectively, our data suggest that serum miRNA expression profiling holds promise as a surrogate tool for noninvasive disease activity assessment in AAV-GN during follow-up, particularly when expression data are normalized to baseline samples. However, like ANCAs, the generally weak to moderate strength of identified associations limits their reliability as standalone markers, indicating that their greatest utility may lie in combination or as components of a broader, integrated model. To validate the monitoring utility of the identified miRNAs and to explore their integration into decision-making algorithms, future studies in larger cohorts should be performed.\n\nSupplementary material 1.", "content_for_embedding": "ANCA-associated vasculitis (AAV) comprises a group of systemic autoimmune disorders characterized by necrotizing small vessel vasculitis. Renal involvement in the form of AAV-GN is a prevalent and severe manifestation of AAV that significantly impacts disease prognosis and management strategies as a major contributor to both morbidity and mortality. Precise noninvasive detection and monitoring of active AAV-GN remain a clinical challenge. Currently, circulating ANCAs serve as a principal biomarker for diagnosis and disease monitoring. However, the ANCA-based approach has several limitations, including the presence of ANCAs in diseases other than AAV-GN and the discordance between ANCA titers and clinical manifestations. Specifically, patients may exhibit persistent ANCA positivity despite clinical remission or, conversely, active disease in the absence of titer elevation [\nMicroRNAs (miRNAs), a class of small noncoding RNAs that regulate gene expression post-transcriptionally, have emerged as promising biomarkers across a range of autoimmune diseases, including systemic lupus erythematosus, psoriasis, and rheumatoid arthritis [\nThis was a prospective follow-up study on serum samples of 60 consecutive cases of AAV after biopsy-proven renal involvement in the form of AAV-GN. The serum samples were collected at renal biopsy (initial diagnosis samples) and at 3-, 6-, 12-, and 24-month intervals post renal biopsy during clinical check-ups (follow-up samples). All serum samples were snap-frozen and stored at −80 °C within 72 h of collection.\nIn every case, the follow-up period terminated with one of the following predefined clinical events: last clinical follow-up at study closure, relapse, death, or need for kidney replacement therapy. Patient enrollment began in January 2018, and follow-up continued until December 2024.\nVariables recorded for each case (and time point) included age, sex, estimated glomerular filtration rate (eGFR in ml/min/1.73 m2, calculated using the CKD-EPI 2021 equation), measured daily proteinuria (24 h urine total protein excretion in grams), ANCA titers, type of immunosuppressive therapy, and Birmingham Vasculitis Activity Score version 3 (BVAS) [\nANCA specificity and titers were determined using enzyme-linked immunosorbent assay (ELISA, Wieslab AB, Malmö, Sweden) at the Institute of Pathology, Medical Faculty of Ljubljana. The positive cutoff levels were 8 IU/ml for MPO-ANCA and 6 IU/ml for PR3-ANCA. Additional routine laboratory parameters, such as C-reactive protein (CRP), were analyzed at the Department of Clinical Chemistry, University Medical Centre Ljubljana.\nDisease activity was assessed by the treating nephrologist based on clinical judgment at the time of treatment and subsequently supplemented by a retrospective review of medical records by the study investigator using the BVAS.\nComplete remission was defined as a BVAS3 score of 0. Standard remission criteria included the absence of clinical symptoms and signs of active vasculitis in any organ system, as confirmed by both the treating physician and the study investigator, no requirement for escalation of immunosuppressive therapy, and normalization of inflammatory markers (CRP).\nFor the purposes of this study, patients who were deemed to be in clinical remission by both the treating physician and the study investigator—based on a comprehensive review of clinical and laboratory data—but who nevertheless exhibited a BVAS3 score between > 0 and ≤ 2 solely due to persistent but progressively improving proteinuria, were classified as being in partial remission. These patients demonstrated negative inflammatory markers, complete resolution of extra renal manifestations, and continuous improvement in renal function.\nAll other patients who did not meet the criteria for complete or partial remission were considered to have active disease.\nRelapse was defined as the recurrence of disease after achieving complete remission, in patients who had completed induction immunosuppressive therapy. Relapse required the presence of new or worsening clinical symptoms and signs of vasculitis, a BVAS3 score > 2, and the need to intensify immunosuppressive therapy.\nWe aimed to include initial disease presentations only but subsequently enrolled five relapse cases after a sustained remission period without immunosuppressive therapy to increase sample size.\nNine miRNAs (\nFor total RNA isolation, 200 µl of stored serum was processed with miRNeasy Serum/Plasma Advanced Kit (Qiagen, Hilden, Germany) following the manufacturer’s protocol. Elution was performed in 20 µL of nuclease-free water and the eluate was stored at −80 °C. Spike-in RNAs, namely UniSp2, UniSp4 and UniSp5 (Qiagen, Hilden, Germany), were used to verify the technical success of the isolation procedure.\nReverse transcription (RT) was performed according to the manufacturer’s instructions. For RT, miRCURY LNA RT Kit (Qiagen, Hilden, Germany) was used with 2 μl of isolated RNA in 10 μl reaction master mix. For RT quality control, UniSp6 was spiked into the RT. The reaction was run at 42 °C for 60 min and 85 °C for 5 min.\nThe obtained RT was diluted 30-fold and 3 μl was used in 10 μl qPCR reaction master mix containing 5 µl of 2X miRCURY SYBR Green Master Mix and 1 µl of appropriate 10X miRCURY LNA miRNA PCR Assay. All qPCR reactions were performed in duplicate on the QuantStudio 7 Pro platform (Thermo Fisher Scientific, Foster City, CA, USA) according to the manufacturer’s instructions. The signal was collected at the endpoint of every cycle. To ascertain the specificity of the qPCR products, melting curve analysis was conducted using a ramping rate of 0.075 °C/1 s in the 60–95 °C range.\nBefore analysis, successful RT was tested using expression analysis of UniSp6 spike-in during RT reaction. Further, successful RNA isolation from serum was evaluated by expression analysis of spike-in RNAs during isolation, namely UniSp2, UniSp4 and UniSp5\nThe geometric mean of expression of reference genes for each sample was subtracted from the expression of analyzed miRNAs (ΔCq) [\nWe included all cases with at least one technically adequate follow-up sample for correlation analyses in unpaired independent samples. The initial sample served as expression normalization reference and therefore was a prerequisite for paired analyses, but not for unpaired independent analyses.\nThirty-eight out of 60 cases initially considered eligible were ultimately selected after sample quality control. Twenty-two cases (19 MPO- and 3 PR3-positive) with technically adequate initial and at least one follow-up sample were included in both unpaired (global) and paired analyses. Sixteen additional cases (11 MPO- and 5 PR3-positive) without a technically adequate initial sample but with at least one follow-up sample were included in unpaired (global) analyses only.\nThe patients were followed up for a median of 38 months (range 3–73 months) up to the occurrence of a predefined clinical event as described in Materials & Methods. Selected clinicopathologic characteristics of the cohort are presented in Table\nCore clinicopathologic characteristics of the study cohort\nDisease activity was negatively correlated to eGFR (Rho = −0.435,\nCorrelation between eGFR and disease activity.\nExpression of miRNAs in independent follow-up samples was correlated to disease activity, eGFR, ANCA titer and BVAS (both compounded and scored as persistent or new/worse). To disease activity, we observed a weak negative correlation with the expression of\nTo eGFR, we observed a weak positive correlation with the expression of\nCorrelations of miRNA expressions with markers of disease activity and miRNA expression differences between disease activity groups\nRho = −0.381\nRho = −0.212\nRho = −0.312\nRho = −0.514\nRho = 0.444\nRho = 0.291\nRho = −0.215\nRho = −0.344\nRho = −0.197\nRho = −0.381\nRho = −0.432\nRho = −0.238\nRho = −0.341\nRho = −0.576\nRho = −0.228\nRho = −0.480\nRho = −0–375\nRho = −0.667\nRho = −0.241\nRho = −0.384\nRho = −0.221\nRho = 0.533\nRho = 0.248\nRho = 0.446\nRho = 0.364\nRho = 0.526\nRho = 0.315\nWe compared the expression of miRNAs in follow-up samples (3-, 6-, 12-, and 24-month intervals months post initial samples) relative to the initial serum sample. We observed statistically significant differential expression of\nSince we observed differential expressions between paired serum samples (follow-up in comparison to initial serum sample), we normalized the expression of investigated miRNAs in follow-up serum samples to the initial one (ΔΔCq) and the normalized expression was again analyzed for correlation to disease activity.\nWith disease activity, we observed a weak negative correlation to expressions of\nSpecifically, a significant differential expression of\nCorrelations of normalized miRNA expressions with disease activity.\nCorrelation of\nAdditionally, negative correlations with the expression of\nCorrelation of\nIn this prospective study, we sought to evaluate the utility of a circulating miRNA signature as a noninvasive biomarker for monitoring disease activity in AAV-GN. We identified a distinct circulating miRNA signature associated with active AAV-GN by preceding comprehensive screening [\nThe most important findings include correlations between the disease activity, BVAS, eGFR and ANCA titers, and the differential expressions of\nOur study also confirmed the inverse relationship between disease activity and eGFR, underscoring the detrimental impact of active vasculitis on renal function. These findings align with previous reports that have demonstrated a significant association between higher disease activity scores and decreased eGFR [\nCurrent knowledge of circulating miRNAs in AAV-GN is minimal and inconsistent. Of note, the existent studies did not stem from comprehensive tissue-based screening with subsequent validation and employed a limited screening panel or analyzed pre-selected miRNAs in serum or urine samples [\nAmong the most promising biomarker miRNAs,\nWe also included three out of five miRNAs belonging to\nWe also observed a down-regulation of\nTwo additional miRNAs (\nAn interesting finding relates to\nAlthough clinical application remains distant, functional annotations of the studied miRNAs to biological pathways and target genes relevant to AAV pathogenesis also support attractive therapeutic avenues by miRNA ago-/antagomirs and miRNA sponges.\nAs a limitation, it is important to acknowledge that our actual study cohort was small due to challenging technical aspects of biofluid-based miRNA expression analysis, resulting in constrained statistical power for subgroup comparisons and correlation analyses.\nCollectively, our data suggest that serum miRNA expression profiling holds promise as a surrogate tool for noninvasive disease activity assessment in AAV-GN during follow-up, particularly when expression data are normalized to baseline samples. However, like ANCAs, the generally weak to moderate strength of identified associations limits their reliability as standalone markers, indicating that their greatest utility may lie in combination or as components of a broader, integrated model. To validate the monitoring utility of the identified miRNAs and to explore their integration into decision-making algorithms, future studies in larger cohorts should be performed.\n\nSupplementary material 1.", "topic": "Diagnostic"}
{"pmid": "40676523", "pmcid": "12305011", "title": "Robust single-trial decoding of physical self-motion from hemodynamic signals in the brain measured by functional ultrasound imaging", "publication_year": "2025", "abstract": "Over the past decades, brain-wide vestibular signals have been measured by imaging techniques such as functional MRI, under head- or whole body-restricted status. In such scenarios, caloric or galvanic vestibular stimulation techniques are typically applied to activate the peripheral vestibular organs, which is far away from real conditions in our daily life. In this study, we employed high-spatiotemporal resolution functional ultrasound imaging technique to measure vestibular-related signals evoked by physical self-motion stimuli across extensive brain regions in macaques. Our findings open a direction for studying the functions of the vestibular system, together with other systems such as visual or motor system, under conditions allowing precise control of stimuli parameters, providing unique advantages over conventional methods.\nPhysical self-motion frequently happens in daily life, during which our vestibular system is critical in various important functions including balance and visual stability maintenance, postural and motor control, locomotion, spatial perception, and path integration-based navigation. Conventional noninvasive methods for studying vestibular functions include functional MRI (fMRI) that conveniently measures brain-wide signals; however, subjects are required to be physically restricted in the scanner. In such cases, caloric or galvanic vestibular stimulation is applied to stimulate peripheral vestibular organs, suffering a loss of precise stimulation of peripheral vestibular organs as during physical motion conditions. In this study, we adopted functional ultrasound (fUS) imaging, a newly emerging minimally invasive technique with high spatiotemporal resolution, to measure vestibular related signals in primates under passive, physical self-motion conditions that selectively activate vestibular organs. We found that robust fUS signals were evoked in brain-wide regions. While many areas overlapped with those previously reported by fMRI or electrophysiology, significant activations were also seen in areas that were not clearly identified previously including area 5, 1-2, M1, V3A, and 7 m. Importantly, using a linear discriminant analysis algorithm, physical self-motion information, including both translation directions, and translation-vs.-rotation, could be reliably decoded from fUS signals on a single-trial basis. In addition to vestibular-related activity, many areas also exhibited visual-motion response, indicating possible multisensory interactions. Our findings suggest that fUS imaging holds a promising tool for studying vestibular functions in tasks under physical self-motion conditions, as well as interactions with visual or motor systems.", "full_text": "As a typical example of embodied intelligence, the vestibular system provides crucial cues for organisms to interact with the environment including the maintenance of balance and visual stability, postural and motor control, locomotion, spatial perception, and path integration during vector-based navigation (\nAnother limitation of using conventional imaging tools (e.g., fMRI, PET, MEG) to measure vestibular signals is that subjects are physically stabilized during scanning. In such cases, alternative stimulation methods, including noninvasive caloric or galvanic vestibular stimulation (CVS or GVS), are employed to stimulate all peripheral vestibular organs and their afferents [PET: (\nThe recently emerging technique of functional ultrasound (fUS) imaging, a hemodynamic technique which visualizes cerebral blood volume (CBV) changes using ultrafast Doppler angiography, appears to address these limitations by offering a minimally invasive, rapid, large-scale, and high spatiotemporal resolution method (up to 100 µm, 100 ms) (\nTo measure vestibular-related signals, a 15.6 MHz ultrasound probe was attached to the heads of two macaques while they were subjected to sinusoidal translational or rotational motion by a 6-degree-of-freedom motion platform (\nExperimental setup and fUS signals evoked by passive, physical self-motion stimuli. (\nUnder physical motion conditions, the animals were passively translated or rotated sinusoidally at a frequency of 0.5 Hz in total darkness (\nBased on the raw fUS signals, we conducted a correlation analysis between the ultrasound Doppler signals and the existence of motion stimuli. The Pearson correlation coefficients were subjected to false discovery rate (FDR) correction with\nAfter identifying areas exhibiting significant vestibular-related signals using the correlation analysis, we then evaluated the response modulation strength for each region of interest (ROI). Specifically, within each ROI, a subregion of 10 × 10 voxels (\nDue to hemodynamics of fUS imaging, CBV changes occurred with a delay. To quantify this, peak time of each ROI was calculated, which occurred at the 11th frame (0.4 s/frame), corresponding to 4.25 ± 0.08 s (mean ± SEM) (\nfUS imaging provides high spatial resolution. We thus first performed a layer-based analysis by dividing each ROI into three laminar compartments (superficial, middle, and deep layers) (\nTo verify the stability of the activated fUS signals, we conducted several analyses. First, we analyzed fUS signals of the same coronal plane across different days (\nTo examine other possible sources, we conducted several control experiments and analyses. In our experiment, we delivered passive self-motion in darkness, aimed to remove possible impact from visual stimuli. Yet the animals’ eye movements including vestibular ocular reflex (VOR) were not limited in this condition and they may confound the fUS signals (\nIn addition to eye movements, in our experimental setup, physical motion stimuli were provided through a motion platform that generated significant noise (90 dB) during movement which may also contributed to the fUS signals. We thus conducted a control experiment by recording the sound from the motion platform and playing it back to the animals while the motion platform remained stationary. We found that these sound related stimuli did not reproduce the fUS signals as measured under the physical motion condition (\nTo evaluate whether fUS signals are sufficiently precise to distinguish different self-motion stimuli, we provided two physical motion directions within each block. Specifically, 6-s duration trials of motions along lateral and back–forth axis were randomly interleaved, with each stimulus condition repeated approximately 200 times, resulting in 400 trials per experimental session. Under this design, we observed significant differences in the mean fUS signals between the two motion directions (\nTo address whether different motion stimuli could be reliably decoded from one single trial rather than the mean response across trials, referring to previous studies (\nMotion direction and type decoding based on single trial. (\nWe found that motion directions could be reliably decoded on a single-trial basis from the fUS signals in both animals (\nTo understand the influence of different time periods on decoding accuracy, we performed cross-temporal decoding by training and testing using different time windows (\nTo assess how many trials are needed for successful decoding, we calculated the mean decoding accuracy across stimulus duration as a function of the number of trials used for training (\nAfter identifying decoding accuracy based on a full image data, we further assessed decoding accuracy based on each ROI using the searchlight approach at each time point. Decoding was performed based on fUS signals within a 1.2-s window (3 frames), sliding with a step of 400 ms (1 frame). Multiple brain regions in both animals exhibited robust decoding capabilities, such as MSTd, VIP, PCC, RSC, PIVC, VPS, and area 5 with some fluctuations (\nIn addition to decoding motion directions, we also used the LDA algorithm to decode different types of physical self-motion on a single-trial basis. Specifically, translation along the lateral axis and rotation around the vertical axis were interleaved within one block and repeated 200 times, to selectively activate the otolith and canal, respectively. We found that decoding accuracy was significantly above chance level (\nSimilar to motion direction decoding, motion type decoding was also significant when there were more than a dozen trials (binomial test,\nTo further assess possible impact from eye movements, we also decoded different self-motion based on the eye position data with the identical algorithm as used for the fUS data (\nGVS has been widely used in previous studies as an alternative and compromised way to activate peripheral vestibular organs during fMRI/PET/MEG scans when physical motion stimuli are not available (e.g., refs.\nGVS experiment. (\nWe observed that GVS reliably activated multiple brain regions captured by fUS (see examples in\nAlthough qualitatively there was large overlapping between GVS and physical motion evoked fUS signals, there was also quantitative difference between the two methods. In particular, CBV change of most regions under physical motion was overall larger than under GVS (\nIn summary, our GVS experiment showed large consistency with previous fMRI/PET/MEG imaging studies, with exception of showing two new areas of area 5 and 1-2, which were also captured by our physical motion stimuli, confirming the validity of the fUS imaging technique. However, GVS failed to reveal V3A, M1, and 7 m, which were indicated by the physical motion stimuli used in the current fUS experiment. Physical motion and GVS evoked signals also differed in CBV, Pearson correlation coefficient, and response delay, which may be due to a number of sources. First, the activation under GVS condition varies depending on parameters such as current intensity, frequency, and delivered position. Second, GVS stimulates the whole inner ear end organs and afferents at the same time, which is different from our physical motion stimulus that selectively activates specific end organs (e.g., horizontal otolith, or horizontal canal). Third, physical self-motion may produce more mixed signals than GVS, such as somatosensory, or motor-related activity to compensate for the inertia force passively applied onto the subjects.\nVisual information, for example, optic flow also plays an important role during self-motion. Accordingly, numerous previous studies have demonstrated many brain regions modulated by optic flow (\nBrain regions activated by both optic flow and physical motion stimuli. (\nWe identified up to 12 bimodal areas that were significantly modulated by both physical motion and optic flow stimuli, including 3a, 2v, MSTd, VPS, VIP, 7a, V3A, MIP, 5, 1-2, M1, and F2. Overall, fUS signals were comparable between the two stimulus conditions, with a modestly stronger CBV change in the vestibular condition (\nNotably, we also observed heterogeneity within individual areas with respect to the vestibular and visual signals (\nIn our current study, fUS imaging with physical motion stimuli revealed the activation of a broad range of brain regions in macaques. Many of these are classical vestibular or multisensory regions concurrently carrying vestibular signals, including PIVC, 2v, 3a, VPS, PCC, RSC, MSTd, and VIP, confirming the validity of applying this technique in vestibular research. Meanwhile, we also identified areas exhibiting robust hemodynamic signals in response to physical self-motion that have not been clearly identified previously. Among these areas, there are roughly three categories in terms of their conventionally defined sensory functions.\nFirst, we observed significant activation by passive self-motion in V3A, an area in the traditional dorsal visual pathway for visual motion processing (\nSecond, robust fUS signals in response to self-motion were detected in motor-related areas, including M1, area 5 and 7 m. For M1, vestibular activation has only been vaguely reported in one human study involving the precentral gyrus (\nThird, significant fUS signals were observed in somatosensory area 1-2. The activation is certainly much larger than the conventional vestibular area 2v at the posterior end of 1-2 (\nIn summary, our study utilizing high spatiotemporal resolution fUS imaging technique under physical motion stimuli revealed robust hemodynamic signals that are highly likely from vestibular origin in some areas that have not been clearly identified in previous studies, urging the need for further experiments, for example, electrophysiological recordings. Note, however, fUS imaging is similar to fMRI that measures hemodynamics and is thus only indirectly linked to changes in neural activity within neighboring populations. It is well known that discrepancies may exist between the imaging and electrophysiology that measures more global or local activity respectively (\nOur study demonstrates the feasibility of fUS imaging in vestibular research and highlights several advantages of this technology. First, fUS imaging allows for studying vestibular signals under real physical passive or active self-motion conditions that can precisely target specific subregions of the peripheral vestibular organ, better simulating natural contexts compared to GVS or CVS methods used in previous imaging research with constraint head or whole body. Second, fUS imaging enables measurement of signals across a fairly large range of brain regions. In the current study, we used an ultrasonic probe with multiple plane wave (MPW) transmissions that imaged an entire plane in one shot (\nHowever, fUS imaging also faces several challenges. First, the equipment used in the study offers a spatial resolution of 100 × 100 µm with a slice thickness of 400 µm and a temporal resolution of 400 ms. At this spatial resolution, it is difficult to observe clusters of neurons within certain brain regions that prefer the same feature, for example, preferred direction or motion type. Therefore, further enhancing spatial resolution is crucial for more detailed exploration in future experiments. Similarly, further improving temporal resolution is also critical to leverage the technique by looking into more detailed dynamic of signals during tasks, for example, decision making. Second, although the current fUS imaging already evokes fairly strong signals (8 to 50% CBV change), which is several folds larger than conventional imaging tools, its sensitivity could be further improved to better approach electrophysiology. Third, the imaging depth of the probe used in this study is 1.5 cm, which limits high-resolution exploration of deep brain regions. Current probes can achieve an imaging depth of up to 4 cm, but with a decreased resolution of 250 µm (from Iconeus). Therefore, there is a trade-off between the imaging depth and resolution in ultrasound imaging, necessitating a balance based on specific research requirements. Fourth, compared to fMRI, which is completely noninvasive, fUS imaging requires craniotomy in large animals, as the thick skull of monkeys significantly absorbs ultrasound waves, impairing imaging signals. Additionally, the application of fUS in humans is mostly restricted to patients (\nWe conducted experiments on two male monkeys, identified as Monkey W (\nAfter behavioral training, rectangular chambers (made from polyetherimide) were surgically installed on the heads of two monkeys. The cranial bones inside the chambers were removed while the dura remained intact. In Monkey W, the center of the chamber (size: 39 × 29 mm) was positioned at AP (antero-posterior): +16, ML (medio-lateral): +15 (right). In Monkey J, the chamber (size: 26.5 × 26.5 mm) was located at AP +3, ML: +9.\nAll animal procedures were approved by the Animal Care Committee of Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences.\nBehavioral training was conducted within a virtual reality system, which provided physical self-motion stimuli via a motion platform (MOOG, 6DOF2000E). During experiments, monkeys were comfortably seated in a custom-designed chair, which was secured to the motion platform (\nAfter extensive training, monkeys underwent fUS imaging (Iconeus instrument, France). Detailed technical procedures could be found elsewhere in previous studies (e.g., ref.\nIn our study, we utilized a 192-channel linear ultrasonic probe (15.6 MHz) with a spatial resolution of 100 × 100 µm and a slice thickness of 400 µm. Employing a custom-made stepper motor, we systematically moved the probe along the antero–posterior axis of the macaque brain with a 1 mm step length to capture continuous images. The probe, affixed to the stepping motor and imaging chamber via a custom-made bracket, was immersed in the chamber with acoustic coupling gel or saline solution during imaging procedures (refer to\nThe primary experimental paradigm utilized a block design, with each block consisting of 20 repeated presentations of motion. The monkeys were seated in a chair and were subjected to passive, physical self-motion stimuli. Throughout this process, the animals were not required to perform any tasks, and they were allowed to make free eye movements. Upon the end of each trial, the animals received water or juice as a reward. The motion platform executed a sinusoidal-like motion at a frequency of 0.5 Hz, inducing accelerations beyond the animal’s perceptual threshold. Each motion cycle lasted for 6 s, followed by a 10-s intertrial interval before the subsequent trial. The platform’s velocity trajectory during each motion cycle followed a Gaussian curve (depicted by the blue curve in\nFor experiment of motion direction decoding, left–right and back–forward axes were randomly interleaved in one block and repeated approximately 200 times. For experiment of motion type decoding, translation (left–right axis) and yaw (rotation around the vertical axis) motion were randomly interleaved within one block, repeated approximately 200 times.\nFor experiment of sound control, the noise produced during physical motion of the motion platform was recorded and was then replayed to the animals (with a peak magnitude: ~90 dB) while the motion platform remained stationary (refer to\nFor experiment of GVS, two electrodes (3M, Ag/AgCl with sticky gel, diameter: 8 mm) were attached to the mastoid regions behind the ears of both monkeys (\nFor experiment of visual stimuli, optic flow simulating self-motion translated along left-to-right axis were provided on the visual display (\nUltrasonic imaging is vulnerable to motion artifacts that can compromise image stability. Therefore, we conducted rigorous stability assessments within each experimental block to ensure the integrity of the data. These assessments aimed to mitigate any impact of platform motion or monkey movement on the acquired images (for detailed procedures, refer to ref.\nTo identify specific brain regions in fUS images, we employed MRI before surgery to align Doppler images with corresponding MRI coronal planes (an example plane is depicted in\nFor each Doppler image acquired in the coronal plane, we calculated the Pearson correlation coefficient between the Doppler signal of each voxel and the existence of stimulus, presenting the correlation coefficient (\nAfter that, we picked voxels with a correlation coefficient\nFor decoding motion directions between the lateral and back–forth axes, 400 trials from monkey W and 398 trials from monkey J were used. For decoding motion types between lateral translation and yaw-rotation, 400 trials were used from monkey J. Before decoding, the data were preprocessed in three steps: 1) subtracting the baseline CBV value (the mean Doppler signals of the 3.2 s preceding stimulus onset) from the raw signals for each trial to eliminate variance due to slow drift of brain activity; 2) applying pillbox spatial filter with a radius of 2 pixels to each frame; 3) aligning the raw fUS data with the behavioral event code to generate a trials × voxels × times matrix; and 4) applying across-trial z-score normalization to each voxel at each time point.\nFor decoding, we first utilized all voxels except those in large vessels and outside the brain area (above dura) within the entire fUS image. Classification was conducted using the MVPA-Light toolbox (\nFor cross-temporal decoding (\nFor assessment of decoding performance with different training set size, we chose fUS data from the whole 0 to 6 s stimulus period as the training set to train the LDA classifier. The size of the training set increased from the first 10 trials to the first 200 trials. And the remaining trials would be picked as the testing set. To ensure the robustness of our decoding performance, we repeated the above process 20 times. In each repetition, the trial order will be shuffled randomly; early trials and later trials were interleaved. At last, we also decoded the eye position data with the same process as a comparison.\nTo assess contribution of each voxel in the fUS image to decoding accuracy, we employed a searchlight analysis (\nIn order to eliminate the influence of eye movement signals on the results during the experiment, we evaluated eye movement data under physical motion in total darkness. We calculated partial correlations between the eye movement (position and velocity) and fUS signal, and between physical motion and fUS signal, respectively. Furthermore, to control for impact of eye movements as much as possible, we conducted additional experiments by training the macaques to cancel VOR by fixating at a central point during physical motion conditions. Then, we compared the activation of different brain regions between the “fixation only” and “vestibular + fixation” condition, and selected the ROIs for the analysis of CBV change signals.\nTo assess the decoding performance of eye data (under total darkness condition) for motion directions and motion types, and to compare it with the decoding performance of fUS signals, we chose eye position data from the whole 0 to 6 s stimulus period as the training set to train the LDA classifier and got the decoding performance with different training set size (the same method as what we did in fUS decoding, refer to\nAppendix 01 (PDF)", "content_for_embedding": "As a typical example of embodied intelligence, the vestibular system provides crucial cues for organisms to interact with the environment including the maintenance of balance and visual stability, postural and motor control, locomotion, spatial perception, and path integration during vector-based navigation (\nAnother limitation of using conventional imaging tools (e.g., fMRI, PET, MEG) to measure vestibular signals is that subjects are physically stabilized during scanning. In such cases, alternative stimulation methods, including noninvasive caloric or galvanic vestibular stimulation (CVS or GVS), are employed to stimulate all peripheral vestibular organs and their afferents [PET: (\nThe recently emerging technique of functional ultrasound (fUS) imaging, a hemodynamic technique which visualizes cerebral blood volume (CBV) changes using ultrafast Doppler angiography, appears to address these limitations by offering a minimally invasive, rapid, large-scale, and high spatiotemporal resolution method (up to 100 µm, 100 ms) (\nTo measure vestibular-related signals, a 15.6 MHz ultrasound probe was attached to the heads of two macaques while they were subjected to sinusoidal translational or rotational motion by a 6-degree-of-freedom motion platform (\nExperimental setup and fUS signals evoked by passive, physical self-motion stimuli. (\nUnder physical motion conditions, the animals were passively translated or rotated sinusoidally at a frequency of 0.5 Hz in total darkness (\nBased on the raw fUS signals, we conducted a correlation analysis between the ultrasound Doppler signals and the existence of motion stimuli. The Pearson correlation coefficients were subjected to false discovery rate (FDR) correction with\nAfter identifying areas exhibiting significant vestibular-related signals using the correlation analysis, we then evaluated the response modulation strength for each region of interest (ROI). Specifically, within each ROI, a subregion of 10 × 10 voxels (\nDue to hemodynamics of fUS imaging, CBV changes occurred with a delay. To quantify this, peak time of each ROI was calculated, which occurred at the 11th frame (0.4 s/frame), corresponding to 4.25 ± 0.08 s (mean ± SEM) (\nfUS imaging provides high spatial resolution. We thus first performed a layer-based analysis by dividing each ROI into three laminar compartments (superficial, middle, and deep layers) (\nTo verify the stability of the activated fUS signals, we conducted several analyses. First, we analyzed fUS signals of the same coronal plane across different days (\nTo examine other possible sources, we conducted several control experiments and analyses. In our experiment, we delivered passive self-motion in darkness, aimed to remove possible impact from visual stimuli. Yet the animals’ eye movements including vestibular ocular reflex (VOR) were not limited in this condition and they may confound the fUS signals (\nIn addition to eye movements, in our experimental setup, physical motion stimuli were provided through a motion platform that generated significant noise (90 dB) during movement which may also contributed to the fUS signals. We thus conducted a control experiment by recording the sound from the motion platform and playing it back to the animals while the motion platform remained stationary. We found that these sound related stimuli did not reproduce the fUS signals as measured under the physical motion condition (\nTo evaluate whether fUS signals are sufficiently precise to distinguish different self-motion stimuli, we provided two physical motion directions within each block. Specifically, 6-s duration trials of motions along lateral and back–forth axis were randomly interleaved, with each stimulus condition repeated approximately 200 times, resulting in 400 trials per experimental session. Under this design, we observed significant differences in the mean fUS signals between the two motion directions (\nTo address whether different motion stimuli could be reliably decoded from one single trial rather than the mean response across trials, referring to previous studies (\nMotion direction and type decoding based on single trial. (\nWe found that motion directions could be reliably decoded on a single-trial basis from the fUS signals in both animals (\nTo understand the influence of different time periods on decoding accuracy, we performed cross-temporal decoding by training and testing using different time windows (\nTo assess how many trials are needed for successful decoding, we calculated the mean decoding accuracy across stimulus duration as a function of the number of trials used for training (\nAfter identifying decoding accuracy based on a full image data, we further assessed decoding accuracy based on each ROI using the searchlight approach at each time point. Decoding was performed based on fUS signals within a 1.2-s window (3 frames), sliding with a step of 400 ms (1 frame). Multiple brain regions in both animals exhibited robust decoding capabilities, such as MSTd, VIP, PCC, RSC, PIVC, VPS, and area 5 with some fluctuations (\nIn addition to decoding motion directions, we also used the LDA algorithm to decode different types of physical self-motion on a single-trial basis. Specifically, translation along the lateral axis and rotation around the vertical axis were interleaved within one block and repeated 200 times, to selectively activate the otolith and canal, respectively. We found that decoding accuracy was significantly above chance level (\nSimilar to motion direction decoding, motion type decoding was also significant when there were more than a dozen trials (binomial test,\nTo further assess possible impact from eye movements, we also decoded different self-motion based on the eye position data with the identical algorithm as used for the fUS data (\nGVS has been widely used in previous studies as an alternative and compromised way to activate peripheral vestibular organs during fMRI/PET/MEG scans when physical motion stimuli are not available (e.g., refs.\nGVS experiment. (\nWe observed that GVS reliably activated multiple brain regions captured by fUS (see examples in\nAlthough qualitatively there was large overlapping between GVS and physical motion evoked fUS signals, there was also quantitative difference between the two methods. In particular, CBV change of most regions under physical motion was overall larger than under GVS (\nIn summary, our GVS experiment showed large consistency with previous fMRI/PET/MEG imaging studies, with exception of showing two new areas of area 5 and 1-2, which were also captured by our physical motion stimuli, confirming the validity of the fUS imaging technique. However, GVS failed to reveal V3A, M1, and 7 m, which were indicated by the physical motion stimuli used in the current fUS experiment. Physical motion and GVS evoked signals also differed in CBV, Pearson correlation coefficient, and response delay, which may be due to a number of sources. First, the activation under GVS condition varies depending on parameters such as current intensity, frequency, and delivered position. Second, GVS stimulates the whole inner ear end organs and afferents at the same time, which is different from our physical motion stimulus that selectively activates specific end organs (e.g., horizontal otolith, or horizontal canal). Third, physical self-motion may produce more mixed signals than GVS, such as somatosensory, or motor-related activity to compensate for the inertia force passively applied onto the subjects.\nVisual information, for example, optic flow also plays an important role during self-motion. Accordingly, numerous previous studies have demonstrated many brain regions modulated by optic flow (\nBrain regions activated by both optic flow and physical motion stimuli. (\nWe identified up to 12 bimodal areas that were significantly modulated by both physical motion and optic flow stimuli, including 3a, 2v, MSTd, VPS, VIP, 7a, V3A, MIP, 5, 1-2, M1, and F2. Overall, fUS signals were comparable between the two stimulus conditions, with a modestly stronger CBV change in the vestibular condition (\nNotably, we also observed heterogeneity within individual areas with respect to the vestibular and visual signals (\nIn our current study, fUS imaging with physical motion stimuli revealed the activation of a broad range of brain regions in macaques. Many of these are classical vestibular or multisensory regions concurrently carrying vestibular signals, including PIVC, 2v, 3a, VPS, PCC, RSC, MSTd, and VIP, confirming the validity of applying this technique in vestibular research. Meanwhile, we also identified areas exhibiting robust hemodynamic signals in response to physical self-motion that have not been clearly identified previously. Among these areas, there are roughly three categories in terms of their conventionally defined sensory functions.\nFirst, we observed significant activation by passive self-motion in V3A, an area in the traditional dorsal visual pathway for visual motion processing (\nSecond, robust fUS signals in response to self-motion were detected in motor-related areas, including M1, area 5 and 7 m. For M1, vestibular activation has only been vaguely reported in one human study involving the precentral gyrus (\nThird, significant fUS signals were observed in somatosensory area 1-2. The activation is certainly much larger than the conventional vestibular area 2v at the posterior end of 1-2 (\nIn summary, our study utilizing high spatiotemporal resolution fUS imaging technique under physical motion stimuli revealed robust hemodynamic signals that are highly likely from vestibular origin in some areas that have not been clearly identified in previous studies, urging the need for further experiments, for example, electrophysiological recordings. Note, however, fUS imaging is similar to fMRI that measures hemodynamics and is thus only indirectly linked to changes in neural activity within neighboring populations. It is well known that discrepancies may exist between the imaging and electrophysiology that measures more global or local activity respectively (\nOur study demonstrates the feasibility of fUS imaging in vestibular research and highlights several advantages of this technology. First, fUS imaging allows for studying vestibular signals under real physical passive or active self-motion conditions that can precisely target specific subregions of the peripheral vestibular organ, better simulating natural contexts compared to GVS or CVS methods used in previous imaging research with constraint head or whole body. Second, fUS imaging enables measurement of signals across a fairly large range of brain regions. In the current study, we used an ultrasonic probe with multiple plane wave (MPW) transmissions that imaged an entire plane in one shot (\nHowever, fUS imaging also faces several challenges. First, the equipment used in the study offers a spatial resolution of 100 × 100 µm with a slice thickness of 400 µm and a temporal resolution of 400 ms. At this spatial resolution, it is difficult to observe clusters of neurons within certain brain regions that prefer the same feature, for example, preferred direction or motion type. Therefore, further enhancing spatial resolution is crucial for more detailed exploration in future experiments. Similarly, further improving temporal resolution is also critical to leverage the technique by looking into more detailed dynamic of signals during tasks, for example, decision making. Second, although the current fUS imaging already evokes fairly strong signals (8 to 50% CBV change), which is several folds larger than conventional imaging tools, its sensitivity could be further improved to better approach electrophysiology. Third, the imaging depth of the probe used in this study is 1.5 cm, which limits high-resolution exploration of deep brain regions. Current probes can achieve an imaging depth of up to 4 cm, but with a decreased resolution of 250 µm (from Iconeus). Therefore, there is a trade-off between the imaging depth and resolution in ultrasound imaging, necessitating a balance based on specific research requirements. Fourth, compared to fMRI, which is completely noninvasive, fUS imaging requires craniotomy in large animals, as the thick skull of monkeys significantly absorbs ultrasound waves, impairing imaging signals. Additionally, the application of fUS in humans is mostly restricted to patients (\nWe conducted experiments on two male monkeys, identified as Monkey W (\nAfter behavioral training, rectangular chambers (made from polyetherimide) were surgically installed on the heads of two monkeys. The cranial bones inside the chambers were removed while the dura remained intact. In Monkey W, the center of the chamber (size: 39 × 29 mm) was positioned at AP (antero-posterior): +16, ML (medio-lateral): +15 (right). In Monkey J, the chamber (size: 26.5 × 26.5 mm) was located at AP +3, ML: +9.\nAll animal procedures were approved by the Animal Care Committee of Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences.\nBehavioral training was conducted within a virtual reality system, which provided physical self-motion stimuli via a motion platform (MOOG, 6DOF2000E). During experiments, monkeys were comfortably seated in a custom-designed chair, which was secured to the motion platform (\nAfter extensive training, monkeys underwent fUS imaging (Iconeus instrument, France). Detailed technical procedures could be found elsewhere in previous studies (e.g., ref.\nIn our study, we utilized a 192-channel linear ultrasonic probe (15.6 MHz) with a spatial resolution of 100 × 100 µm and a slice thickness of 400 µm. Employing a custom-made stepper motor, we systematically moved the probe along the antero–posterior axis of the macaque brain with a 1 mm step length to capture continuous images. The probe, affixed to the stepping motor and imaging chamber via a custom-made bracket, was immersed in the chamber with acoustic coupling gel or saline solution during imaging procedures (refer to\nThe primary experimental paradigm utilized a block design, with each block consisting of 20 repeated presentations of motion. The monkeys were seated in a chair and were subjected to passive, physical self-motion stimuli. Throughout this process, the animals were not required to perform any tasks, and they were allowed to make free eye movements. Upon the end of each trial, the animals received water or juice as a reward. The motion platform executed a sinusoidal-like motion at a frequency of 0.5 Hz, inducing accelerations beyond the animal’s perceptual threshold. Each motion cycle lasted for 6 s, followed by a 10-s intertrial interval before the subsequent trial. The platform’s velocity trajectory during each motion cycle followed a Gaussian curve (depicted by the blue curve in\nFor experiment of motion direction decoding, left–right and back–forward axes were randomly interleaved in one block and repeated approximately 200 times. For experiment of motion type decoding, translation (left–right axis) and yaw (rotation around the vertical axis) motion were randomly interleaved within one block, repeated approximately 200 times.\nFor experiment of sound control, the noise produced during physical motion of the motion platform was recorded and was then replayed to the animals (with a peak magnitude: ~90 dB) while the motion platform remained stationary (refer to\nFor experiment of GVS, two electrodes (3M, Ag/AgCl with sticky gel, diameter: 8 mm) were attached to the mastoid regions behind the ears of both monkeys (\nFor experiment of visual stimuli, optic flow simulating self-motion translated along left-to-right axis were provided on the visual display (\nUltrasonic imaging is vulnerable to motion artifacts that can compromise image stability. Therefore, we conducted rigorous stability assessments within each experimental block to ensure the integrity of the data. These assessments aimed to mitigate any impact of platform motion or monkey movement on the acquired images (for detailed procedures, refer to ref.\nTo identify specific brain regions in fUS images, we employed MRI before surgery to align Doppler images with corresponding MRI coronal planes (an example plane is depicted in\nFor each Doppler image acquired in the coronal plane, we calculated the Pearson correlation coefficient between the Doppler signal of each voxel and the existence of stimulus, presenting the correlation coefficient (\nAfter that, we picked voxels with a correlation coefficient\nFor decoding motion directions between the lateral and back–forth axes, 400 trials from monkey W and 398 trials from monkey J were used. For decoding motion types between lateral translation and yaw-rotation, 400 trials were used from monkey J. Before decoding, the data were preprocessed in three steps: 1) subtracting the baseline CBV value (the mean Doppler signals of the 3.2 s preceding stimulus onset) from the raw signals for each trial to eliminate variance due to slow drift of brain activity; 2) applying pillbox spatial filter with a radius of 2 pixels to each frame; 3) aligning the raw fUS data with the behavioral event code to generate a trials × voxels × times matrix; and 4) applying across-trial z-score normalization to each voxel at each time point.\nFor decoding, we first utilized all voxels except those in large vessels and outside the brain area (above dura) within the entire fUS image. Classification was conducted using the MVPA-Light toolbox (\nFor cross-temporal decoding (\nFor assessment of decoding performance with different training set size, we chose fUS data from the whole 0 to 6 s stimulus period as the training set to train the LDA classifier. The size of the training set increased from the first 10 trials to the first 200 trials. And the remaining trials would be picked as the testing set. To ensure the robustness of our decoding performance, we repeated the above process 20 times. In each repetition, the trial order will be shuffled randomly; early trials and later trials were interleaved. At last, we also decoded the eye position data with the same process as a comparison.\nTo assess contribution of each voxel in the fUS image to decoding accuracy, we employed a searchlight analysis (\nIn order to eliminate the influence of eye movement signals on the results during the experiment, we evaluated eye movement data under physical motion in total darkness. We calculated partial correlations between the eye movement (position and velocity) and fUS signal, and between physical motion and fUS signal, respectively. Furthermore, to control for impact of eye movements as much as possible, we conducted additional experiments by training the macaques to cancel VOR by fixating at a central point during physical motion conditions. Then, we compared the activation of different brain regions between the “fixation only” and “vestibular + fixation” condition, and selected the ROIs for the analysis of CBV change signals.\nTo assess the decoding performance of eye data (under total darkness condition) for motion directions and motion types, and to compare it with the decoding performance of fUS signals, we chose eye position data from the whole 0 to 6 s stimulus period as the training set to train the LDA classifier and got the decoding performance with different training set size (the same method as what we did in fUS decoding, refer to\nAppendix 01 (PDF)", "topic": "Diagnostic"}
{"pmid": "40652236", "pmcid": "12286860", "title": "Inter-individual and inter-site neural code conversion without shared stimuli", "publication_year": "N/A", "abstract": "Inter-individual variability in fine-grained functional topographies poses challenges for scalable data analysis and modeling. Functional alignment techniques can help mitigate these individual differences but they typically require paired brain data with the same stimuli between individuals, which are often unavailable. Here we present a neural code conversion method that overcomes this constraint by optimizing conversion parameters based on the discrepancy between the stimulus contents represented by original and converted brain activity patterns. This approach, combined with hierarchical features of deep neural networks as latent content representations, achieves conversion accuracies that are comparable with methods using shared stimuli. The converted brain activity from a source subject can be accurately decoded using the target’s pre-trained decoders, producing high-quality visual image reconstructions that rival within-individual decoding, even with data across different sites and limited training samples. Our approach offers a promising framework for scalable neural data analysis and modeling and a foundation for brain-to-brain communication.\nA neural code conversion method is introduced using deep neural network representations to align brain data across individuals without shared stimuli. The approach enables accurate inter-individual brain decoding and visual image reconstruction across sites.", "full_text": "Individual differences in brain organization are observed at different scales, from macroscopic anatomy to fine-grained functional topography\nFunctional alignment has been important in functional magnetic resonance imaging (fMRI) research, addressing individual differences in functional topography. This approach generally involves presenting the same stimuli to different subjects and aligning brain activity patterns to make them similar or shared across individuals\nAlthough shared stimuli in functional alignment ensure that brain activity patterns across individuals reflect the same stimulus content, the content can be more flexibly represented by a combination of elemental, latent features, such as image bases or deep neural network (DNN) features\nIn this study we introduce a content-loss-based functional alignment method that converts brain activity patterns between individuals without requiring shared stimuli. For each subject pair, we designate one as the target and the other as the source. First, we pre-train decoders to predict the latent features of stimuli perceived by the target subject on the basis of their measured brain activity\nWe evaluate the neural code conversion approach through several key analyses. First, we assess the method’s ability to convert brain activity patterns across individuals and capture fine-grained visual features for inter-individual image reconstruction, by comparing converters optimized with visual content versus paired brain activity. We then examine whether the method remains effective without shared stimuli, by evaluating conversion performance with both overlapping and non-overlapping stimuli between converter and decoder trainings. To demonstrate broader applicability, we examine inter-site conversion and reconstruction across different fMRI datasets collected under varying experimental conditions. We also assess the generalizability of converted brain activity using an alternative decoding scheme and evaluate the method’s performance with limited training data. Although the method is primarily validated in the visual domain, we conduct a preliminary analysis to explore its potential extension to other cognitive domains. Through these analyses, we aim to establish a flexible framework for functional alignment that eliminates the need for shared stimuli while preserving fine-grained neural representations.\nOur analyses used three fMRI datasets for natural images, involving 114 subject pairs total (refer to the ‘Datasets’ section in the\nWe first investigated whether brain activity patterns could be reliably aligned across individuals using a content-loss-based converter within the Deeprecon dataset. The conversion was performed across the entire visual cortex, and its accuracy was evaluated by two metrics: (1) pattern correlation, which is the Pearson correlation coefficient between the converted and measured voxel patterns for a test stimulus (Fig.\nFigure\nWe also extended our analysis to different selections of visual ROIs. We performed subarea-wise conversion analyses by training separate converters for paired ROIs between source and target subjects\nTo examine whether the content loss approach remains effective without shared stimuli, we performed neural code conversion with no stimulus overlap between the converter and decoder trainings. Specifically, we randomly split the training samples of the Deeprecon dataset into two halves on the basis of stimulus categories, assigning one to the source and the other to the target to ensure no overlap in their training stimuli and categories (referred to as the non-overlapping condition; see Supplementary Fig.\nTo further evaluate the potential of our approach, we conducted preliminary analyses examining neural responses in the auditory cortex during sound stimulus presentation\nWe next investigated whether fine-grained feature representations of stimuli were preserved in the converted brain activity by a DNN feature decoding analysis\nThe content-loss-based converters exhibited comparable decoding accuracies with those obtained through the within-individual decoding, with consistently similar trends across various DNN layers (Fig.\nWe further reconstructed images using fine-grained DNN feature representations decoded from converted brain activity (Fig.\nWe performed a pairwise identification analysis for a quantitative evaluation of reconstruction performance. This analysis used the pixel and DNN feature patterns of the reconstructed image to identify the true stimulus between two alternatives (refer to the ‘Identification analysis’ section in the\nWe observed that both types of inter-individual converters achieved comparable but slightly lower identification accuracies than within-individual reconstruction (Fig.\nWe extended our analysis to investigate the feasibility of inter-site neural code conversion, where converters were trained between source and target subjects from distinct sites. For this analysis, we used the Deeprecon dataset and two additional datasets: the NSD and the THINGS dataset. The source subject was selected from one of these three datasets, whereas the target subject was selected from a different dataset, resulting in 94 individual pairs with no stimuli shared between any pairs. Due to the absence of ground truth (measured brain activity) for evaluating conversion accuracy in the brain space, we opted to evaluate the inter-site neural code conversion through the decoding accuracy and image reconstruction from the converted brain activity.\nThe inter-site decoding shows a similar decoding tendency and comparable accuracy across all DNN layers compared with the within-individual decoding for test samples from each dataset (Supplementary Fig.\nTo confirm whether the converted brain activity contains generalizable representations rather than those tailored for a specific readout (the VGG19 decoder), we examined the feasibility of decoding the converted brain activity using a different scheme. A different feature decoder was trained to predict CLIP-ViT features\nDecoding CLIP-ViT features from converted brain activity demonstrates accuracies similar to those of the within-individual decoding across all evaluated DNN layers (Supplementary Fig.\nWe investigated the effect of training sample size for converters on image reconstruction quality. We varied the number of training samples for converters (trained with VGG19 features) at various levels: 300, 600, 900, 1,200, 2,400, 3,600, 4,800 and 6,000 training samples, with data collection time ranging from 40 min to approximately 13 h. To evaluate the decoding from converted brain activity, we consistently used 6,000 samples from the target subject to train the VGG19 and CLIP-ViT feature decoders.\nFigure\nWe aimed to develop a functional alignment method that: (1) eliminates the need for shared stimuli across individuals during training; and (2) captures fine-grained feature representations, enabling downstream tasks such as decoding and image reconstruction. A major difference between our method and previous ones is the content-loss-based optimization, which minimizes the discrepancy between the stimulus contents and those decoded from converted brain activity patterns, rather than directly minimizing differences between paired brain activity patterns.\nAlthough we used brain-loss-based approaches with shared stimuli, shared stimuli may not be strictly necessary in other contexts. For example, alignment can still be achieved without shared stimuli through methods such as connectivity hyperalignment\nThe content-loss-based converter uses a training approach similar to feature decoders, but it specializes in learning the statistical relationship between the source and target brain spaces in several key aspects. First, it successfully converts brain activity patterns across individuals, achieving conversion accuracy similar to converters optimized by brain loss (Fig.\nOur primary goal was to convert brain activity across individuals’ innate spaces without shared stimuli, enabling their use in downstream tasks such as decoding and image reconstruction. However, inter-individual decoding can still be achieved without explicit alignment. A multi-subject shared decoder can be trained with alignment layers optimized for specific tasks\nAlthough our approach demonstrates effectiveness, it is subject to dataset- and model-related limitations. The substantial overlap in semantic and visual content between training and test sets in the NSD dataset may increase the risk of spurious predictions\nThe potential of our approach extends in several directions. First, determining the optimal features for visual content in neural code conversion requires further investigation. Future adaptations could use latent features derived from established models such as motion\nOur approach has practical implications in several aspects. First, our approach enables brain data conversion across datasets, expanding the reuse of publicly available data and supporting scalable analysis and modeling beyond institutional and geographical barriers. Second, our approach potentially reduces both the economic costs and time investments required for brain data collection by inter-individual decoding with fewer training samples (Fig.\nWe reanalyzed four previously published and publicly available datasets\nFive healthy subjects (four males and one female; age range = 25–36 years) with normal or corrected-to-normal vision participated in the experiment. The natural image stimuli were selected from 200 representative categories in the ImageNet dataset (2011, fall release)\nThree healthy subjects (one male and two females; mean age = 25.33 years) with normal or corrected-to-normal vision participated in the experiment. The image stimuli were taken from the THINGS object concept and image database\nEight healthy subjects (two males and six females; age range = 19–32 years) with normal or corrected-to-normal vision participated in the experiment. The image stimuli were sourced from the 80 COCO categories within Microsoft’s COCO image database\nThe content-loss-based neural code converter for each pair of subjects uses a nonlinear multilayer perceptron (MLP) to predict the brain activity patterns of one subject (target) from the brain activity patterns of another subject (source). It has two hidden layers with instance normalization and ReLU functions, and the number of units in each hidden layer is half that of the input layer. The converter\nThe converter training was resolved through an iterative process. Each iteration involves a stochastic decoding strategy applied to all VGG19 layers (refer to the ‘DNN models’ section in the\nThe brain-loss-based neural code converter consists of a set of regularized linear regression models\nIn addition to the brain-loss-based converter, we also used other standard functional alignment methods for comparison, including the pairwise Procrustes transformation and template-mediated Procrustes transformation (hyperalignment\nWe used the VGG19 DNN model\nFor the evaluation of reconstructed images, we used another DNN model, the AlexNet\nWe used the CLIP-ViT model\nWe evaluated the conversion accuracy using two metrics: pattern correlation and profile correlation. Pattern correlation is the Pearson correlation coefficient between the converted and measured voxel patterns for a test stimulus. Profile correlation is the Pearson correlation coefficient between the sequences of converted and measured responses of a single voxel to the 50 natural test stimuli. Repeated measures of the brain responses to an identical stimulus in fMRI data are subject to measurement noise, which impacts the evaluation of conversion accuracy. To address this issue, we performed the noise ceiling estimation\nWe used a ridge regression model as a DNN feature decoder. This model predicts the feature values of the stimulus, given an fMRI activity pattern evoked by the stimulus. We normalized both the feature values and voxel responses before model training and used a voxel selection procedure. This procedure involved calculating the Pearson correlation coefficients between sequences of voxel responses and feature values for all voxels. The 500 voxels exhibiting the highest absolute correlations were selected for training. We set the ridge regularization parameter to 100 to enhance model robustness. The feature decoding analysis is detailed in the studies by Horikawa and Kamitani\nThe reconstruction method used in this study was extended from our original deep image reconstruction study\nIf we denote\nWe used pairwise identification analysis to quantify the accuracy of image reconstruction. For each reconstructed image, its features were reshaped into a one-dimensional vector and compared with the true feature vector of the presented image and the false alternative of another image. An identification was considered correct when the correlation coefficient of the reconstructed image’s feature vector was greater with the true feature vector than with the false alternative. The false alternative image was sourced from the remaining images in the test dataset. For each reconstructed image, this process was repeated for all remaining test images as the false alternative. For Deeprecon natural images, 49 false alternatives were used per reconstructed image (50 images × 49 comparisons = 2,450 comparisons). For THINGS or NSD images, 99 false alternatives were used per reconstructed image (100 images × 99 comparisons = 9,900 comparisons for each dataset). We defined the identification accuracy for a reconstructed image as the ratio of correct identifications. For each individual pair or each subject (Within), we calculated the mean identification accuracy by averaging the identification accuracies of all reconstructed images, which was used as a data point for group analysis.\nWe performed group-level statistical inference by showing the group means and confidence intervals in the figures. For DNN feature decoding and image reconstruction in within-individual analyses, each data point represents the mean accuracy for a subject. The mean accuracies from all subjects were used to calculate the group mean and its 95% confidence interval. For conversion accuracy, DNN feature decoding, and image reconstruction in inter-individual analyses, each data point represents the mean accuracy corresponding to a unique pair of subjects. Due to potential correlations between pairs involving the same subject (dyadic dependency), we applied bootstrapping to these dyadic data points to calculate the group mean and 95% confidence interval. We performed bootstrap sampling separately on the source and target IDs, obtaining data points of the original sample size while ensuring that pairs where the source and target IDs were the same were excluded. The obtained data points were then used to calculate the mean. This process was repeated 1,000 times to generate bootstrap replicates, from which we calculated the 95% confidence interval.\nFurther information on research design is available in the\n\nSupplementary Information\nReporting Summary\nPeer Review file\n\nSource Data Fig. 2.\nSource Data Fig. 3.\nSource Data Fig. 4.\nSource Data Fig. 5.\nSource Data Fig. 6.", "content_for_embedding": "Individual differences in brain organization are observed at different scales, from macroscopic anatomy to fine-grained functional topography\nFunctional alignment has been important in functional magnetic resonance imaging (fMRI) research, addressing individual differences in functional topography. This approach generally involves presenting the same stimuli to different subjects and aligning brain activity patterns to make them similar or shared across individuals\nAlthough shared stimuli in functional alignment ensure that brain activity patterns across individuals reflect the same stimulus content, the content can be more flexibly represented by a combination of elemental, latent features, such as image bases or deep neural network (DNN) features\nIn this study we introduce a content-loss-based functional alignment method that converts brain activity patterns between individuals without requiring shared stimuli. For each subject pair, we designate one as the target and the other as the source. First, we pre-train decoders to predict the latent features of stimuli perceived by the target subject on the basis of their measured brain activity\nWe evaluate the neural code conversion approach through several key analyses. First, we assess the method’s ability to convert brain activity patterns across individuals and capture fine-grained visual features for inter-individual image reconstruction, by comparing converters optimized with visual content versus paired brain activity. We then examine whether the method remains effective without shared stimuli, by evaluating conversion performance with both overlapping and non-overlapping stimuli between converter and decoder trainings. To demonstrate broader applicability, we examine inter-site conversion and reconstruction across different fMRI datasets collected under varying experimental conditions. We also assess the generalizability of converted brain activity using an alternative decoding scheme and evaluate the method’s performance with limited training data. Although the method is primarily validated in the visual domain, we conduct a preliminary analysis to explore its potential extension to other cognitive domains. Through these analyses, we aim to establish a flexible framework for functional alignment that eliminates the need for shared stimuli while preserving fine-grained neural representations.\nOur analyses used three fMRI datasets for natural images, involving 114 subject pairs total (refer to the ‘Datasets’ section in the\nWe first investigated whether brain activity patterns could be reliably aligned across individuals using a content-loss-based converter within the Deeprecon dataset. The conversion was performed across the entire visual cortex, and its accuracy was evaluated by two metrics: (1) pattern correlation, which is the Pearson correlation coefficient between the converted and measured voxel patterns for a test stimulus (Fig.\nFigure\nWe also extended our analysis to different selections of visual ROIs. We performed subarea-wise conversion analyses by training separate converters for paired ROIs between source and target subjects\nTo examine whether the content loss approach remains effective without shared stimuli, we performed neural code conversion with no stimulus overlap between the converter and decoder trainings. Specifically, we randomly split the training samples of the Deeprecon dataset into two halves on the basis of stimulus categories, assigning one to the source and the other to the target to ensure no overlap in their training stimuli and categories (referred to as the non-overlapping condition; see Supplementary Fig.\nTo further evaluate the potential of our approach, we conducted preliminary analyses examining neural responses in the auditory cortex during sound stimulus presentation\nWe next investigated whether fine-grained feature representations of stimuli were preserved in the converted brain activity by a DNN feature decoding analysis\nThe content-loss-based converters exhibited comparable decoding accuracies with those obtained through the within-individual decoding, with consistently similar trends across various DNN layers (Fig.\nWe further reconstructed images using fine-grained DNN feature representations decoded from converted brain activity (Fig.\nWe performed a pairwise identification analysis for a quantitative evaluation of reconstruction performance. This analysis used the pixel and DNN feature patterns of the reconstructed image to identify the true stimulus between two alternatives (refer to the ‘Identification analysis’ section in the\nWe observed that both types of inter-individual converters achieved comparable but slightly lower identification accuracies than within-individual reconstruction (Fig.\nWe extended our analysis to investigate the feasibility of inter-site neural code conversion, where converters were trained between source and target subjects from distinct sites. For this analysis, we used the Deeprecon dataset and two additional datasets: the NSD and the THINGS dataset. The source subject was selected from one of these three datasets, whereas the target subject was selected from a different dataset, resulting in 94 individual pairs with no stimuli shared between any pairs. Due to the absence of ground truth (measured brain activity) for evaluating conversion accuracy in the brain space, we opted to evaluate the inter-site neural code conversion through the decoding accuracy and image reconstruction from the converted brain activity.\nThe inter-site decoding shows a similar decoding tendency and comparable accuracy across all DNN layers compared with the within-individual decoding for test samples from each dataset (Supplementary Fig.\nTo confirm whether the converted brain activity contains generalizable representations rather than those tailored for a specific readout (the VGG19 decoder), we examined the feasibility of decoding the converted brain activity using a different scheme. A different feature decoder was trained to predict CLIP-ViT features\nDecoding CLIP-ViT features from converted brain activity demonstrates accuracies similar to those of the within-individual decoding across all evaluated DNN layers (Supplementary Fig.\nWe investigated the effect of training sample size for converters on image reconstruction quality. We varied the number of training samples for converters (trained with VGG19 features) at various levels: 300, 600, 900, 1,200, 2,400, 3,600, 4,800 and 6,000 training samples, with data collection time ranging from 40 min to approximately 13 h. To evaluate the decoding from converted brain activity, we consistently used 6,000 samples from the target subject to train the VGG19 and CLIP-ViT feature decoders.\nFigure\nWe aimed to develop a functional alignment method that: (1) eliminates the need for shared stimuli across individuals during training; and (2) captures fine-grained feature representations, enabling downstream tasks such as decoding and image reconstruction. A major difference between our method and previous ones is the content-loss-based optimization, which minimizes the discrepancy between the stimulus contents and those decoded from converted brain activity patterns, rather than directly minimizing differences between paired brain activity patterns.\nAlthough we used brain-loss-based approaches with shared stimuli, shared stimuli may not be strictly necessary in other contexts. For example, alignment can still be achieved without shared stimuli through methods such as connectivity hyperalignment\nThe content-loss-based converter uses a training approach similar to feature decoders, but it specializes in learning the statistical relationship between the source and target brain spaces in several key aspects. First, it successfully converts brain activity patterns across individuals, achieving conversion accuracy similar to converters optimized by brain loss (Fig.\nOur primary goal was to convert brain activity across individuals’ innate spaces without shared stimuli, enabling their use in downstream tasks such as decoding and image reconstruction. However, inter-individual decoding can still be achieved without explicit alignment. A multi-subject shared decoder can be trained with alignment layers optimized for specific tasks\nAlthough our approach demonstrates effectiveness, it is subject to dataset- and model-related limitations. The substantial overlap in semantic and visual content between training and test sets in the NSD dataset may increase the risk of spurious predictions\nThe potential of our approach extends in several directions. First, determining the optimal features for visual content in neural code conversion requires further investigation. Future adaptations could use latent features derived from established models such as motion\nOur approach has practical implications in several aspects. First, our approach enables brain data conversion across datasets, expanding the reuse of publicly available data and supporting scalable analysis and modeling beyond institutional and geographical barriers. Second, our approach potentially reduces both the economic costs and time investments required for brain data collection by inter-individual decoding with fewer training samples (Fig.\nWe reanalyzed four previously published and publicly available datasets\nFive healthy subjects (four males and one female; age range = 25–36 years) with normal or corrected-to-normal vision participated in the experiment. The natural image stimuli were selected from 200 representative categories in the ImageNet dataset (2011, fall release)\nThree healthy subjects (one male and two females; mean age = 25.33 years) with normal or corrected-to-normal vision participated in the experiment. The image stimuli were taken from the THINGS object concept and image database\nEight healthy subjects (two males and six females; age range = 19–32 years) with normal or corrected-to-normal vision participated in the experiment. The image stimuli were sourced from the 80 COCO categories within Microsoft’s COCO image database\nThe content-loss-based neural code converter for each pair of subjects uses a nonlinear multilayer perceptron (MLP) to predict the brain activity patterns of one subject (target) from the brain activity patterns of another subject (source). It has two hidden layers with instance normalization and ReLU functions, and the number of units in each hidden layer is half that of the input layer. The converter\nThe converter training was resolved through an iterative process. Each iteration involves a stochastic decoding strategy applied to all VGG19 layers (refer to the ‘DNN models’ section in the\nThe brain-loss-based neural code converter consists of a set of regularized linear regression models\nIn addition to the brain-loss-based converter, we also used other standard functional alignment methods for comparison, including the pairwise Procrustes transformation and template-mediated Procrustes transformation (hyperalignment\nWe used the VGG19 DNN model\nFor the evaluation of reconstructed images, we used another DNN model, the AlexNet\nWe used the CLIP-ViT model\nWe evaluated the conversion accuracy using two metrics: pattern correlation and profile correlation. Pattern correlation is the Pearson correlation coefficient between the converted and measured voxel patterns for a test stimulus. Profile correlation is the Pearson correlation coefficient between the sequences of converted and measured responses of a single voxel to the 50 natural test stimuli. Repeated measures of the brain responses to an identical stimulus in fMRI data are subject to measurement noise, which impacts the evaluation of conversion accuracy. To address this issue, we performed the noise ceiling estimation\nWe used a ridge regression model as a DNN feature decoder. This model predicts the feature values of the stimulus, given an fMRI activity pattern evoked by the stimulus. We normalized both the feature values and voxel responses before model training and used a voxel selection procedure. This procedure involved calculating the Pearson correlation coefficients between sequences of voxel responses and feature values for all voxels. The 500 voxels exhibiting the highest absolute correlations were selected for training. We set the ridge regularization parameter to 100 to enhance model robustness. The feature decoding analysis is detailed in the studies by Horikawa and Kamitani\nThe reconstruction method used in this study was extended from our original deep image reconstruction study\nIf we denote\nWe used pairwise identification analysis to quantify the accuracy of image reconstruction. For each reconstructed image, its features were reshaped into a one-dimensional vector and compared with the true feature vector of the presented image and the false alternative of another image. An identification was considered correct when the correlation coefficient of the reconstructed image’s feature vector was greater with the true feature vector than with the false alternative. The false alternative image was sourced from the remaining images in the test dataset. For each reconstructed image, this process was repeated for all remaining test images as the false alternative. For Deeprecon natural images, 49 false alternatives were used per reconstructed image (50 images × 49 comparisons = 2,450 comparisons). For THINGS or NSD images, 99 false alternatives were used per reconstructed image (100 images × 99 comparisons = 9,900 comparisons for each dataset). We defined the identification accuracy for a reconstructed image as the ratio of correct identifications. For each individual pair or each subject (Within), we calculated the mean identification accuracy by averaging the identification accuracies of all reconstructed images, which was used as a data point for group analysis.\nWe performed group-level statistical inference by showing the group means and confidence intervals in the figures. For DNN feature decoding and image reconstruction in within-individual analyses, each data point represents the mean accuracy for a subject. The mean accuracies from all subjects were used to calculate the group mean and its 95% confidence interval. For conversion accuracy, DNN feature decoding, and image reconstruction in inter-individual analyses, each data point represents the mean accuracy corresponding to a unique pair of subjects. Due to potential correlations between pairs involving the same subject (dyadic dependency), we applied bootstrapping to these dyadic data points to calculate the group mean and 95% confidence interval. We performed bootstrap sampling separately on the source and target IDs, obtaining data points of the original sample size while ensuring that pairs where the source and target IDs were the same were excluded. The obtained data points were then used to calculate the mean. This process was repeated 1,000 times to generate bootstrap replicates, from which we calculated the 95% confidence interval.\nFurther information on research design is available in the\n\nSupplementary Information\nReporting Summary\nPeer Review file\n\nSource Data Fig. 2.\nSource Data Fig. 3.\nSource Data Fig. 4.\nSource Data Fig. 5.\nSource Data Fig. 6.", "topic": "Diagnostic"}
{"pmid": "40640106", "pmcid": "12242899", "title": "Investigations of Anti‐Reflux Formulations Containing Alginates Using MRI: A Feasibility Study Using Conventional 3.0T and 0.5T Open Upright Scanning", "publication_year": "N/A", "abstract": "Sodium alginates are widely used for their gelling, thickening, and stabilizing properties. Raft‐producing formulations have been used widely for many years to treat the symptoms of anti‐reflux disease and those suffering occasional symptoms. The aim of this study was to determine the feasibility of characterizing rafts formed from alginate‐containing anti‐reflux formulations in vivo using either a supine high‐field 3T scanner or an upright low‐field 0.5T MRI scanner. Six healthy participants (one male, five female, age range 23–50 years) attended three study visits following an overnight fast and were scanned at one field strength (", "full_text": "fraction of single guluronate units\nfraction of two G unit block\nfraction of block containing only three G units in a row\nfraction of block containing two G units connected to one M unit\nfraction of mixed GM unit block\nfraction of single mannuronate units\nfraction of block containing alternating MGM units\nfraction of two M unit block\nForward\nGuluronic\nMannuronic\nSodium alginate is derived from brown seaweed and belongs to a family of linear co‐polymers containing 1,4‐β‐D mannuronic (M) and α‐l‐guluronic (G) acids. Their physical properties depend on the combination of M and G blocks and vary substantially between the different seaweeds harvested, and also the location within the plants where the alginate is extracted. Alginates have been extensively researched and are widely used for their gelling, thickening, and stabilizing properties, particularly in the food industry [\nRaft producing alginate formulations have been used for many years to treat gastroesophageal reflux disease (GERD) [\nUnderstanding how alginate formulations create raft barriers in the stomach is important for the product design, dose and usage. Magnetic resonance imaging (MRI) can visualise these rafts in vivo and characterise their properties [\nConventional MRI scanners have their main magnetic field aligned horizontally along the ‘tunnel’, and participants can only be scanned in the supine, prone or side positions. This is not the general body position of a patient when they consume an oral alginate formulation to generate a gel raft to prevent gastric reflux, although some patients do take them before bedtime. Open MRI systems can be used to study participants in a more natural body position. The inherent design of the open MRI system yields lower image quality and allows fewer imaging sequences than a classic clinical horizontal bore scanner and therefore may be less suited for the detailed characterisation of the raft properties.\nThe aim of this study was to determine the feasibility of characterising alginate forming raft properties using 3T supine MRI and visualisation of rafts in the open upright MRI system in a small‐scale healthy participant study.\nSome initial in vitro characterisations of the different formulations used were carried out to assess raft strength and chemical composition prior to the in vivo study. These methods are briefly described below.\nThe raft strength of anti‐reflux suspension formulation was measured according to the British Pharmacopoeia procedure using a texture analyzer TA.XTplus with L‐shaped hook (A/ARH) from Stable Micro Systems. 10 mL and 20 mL of the anti‐reflux formulation were added to 150 mL of 0.1 M HCl. The formed raft was characterized via the L‐hook by the maximum force required to move the probe through the raft mass. Full details of the methodology can be found in the supplementary information, including Figure\nAdditionally, a second method was introduced by Dettmar et al. in 2005 [\nThe materials were analysed according to ASTM F2259‐10 [\nEthical approval for the study was obtained from the University of Nottingham Medical School Ethics Committee (ref 209‐0223) and all participants gave written informed consent. Healthy participants (aged between 18 and 55 years) were recruited to be scanned with either a 3T conventional scanner in the supine position or a 0.5T open scanner in the upright sitting position. Inclusion and exclusion criteria are given in the supplementary information.\nParticipants attended for three separate MRI visits with a minimum 7‐day gap between sequential scans (max 21 days). They were given a different alginate product on each visit. The order of the alginate products was set using a Latin Square block design. Formulation details are given in Table\nFormulation details of the alginate products commercially available and sourced from Turkey.\n\nParticipants were asked to attend each session in the morning after an overnight fast from midnight the previous night (minimum 9 h fast). They were also asked to abstain from alcohol for the previous 24 h and caffeine and strenuous exercise for the previous 18 h. After reconfirming consent to participate and reassessment of MR safety questions, the participant was changed into disposable MRI‐compatible overalls.\nParticipants then had a 10‐min baseline scan to check that the stomach was empty prior to providing the interventions.\nThe participant came out of the scanner and sat upright to consume the liquid drinks. The drink consisted of 200 mL Vanilla Fortisip (300 kCal preload) followed 20 min later by a 500 mL Lemon Juice drink (60% Water, 10% Sugar, 30% Lemon Juice, 246 kCal) [\nThe participant stayed within the magnet and was asked to consume the same drink as the 3T scanner.\nImmediately following consumption of the drinks and formulation the participant was then scanned using a variety of sequences to determine the position, volume and other characteristics of the alginate raft formed. Scans were then acquired every 20 min for approximately 2 h (six different time points).\nParticipants were scanned supine in a 3.0T Widebore Ingenia Scanner (Philips, Best, The Netherlands). A 16‐channel DS Anterior coil was placed on the abdomen and used in combination with a 16‐channel posterior coil which was inside the scanner bed. The sequences used for the 3.0T scanning are given below and parameters are summarized in Table\nSequence parameters for 3T supine scanning.\nHASTE\n(Gast vol)\n224 × 199\n(400 × 400)\nHASTE\n(Raft vol)\n224 × 199\n(400 × 400)\n2 ×\n12–15\n212 × 205\n240 × 240\nHASTE\n(High res placement)\n288 × 239\n(400 × 400)\nHASTE\n(High res)\n400 × 398\n(400 × 400)\nHASTE\n(High res)\n400 × 400\n(400 × 400)\nAbbreviations: HASTE, Half‐fourier Acquisition Single‐shot Turbo spin‐Echo; vol, volume; res, resolution; FOV, Field of View; Acq, acquisition; recon, reconstructed; SENSE, SENSitivity Encoding; FA, Flip Angle; Orient, Image Orientation; TR = Repetition time; TE = Echo Time; Cor = coronal orientation.\nT2prep values used were 20, 50, 80, 120, 180, 300, 500 ms.\nAxial T2‐Weighted (T2W) Half Fourier Acquisition Single‐shot Turbo Spin‐Echo (HASTE) sequence with 30–38 slices of 5 mm slice thickness, with a 1 mm gap between slices. The number of slices depended on the size of the stomach and the ability of the participant to hold their breath well. The echo time (TE) was 80 ms, which produced images that were moderately T2‐weighted. This sequence was acquired in a single breath hold of approximately 15–19 s.\nTo aid in the visualization of the raft, a second Axial T2W HASTE scan was acquired with the same slice thickness, gap, and image field of view as the previous sequence, but with the echo time = 300 ms. This sequence produced images that were heavily T2‐weighted, with the more solid raft appearing very dark in the images and the liquid meal appearing very bright. Flow artifacts, which also appear dark in the images and which might be present in both this sequence and the previous sequence, were assumed to be random and not the same between the two sequences; however, the raft was assumed to be in the same location for both sequences. This was acquired in two breath holds of approximately 12–15 s each.\nThis sequence used a T2prepared‐balanced turbo field echo (T2prep‐bTFE) sequence [\nTo aid in the placement of some high resolution T2W scans through the raft, a set of lower resolution coronal T2W HASTE scans was acquired. Up to 20 slices of 8 mm slice thickness with no gap between slices were acquired through the whole stomach. These images were moderately T2W. The number of slices varied depending on the size of the stomach, and the data was acquired in either one (20s) or two (13 s) separate breath holds.\nT2W HASTE scans were acquired in the coronal plane with a slice thickness of 5 mm and two slices with a 0.5 mm slice gap. Two different echo time scans were acquired to change the image contrast in the raft, TE = 80 ms and TE = 160 ms. These were acquired in two separate short breath holds of less than 5 s each.\nObservers carrying out the analysis had more than 5 years of experience in analyzing gastro‐intestinal MRI data. All volumes were measured using the Medical Image Processing and Visualization (MIPAV version 11.0.8) software [\nThese were measured by a single observer, by manually drawing around the content and air in the stomach on all slices which contained the organ. These regions of interest (ROIs) were then summed across all the slices to generate a total content or air volume in mL. This was carried out using the avial T2W images with echo time (TE) = 80 ms.\nThese were measured by a single observer, by manually drawing around the raft in the stomach on all slices which visually contained the raft. To aid in the decision making of whether a particular slice through the stomach contained the raft, both the T2W axial image sets along with the lower resolution coronal T2W sequence were visualized.\nSmall ROIs were drawn on the T2 datasets at different positions within the raft by a single observer. The mean signal intensity of the ROI at all the different T2prep TEs were used to calculate the T2 of the raft using an in‐house program which modelled the effect of the T2‐preparation scheme and subsequent imaging sequence [\nThe high‐resolution coronal images showed that visually the rafts looked to have different signal contrast which can be described as different ‘texture’ in the image. To test whether this difference in ‘texture’ could be quantified, the high‐resolution coronal images with TE = 80 ms were put through an analysis pipeline to generate a numerical ‘texture’ value for the stomach region which was based on the contrast differences in the images using the Haralick ‘contrast’ algorithm [\nParticipants were scanned upright (80° bed angle) in a 0.5T Open Paramed Scanner (ASG Superconductors, Genova, Italy). A body coil was placed around the abdomen and padding was added inside the coil to minimize motion of the abdomen. Arms were rested on a pillow at the top of the coil to keep them out of the imaging Field of View (FOV).\nVarious image sequences were used to visualize the raft in the stomach. However, at each time point, the following sequences were always acquired, and parameters are summarized in Table\nSequence parameters for 0.5T upright scanning.\n116 × 116\n(173 × 114)\n12\n14\n20\n23\n3294/102\n3801/102\n228 × 164\n(318 × 229)\n3\n5\n5\n8\n2432/120\n3953/120\n228 × 164\n(318 × 229)\n6\n10\n9\n15\n4459/64\n7601/64\n228 × 164\n(318 × 229)\n6\n10\n10\n16\n4865/120\n7905/120\n228 × 164\n(318 × 229)\n6\n10\n10\n17\n5270/180\n8564/180\n\nAbbreviations: HASTE, Half‐fourier Acquisition Single‐shot Turbo spin‐Echo; vol, volume; res, resolution; FOV, Field of View; Acq, acquisition; recon, reconstructed; FA, Flip Angle; Orient, Image Orientation; TR, Repetition time; TE, Echo Time; Cor, coronal orientation; Sag, sagittal orientation.\nEcho Train Length was 19. Six shots were used.\nThis was a coronal sequence which covered the full stomach anatomy. It had a 10 mm slice thickness with a 3 mm slice gap. A total of 12–14 slices were acquired in a single approx. 20–23 s breath hold. This sequence had quite low image resolution and it was not always possible to visualize the raft. This sequence was used to measure the gastric content and air volumes.\nThis sequence was either 3 (initially for first subject first visit) or five slices of 8 mm slice thickness with 4 mm slice gap. This was positioned through the main body of the stomach to generate an image which cut through the raft to visualize the depth of the raft and for positioning of the axial scans. Good contrast between the meal and raft was generally seen with these images. The images were acquired in a 5 or 8 s breath hold.\nThis sequence was set up and positioned in the plane of the raft with a minimum of 6 slices; however, additional slices could be added if the raft appeared to cover a greater depth. This sequence was run with 3 different image contrasts using TE = 64, TE = 120, and TE = 180 ms. The slice thickness was 8 mm with a 1 mm gap. Breath holds were between 9 and 17 s.\nObservers carrying out the analysis had more than 5 years of experience in analyzing gastro‐intestinal MRI data. All volumes were measured using the Medical Image Processing and Visualization (MIPAV version 11.0.8) software [\nThese were measured using the same method as the 3T data, with the analysis carried out using the coronal FSE sequence, which covered the full stomach anatomy.\nIt was not always possible to clearly visualize the bottom of the raft in the axial plane, and on some occasions, the bottom of the raft had not been included in the images acquired. Therefore, to gain an approximation of the raft volumes, the measurements of the approximate depth of the raft were carried out on the sagittal HASTE images, and the approximate cross‐section of the raft was defined from an axial slice in the center of the raft. These two measurements, made by a single observer, were then multiplied together to give an approximate raft volume—assuming an approximately cylindrical‐shaped mask. To check whether the data were consistently over or underestimating the volumes, the full raft volume was also measured from the axial images and compared to the approximate value for two to three datasets for each subject.\nData are presented as median and inter‐quartile range (IQR), apart from the NMR spectroscopy data which is presented as median and range. A nonparametric one‐way ANOVA (Kruskal–Wallis) was carried out (using Prism version 10.2.3, GraphPad Software LLC) to determine whether there were differences in raft strength, raft mass, and extrusion strength for the same dose of the different formulations. Dunn's multiple comparison test (with adjusted\nAll analyses were conducted with the observer blind to which alginate formulation had been consumed. Data are presented as median and IQR. As this was a feasibility study with very small numbers of participants, no statistical tests were carried out. Comparison of data between upright and supine positions was carried out by pooling all data from the different formulations.\nThe results of the characterization according to the raft strength, FW extrusion experiments are shown in Figure\nIn vitro testing results. (A) Results from L‐hook raft strength experiments. (B) Results from the forward extrusion experiment (carried out only on a 10 g dose). Statistics shown on graphs from one‐way ANOVA (Kruskal–Wallis) between formulations, followed by Dunn's multiple comparison test with adjusted\nGraph showing NMR analysis of the components of the alginates isolated from the formulations along with the Protanal LFR 5/60 (obtained from Laminaria hyperborea) and two other sodium alginates obtained from other brown algae. F\nSix participants were recruited to the study (5 F, 1 M, median age: 28, range 23–50 years, median BMI 23.3, range 18.4–28.8 kg/m\nImages showing alginate raft in stomach. A&B Images from a participant at 3 T supine in the axial plane. (A) moderately T2‐weighted HASTE sequence, (B) heavily T2‐weighted HASTE sequence. (C, D) Images from a different participant 0.5 T upright in the sagittal plane. Images are consecutive slices from a moderately T2‐weighted HASTE sequence. The three components of the stomach contents are highlighted, alginate rafts—red arrows, liquid acid meal—solid white arrows, solid milk protein aggregate (from fortisip drink) ‐ dotted white arrows. Other relevant abdominal anatomy shown with blue arrows.\nFigure\nGraphs showing gastric content (A, B), gas (C, D) and raft volumes (E, F), split by formulation and scanner. Data are shown as median and range.\nWhen the data from all formulations were pooled for each scanner, there appears to be slight differences in behaviour of the different volumes measured (Figure\nGraphs showing gastric content (A), gas (B), and raft volume (C) for the different scanner and body positions. Data pooled across all formulations. Data shown as median with error bars 95% confidence interval for median.\nTable\nT2 data (median (range)) combined from two participants for the upper and lower regions of the raft. Where no data was measured either due to artefacts or lack of raft to draw ROI the data is left blank.\nThe texture analysis data and example images are shown in Figure\nAn example set of images from one volunteer at T40 min for the three different formulations. ROIs for the stomach used in the texture analysis shown in Red. Graph of Haralick contrast texture with time and formulation shown below images.\nSome notable features captured from the upright scanner images are shown in Figure\nImages from the 0.5 T Upright scanner. Images A (sagittal) and B (axial) are from the same participant at the final T100 time point and illustrate the darker ‘halo’ effect of stronger gel encapsulating either ungelled or weaker gelled formulation. Figures C and D are from two different participants (and different formulations) whose stomach geometry allowed for the bottom of the raft to elongate in the head‐foot direction as the stomach emptied and the axial cross‐section of the stomach reduced. The sagittal images shown are from different time point in the study.\nThis was a small‐scale feasibility study which showed formulations which produced alginate rafts floating in the stomach could be visualised using both conventional supine scanning (at 3T), but also lower field (0.5T) open geometry, allowing for upright positioning of the participants. The study protocol produced a stomach that emptied at a very similar rate across different study days and allowed all formulations to produce rafts in all volunteers. This study builds on prior work [\nThe in vitro study of the raft strength (L‐hook) of the three formulations showed statistical reduced values for product\nThe alginates isolated from formulations\nThe alginate isolated from formulation X showed reduced G contents and enhanced 1,4‐β‐D mannuronic (M) acid content, whereas for the alginate from formulation Z, even higher M contents were detected. The amounts of these chemical structural elements are similar in formulation Z to other alginate products obtained from different brown seaweed species. This shows the importance of the chemical structure of the alginates for the performance in anti‐reflux formulations, especially when the formulations are based on similar recipes (constant CaCO\nA previous study looked at the chemical effects of neutralisation of different formulations and showed wide differences between products [\nRaft behavior appeared to be different depending on body position, supine and upright. Specifically, raft volumes in the upright scanner did not decrease towards the end of the study period, unlike the raft volumes in the horizontal scanner, which decreased. These differences are probably due to the position of the raft within the stomach, with the supine position allowing the raft to float near the antral area and could more easily be broken down and emptied from the stomach. In this study, there also appeared to be a very slight difference in gastric emptying rate between the body positions, with the upright position emptying slightly slower. This may have been due to layering of the milk protein from the Fortisip drink after acidification in the stomach [\nThe differences seen between upright and supine may also be attributed to the differences in image acquisition between the two scanners, as there would be larger partial volume effects from the upright scanning, which had a slice thickness of 10 mm and a gap of 3 mm compared to the thinner slices of 5 mm and a gap 1 mm supine at 3.0T. However, partial volume effects would be present for all measurements, and the differences in volume decreases occur after the initial postprandial volume, which was very similar between the two scanners. It was not possible to achieve a smaller slice thickness and gap and cover the full stomach in a single breath‐hold on the upright, and there is also the possibility that the differences come from the different individuals scanned due to intersubject variations. Therefore, further studies that can image the same individual both upright and supine are needed to understand if the emptying rates are different with the different body positions.\nQuantitative measurements of T2 were carried out in two out of the three participants at 3T and showed that the raft formed was very heterogeneous. The area of the raft nearest the air, floating at the very top produced a shorter T2 value indicating a stronger gel, or more viscous formulation, compared to any lower regions that could be measured which may have been weaker or less viscous. Previous studies have also characterised gel in the stomach from various different food‐grade polymers [\nThe image texture analysis data produced a quantified parameter which correlated well with the visual appearance of the rafts in the high‐resolution images. Formulation\nThere were limitations to this study. Due to the small number of participants, no statistical testing of differences between the alginate formulations were carried out and all data could be considered as semi‐quantitative only. A larger study would be needed to ascertain whether the different raft strengths from the formulations produced significantly different measurements over time. For the supine scanning, there were no time restrictions placed as to when participants could use the toilet facilities, and this resulted in body position changes which were not consistent between subjects and across the different formulations. These changes may have influenced the volume of the rafts at 3T, and future studies would look to set a formal break time in the scanning. In addition, any changes to the position of the diaphragm during the two breath‐hold scan may have resulted in either a slight over or underestimation of the raft volume, but this should not have been significant as the raft covered many slices in the axial plane. Problems with banding artefacts from the balanced TFE image acquisition and motion of the stomach, both from respiratory position and stomach walls for the measurements of T2, yielded a reduced amount of data for this particular parameter. Images sets with just a few banding artefacts across the data could be used for quantifying the T2 in some locations within the raft, however those with many artefacts had to be completely discarded. The range of T2prep echo times allowed for some loss of individual echo time data, but still allowed for the T2 fitting calculation to be made. Future studies could look to use alternative imaging sequences to measure the T2 [\nIn conclusion, this small‐scale feasibility study showed it was possible to image alginate rafts formed in the stomach using both 3T supine and 0.5T upright MRI scanners. Quantification of different raft properties in vivo were carried out, on three alginate formulations which produced very different raft strength and mass from in vitro experiments, due to structural chemical differences in the alginates used. The data from this study suggested that the raft behaviour (emptying and breakdown) may differ when participants are supine compared to sitting upright after dosing. Further larger scale in vivo studies are needed to determine what differences to the raft characteristics in vivo can be determined from MRI (e.g., strength, volume, retention) from the different formulations and whether statistical differences in emptying rates from body positioning are found.\nMatthias Knarr is an employee of PS Biopolymers (previously known as IFF N&H, now part of ROQUETTE Health & Pharma Solutions). All other authors declare no competing interests in this work.\n\nFigure S2 Illustration of the method for raft strength testing using the extrusion method.\nFigure S3 Image showing map of z‐score following Haralick texture analysis contrast algorithm. Whiter regions in the map have a higher z‐score indicating a more heterogeneous contrast in the original image.\nFigure S4 Definition of the stomach region for z‐score analysis. A: Original high‐resolution coronal image showing the liver (red) and stomach (orange) ROIs defined. Note the stomach ROI is inside the walls of the stomach. B: Z‐score map following Haralick texture analysis showing the stomach ROI. This ROI is inside the stomach walls to make sure the average z‐score from the stomach comes from the raft texture and not from any edges of the stomach which also have high z‐scores.\n\n\n", "content_for_embedding": "fraction of single guluronate units\nfraction of two G unit block\nfraction of block containing only three G units in a row\nfraction of block containing two G units connected to one M unit\nfraction of mixed GM unit block\nfraction of single mannuronate units\nfraction of block containing alternating MGM units\nfraction of two M unit block\nForward\nGuluronic\nMannuronic\nSodium alginate is derived from brown seaweed and belongs to a family of linear co‐polymers containing 1,4‐β‐D mannuronic (M) and α‐l‐guluronic (G) acids. Their physical properties depend on the combination of M and G blocks and vary substantially between the different seaweeds harvested, and also the location within the plants where the alginate is extracted. Alginates have been extensively researched and are widely used for their gelling, thickening, and stabilizing properties, particularly in the food industry [\nRaft producing alginate formulations have been used for many years to treat gastroesophageal reflux disease (GERD) [\nUnderstanding how alginate formulations create raft barriers in the stomach is important for the product design, dose and usage. Magnetic resonance imaging (MRI) can visualise these rafts in vivo and characterise their properties [\nConventional MRI scanners have their main magnetic field aligned horizontally along the ‘tunnel’, and participants can only be scanned in the supine, prone or side positions. This is not the general body position of a patient when they consume an oral alginate formulation to generate a gel raft to prevent gastric reflux, although some patients do take them before bedtime. Open MRI systems can be used to study participants in a more natural body position. The inherent design of the open MRI system yields lower image quality and allows fewer imaging sequences than a classic clinical horizontal bore scanner and therefore may be less suited for the detailed characterisation of the raft properties.\nThe aim of this study was to determine the feasibility of characterising alginate forming raft properties using 3T supine MRI and visualisation of rafts in the open upright MRI system in a small‐scale healthy participant study.\nSome initial in vitro characterisations of the different formulations used were carried out to assess raft strength and chemical composition prior to the in vivo study. These methods are briefly described below.\nThe raft strength of anti‐reflux suspension formulation was measured according to the British Pharmacopoeia procedure using a texture analyzer TA.XTplus with L‐shaped hook (A/ARH) from Stable Micro Systems. 10 mL and 20 mL of the anti‐reflux formulation were added to 150 mL of 0.1 M HCl. The formed raft was characterized via the L‐hook by the maximum force required to move the probe through the raft mass. Full details of the methodology can be found in the supplementary information, including Figure\nAdditionally, a second method was introduced by Dettmar et al. in 2005 [\nThe materials were analysed according to ASTM F2259‐10 [\nEthical approval for the study was obtained from the University of Nottingham Medical School Ethics Committee (ref 209‐0223) and all participants gave written informed consent. Healthy participants (aged between 18 and 55 years) were recruited to be scanned with either a 3T conventional scanner in the supine position or a 0.5T open scanner in the upright sitting position. Inclusion and exclusion criteria are given in the supplementary information.\nParticipants attended for three separate MRI visits with a minimum 7‐day gap between sequential scans (max 21 days). They were given a different alginate product on each visit. The order of the alginate products was set using a Latin Square block design. Formulation details are given in Table\nFormulation details of the alginate products commercially available and sourced from Turkey.\n\nParticipants were asked to attend each session in the morning after an overnight fast from midnight the previous night (minimum 9 h fast). They were also asked to abstain from alcohol for the previous 24 h and caffeine and strenuous exercise for the previous 18 h. After reconfirming consent to participate and reassessment of MR safety questions, the participant was changed into disposable MRI‐compatible overalls.\nParticipants then had a 10‐min baseline scan to check that the stomach was empty prior to providing the interventions.\nThe participant came out of the scanner and sat upright to consume the liquid drinks. The drink consisted of 200 mL Vanilla Fortisip (300 kCal preload) followed 20 min later by a 500 mL Lemon Juice drink (60% Water, 10% Sugar, 30% Lemon Juice, 246 kCal) [\nThe participant stayed within the magnet and was asked to consume the same drink as the 3T scanner.\nImmediately following consumption of the drinks and formulation the participant was then scanned using a variety of sequences to determine the position, volume and other characteristics of the alginate raft formed. Scans were then acquired every 20 min for approximately 2 h (six different time points).\nParticipants were scanned supine in a 3.0T Widebore Ingenia Scanner (Philips, Best, The Netherlands). A 16‐channel DS Anterior coil was placed on the abdomen and used in combination with a 16‐channel posterior coil which was inside the scanner bed. The sequences used for the 3.0T scanning are given below and parameters are summarized in Table\nSequence parameters for 3T supine scanning.\nHASTE\n(Gast vol)\n224 × 199\n(400 × 400)\nHASTE\n(Raft vol)\n224 × 199\n(400 × 400)\n2 ×\n12–15\n212 × 205\n240 × 240\nHASTE\n(High res placement)\n288 × 239\n(400 × 400)\nHASTE\n(High res)\n400 × 398\n(400 × 400)\nHASTE\n(High res)\n400 × 400\n(400 × 400)\nAbbreviations: HASTE, Half‐fourier Acquisition Single‐shot Turbo spin‐Echo; vol, volume; res, resolution; FOV, Field of View; Acq, acquisition; recon, reconstructed; SENSE, SENSitivity Encoding; FA, Flip Angle; Orient, Image Orientation; TR = Repetition time; TE = Echo Time; Cor = coronal orientation.\nT2prep values used were 20, 50, 80, 120, 180, 300, 500 ms.\nAxial T2‐Weighted (T2W) Half Fourier Acquisition Single‐shot Turbo Spin‐Echo (HASTE) sequence with 30–38 slices of 5 mm slice thickness, with a 1 mm gap between slices. The number of slices depended on the size of the stomach and the ability of the participant to hold their breath well. The echo time (TE) was 80 ms, which produced images that were moderately T2‐weighted. This sequence was acquired in a single breath hold of approximately 15–19 s.\nTo aid in the visualization of the raft, a second Axial T2W HASTE scan was acquired with the same slice thickness, gap, and image field of view as the previous sequence, but with the echo time = 300 ms. This sequence produced images that were heavily T2‐weighted, with the more solid raft appearing very dark in the images and the liquid meal appearing very bright. Flow artifacts, which also appear dark in the images and which might be present in both this sequence and the previous sequence, were assumed to be random and not the same between the two sequences; however, the raft was assumed to be in the same location for both sequences. This was acquired in two breath holds of approximately 12–15 s each.\nThis sequence used a T2prepared‐balanced turbo field echo (T2prep‐bTFE) sequence [\nTo aid in the placement of some high resolution T2W scans through the raft, a set of lower resolution coronal T2W HASTE scans was acquired. Up to 20 slices of 8 mm slice thickness with no gap between slices were acquired through the whole stomach. These images were moderately T2W. The number of slices varied depending on the size of the stomach, and the data was acquired in either one (20s) or two (13 s) separate breath holds.\nT2W HASTE scans were acquired in the coronal plane with a slice thickness of 5 mm and two slices with a 0.5 mm slice gap. Two different echo time scans were acquired to change the image contrast in the raft, TE = 80 ms and TE = 160 ms. These were acquired in two separate short breath holds of less than 5 s each.\nObservers carrying out the analysis had more than 5 years of experience in analyzing gastro‐intestinal MRI data. All volumes were measured using the Medical Image Processing and Visualization (MIPAV version 11.0.8) software [\nThese were measured by a single observer, by manually drawing around the content and air in the stomach on all slices which contained the organ. These regions of interest (ROIs) were then summed across all the slices to generate a total content or air volume in mL. This was carried out using the avial T2W images with echo time (TE) = 80 ms.\nThese were measured by a single observer, by manually drawing around the raft in the stomach on all slices which visually contained the raft. To aid in the decision making of whether a particular slice through the stomach contained the raft, both the T2W axial image sets along with the lower resolution coronal T2W sequence were visualized.\nSmall ROIs were drawn on the T2 datasets at different positions within the raft by a single observer. The mean signal intensity of the ROI at all the different T2prep TEs were used to calculate the T2 of the raft using an in‐house program which modelled the effect of the T2‐preparation scheme and subsequent imaging sequence [\nThe high‐resolution coronal images showed that visually the rafts looked to have different signal contrast which can be described as different ‘texture’ in the image. To test whether this difference in ‘texture’ could be quantified, the high‐resolution coronal images with TE = 80 ms were put through an analysis pipeline to generate a numerical ‘texture’ value for the stomach region which was based on the contrast differences in the images using the Haralick ‘contrast’ algorithm [\nParticipants were scanned upright (80° bed angle) in a 0.5T Open Paramed Scanner (ASG Superconductors, Genova, Italy). A body coil was placed around the abdomen and padding was added inside the coil to minimize motion of the abdomen. Arms were rested on a pillow at the top of the coil to keep them out of the imaging Field of View (FOV).\nVarious image sequences were used to visualize the raft in the stomach. However, at each time point, the following sequences were always acquired, and parameters are summarized in Table\nSequence parameters for 0.5T upright scanning.\n116 × 116\n(173 × 114)\n12\n14\n20\n23\n3294/102\n3801/102\n228 × 164\n(318 × 229)\n3\n5\n5\n8\n2432/120\n3953/120\n228 × 164\n(318 × 229)\n6\n10\n9\n15\n4459/64\n7601/64\n228 × 164\n(318 × 229)\n6\n10\n10\n16\n4865/120\n7905/120\n228 × 164\n(318 × 229)\n6\n10\n10\n17\n5270/180\n8564/180\n\nAbbreviations: HASTE, Half‐fourier Acquisition Single‐shot Turbo spin‐Echo; vol, volume; res, resolution; FOV, Field of View; Acq, acquisition; recon, reconstructed; FA, Flip Angle; Orient, Image Orientation; TR, Repetition time; TE, Echo Time; Cor, coronal orientation; Sag, sagittal orientation.\nEcho Train Length was 19. Six shots were used.\nThis was a coronal sequence which covered the full stomach anatomy. It had a 10 mm slice thickness with a 3 mm slice gap. A total of 12–14 slices were acquired in a single approx. 20–23 s breath hold. This sequence had quite low image resolution and it was not always possible to visualize the raft. This sequence was used to measure the gastric content and air volumes.\nThis sequence was either 3 (initially for first subject first visit) or five slices of 8 mm slice thickness with 4 mm slice gap. This was positioned through the main body of the stomach to generate an image which cut through the raft to visualize the depth of the raft and for positioning of the axial scans. Good contrast between the meal and raft was generally seen with these images. The images were acquired in a 5 or 8 s breath hold.\nThis sequence was set up and positioned in the plane of the raft with a minimum of 6 slices; however, additional slices could be added if the raft appeared to cover a greater depth. This sequence was run with 3 different image contrasts using TE = 64, TE = 120, and TE = 180 ms. The slice thickness was 8 mm with a 1 mm gap. Breath holds were between 9 and 17 s.\nObservers carrying out the analysis had more than 5 years of experience in analyzing gastro‐intestinal MRI data. All volumes were measured using the Medical Image Processing and Visualization (MIPAV version 11.0.8) software [\nThese were measured using the same method as the 3T data, with the analysis carried out using the coronal FSE sequence, which covered the full stomach anatomy.\nIt was not always possible to clearly visualize the bottom of the raft in the axial plane, and on some occasions, the bottom of the raft had not been included in the images acquired. Therefore, to gain an approximation of the raft volumes, the measurements of the approximate depth of the raft were carried out on the sagittal HASTE images, and the approximate cross‐section of the raft was defined from an axial slice in the center of the raft. These two measurements, made by a single observer, were then multiplied together to give an approximate raft volume—assuming an approximately cylindrical‐shaped mask. To check whether the data were consistently over or underestimating the volumes, the full raft volume was also measured from the axial images and compared to the approximate value for two to three datasets for each subject.\nData are presented as median and inter‐quartile range (IQR), apart from the NMR spectroscopy data which is presented as median and range. A nonparametric one‐way ANOVA (Kruskal–Wallis) was carried out (using Prism version 10.2.3, GraphPad Software LLC) to determine whether there were differences in raft strength, raft mass, and extrusion strength for the same dose of the different formulations. Dunn's multiple comparison test (with adjusted\nAll analyses were conducted with the observer blind to which alginate formulation had been consumed. Data are presented as median and IQR. As this was a feasibility study with very small numbers of participants, no statistical tests were carried out. Comparison of data between upright and supine positions was carried out by pooling all data from the different formulations.\nThe results of the characterization according to the raft strength, FW extrusion experiments are shown in Figure\nIn vitro testing results. (A) Results from L‐hook raft strength experiments. (B) Results from the forward extrusion experiment (carried out only on a 10 g dose). Statistics shown on graphs from one‐way ANOVA (Kruskal–Wallis) between formulations, followed by Dunn's multiple comparison test with adjusted\nGraph showing NMR analysis of the components of the alginates isolated from the formulations along with the Protanal LFR 5/60 (obtained from Laminaria hyperborea) and two other sodium alginates obtained from other brown algae. F\nSix participants were recruited to the study (5 F, 1 M, median age: 28, range 23–50 years, median BMI 23.3, range 18.4–28.8 kg/m\nImages showing alginate raft in stomach. A&B Images from a participant at 3 T supine in the axial plane. (A) moderately T2‐weighted HASTE sequence, (B) heavily T2‐weighted HASTE sequence. (C, D) Images from a different participant 0.5 T upright in the sagittal plane. Images are consecutive slices from a moderately T2‐weighted HASTE sequence. The three components of the stomach contents are highlighted, alginate rafts—red arrows, liquid acid meal—solid white arrows, solid milk protein aggregate (from fortisip drink) ‐ dotted white arrows. Other relevant abdominal anatomy shown with blue arrows.\nFigure\nGraphs showing gastric content (A, B), gas (C, D) and raft volumes (E, F), split by formulation and scanner. Data are shown as median and range.\nWhen the data from all formulations were pooled for each scanner, there appears to be slight differences in behaviour of the different volumes measured (Figure\nGraphs showing gastric content (A), gas (B), and raft volume (C) for the different scanner and body positions. Data pooled across all formulations. Data shown as median with error bars 95% confidence interval for median.\nTable\nT2 data (median (range)) combined from two participants for the upper and lower regions of the raft. Where no data was measured either due to artefacts or lack of raft to draw ROI the data is left blank.\nThe texture analysis data and example images are shown in Figure\nAn example set of images from one volunteer at T40 min for the three different formulations. ROIs for the stomach used in the texture analysis shown in Red. Graph of Haralick contrast texture with time and formulation shown below images.\nSome notable features captured from the upright scanner images are shown in Figure\nImages from the 0.5 T Upright scanner. Images A (sagittal) and B (axial) are from the same participant at the final T100 time point and illustrate the darker ‘halo’ effect of stronger gel encapsulating either ungelled or weaker gelled formulation. Figures C and D are from two different participants (and different formulations) whose stomach geometry allowed for the bottom of the raft to elongate in the head‐foot direction as the stomach emptied and the axial cross‐section of the stomach reduced. The sagittal images shown are from different time point in the study.\nThis was a small‐scale feasibility study which showed formulations which produced alginate rafts floating in the stomach could be visualised using both conventional supine scanning (at 3T), but also lower field (0.5T) open geometry, allowing for upright positioning of the participants. The study protocol produced a stomach that emptied at a very similar rate across different study days and allowed all formulations to produce rafts in all volunteers. This study builds on prior work [\nThe in vitro study of the raft strength (L‐hook) of the three formulations showed statistical reduced values for product\nThe alginates isolated from formulations\nThe alginate isolated from formulation X showed reduced G contents and enhanced 1,4‐β‐D mannuronic (M) acid content, whereas for the alginate from formulation Z, even higher M contents were detected. The amounts of these chemical structural elements are similar in formulation Z to other alginate products obtained from different brown seaweed species. This shows the importance of the chemical structure of the alginates for the performance in anti‐reflux formulations, especially when the formulations are based on similar recipes (constant CaCO\nA previous study looked at the chemical effects of neutralisation of different formulations and showed wide differences between products [\nRaft behavior appeared to be different depending on body position, supine and upright. Specifically, raft volumes in the upright scanner did not decrease towards the end of the study period, unlike the raft volumes in the horizontal scanner, which decreased. These differences are probably due to the position of the raft within the stomach, with the supine position allowing the raft to float near the antral area and could more easily be broken down and emptied from the stomach. In this study, there also appeared to be a very slight difference in gastric emptying rate between the body positions, with the upright position emptying slightly slower. This may have been due to layering of the milk protein from the Fortisip drink after acidification in the stomach [\nThe differences seen between upright and supine may also be attributed to the differences in image acquisition between the two scanners, as there would be larger partial volume effects from the upright scanning, which had a slice thickness of 10 mm and a gap of 3 mm compared to the thinner slices of 5 mm and a gap 1 mm supine at 3.0T. However, partial volume effects would be present for all measurements, and the differences in volume decreases occur after the initial postprandial volume, which was very similar between the two scanners. It was not possible to achieve a smaller slice thickness and gap and cover the full stomach in a single breath‐hold on the upright, and there is also the possibility that the differences come from the different individuals scanned due to intersubject variations. Therefore, further studies that can image the same individual both upright and supine are needed to understand if the emptying rates are different with the different body positions.\nQuantitative measurements of T2 were carried out in two out of the three participants at 3T and showed that the raft formed was very heterogeneous. The area of the raft nearest the air, floating at the very top produced a shorter T2 value indicating a stronger gel, or more viscous formulation, compared to any lower regions that could be measured which may have been weaker or less viscous. Previous studies have also characterised gel in the stomach from various different food‐grade polymers [\nThe image texture analysis data produced a quantified parameter which correlated well with the visual appearance of the rafts in the high‐resolution images. Formulation\nThere were limitations to this study. Due to the small number of participants, no statistical testing of differences between the alginate formulations were carried out and all data could be considered as semi‐quantitative only. A larger study would be needed to ascertain whether the different raft strengths from the formulations produced significantly different measurements over time. For the supine scanning, there were no time restrictions placed as to when participants could use the toilet facilities, and this resulted in body position changes which were not consistent between subjects and across the different formulations. These changes may have influenced the volume of the rafts at 3T, and future studies would look to set a formal break time in the scanning. In addition, any changes to the position of the diaphragm during the two breath‐hold scan may have resulted in either a slight over or underestimation of the raft volume, but this should not have been significant as the raft covered many slices in the axial plane. Problems with banding artefacts from the balanced TFE image acquisition and motion of the stomach, both from respiratory position and stomach walls for the measurements of T2, yielded a reduced amount of data for this particular parameter. Images sets with just a few banding artefacts across the data could be used for quantifying the T2 in some locations within the raft, however those with many artefacts had to be completely discarded. The range of T2prep echo times allowed for some loss of individual echo time data, but still allowed for the T2 fitting calculation to be made. Future studies could look to use alternative imaging sequences to measure the T2 [\nIn conclusion, this small‐scale feasibility study showed it was possible to image alginate rafts formed in the stomach using both 3T supine and 0.5T upright MRI scanners. Quantification of different raft properties in vivo were carried out, on three alginate formulations which produced very different raft strength and mass from in vitro experiments, due to structural chemical differences in the alginates used. The data from this study suggested that the raft behaviour (emptying and breakdown) may differ when participants are supine compared to sitting upright after dosing. Further larger scale in vivo studies are needed to determine what differences to the raft characteristics in vivo can be determined from MRI (e.g., strength, volume, retention) from the different formulations and whether statistical differences in emptying rates from body positioning are found.\nMatthias Knarr is an employee of PS Biopolymers (previously known as IFF N&H, now part of ROQUETTE Health & Pharma Solutions). All other authors declare no competing interests in this work.\n\nFigure S2 Illustration of the method for raft strength testing using the extrusion method.\nFigure S3 Image showing map of z‐score following Haralick texture analysis contrast algorithm. Whiter regions in the map have a higher z‐score indicating a more heterogeneous contrast in the original image.\nFigure S4 Definition of the stomach region for z‐score analysis. A: Original high‐resolution coronal image showing the liver (red) and stomach (orange) ROIs defined. Note the stomach ROI is inside the walls of the stomach. B: Z‐score map following Haralick texture analysis showing the stomach ROI. This ROI is inside the stomach walls to make sure the average z‐score from the stomach comes from the raft texture and not from any edges of the stomach which also have high z‐scores.\n\n\n", "topic": "Diagnostic"}
{"pmid": "40626236", "pmcid": "12234767", "title": "Assessment of arrhythmias and heart rate response in healthy adolescents performing face immersion and body submersion in ice‐cold water", "publication_year": "N/A", "abstract": "As cold‐water immersion becomes more popular and accessible, it is important to explore potential risks. This study examines the cardiac autonomic response and arrhythmia occurrence in healthy adolescents during face and body immersion. Healthy ninth‐grade students, aged 15–16 years, were recruited to perform face immersion (FI) in 10°C water and body immersion in 2°C water (IWI). Electrocardiograms (ECGs) were continuously recorded, and the heart rate (HR) response and occurrence of arrhythmias were assessed. Among the 54 individuals performing FI, six had supraventricular extrasystoles, and two had ventricular bigeminy. Among the 20 performing IWI, four had supraventricular extrasystoles. The HR response was more pronounced during FI compared to IWI (", "full_text": "Body immersion into cold water has become an increasingly popular activity in Northern Scandinavia. In Sweden, rather than swimming actively in the cold water, the usual practice involves immersing the body into the cold water through a small hole made in the frozen lake or sea. This activity has received praise from those who practice it and has become a popular topic in the mainstream press, with claims of numerous health benefits such as boost immune system, improved mental health and reduced stress (Knechtle et al.,\nThe impact of sudden exposure to cold water immersion triggers the activation of the neurogenically mediated cold shock response, which induces uncontrollable heavy breathing followed by hyperventilation (Tipton,\nSince cold water immersion has gained popularity and thereby accessibility, there is an increasing number of individuals from various age groups partaking in this activity. This highlights the importance of examining the potential risks associated with it. The objective of this study was to examine the cardiac autonomic response and the occurrence of arrhythmias in healthy adolescents during face immersion and body immersion in ice‐cold water.\nIn some schools in this region, ice‐bathing is a part of the physical education during the ninth year at school. Therefore, healthy ninth‐grade students, aged 15–16 years, were recruited for participation. Information was distributed to all pupils in five school classes, followed by a verbal presentation of the study, allowing the children to ask questions. Informed written consent was obtained from the legal guardians of the participants. Prior to participation, participants completed a questionnaire to provide information on clinical details, including date of birth, gender, existing medical conditions, and ongoing medical treatment.\nThe water provocations were divided into two separate sessions, and both occurred either as a part of the participants' physical education class or in direct association with it. Each of the sessions followed its own protocol for the water provocations. The face immersion (FI) took place indoors and included immersing the face in 10°C water (Foster & Sheel,\nContinuous ECG monitoring was conducted using the Actiwave‐Cardio monitor (CamNtech, Cambridge, UK), which is a waterproof single‐channel ECG recorder. Additionally, this device monitors and stores body movement and position through a tri‐axial accelerometer. Both the monitor and the two electrodes were covered with water‐resistant adhesive plasters in order to minimize disturbances. The ECG monitor samples ECG data at a rate of 500 Hz, and a custom‐made software automatically detects heartbeats. Errors in the detection were manually corrected, and instances of arrhythmic beats were noted.\nAdditionally, during IWI the participants were also equipped with a Garmin HRM‐swim heart rate monitor chest strap (Garmin, Lenexa, Kansas). The chest strap was connected to a Fenix 6 Garmin fitness and sports watch (Garmin, Lenexa, Kansas), which recorded one heart rate (HR) value per second. The data from the Garmin monitor was only used as a complement during the error correction of the IWI recordings. Upon reviewing recordings from FI, it was found that the Garmin monitor had not successfully captured the more rapid changes in HR that occurred during FI, making the data unsuitable for analysis.\nThere was a fast decrease in HR after the start of FI that lasted until they aborted the immersion, where the maximum and minimum HR occurred at different time points in each subject during FI. Therefore, the following indices were determined. Baseline HR was calculated as the average during the last 5 s before the start of FI. The maximum and minimum HR were determined during the immersion, and the decrease in HR was defined as the difference between them. The duration was defined as the time between the start of FI and the end of the immersion.\nThe HR response had a less pronounced reaction with variable and slower changes during IWI as compared to FI. To reduce the impact of disturbances in the ECG due to intermittent muscular activity during IWI, HR was calculated as consecutive 5‐s averages from 5 s before the start of IWI to 30 s after the immersion. Following that, as the subjects started to exit the water, the ECG could not be analyzed due to excessive interference from movements and muscular activity.\nDescriptive data for continuous variables is presented as means ± SD. The Mann–Whitney U test was used to assess differences in HR between the two sexes during FI and IWI. The Friedman test was used to examine differences in HR across multiple time points during IWI. The selected time points included the initiation of immersion and subsequent 5‐s intervals throughout the immersion period, reaching up to 30 s. Post hoc analysis was conducted with Wilcoxon signed‐rank tests. The pairwise comparison between FI and IWI was conducted with Wilcoxon signed‐rank tests.\nThe overall HR response during each immersion was presented in the figures as group averages, where standard errors of the mean (SEM) values were used as an estimate of the uncertainty in the response. This was determined by converting the original beat‐to‐beat HR data to synchronized and equidistantly sampled data by cubic spline interpolation and resampling at 4.8 Hz. The group averages were smoothed by calculating one‐second moving averages. IBM SPSS v28 (IBM Corp., Armonk, NY, USA) and Matlab R2024b (Mathworks Inc., Natick, MA, USA) were used for all analyses.\nThe study was approved by the Regional Ethical Board in Umeå, Sweden (Dnr 2017–145‐31 M) and was conducted in accordance with the Declaration of Helsinki. All participants, as well as their legal guardians, provided written informed consent before participating in the study.\nFifty‐five individuals performed FI, but one was excluded due to a duration less than 10 seconds. Among these 54 individuals, 23 also participated in IWI. However, two were excluded from the IWI analysis due to significant ECG disturbances, and one was excluded for having a duration in the water that was considered too short. This resulted in the inclusion of 20 individuals in the IWI analysis.\nAmong the remaining 54 individuals who performed FI, five had occasional supraventricular extrasystoles, and one experienced supraventricular extrasystoles at regular intervals during FI. One individual had ventricular bigeminy at the end of FI, and one had ventricular bigeminy after completing FI.\nAmong the remaining 20 who performed IWI, three had occasional supraventricular extrasystoles and one experienced supraventricular extrasystoles at regular intervals.\nA total of 54 adolescents performed face immersion with long enough exposure (mean duration 25.7 ± 5.3 s, range 10.7–35.1 s). Descriptive statistics for the entire group are presented in Table\nHeart rate reaction during face immersion.\n\nHeart rate reaction in boys and girls during face immersion. Data is presented as means and standard error of the mean (SEM).\nAmong the 20 participants included in the arrhythmia analysis, two were excluded from the heart rate response analysis due to a gap of approximately 10 s in their ECG data during the first 30 s of immersion. Consequently, the analysis comprised 18 participants, of whom 8 were girls (44%). The mean duration was 42.0 ± 9.2 s, range 28.0–65.0 s. In the entire cohort, HR increased before the start and 5 s into the immersion in ice‐cold water (Table\nHeart rate reaction during body immersion in ice‐cold water. HR values are given in beats per minute (bpm). Data are presented as mean and standard deviation (SD). N, number of subjects; HR, heart rate.\nHeart rate reaction in boys and girls during ice‐water immersion. Data is presented as means and standard error of the mean (SEM).\nIn a pairwise analysis involving the 18 participants who underwent both FI and IWI, there was a notable difference in HR reduction comparing the two procedures. During the initial 25 s of FI, participants showed a pronounced decrease of 59 ± 19 beats, in contrast to a more modest reduction of 7 ± 23 beats during the first 25 s of IWI (\nThe focus of this study was to examine the incidence of arrhythmias and the cardiac autonomic response during face immersion and ice‐water immersion in healthy adolescents. In summary, supraventricular extrasystoles were common both during FI and IWI, whereas ventricular extrasystoles occurred only during FI. Additionally, the HR response was more pronounced during FI compared to IWI. In both FI and IWI, girls initially had a higher HR and a more pronounced reduction in HR than the boys, but these differences were not statistically significant. The HR progression during the first 30 seconds of IWI differed between boys and girls, with boys maintaining a relatively steady HR throughout the IWI, whereas girls experienced a marked and near‐linear reduction.\nBoth FI and IWI induce a high level of activation in the ANS. In the case of FI, this activates the diving reflex, and FI has been shown to be useful in an experimental setting as a substitute for whole‐body submersion (Shamsuzzaman et al.,\nDuring IWI, the participants immersed their bodies, keeping their heads above the ice‐cold water. This immediately initiates the cold shock response, the body's physiological reaction to sudden exposure to cold water, leading to a rapid activation of the SNS (Tipton et al.,\nThe physiological responses to water activities, particularly in cold water, can potentially trigger arrhythmias in some individuals, even if they are generally healthy (Asplund & Creswell,\nAs expected, the participants in this study had a more pronounced reduction in HR during FI compared to IWI. A rapid decrease in HR requires a strong activation of the PNS. The diving reflex, characterized by apnea and activation of cold receptors in the face, acts as a potent mediator in facilitating this process. In contrast, there is an initial quick and deep inhalation during IWI, but this rapidly transitions into hyperventilation. Consequently, the PNS response is much weaker, resulting in a less pronounced reduction in HR. The girls in this study generally had a higher HR than boys. All participants in the study had undergone puberty, and since the heart is proportionate to body size, the female heart is typically smaller. Consequently, it pumps less blood in each heartbeat, requiring a faster HR to maintain the cardiac output (Prabhavathi et al.,\nBaseline heart rates were relatively high prior to each cold‐water immersion. Each recording session included approximately 20 participants, all of whom were required to complete the immersion during a scheduled school session. Consequently, ECG monitors could only be applied, and baseline measurements recorded, shortly before immersion. It is likely that heart rates were elevated at this time due to anticipatory stress or excitement related to the impending exposure to cold water.\nSince body immersion in ice‐cold water is becoming a more common practice in many parts of the world, the need to investigate its potential harmful effects increases. In this study on healthy adolescents, no ventricular premature beats were observed. The circumstances in which these adolescents, fully clothed, immersed themselves in the ice‐cold water is comparable to a situation in which someone walks or tour skates on natural ice, and suddenly the ice breaks, making the person to fall into the cold water. This suggests that, under these circumstances and with a relatively short duration in the ice‐cold water (<60 s), the risk of severe arrhythmias is relatively low in this age group, provided that the individual does not have a predisposition to develop arrhythmias. However, it is important to emphasize that the risk probably is higher if the whole body including the face, is submerged into the ice‐cold water and both the diving reflex and the trigemino‐cardiac reflex is activated (Bierens et al.,\nThe results presented in this study showed that the diving reflex‐mediated FI induced a more pronounced HR reduction and ventricular extrasystoles, compared with cold shock‐mediated IWI, which only triggered supraventricular extrasystoles. These findings imply that the risk of severe arrhythmias is relatively low when briefly immersing only the body in healthy adolescents without a predisposition to develop arrhythmias. However, the risk is likely higher when ice‐cold water is combined with whole‐body submersion and apnea.\nThis work was supported by the Swedish Heart Lung Foundation (A.R. Grant number: 20210468), Oskarfonden (\nThe authors have no conflict of interest to declare.\nThe study was approved by the Regional Ethical Review Board in Umeå, Sweden.\nWritten informed consent was obtained from all participants.", "content_for_embedding": "Body immersion into cold water has become an increasingly popular activity in Northern Scandinavia. In Sweden, rather than swimming actively in the cold water, the usual practice involves immersing the body into the cold water through a small hole made in the frozen lake or sea. This activity has received praise from those who practice it and has become a popular topic in the mainstream press, with claims of numerous health benefits such as boost immune system, improved mental health and reduced stress (Knechtle et al.,\nThe impact of sudden exposure to cold water immersion triggers the activation of the neurogenically mediated cold shock response, which induces uncontrollable heavy breathing followed by hyperventilation (Tipton,\nSince cold water immersion has gained popularity and thereby accessibility, there is an increasing number of individuals from various age groups partaking in this activity. This highlights the importance of examining the potential risks associated with it. The objective of this study was to examine the cardiac autonomic response and the occurrence of arrhythmias in healthy adolescents during face immersion and body immersion in ice‐cold water.\nIn some schools in this region, ice‐bathing is a part of the physical education during the ninth year at school. Therefore, healthy ninth‐grade students, aged 15–16 years, were recruited for participation. Information was distributed to all pupils in five school classes, followed by a verbal presentation of the study, allowing the children to ask questions. Informed written consent was obtained from the legal guardians of the participants. Prior to participation, participants completed a questionnaire to provide information on clinical details, including date of birth, gender, existing medical conditions, and ongoing medical treatment.\nThe water provocations were divided into two separate sessions, and both occurred either as a part of the participants' physical education class or in direct association with it. Each of the sessions followed its own protocol for the water provocations. The face immersion (FI) took place indoors and included immersing the face in 10°C water (Foster & Sheel,\nContinuous ECG monitoring was conducted using the Actiwave‐Cardio monitor (CamNtech, Cambridge, UK), which is a waterproof single‐channel ECG recorder. Additionally, this device monitors and stores body movement and position through a tri‐axial accelerometer. Both the monitor and the two electrodes were covered with water‐resistant adhesive plasters in order to minimize disturbances. The ECG monitor samples ECG data at a rate of 500 Hz, and a custom‐made software automatically detects heartbeats. Errors in the detection were manually corrected, and instances of arrhythmic beats were noted.\nAdditionally, during IWI the participants were also equipped with a Garmin HRM‐swim heart rate monitor chest strap (Garmin, Lenexa, Kansas). The chest strap was connected to a Fenix 6 Garmin fitness and sports watch (Garmin, Lenexa, Kansas), which recorded one heart rate (HR) value per second. The data from the Garmin monitor was only used as a complement during the error correction of the IWI recordings. Upon reviewing recordings from FI, it was found that the Garmin monitor had not successfully captured the more rapid changes in HR that occurred during FI, making the data unsuitable for analysis.\nThere was a fast decrease in HR after the start of FI that lasted until they aborted the immersion, where the maximum and minimum HR occurred at different time points in each subject during FI. Therefore, the following indices were determined. Baseline HR was calculated as the average during the last 5 s before the start of FI. The maximum and minimum HR were determined during the immersion, and the decrease in HR was defined as the difference between them. The duration was defined as the time between the start of FI and the end of the immersion.\nThe HR response had a less pronounced reaction with variable and slower changes during IWI as compared to FI. To reduce the impact of disturbances in the ECG due to intermittent muscular activity during IWI, HR was calculated as consecutive 5‐s averages from 5 s before the start of IWI to 30 s after the immersion. Following that, as the subjects started to exit the water, the ECG could not be analyzed due to excessive interference from movements and muscular activity.\nDescriptive data for continuous variables is presented as means ± SD. The Mann–Whitney U test was used to assess differences in HR between the two sexes during FI and IWI. The Friedman test was used to examine differences in HR across multiple time points during IWI. The selected time points included the initiation of immersion and subsequent 5‐s intervals throughout the immersion period, reaching up to 30 s. Post hoc analysis was conducted with Wilcoxon signed‐rank tests. The pairwise comparison between FI and IWI was conducted with Wilcoxon signed‐rank tests.\nThe overall HR response during each immersion was presented in the figures as group averages, where standard errors of the mean (SEM) values were used as an estimate of the uncertainty in the response. This was determined by converting the original beat‐to‐beat HR data to synchronized and equidistantly sampled data by cubic spline interpolation and resampling at 4.8 Hz. The group averages were smoothed by calculating one‐second moving averages. IBM SPSS v28 (IBM Corp., Armonk, NY, USA) and Matlab R2024b (Mathworks Inc., Natick, MA, USA) were used for all analyses.\nThe study was approved by the Regional Ethical Board in Umeå, Sweden (Dnr 2017–145‐31 M) and was conducted in accordance with the Declaration of Helsinki. All participants, as well as their legal guardians, provided written informed consent before participating in the study.\nFifty‐five individuals performed FI, but one was excluded due to a duration less than 10 seconds. Among these 54 individuals, 23 also participated in IWI. However, two were excluded from the IWI analysis due to significant ECG disturbances, and one was excluded for having a duration in the water that was considered too short. This resulted in the inclusion of 20 individuals in the IWI analysis.\nAmong the remaining 54 individuals who performed FI, five had occasional supraventricular extrasystoles, and one experienced supraventricular extrasystoles at regular intervals during FI. One individual had ventricular bigeminy at the end of FI, and one had ventricular bigeminy after completing FI.\nAmong the remaining 20 who performed IWI, three had occasional supraventricular extrasystoles and one experienced supraventricular extrasystoles at regular intervals.\nA total of 54 adolescents performed face immersion with long enough exposure (mean duration 25.7 ± 5.3 s, range 10.7–35.1 s). Descriptive statistics for the entire group are presented in Table\nHeart rate reaction during face immersion.\n\nHeart rate reaction in boys and girls during face immersion. Data is presented as means and standard error of the mean (SEM).\nAmong the 20 participants included in the arrhythmia analysis, two were excluded from the heart rate response analysis due to a gap of approximately 10 s in their ECG data during the first 30 s of immersion. Consequently, the analysis comprised 18 participants, of whom 8 were girls (44%). The mean duration was 42.0 ± 9.2 s, range 28.0–65.0 s. In the entire cohort, HR increased before the start and 5 s into the immersion in ice‐cold water (Table\nHeart rate reaction during body immersion in ice‐cold water. HR values are given in beats per minute (bpm). Data are presented as mean and standard deviation (SD). N, number of subjects; HR, heart rate.\nHeart rate reaction in boys and girls during ice‐water immersion. Data is presented as means and standard error of the mean (SEM).\nIn a pairwise analysis involving the 18 participants who underwent both FI and IWI, there was a notable difference in HR reduction comparing the two procedures. During the initial 25 s of FI, participants showed a pronounced decrease of 59 ± 19 beats, in contrast to a more modest reduction of 7 ± 23 beats during the first 25 s of IWI (\nThe focus of this study was to examine the incidence of arrhythmias and the cardiac autonomic response during face immersion and ice‐water immersion in healthy adolescents. In summary, supraventricular extrasystoles were common both during FI and IWI, whereas ventricular extrasystoles occurred only during FI. Additionally, the HR response was more pronounced during FI compared to IWI. In both FI and IWI, girls initially had a higher HR and a more pronounced reduction in HR than the boys, but these differences were not statistically significant. The HR progression during the first 30 seconds of IWI differed between boys and girls, with boys maintaining a relatively steady HR throughout the IWI, whereas girls experienced a marked and near‐linear reduction.\nBoth FI and IWI induce a high level of activation in the ANS. In the case of FI, this activates the diving reflex, and FI has been shown to be useful in an experimental setting as a substitute for whole‐body submersion (Shamsuzzaman et al.,\nDuring IWI, the participants immersed their bodies, keeping their heads above the ice‐cold water. This immediately initiates the cold shock response, the body's physiological reaction to sudden exposure to cold water, leading to a rapid activation of the SNS (Tipton et al.,\nThe physiological responses to water activities, particularly in cold water, can potentially trigger arrhythmias in some individuals, even if they are generally healthy (Asplund & Creswell,\nAs expected, the participants in this study had a more pronounced reduction in HR during FI compared to IWI. A rapid decrease in HR requires a strong activation of the PNS. The diving reflex, characterized by apnea and activation of cold receptors in the face, acts as a potent mediator in facilitating this process. In contrast, there is an initial quick and deep inhalation during IWI, but this rapidly transitions into hyperventilation. Consequently, the PNS response is much weaker, resulting in a less pronounced reduction in HR. The girls in this study generally had a higher HR than boys. All participants in the study had undergone puberty, and since the heart is proportionate to body size, the female heart is typically smaller. Consequently, it pumps less blood in each heartbeat, requiring a faster HR to maintain the cardiac output (Prabhavathi et al.,\nBaseline heart rates were relatively high prior to each cold‐water immersion. Each recording session included approximately 20 participants, all of whom were required to complete the immersion during a scheduled school session. Consequently, ECG monitors could only be applied, and baseline measurements recorded, shortly before immersion. It is likely that heart rates were elevated at this time due to anticipatory stress or excitement related to the impending exposure to cold water.\nSince body immersion in ice‐cold water is becoming a more common practice in many parts of the world, the need to investigate its potential harmful effects increases. In this study on healthy adolescents, no ventricular premature beats were observed. The circumstances in which these adolescents, fully clothed, immersed themselves in the ice‐cold water is comparable to a situation in which someone walks or tour skates on natural ice, and suddenly the ice breaks, making the person to fall into the cold water. This suggests that, under these circumstances and with a relatively short duration in the ice‐cold water (<60 s), the risk of severe arrhythmias is relatively low in this age group, provided that the individual does not have a predisposition to develop arrhythmias. However, it is important to emphasize that the risk probably is higher if the whole body including the face, is submerged into the ice‐cold water and both the diving reflex and the trigemino‐cardiac reflex is activated (Bierens et al.,\nThe results presented in this study showed that the diving reflex‐mediated FI induced a more pronounced HR reduction and ventricular extrasystoles, compared with cold shock‐mediated IWI, which only triggered supraventricular extrasystoles. These findings imply that the risk of severe arrhythmias is relatively low when briefly immersing only the body in healthy adolescents without a predisposition to develop arrhythmias. However, the risk is likely higher when ice‐cold water is combined with whole‐body submersion and apnea.\nThis work was supported by the Swedish Heart Lung Foundation (A.R. Grant number: 20210468), Oskarfonden (\nThe authors have no conflict of interest to declare.\nThe study was approved by the Regional Ethical Review Board in Umeå, Sweden.\nWritten informed consent was obtained from all participants.", "topic": "Diagnostic"}
{"pmid": "40607705", "pmcid": "12292671", "title": "Necroptotic and Apoptotic Pathways in Sepsis: A Comparative Analysis of Pediatric and Adult ICU Patients", "publication_year": "N/A", "abstract": "", "full_text": "Sepsis and systemic inflammatory response syndrome (SIRS) remain leading causes of morbidity and mortality among pediatric and adult patients admitted to intensive care units (ICUs) worldwide. Despite advances in critical care, the underlying mechanisms driving organ dysfunction in these conditions are not fully understood, limiting the development of targeted therapies.\nNecroptosis, a regulated form of necrotic cell death, has emerged as a significant contributor to the pathophysiology of various inflammatory diseases, including sepsis, trauma-induced SIRS, and cardiac conditions. Unlike apoptosis, necroptosis is characterized by the activation of receptor-interacting protein kinases (RIPK)1 and RIPK3, leading to the phosphorylation of mixed lineage kinase domain-like protein (MLKL), which results in cell membrane rupture and the release of pro-inflammatory intracellular contents [\nIn pediatric populations, the role of necroptosis in critical illnesses is increasingly recognized. Experimental studies have shown that pharmacological inhibition of necroptosis can attenuate lung injury and improve survival in neonatal models of sepsis [\nIn this context, specific proteins such as A20, a ubiquitin-editing enzyme, play a central role in modulating inflammation and cell death by inhibiting RIPK3-dependent necroptosis [\nUnderstanding the balance between necroptosis and apoptosis in sepsis is crucial, as it may unveil novel biomarkers for disease severity and potential therapeutic targets [\nThis is a prospective, single-center, observational study conducted at the University General Hospital of Heraklion, encompassing the Intensive Care Unit (ICU), Pediatric Intensive Care Unit (PICU), and Cardiac Intensive Care Unit (CICU). The primary objective was to assess the expression of necroptosis-related proteins in critically ill pediatric and adult patients with sepsis, trauma/surgery-induced SIRS, or heart disease and to compare findings with those from healthy control subjects. The study also aimed to investigate the relationships between necroptosis protein levels and clinical or laboratory severity indices, as well as patient outcomes. This study adhered to STROBE reporting guidelines for observational research.\nThe study enrolled critically ill pediatric and adult patients admitted between June and November 2023. Patients were prospectively categorized into four groups: Sepsis/septic shock (n = 23): patients fulfilling the Sepsis-3 criteria; SIRS (n = 29): patients with non-infectious SIRS due to surgery or trauma; cardiac (n = 19): patients monitored in the CICU for acute heart conditions; and healthy controls (n = 17): age-matched pediatric and adult subjects without known acute or chronic diseases.\nInclusion criteria comprised admission to the ICU, PICU, or CICU with a confirmed diagnosis of sepsis, trauma/SIRS, or acute cardiac disease. Exclusion criteria were the presence of chronic illness (e.g., autoimmune disease, diabetes, and renal or hepatic insufficiency), congenital or acquired immunodeficiencies, malignancies, or current use of immunosuppressive or immunomodulatory therapy.\nClinical and laboratory data were obtained from the patients’ official medical records (both handwritten and electronic). Documentation included the following: diagnostic categorization according to international criteria (sepsis, SIRS, or cardiac); disease severity scores: SOFA (Sequential Organ Failure Assessment), qSOFA, APACHE II (Acute Physiology and Chronic Health Evaluation), PRISM III (Pediatric Risk of Mortality), and PeLOD (Pediatric Logistic Organ Dysfunction), as applicable by age group; and laboratory markers of systemic inflammation and infection (e.g., CRP, procalcitonin, and leukocyte count).\nThis study was approved by the Administrative Board, the Scientific Council of the University General Hospital of Heraklion, and the Bioethics Committee (Approval No. 19050/2023; Date: 26 June 2023). All procedures complied with the principles of the Declaration of Helsinki and the General Data Protection Regulation (GDPR, EU 2016/679). Given the prospective nature of the study and the collection of sensitive clinical and biological data, written informed consent was obtained from all participants or their legal guardians, as required by institutional and legal regulations.\nPeripheral blood samples were collected within the first 24 h following ICU admission and clinical confirmation of sepsis or SIRS. Serum was separated and stored under standardized conditions until analysis.\nQuantification of necroptosis-associated proteins—RIPK1, RIPK3, MLKL, and A20—as well as caspase-8 and proinflammatory cytokines IL-1β and IL-18, was performed using commercially available sandwich ELISA kits (ELK Biotechnology, Denver, CO, USA), according to the manufacturer’s instructions. The assays were conducted in duplicate, and optical density was measured at 450 nm using a microplate reader. Protein concentrations were derived from standard curves based on known calibrator concentrations.\nDetection limits were as follows: RIPK1 (0.063 ng/mL), RIPK3 and MLKL (0.122 ng/mL), A20 (0.17 ng/mL), caspase-8 (0.244 ng/mL), IL-18 (5.9 pg/mL), and IL-1β (5.8 pg/mL). These biomarker levels were analyzed in relation to clinical severity scores (SOFA, qSOFA, APACHE II, PRISM, and PELOD-2) and outcomes and were compared across diagnostic groups and healthy controls.\nThe biomarkers included in this study were selected to represent the central regulators of necroptosis and apoptosis and to capture key mediators of necroinflammatory signaling in sepsis [\nRIPK1, RIPK3, MLKL, and A20 are core components of the necroptosis cascade [\nCaspase-8 was chosen as the apoptosis-related marker due to its dual functionality: It triggers extrinsic apoptosis through FADD activation and simultaneously suppresses necroptosis by cleaving RIPK1 and RIPK3, thus preventing necrosome formation [\nWhile caspase-3 is a downstream executioner of apoptosis, it does not reflect the regulatory balance between apoptotic and necroptotic pathways and was therefore not included in this phase of the study [\nWe included IL-1β and IL-18 because these cytokines are products of inflammasome activation and serve as biomarkers of necroinflammation and pyroptosis—pathways that intersect cytokine-mediated inflammation and programmed necrosis [\nIn contrast, classical pro-inflammatory cytokines such as TNF-α and IL-6 were excluded from our biomarker panel due to their non-specificity, rapid kinetics, and broad elevation in various inflammatory conditions (e.g., trauma, surgery, and non-septic illness), which limit their usefulness as stable indicators of programmed cell death pathways in critically ill patients [\nBy focusing on these markers, in our study, we aimed to dissect the molecular interplay between necroptosis, apoptosis, and necroinflammation during critical illness and sepsis, rather than measuring systemic inflammation signals with limited mechanistic specificity.\nData were recorded in Microsoft Excel and analyzed using SPSS software (version 29.0, IBM Corp., Armonk, NY, USA). Continuous variables were tested for normality and are presented as the mean ± standard deviation (SD) or median with interquartile range (IQR), as appropriate. Categorical variables were expressed as absolute (n) and relative (%) frequencies. Group comparisons for continuous variables were performed using t-tests or one-way ANOVA for normally distributed data and Mann–Whitney U or Kruskal–Wallis tests for non-normally distributed data. Categorical variables were compared using the chi-square test or Fisher’s exact test. Spearman’s rank correlation coefficient was used to assess associations between continuous variables. Backwards stepwise multivariate linear regression was performed to identify independent associations between biomarkers and clinical outcomes. Receiver operating characteristic (ROC) curve analyses were conducted to evaluate the predictive performance of necroptosis biomarkers. A\nThis prospective, single-center clinical study included 88 participants admitted to the Pediatric and Adult Intensive Care Units (ICUs) and the Cardiac Intensive Care Unit at the University Hospital of Heraklion between June and November 2023. The cohort comprised 56 adults (63.6%) and 32 children (36.4%), categorized into four groups: sepsis (26.1%), trauma/surgery (SIRS) (33%), cardiac conditions (21.6%), and healthy controls (19.3%).\nSignificant differences were observed between adults and children in age, body weight, and Body Mass Index (BMI) (\nLaboratory analyses revealed that adults had significantly higher levels of glucose (152 vs. 103 mg/dL,\nAmong ICU patients, RIPK-1 levels were significantly higher in adults (median [IQR]: 20.2 [7.4–46.5] ng/mL) compared to children (6.2 [4.4–16.2] ng/mL;\nIn the healthy control population, RIPK-1 levels did not significantly differ between adults (3.17 ng/mL) and children (2.47 ng/mL;\nComparative analysis across diagnostic categories revealed that patients with sepsis exhibited significantly elevated levels of RIPK-1, IL-1β, and IL-18, along with reduced caspase-8 levels, relative to patients with SIRS or cardiac conditions. Importantly, the exclusion of two adult outliers—one from the sepsis group and one from the SIRS group—did not alter the statistical significance of these intergroup differences.\nAlthough the overall sample size limited power for detailed subgroup analyses, particularly within pediatric diagnostic strata, we conducted additional stratified comparisons. Specifically, age-stratified analyses of diagnostic group differences are presented in\nRIPK-1 and RIPK-3, key mediators of the necroptosis pathway, were elevated in patients with sepsis across both age groups, with RIPK-1 reaching statistical significance (\nIL-1β levels were significantly elevated in all three patient groups—sepsis, SIRS, and cardiac—compared to healthy controls, with similar distributions observed in both adults and children. IL-18 levels followed a comparable pattern among the patient groups, showing significantly higher concentrations in adults relative to healthy controls. However, due to missing data for IL-18 in the pediatric healthy control group, direct comparison in children was not feasible. These biomarker patterns are illustrated in\nCaspase-8 levels were significantly reduced in the sepsis group compared to healthy controls and cardiac patients in both adults and children. The ubiquitin-editing enzyme A20 was significantly elevated in adult sepsis patients compared to healthy controls. However, due to missing data in pediatric sepsis cases, reliable analysis of A20 levels in this subgroup was not feasible. These findings are illustrated in\nRIPK1 levels demonstrated significant positive correlations with APACHE II (rs = 0.39,\nA multivariate linear regression analysis, adjusted for age groups, identified A20 as the sole biomarker independently associated with blood lactate levels (Standardized Coefficient Beta = 0.55,\nReceiver Operating Characteristic analysis demonstrated that RIPK-1 (AUC = 0.81, 95% CI: 0.69–0.93,\nThis prospective study provides novel insights into the expression of necroptosis- and apoptosis-related proteins in critically ill pediatric and adult patients with sepsis, trauma/SIRS, or cardiac disease. We observed prominent necroptosis activation in sepsis—evidenced by elevated RIPK-1, IL-1β, and IL-18 levels and suppressed caspase-8 levels. These biomarker changes correlated with prolonged ICU stay and higher illness severity, underscoring the mechanistic relevance of necroptosis in systemic inflammation and organ dysfunction.\nA particularly striking finding is the marked increase in RIPK-1 levels among septic patients—both adults and children—relative to all other diagnostic groups. As a central mediator of necroptosis, RIPK-1 facilitates inflammatory cell death, especially when caspase-8 activity is diminished [\nEqually significant is the consistent suppression of caspase-8 in both adult and pediatric sepsis cohorts when compared to healthy controls. Caspase-8 plays a critical inhibitory role over RIPK-1-RIPK3 complex formation; thus, its downregulation removes a key checkpoint, enabling necrosome assembly and pro-inflammatory cell death [\nOur study also demonstrated substantially elevated levels of IL-1β and IL-18 in critically ill patients—including those with sepsis—compared to healthy adult and pediatric controls. Notably, IL-18 exhibited the highest discriminative performance in our ROC analysis, suggesting strong diagnostic value. These cytokines are key products of inflammasome activation and serve as potent effectors of necroinflammation, often released during membrane rupture inherent in necroptotic or pyroptotic cell death pathways [\nThe high expression of IL-1β and IL-18 in our septic cohort further supports the involvement of necroptotic and inflammasome-mediated mechanisms in critical illness [\nIn our study, A20 (TNFAIP3)—a ubiquitin-editing enzyme and known negative regulator of necroptosis and NF-κB signaling—was significantly upregulated in adult sepsis patients compared to healthy controls. Notably, higher A20 expression correlated independently with elevated blood lactate levels, a surrogate marker of tissue hypoxia and illness severity.\nA20 is a well-documented regulator of programmed cell death: by removing K63-linked ubiquitin chains from RIPK1, A20 prevents the formation of RIPK1–RIPK3 necrosomes and thereby inhibits necroptosis [\nWhile A20 dynamics are relatively well-characterized in autoimmune and chronic inflammatory conditions, their role in acute sepsis is less explored [\nAlthough adult patients in our cohort exhibited significantly higher RIPK-1 levels than pediatric patients, the distribution of this biomarker across diagnostic categories was remarkably consistent—decreasing progressively through sepsis, SIRS, cardiac cases, and healthy controls in both age groups. Pediatric patients demonstrated higher caspase-8 levels overall; however, within the sepsis group, caspase-8 was suppressed compared to healthy controls in both adults and children. This suggests that while age influences basal expression, the diagnostic patterns of necroptosis pathway activation are parallel in both cohorts.\nAge-related divergence in programmed cell-death regulation has been previously reported. In murine models, T-cell-specific RIPK1 deficiency leads to activation of RIPK3, caspase-8, and mTORC1, driving T-cell senescence and age-related inflammatory phenotypes—an effect modulated by environmental signals [\nInterestingly, among cardiac patients, caspase-8 levels were lower in adults than in children, potentially reflecting chronic inflammatory states. Estrogen deficiency and pre-menopausal hormonal changes exacerbate necroptosis-mediated cardiac injury through RIPK1-signaling in experimental models [\nDespite these biochemical divergences, clinical severity scores and outcomes were comparable between adults and children, with outcome hardpoints demonstrating significant correlations with necroptosis biomolecules in both groups, underscoring the shared underlying biology of critical illness [\nOur ROC analysis revealed that RIPK-1 and IL-18 demonstrated good diagnostic accuracy for sepsis within 24 h of ICU admission—suggesting strong potential as early biomarkers of disease severity. In contrast, caspase-8 showed an inverse predictive pattern, consistent with its anti-necroptotic, potentially protective role in this context. These findings collectively propose that necroptosis-related proteins may serve not only as indicators of severity but also as early therapeutic targets.\nImportantly, in preclinical sepsis models, small-molecule RIPK1 inhibitors, such as necrostatins, have shown promising protective effects: Necrostatin-1 blocks RIPK1 kinase activity, limiting necrosome formation and downstream inflammation in experimental models of systemic inflammation and lung or kidney injury [\nA major strength of this study lies in its prospective design and inclusion of both pediatric and adult cohorts, which allows for a comparative analysis of age-related differences in necroptosis pathways. Additionally, the use of multiple biomarkers related to both necroptosis, apoptosis, and inflammation (RIPK1, RIPK3, MLKL, caspase-8, IL-1β, IL-18, and A20) provides a multidimensional view of programmed cell death in critical illness. The application of ROC analysis also adds a translational aspect, supporting the diagnostic and prognostic relevance of these molecules.\nHowever, several limitations must be acknowledged. First, although the overall sample size was sufficient to detect significant trends, subgroup analyses stratified by age and diagnostic category may have been underpowered, particularly within pediatric strata. Given the absence of statistically significant differences in RIPK3, MLKL, A20, IL-1β, or IL-18 between adults and children, and the lack of age-related effect modification in biomarker–outcome correlations, biomarker data were pooled in the primary analyses to preserve statistical power. This decision is further supported by the consistent direction and magnitude of diagnostic group differences across age groups. Nonetheless, age-specific comparisons are transparently reported in\nThis study advances our understanding of the immunopathology of sepsis by identifying necroptosis as a key contributor to disease progression and outcome. The identical trends between age groups and the differential expression of necroptosis-related markers among disease states not only enrich our biological insight but also open the door to personalized approaches in critical care. Future studies should explore longitudinal trajectories of necroptosis biomarkers, validate their predictive value in larger, multicenter cohorts, and assess their response to targeted therapies. Interventional trials using RIPK1 inhibitors or caspase-8 modulators could test the therapeutic potential of modulating cell death pathways in sepsis. Additionally, integrating these biomarkers into clinical decision-support tools may enhance early risk stratification and treatment allocation.\nIn conclusion, the findings from this study provide a strong rationale for considering necroptosis not merely as a biological consequence but as a potential driver of systemic inflammation and organ dysfunction in sepsis. Translating these insights into bedside applications represents a promising frontier for improving outcomes in both pediatric and adult critical care populations.\nThis study underscores the pivotal role of necroptosis in the pathophysiology of sepsis, as reflected by elevated levels of RIPK1, IL-1β, and IL-18 and reduced expression of caspase-8 across both pediatric and adult patients. These molecular alterations were associated with increased disease severity and prolonged ICU stay, particularly in septic individuals. The observed upregulation of A20 may represent a compensatory anti-necroinflammatory mechanism. Although the study was not primarily designed for age-stratified comparisons, the inclusion of both age groups allowed for exploratory analysis, revealing consistent biomarker expression patterns across the lifespan. Collectively, these findings support the translational potential of necroptosis-related biomarkers for risk stratification and therapeutic targeting in critically ill patients of all ages.", "content_for_embedding": "Sepsis and systemic inflammatory response syndrome (SIRS) remain leading causes of morbidity and mortality among pediatric and adult patients admitted to intensive care units (ICUs) worldwide. Despite advances in critical care, the underlying mechanisms driving organ dysfunction in these conditions are not fully understood, limiting the development of targeted therapies.\nNecroptosis, a regulated form of necrotic cell death, has emerged as a significant contributor to the pathophysiology of various inflammatory diseases, including sepsis, trauma-induced SIRS, and cardiac conditions. Unlike apoptosis, necroptosis is characterized by the activation of receptor-interacting protein kinases (RIPK)1 and RIPK3, leading to the phosphorylation of mixed lineage kinase domain-like protein (MLKL), which results in cell membrane rupture and the release of pro-inflammatory intracellular contents [\nIn pediatric populations, the role of necroptosis in critical illnesses is increasingly recognized. Experimental studies have shown that pharmacological inhibition of necroptosis can attenuate lung injury and improve survival in neonatal models of sepsis [\nIn this context, specific proteins such as A20, a ubiquitin-editing enzyme, play a central role in modulating inflammation and cell death by inhibiting RIPK3-dependent necroptosis [\nUnderstanding the balance between necroptosis and apoptosis in sepsis is crucial, as it may unveil novel biomarkers for disease severity and potential therapeutic targets [\nThis is a prospective, single-center, observational study conducted at the University General Hospital of Heraklion, encompassing the Intensive Care Unit (ICU), Pediatric Intensive Care Unit (PICU), and Cardiac Intensive Care Unit (CICU). The primary objective was to assess the expression of necroptosis-related proteins in critically ill pediatric and adult patients with sepsis, trauma/surgery-induced SIRS, or heart disease and to compare findings with those from healthy control subjects. The study also aimed to investigate the relationships between necroptosis protein levels and clinical or laboratory severity indices, as well as patient outcomes. This study adhered to STROBE reporting guidelines for observational research.\nThe study enrolled critically ill pediatric and adult patients admitted between June and November 2023. Patients were prospectively categorized into four groups: Sepsis/septic shock (n = 23): patients fulfilling the Sepsis-3 criteria; SIRS (n = 29): patients with non-infectious SIRS due to surgery or trauma; cardiac (n = 19): patients monitored in the CICU for acute heart conditions; and healthy controls (n = 17): age-matched pediatric and adult subjects without known acute or chronic diseases.\nInclusion criteria comprised admission to the ICU, PICU, or CICU with a confirmed diagnosis of sepsis, trauma/SIRS, or acute cardiac disease. Exclusion criteria were the presence of chronic illness (e.g., autoimmune disease, diabetes, and renal or hepatic insufficiency), congenital or acquired immunodeficiencies, malignancies, or current use of immunosuppressive or immunomodulatory therapy.\nClinical and laboratory data were obtained from the patients’ official medical records (both handwritten and electronic). Documentation included the following: diagnostic categorization according to international criteria (sepsis, SIRS, or cardiac); disease severity scores: SOFA (Sequential Organ Failure Assessment), qSOFA, APACHE II (Acute Physiology and Chronic Health Evaluation), PRISM III (Pediatric Risk of Mortality), and PeLOD (Pediatric Logistic Organ Dysfunction), as applicable by age group; and laboratory markers of systemic inflammation and infection (e.g., CRP, procalcitonin, and leukocyte count).\nThis study was approved by the Administrative Board, the Scientific Council of the University General Hospital of Heraklion, and the Bioethics Committee (Approval No. 19050/2023; Date: 26 June 2023). All procedures complied with the principles of the Declaration of Helsinki and the General Data Protection Regulation (GDPR, EU 2016/679). Given the prospective nature of the study and the collection of sensitive clinical and biological data, written informed consent was obtained from all participants or their legal guardians, as required by institutional and legal regulations.\nPeripheral blood samples were collected within the first 24 h following ICU admission and clinical confirmation of sepsis or SIRS. Serum was separated and stored under standardized conditions until analysis.\nQuantification of necroptosis-associated proteins—RIPK1, RIPK3, MLKL, and A20—as well as caspase-8 and proinflammatory cytokines IL-1β and IL-18, was performed using commercially available sandwich ELISA kits (ELK Biotechnology, Denver, CO, USA), according to the manufacturer’s instructions. The assays were conducted in duplicate, and optical density was measured at 450 nm using a microplate reader. Protein concentrations were derived from standard curves based on known calibrator concentrations.\nDetection limits were as follows: RIPK1 (0.063 ng/mL), RIPK3 and MLKL (0.122 ng/mL), A20 (0.17 ng/mL), caspase-8 (0.244 ng/mL), IL-18 (5.9 pg/mL), and IL-1β (5.8 pg/mL). These biomarker levels were analyzed in relation to clinical severity scores (SOFA, qSOFA, APACHE II, PRISM, and PELOD-2) and outcomes and were compared across diagnostic groups and healthy controls.\nThe biomarkers included in this study were selected to represent the central regulators of necroptosis and apoptosis and to capture key mediators of necroinflammatory signaling in sepsis [\nRIPK1, RIPK3, MLKL, and A20 are core components of the necroptosis cascade [\nCaspase-8 was chosen as the apoptosis-related marker due to its dual functionality: It triggers extrinsic apoptosis through FADD activation and simultaneously suppresses necroptosis by cleaving RIPK1 and RIPK3, thus preventing necrosome formation [\nWhile caspase-3 is a downstream executioner of apoptosis, it does not reflect the regulatory balance between apoptotic and necroptotic pathways and was therefore not included in this phase of the study [\nWe included IL-1β and IL-18 because these cytokines are products of inflammasome activation and serve as biomarkers of necroinflammation and pyroptosis—pathways that intersect cytokine-mediated inflammation and programmed necrosis [\nIn contrast, classical pro-inflammatory cytokines such as TNF-α and IL-6 were excluded from our biomarker panel due to their non-specificity, rapid kinetics, and broad elevation in various inflammatory conditions (e.g., trauma, surgery, and non-septic illness), which limit their usefulness as stable indicators of programmed cell death pathways in critically ill patients [\nBy focusing on these markers, in our study, we aimed to dissect the molecular interplay between necroptosis, apoptosis, and necroinflammation during critical illness and sepsis, rather than measuring systemic inflammation signals with limited mechanistic specificity.\nData were recorded in Microsoft Excel and analyzed using SPSS software (version 29.0, IBM Corp., Armonk, NY, USA). Continuous variables were tested for normality and are presented as the mean ± standard deviation (SD) or median with interquartile range (IQR), as appropriate. Categorical variables were expressed as absolute (n) and relative (%) frequencies. Group comparisons for continuous variables were performed using t-tests or one-way ANOVA for normally distributed data and Mann–Whitney U or Kruskal–Wallis tests for non-normally distributed data. Categorical variables were compared using the chi-square test or Fisher’s exact test. Spearman’s rank correlation coefficient was used to assess associations between continuous variables. Backwards stepwise multivariate linear regression was performed to identify independent associations between biomarkers and clinical outcomes. Receiver operating characteristic (ROC) curve analyses were conducted to evaluate the predictive performance of necroptosis biomarkers. A\nThis prospective, single-center clinical study included 88 participants admitted to the Pediatric and Adult Intensive Care Units (ICUs) and the Cardiac Intensive Care Unit at the University Hospital of Heraklion between June and November 2023. The cohort comprised 56 adults (63.6%) and 32 children (36.4%), categorized into four groups: sepsis (26.1%), trauma/surgery (SIRS) (33%), cardiac conditions (21.6%), and healthy controls (19.3%).\nSignificant differences were observed between adults and children in age, body weight, and Body Mass Index (BMI) (\nLaboratory analyses revealed that adults had significantly higher levels of glucose (152 vs. 103 mg/dL,\nAmong ICU patients, RIPK-1 levels were significantly higher in adults (median [IQR]: 20.2 [7.4–46.5] ng/mL) compared to children (6.2 [4.4–16.2] ng/mL;\nIn the healthy control population, RIPK-1 levels did not significantly differ between adults (3.17 ng/mL) and children (2.47 ng/mL;\nComparative analysis across diagnostic categories revealed that patients with sepsis exhibited significantly elevated levels of RIPK-1, IL-1β, and IL-18, along with reduced caspase-8 levels, relative to patients with SIRS or cardiac conditions. Importantly, the exclusion of two adult outliers—one from the sepsis group and one from the SIRS group—did not alter the statistical significance of these intergroup differences.\nAlthough the overall sample size limited power for detailed subgroup analyses, particularly within pediatric diagnostic strata, we conducted additional stratified comparisons. Specifically, age-stratified analyses of diagnostic group differences are presented in\nRIPK-1 and RIPK-3, key mediators of the necroptosis pathway, were elevated in patients with sepsis across both age groups, with RIPK-1 reaching statistical significance (\nIL-1β levels were significantly elevated in all three patient groups—sepsis, SIRS, and cardiac—compared to healthy controls, with similar distributions observed in both adults and children. IL-18 levels followed a comparable pattern among the patient groups, showing significantly higher concentrations in adults relative to healthy controls. However, due to missing data for IL-18 in the pediatric healthy control group, direct comparison in children was not feasible. These biomarker patterns are illustrated in\nCaspase-8 levels were significantly reduced in the sepsis group compared to healthy controls and cardiac patients in both adults and children. The ubiquitin-editing enzyme A20 was significantly elevated in adult sepsis patients compared to healthy controls. However, due to missing data in pediatric sepsis cases, reliable analysis of A20 levels in this subgroup was not feasible. These findings are illustrated in\nRIPK1 levels demonstrated significant positive correlations with APACHE II (rs = 0.39,\nA multivariate linear regression analysis, adjusted for age groups, identified A20 as the sole biomarker independently associated with blood lactate levels (Standardized Coefficient Beta = 0.55,\nReceiver Operating Characteristic analysis demonstrated that RIPK-1 (AUC = 0.81, 95% CI: 0.69–0.93,\nThis prospective study provides novel insights into the expression of necroptosis- and apoptosis-related proteins in critically ill pediatric and adult patients with sepsis, trauma/SIRS, or cardiac disease. We observed prominent necroptosis activation in sepsis—evidenced by elevated RIPK-1, IL-1β, and IL-18 levels and suppressed caspase-8 levels. These biomarker changes correlated with prolonged ICU stay and higher illness severity, underscoring the mechanistic relevance of necroptosis in systemic inflammation and organ dysfunction.\nA particularly striking finding is the marked increase in RIPK-1 levels among septic patients—both adults and children—relative to all other diagnostic groups. As a central mediator of necroptosis, RIPK-1 facilitates inflammatory cell death, especially when caspase-8 activity is diminished [\nEqually significant is the consistent suppression of caspase-8 in both adult and pediatric sepsis cohorts when compared to healthy controls. Caspase-8 plays a critical inhibitory role over RIPK-1-RIPK3 complex formation; thus, its downregulation removes a key checkpoint, enabling necrosome assembly and pro-inflammatory cell death [\nOur study also demonstrated substantially elevated levels of IL-1β and IL-18 in critically ill patients—including those with sepsis—compared to healthy adult and pediatric controls. Notably, IL-18 exhibited the highest discriminative performance in our ROC analysis, suggesting strong diagnostic value. These cytokines are key products of inflammasome activation and serve as potent effectors of necroinflammation, often released during membrane rupture inherent in necroptotic or pyroptotic cell death pathways [\nThe high expression of IL-1β and IL-18 in our septic cohort further supports the involvement of necroptotic and inflammasome-mediated mechanisms in critical illness [\nIn our study, A20 (TNFAIP3)—a ubiquitin-editing enzyme and known negative regulator of necroptosis and NF-κB signaling—was significantly upregulated in adult sepsis patients compared to healthy controls. Notably, higher A20 expression correlated independently with elevated blood lactate levels, a surrogate marker of tissue hypoxia and illness severity.\nA20 is a well-documented regulator of programmed cell death: by removing K63-linked ubiquitin chains from RIPK1, A20 prevents the formation of RIPK1–RIPK3 necrosomes and thereby inhibits necroptosis [\nWhile A20 dynamics are relatively well-characterized in autoimmune and chronic inflammatory conditions, their role in acute sepsis is less explored [\nAlthough adult patients in our cohort exhibited significantly higher RIPK-1 levels than pediatric patients, the distribution of this biomarker across diagnostic categories was remarkably consistent—decreasing progressively through sepsis, SIRS, cardiac cases, and healthy controls in both age groups. Pediatric patients demonstrated higher caspase-8 levels overall; however, within the sepsis group, caspase-8 was suppressed compared to healthy controls in both adults and children. This suggests that while age influences basal expression, the diagnostic patterns of necroptosis pathway activation are parallel in both cohorts.\nAge-related divergence in programmed cell-death regulation has been previously reported. In murine models, T-cell-specific RIPK1 deficiency leads to activation of RIPK3, caspase-8, and mTORC1, driving T-cell senescence and age-related inflammatory phenotypes—an effect modulated by environmental signals [\nInterestingly, among cardiac patients, caspase-8 levels were lower in adults than in children, potentially reflecting chronic inflammatory states. Estrogen deficiency and pre-menopausal hormonal changes exacerbate necroptosis-mediated cardiac injury through RIPK1-signaling in experimental models [\nDespite these biochemical divergences, clinical severity scores and outcomes were comparable between adults and children, with outcome hardpoints demonstrating significant correlations with necroptosis biomolecules in both groups, underscoring the shared underlying biology of critical illness [\nOur ROC analysis revealed that RIPK-1 and IL-18 demonstrated good diagnostic accuracy for sepsis within 24 h of ICU admission—suggesting strong potential as early biomarkers of disease severity. In contrast, caspase-8 showed an inverse predictive pattern, consistent with its anti-necroptotic, potentially protective role in this context. These findings collectively propose that necroptosis-related proteins may serve not only as indicators of severity but also as early therapeutic targets.\nImportantly, in preclinical sepsis models, small-molecule RIPK1 inhibitors, such as necrostatins, have shown promising protective effects: Necrostatin-1 blocks RIPK1 kinase activity, limiting necrosome formation and downstream inflammation in experimental models of systemic inflammation and lung or kidney injury [\nA major strength of this study lies in its prospective design and inclusion of both pediatric and adult cohorts, which allows for a comparative analysis of age-related differences in necroptosis pathways. Additionally, the use of multiple biomarkers related to both necroptosis, apoptosis, and inflammation (RIPK1, RIPK3, MLKL, caspase-8, IL-1β, IL-18, and A20) provides a multidimensional view of programmed cell death in critical illness. The application of ROC analysis also adds a translational aspect, supporting the diagnostic and prognostic relevance of these molecules.\nHowever, several limitations must be acknowledged. First, although the overall sample size was sufficient to detect significant trends, subgroup analyses stratified by age and diagnostic category may have been underpowered, particularly within pediatric strata. Given the absence of statistically significant differences in RIPK3, MLKL, A20, IL-1β, or IL-18 between adults and children, and the lack of age-related effect modification in biomarker–outcome correlations, biomarker data were pooled in the primary analyses to preserve statistical power. This decision is further supported by the consistent direction and magnitude of diagnostic group differences across age groups. Nonetheless, age-specific comparisons are transparently reported in\nThis study advances our understanding of the immunopathology of sepsis by identifying necroptosis as a key contributor to disease progression and outcome. The identical trends between age groups and the differential expression of necroptosis-related markers among disease states not only enrich our biological insight but also open the door to personalized approaches in critical care. Future studies should explore longitudinal trajectories of necroptosis biomarkers, validate their predictive value in larger, multicenter cohorts, and assess their response to targeted therapies. Interventional trials using RIPK1 inhibitors or caspase-8 modulators could test the therapeutic potential of modulating cell death pathways in sepsis. Additionally, integrating these biomarkers into clinical decision-support tools may enhance early risk stratification and treatment allocation.\nIn conclusion, the findings from this study provide a strong rationale for considering necroptosis not merely as a biological consequence but as a potential driver of systemic inflammation and organ dysfunction in sepsis. Translating these insights into bedside applications represents a promising frontier for improving outcomes in both pediatric and adult critical care populations.\nThis study underscores the pivotal role of necroptosis in the pathophysiology of sepsis, as reflected by elevated levels of RIPK1, IL-1β, and IL-18 and reduced expression of caspase-8 across both pediatric and adult patients. These molecular alterations were associated with increased disease severity and prolonged ICU stay, particularly in septic individuals. The observed upregulation of A20 may represent a compensatory anti-necroinflammatory mechanism. Although the study was not primarily designed for age-stratified comparisons, the inclusion of both age groups allowed for exploratory analysis, revealing consistent biomarker expression patterns across the lifespan. Collectively, these findings support the translational potential of necroptosis-related biomarkers for risk stratification and therapeutic targeting in critically ill patients of all ages.", "topic": "Diagnostic"}
{"pmid": "40594632", "pmcid": "12224546", "title": "High-speed whole-brain imaging in ", "publication_year": "N/A", "abstract": "Recent advances in brain-wide recordings of small animals such as worms, fish, and flies have revealed complex activity involving large populations of neurons. In the", "full_text": "Across model systems, there has been a major push to develop methods that capture large-scale, high-resolution neural activity distributed across the brain (\nIn flies, single-photon light-sheet approaches such as SCAPE have achieved large-volume, high-speed (10 volumes per second) imaging (\nThe recent development of two-photon light-bead microscopy (LBM) (\nTo date, LBM has only been applied to the mouse cortex. However, LBM has the potential to address the shortcomings of existing volumetric calcium imaging methods used in small animals and, in particular, could have an immediate impact in the case of Drosophila melanogaster which would benefit from improvements in both the speed and the fraction of the brain being imaged. This would also enable imaging of faster genetically encoded voltage indicators (\nLBM was originally developed as an added module to the 2P-RAM microscope, replacing the original microscope remote focusing capability with the LBM optical module. Its original configuration, which uses only 120 pixels per line, would not translate well to the\nLight-Bead Microscopy (LBM) (\nOur LBM implementation, which configuration is depicted in the\nOur comparative system, a piezo-driven microscope built according to the current state-of-the-art two-photon approach for\nIn what follows, we compare the capabilities of the two volumetric imaging approaches to measure the rapid and widespread neural dynamics associated with auditory stimuli. We imaged head-fixed female flies walking on an air-supported spherical treadmill and presented auditory stimuli in the form of artificial courtship song pulse trains; male flies generate courtship songs comprising two main modes, sine and pulse (\nFirst, we presented pulse trains at different train repetition frequencies varying from 0.25 to 5 Hz (\nTo extract neural activity correlated with the auditory stimulus, for each ROI, we calculated the correlation coefficient between calcium signal and a filtered auditory stimulus (\nTo determine whether LBM could extract fast timescale activity, we inspected the 0.5% ROIs with the highest correlation to the stimulus (\nMean activity of ROIs with the highest stimulus-correlated activity extracted from LBM imaging tracked the auditory stimulus at all frequencies presented (\nNext, we investigated whether LBM’s high frame rate could resolve even faster dynamics, namely neural responses to the courtship pulse song inter-pulse interval (IPI). This song feature varies across species (\nWhile the above analyses suggests that GCaMP8m signals can track individual song pulses, they do not reveal the shape of those responses. To explore this, we calculated a pulse-triggered average by combining and time-aligning all activity samples within ± 18ms of all pulses across the same subset of ROIs and found that the reconstructed activity peaked at ~9 ms following each pulse (\nFinally, because we imaged neural activity while female flies walked on an air-supported treadmill (\nThe LBM method, with its reliance on time-multiplexed two-photon foci, is capable of high rate volumetric imaging. With the proper combination of laser, scanners, and optical components, we have demonstrated it can capture activity simultaneously throughout the entire fly brain.\nLBM speed is fundamentally limited only by the fluorescence lifetime of the probe, which means that information cannot be extracted from the specimen at a faster rate. However, different LBM configurations can favor different applications. Of particular importance is the choice of resonant scanner frequency and laser repetition rate, parameters which, respectively, fix the number of pixels per line, and the number of light-beads. The original LBM implementation (\nIn the future, several refinements of the microscope could further improve our ability to extract neuronal dynamics. These include increasing the signal-to-noise ratio (SNR) of the images and improving control of the light-beads power distribution. With the power used in our experiments, images acquired are typically in the single-photon per pixel regime: most pixels result in zero to only a few photons being detected. Future brighter probes will, of course, be beneficial. Fast detection systems with lower noise, such as Hybrid Photo-Detectors (HPD) which differentiate events with zero, one, and multiple photons better than photomultiplier tubes (PMTs) should in principle increase the SNR. Their higher speed will also help reduce further the low cross-talk (\nWe have shown that our LBM implementation enables volumetric imaging of the entire\nThe ability to extract neural activity across the entire brain with high spatial and temporal resolution represents a significant technological advance that opens new avenues for studying how neural circuits process fast and complex stimuli or generate behavior (\n3–6 day old female\nFemale flies were chilled on ice, then placed in a Peltier-cooled “sarcophagus” held at 4°C, with the head of the animal placed in a 3D printed holder. The head of the fly was tilted at a 80° angle relative to the thorax and restrained with UV-cured glue. The arista were exposed so that the flies were able to hear. The holder was then filled with saline (103 mM NaCl, 3 mM KCl, 5 mMTES, 1 mM NaH\nAuditory stimuli were delivered in a localized manner using a headphone speaker and sound tube, as previously described (\nTo synchronize the imaging computer with the stimulus and behavior computer, we employed an Inter-Integrated Circuit (I2C) controlled by a NI USB-8452 interface. At a rate of 100 Hz, a digital signal containing the Fictrac frame number was sent from the stimulus and behavior computer to the imaging computer. This metadata is directly embedded in the image files generated by Scanimage during imaging.\nWe modified the optical assembly design described in Demas et al., 2021(\nThe axial multiplexing module, which splits the laser beam into multiple beams, is composed of two ring cavities. The first optical cavity includes four concave mirrors (500 mm focal length) positioned such that upon each circulation through the cavity the beam accumulates additional convergence. A partial beam splitter placed in the beam path allows a fraction ( 9%) of the beam to escape the cavity every time it circulates, generating a series of spatially separated and temporally offset beams. This set of beams is then sent through a half-wave plate and a polarizing beam-splitter cube. A high portion of the power is transmitted through the cube and sent toward the microscope objective where it forms the first and deepest set of light beads. The portion reflected by the polarizing beam-splitter cube is traveling through the second optical cavity, where a large amount of convergence is added and the pulses are delayed by another ~7 ns. This second set of beams is returned to the microscope path to form the second set of light beads, located directly above the first one, and therefore probing the most shallow layers of the tissue.\nThe separation between imaging planes (\nLBM requires a laser with a lower repetition rate than that used in a conventional two-photon microscope. We chose a 960nm laser (White Dwarf, Class5) operating at a repetition rate of 5MHz. As demonstrated in Demas, a separation of ~ 7ns between pulses is sufficient to properly identify the fluorescence signal source among the different beads. Applying the same strategy, up to 28 different light beads can be generated simultaneously in our system. Coupling this laser with a 8 kHz resonant galvo scanner (CRS8, Cambridge Technologies), we can achieve a maximum of 226 pixels per scan line. Recording images with 512 lines results in a volumetric rate of ~28 Hz. Reducing the number of scan lines gives us a proportionally faster frame rate.\nBy orienting the animal’s body axis parallel to the resonant scanner axis, the 226 by 512 pixels image format matches the aspect ratio of the fly brain. Consequently, a high spatial density sampling is obtained in the two directions of the planes with an average pixel size of 1.3μm on both axes.\nOur acquisition system includes a High-Speed vDAQ (mbfbioscience), digitalizing the signal at a rate of 2 GHz. This high sampling rate allow to differentiate signal coming from one pulse (one plane) from the signal of the next pulse 7 ns later (next plane). However, given temporal decay of fluorescent signals is exponential, some amount of cross-talk between planes is unavoidable. Fortunately, it can be reduced by integrating only the sampling time points which coincide with the peak response to each laser pulse. The widths and location of each of the 28 signal integration windows were set to capture these peaks. The remaining cross-talk (see\nThe microscope included a laser reflecting dichroic (cutoff 765nm, Alluxa), to separate excitation and detection paths. The detection path consisted of a first filter removing the spurious near-infrared laser light (FF01–720/SP, Semrock) followed by a beamsplitter (FF555-Di03, Semrock) separating green and red fluorescent light further individually filtered (green: FF02–525/40, Red: FF01–593/40, Semrock). Photons were detected with two GAsP photomultiplier tubes (H10770PA-40, Hamamatsu).\nFor our comparisons with conventional piezo-driven 2-photon imaging, we carried out experiments on a custom-built scanning microscope equipped a 8kHz resonant scanner, a 80MHz repetition rate Ti:sapphire laser (Chameleon Ultra II - Coherent) set to 920 nm and a 20x water immersion objective (Leica 20x HCX APO 1.0 NA) mounted on a 400um travel piezo objective-mount (Physik Instrumente). Dissected flies were placed below the objective and perfused with saline. The microscope included a laser transmitting dichroic (FF665-DI02 Multiphoton shortpass Dichroic, Semrock). The detection path consisted of a near-infrared filter (FF01–680/SP, Semrock), a 562 nm beamsplitter (FF562-DI03, Semrock) which separated green and red channels, with a 525/45nm filter (FF01–525/45, Semrock) into the green channel path and a 600/52nm filter (FF01–600/52, Semrock) in the red channel. Photons were detected with two GAsP photomultiplier tubes (Hamamatsu H10770PA-40-S1). For functional imaging, we acquired whole-brain volumes with 256 × 128 × 50 XYZ voxels of size 2.4 × 2.4 × 5 μm, and a volumetric rate of 2.2 Hz. We also employed this microscope to capture high-resolution anatomical stacks of all flies after functional imaging conducted either by LB or piezo-driven 2P recordings. We recorded a total of 50 whole-brain volumes 1024 × 512 × 150 XYZ voxels of size 0.6 × 0.6 × 2 μm.\nFor both 28 Hz LBM and piezo-driven 2P functional recording, each frame of the anatomical (red) channel was motion-corrected by using ANTS(\n48,000 (LB) and 47,000 (piezo-driven 2p) ROIs were extracted in each trial of each animal, then z-scored to account for differences in baseline fluorescence across animals. To identify stimulus-correlated ROIs, we first generated a target template by binarizing the stimulus sequence and convolving it with a kernel with the temporal properties of GCaMP6f (50ms rise time and 140ms decay time(\nDiscrete Fourier transforms were computed on mean-subtracted activity data using scipy’s ‘fft’ function based on the fast Fourier transform algorithm (\nTo reconstruct the pulse triggered average, we identified all time points within a ±18 ms window around each pulse and extracted the corresponding fluorescence values in auditory ROIs, building a distribution of activity around each pulse. The pulse triggered average was plotted by taking the average fluorescence value in each 0.9 ms bin. This approach was based on (\nIn\nBoth LBM and conventional 2P microscopes were controlled using ScanImage 2022. The auditory stimulus was presented using the FlyVR software package, available on Github:", "content_for_embedding": "Across model systems, there has been a major push to develop methods that capture large-scale, high-resolution neural activity distributed across the brain (\nIn flies, single-photon light-sheet approaches such as SCAPE have achieved large-volume, high-speed (10 volumes per second) imaging (\nThe recent development of two-photon light-bead microscopy (LBM) (\nTo date, LBM has only been applied to the mouse cortex. However, LBM has the potential to address the shortcomings of existing volumetric calcium imaging methods used in small animals and, in particular, could have an immediate impact in the case of Drosophila melanogaster which would benefit from improvements in both the speed and the fraction of the brain being imaged. This would also enable imaging of faster genetically encoded voltage indicators (\nLBM was originally developed as an added module to the 2P-RAM microscope, replacing the original microscope remote focusing capability with the LBM optical module. Its original configuration, which uses only 120 pixels per line, would not translate well to the\nLight-Bead Microscopy (LBM) (\nOur LBM implementation, which configuration is depicted in the\nOur comparative system, a piezo-driven microscope built according to the current state-of-the-art two-photon approach for\nIn what follows, we compare the capabilities of the two volumetric imaging approaches to measure the rapid and widespread neural dynamics associated with auditory stimuli. We imaged head-fixed female flies walking on an air-supported spherical treadmill and presented auditory stimuli in the form of artificial courtship song pulse trains; male flies generate courtship songs comprising two main modes, sine and pulse (\nFirst, we presented pulse trains at different train repetition frequencies varying from 0.25 to 5 Hz (\nTo extract neural activity correlated with the auditory stimulus, for each ROI, we calculated the correlation coefficient between calcium signal and a filtered auditory stimulus (\nTo determine whether LBM could extract fast timescale activity, we inspected the 0.5% ROIs with the highest correlation to the stimulus (\nMean activity of ROIs with the highest stimulus-correlated activity extracted from LBM imaging tracked the auditory stimulus at all frequencies presented (\nNext, we investigated whether LBM’s high frame rate could resolve even faster dynamics, namely neural responses to the courtship pulse song inter-pulse interval (IPI). This song feature varies across species (\nWhile the above analyses suggests that GCaMP8m signals can track individual song pulses, they do not reveal the shape of those responses. To explore this, we calculated a pulse-triggered average by combining and time-aligning all activity samples within ± 18ms of all pulses across the same subset of ROIs and found that the reconstructed activity peaked at ~9 ms following each pulse (\nFinally, because we imaged neural activity while female flies walked on an air-supported treadmill (\nThe LBM method, with its reliance on time-multiplexed two-photon foci, is capable of high rate volumetric imaging. With the proper combination of laser, scanners, and optical components, we have demonstrated it can capture activity simultaneously throughout the entire fly brain.\nLBM speed is fundamentally limited only by the fluorescence lifetime of the probe, which means that information cannot be extracted from the specimen at a faster rate. However, different LBM configurations can favor different applications. Of particular importance is the choice of resonant scanner frequency and laser repetition rate, parameters which, respectively, fix the number of pixels per line, and the number of light-beads. The original LBM implementation (\nIn the future, several refinements of the microscope could further improve our ability to extract neuronal dynamics. These include increasing the signal-to-noise ratio (SNR) of the images and improving control of the light-beads power distribution. With the power used in our experiments, images acquired are typically in the single-photon per pixel regime: most pixels result in zero to only a few photons being detected. Future brighter probes will, of course, be beneficial. Fast detection systems with lower noise, such as Hybrid Photo-Detectors (HPD) which differentiate events with zero, one, and multiple photons better than photomultiplier tubes (PMTs) should in principle increase the SNR. Their higher speed will also help reduce further the low cross-talk (\nWe have shown that our LBM implementation enables volumetric imaging of the entire\nThe ability to extract neural activity across the entire brain with high spatial and temporal resolution represents a significant technological advance that opens new avenues for studying how neural circuits process fast and complex stimuli or generate behavior (\n3–6 day old female\nFemale flies were chilled on ice, then placed in a Peltier-cooled “sarcophagus” held at 4°C, with the head of the animal placed in a 3D printed holder. The head of the fly was tilted at a 80° angle relative to the thorax and restrained with UV-cured glue. The arista were exposed so that the flies were able to hear. The holder was then filled with saline (103 mM NaCl, 3 mM KCl, 5 mMTES, 1 mM NaH\nAuditory stimuli were delivered in a localized manner using a headphone speaker and sound tube, as previously described (\nTo synchronize the imaging computer with the stimulus and behavior computer, we employed an Inter-Integrated Circuit (I2C) controlled by a NI USB-8452 interface. At a rate of 100 Hz, a digital signal containing the Fictrac frame number was sent from the stimulus and behavior computer to the imaging computer. This metadata is directly embedded in the image files generated by Scanimage during imaging.\nWe modified the optical assembly design described in Demas et al., 2021(\nThe axial multiplexing module, which splits the laser beam into multiple beams, is composed of two ring cavities. The first optical cavity includes four concave mirrors (500 mm focal length) positioned such that upon each circulation through the cavity the beam accumulates additional convergence. A partial beam splitter placed in the beam path allows a fraction ( 9%) of the beam to escape the cavity every time it circulates, generating a series of spatially separated and temporally offset beams. This set of beams is then sent through a half-wave plate and a polarizing beam-splitter cube. A high portion of the power is transmitted through the cube and sent toward the microscope objective where it forms the first and deepest set of light beads. The portion reflected by the polarizing beam-splitter cube is traveling through the second optical cavity, where a large amount of convergence is added and the pulses are delayed by another ~7 ns. This second set of beams is returned to the microscope path to form the second set of light beads, located directly above the first one, and therefore probing the most shallow layers of the tissue.\nThe separation between imaging planes (\nLBM requires a laser with a lower repetition rate than that used in a conventional two-photon microscope. We chose a 960nm laser (White Dwarf, Class5) operating at a repetition rate of 5MHz. As demonstrated in Demas, a separation of ~ 7ns between pulses is sufficient to properly identify the fluorescence signal source among the different beads. Applying the same strategy, up to 28 different light beads can be generated simultaneously in our system. Coupling this laser with a 8 kHz resonant galvo scanner (CRS8, Cambridge Technologies), we can achieve a maximum of 226 pixels per scan line. Recording images with 512 lines results in a volumetric rate of ~28 Hz. Reducing the number of scan lines gives us a proportionally faster frame rate.\nBy orienting the animal’s body axis parallel to the resonant scanner axis, the 226 by 512 pixels image format matches the aspect ratio of the fly brain. Consequently, a high spatial density sampling is obtained in the two directions of the planes with an average pixel size of 1.3μm on both axes.\nOur acquisition system includes a High-Speed vDAQ (mbfbioscience), digitalizing the signal at a rate of 2 GHz. This high sampling rate allow to differentiate signal coming from one pulse (one plane) from the signal of the next pulse 7 ns later (next plane). However, given temporal decay of fluorescent signals is exponential, some amount of cross-talk between planes is unavoidable. Fortunately, it can be reduced by integrating only the sampling time points which coincide with the peak response to each laser pulse. The widths and location of each of the 28 signal integration windows were set to capture these peaks. The remaining cross-talk (see\nThe microscope included a laser reflecting dichroic (cutoff 765nm, Alluxa), to separate excitation and detection paths. The detection path consisted of a first filter removing the spurious near-infrared laser light (FF01–720/SP, Semrock) followed by a beamsplitter (FF555-Di03, Semrock) separating green and red fluorescent light further individually filtered (green: FF02–525/40, Red: FF01–593/40, Semrock). Photons were detected with two GAsP photomultiplier tubes (H10770PA-40, Hamamatsu).\nFor our comparisons with conventional piezo-driven 2-photon imaging, we carried out experiments on a custom-built scanning microscope equipped a 8kHz resonant scanner, a 80MHz repetition rate Ti:sapphire laser (Chameleon Ultra II - Coherent) set to 920 nm and a 20x water immersion objective (Leica 20x HCX APO 1.0 NA) mounted on a 400um travel piezo objective-mount (Physik Instrumente). Dissected flies were placed below the objective and perfused with saline. The microscope included a laser transmitting dichroic (FF665-DI02 Multiphoton shortpass Dichroic, Semrock). The detection path consisted of a near-infrared filter (FF01–680/SP, Semrock), a 562 nm beamsplitter (FF562-DI03, Semrock) which separated green and red channels, with a 525/45nm filter (FF01–525/45, Semrock) into the green channel path and a 600/52nm filter (FF01–600/52, Semrock) in the red channel. Photons were detected with two GAsP photomultiplier tubes (Hamamatsu H10770PA-40-S1). For functional imaging, we acquired whole-brain volumes with 256 × 128 × 50 XYZ voxels of size 2.4 × 2.4 × 5 μm, and a volumetric rate of 2.2 Hz. We also employed this microscope to capture high-resolution anatomical stacks of all flies after functional imaging conducted either by LB or piezo-driven 2P recordings. We recorded a total of 50 whole-brain volumes 1024 × 512 × 150 XYZ voxels of size 0.6 × 0.6 × 2 μm.\nFor both 28 Hz LBM and piezo-driven 2P functional recording, each frame of the anatomical (red) channel was motion-corrected by using ANTS(\n48,000 (LB) and 47,000 (piezo-driven 2p) ROIs were extracted in each trial of each animal, then z-scored to account for differences in baseline fluorescence across animals. To identify stimulus-correlated ROIs, we first generated a target template by binarizing the stimulus sequence and convolving it with a kernel with the temporal properties of GCaMP6f (50ms rise time and 140ms decay time(\nDiscrete Fourier transforms were computed on mean-subtracted activity data using scipy’s ‘fft’ function based on the fast Fourier transform algorithm (\nTo reconstruct the pulse triggered average, we identified all time points within a ±18 ms window around each pulse and extracted the corresponding fluorescence values in auditory ROIs, building a distribution of activity around each pulse. The pulse triggered average was plotted by taking the average fluorescence value in each 0.9 ms bin. This approach was based on (\nIn\nBoth LBM and conventional 2P microscopes were controlled using ScanImage 2022. The auditory stimulus was presented using the FlyVR software package, available on Github:", "topic": "Diagnostic"}
{"pmid": "40590093", "pmcid": "12304837", "title": "Lipid‐associated macrophages are more abundant in subcutaneous than visceral adipose tissue in patients with obesity", "publication_year": "N/A", "abstract": "", "full_text": "\n\nSubcutaneous and visceral adipose tissue (SAT and VAT, respectively) have different biological characteristics.\nObesity triggers adipose tissue remodeling and immune cells infiltration.\n\nWe demonstrate that white adipose tissue–infiltrated CD11b\nWe also observe that SAT‐infiltrated CD11b\n\nOur results regarding how LAMs (phagocytic cells with a lipid‐handling capacity) are more present in SAT to likely address correct adipose tissue remodeling and endocrine function could open a new therapeutic window to fight against obesity‐related metabolic complications.\nObesity is a chronic, relapsing, progressive disease with a multifactorial etiology [\nWhite adipose tissue (WAT) is an organ responsible for energy storage and comprises a heterogeneous cell population, such as preadipocytes, adipocytes, fibroblasts, and immune cells [\nIt has been broadly described that an increase in WAT hypertrophy and hyperplasia causes local and systemic, low‐grade, chronic inflammation, or meta‐inflammation, that triggers the development of severe metabolic diseases [\nPrevious single‐cell studies have characterized the cellular composition of immune cells and furthered our understanding of their involvement in obesity [\nIt has been reported that individuals with obesity show differences in adipose tissue‐infiltrated macrophages (ATMs) and their surface markers compared with normal‐weight individuals [\nAlthough the dynamics of WAT‐infiltrated immune cells during obesity are well documented, the molecular mechanisms regulating immune and metabolic dysfunction and their depot characterization within human WAT remain poorly understood. Here, we focus on WAT‐infiltrated CD11b\nThe study was approved (code PI‐18‐078) by the ethical committee of the Hospital Germans Trias i Pujol (Badalona, Spain) and the ethical committee from Alcorcón Foundation University Hospital and Rey Juan Carlos University and was conducted in accordance with the guidelines of the Helsinki convention. Participants gave written informed consent before clinical data collection.\nThree different cohorts of patients were enrolled (Table\nClinical parameters of cohorts 1, 2, and 3.\n\nAbbreviations: BS, bariatric surgery; CRP, C‐reactive protein; HbA1c, glycated hemoglobin; HDL‐c, high‐density lipoprotein cholesterol; HOMA‐IR, homeostasis model assessment of insulin resistance; LDL‐c, low‐density lipoprotein cholesterol; NS, not significant; Sig., statistical significance; TAG, triglycerides; Total‐c; total cholesterol.\n\n\n\n\nSerum samples were collected after 12‐h fasting and frozen at −20 °C at baseline and at 6 and 24 months after BS. Glucose and insulin levels, as well as lipid profiles (total cholesterol, high‐density lipoprotein cholesterol, low‐density lipoprotein cholesterol, and triglycerides), were measured in the certified core clinical laboratory. Homeostasis model assessment of insulin resistance (HOMA‐IR) was calculated as:\nImmediately after surgical extraction, isolation of the stromal vascular fraction (SVF) from SAT and VAT biopsies was performed under sterile conditions. First, biopsies were washed with Hanks’ Balanced Salt Solution (Capricorn Scientific, HBSS‐2A), minced using a scalpel, and digested using 1 mg/mL of collagenase NB4 (SERVA, S1745401) in Hanks’ Balanced Salt Solution. The digestion was performed at 37°C for 1 h with stirring up every 10 min. Once the tissue was totally digested, digestion was stopped by putting the samples in ice. Then, the solution containing the SVF was filtered through a 100‐μm filter and centrifuged at 500\nMagnetic labeling and separation were performed using a MidiMACS kit with LS column (Miltenyi Biotec, 130‐042‐301) according to the manufacturer's instructions. The eluted fraction enriched with CD11b\nThe aliquots from SAT and VAT were labeled with 7‐AAD (Miltenyi Biotec, 130‐111‐568) and CD11b (Miltenyi Biotec, 130‐113‐797) and incubated with CountBright counting beads (Invitrogen,\nThe total quantity and integrity of the extracted RNA were evaluated using a Bioanalyzer system (Nano 6000 assay on Agilent's 2100 Bioanalyzer). RNA from each sample was used for microarray hybridization using Affymetrix array (Clariom D Assay, human, Thermo Fisher Scientific, Inc.) and processed using the Applied Biosystems GeneChip System 3000 (Thermo Fisher Scientific).\nSample processing was performed at the High Technology Unit facility at Vall d'Hebron Institut de Recerca in Barcelona, Spain, selecting samples with RNA concentrations ≥3 μg and RNA integrity with numbers >7. The cohort of individuals was clustered by glycemia levels and initially assigned to two groups: glycemia ≤100 mg/dL and glycemia >100 mg/dL.\nAll statistical analyses of microarray data were performed using the R‐based software, R version 4.0.3 (R Project for Statistical Computing). Quality control was performed using the arrayQualityMetrics package 3.64 (Bioconductor). Background correction, probe set summarization, and normalization were performed using the oligo package with the most up‐to‐date annotation in Bioconductor version 3.12. A paired‐sample design comparing VAT and SAT from the same individual was applied. Subsequent differential expression analysis was performed using the limma package at the gene level, focusing on known genes (with assigned gene symbols). Transcripts were considered for further analyses if they matched the double criteria or false detection rate (FDR) of <0.05 and log (fold change) VAT versus SAT of >1.5. Exploratory inference of putatively affected biological functions was performed using GOrilla (Multi Knowledge Project) v2, harnessing Gene Ontology categories to perform pathway analyses. In‐depth functional enrichment analyses were performed using Gene Set Enrichment Analysis and the results visualized using the Enrichment Map tool in Cytoscape (Cytoscape Consortium) 2.10.3. Pre‐ranked–based analyses were performed using ranking by log2ratio or signed −log10\nWhole VAT and SAT samples were obtained from cohort 2 at the time of surgery. SAT was obtained from cohort 3 at the time of surgery and 3 months after the intervention. Total RNA was then extracted from whole adipose samples using a standard column‐affinity based methodology (NucleoSpin RNA II, MACHEREY‐NAGEL). An amount of 500 ng of total RNA was retro‐transcribed into complementary DNA (cDNA) using random hexamer primers and MultiScribe Reverse Transcriptase (TaqMan Reverse Transcription Reagents, ThermoFisher Scientific), following the manufacturer's instructions. Platinum Quantitative PCR SuperMix‐UDG with ROX reagent (ThermoFisher Scientific) was used as master mix reagent, and expression levels of each gene of interest were assessed with the specific TaqMan probes (ThermoFisher Scientific). As an endogenous control, peptidylprolyl isomerase A was used. Quantitative reverse transcriptase‐polymerase chain reaction (RT‐PCR) was carried out in an ABI PRISM 7900HT Sequence Detection System (ThermoFisher Scientific) using the following conditions: 2 min at 50 °C, 10 min at 95 °C followed by 40 cycles of 15 s at 95 °C, and 1 min at 60 °C. Relative mRNA levels were determined using the 2\nThe statistical analyses performed indicate a comparison between controls and treatments of each experimental model. One‐way ANOVA was performed when more than two groups were compared, followed by Tukey's post hoc analysis. Correlation analyses were conducted by age‐ and sex‐adjusted multiple linear regression. Multicollinearity was assessed by calculating the variance inflation factor (VIF) for each covariables in all regressions; no significant multicollinearity was detected in any case (VIF < 1.5). Standardized multiple regression model coefficients (\nThe clinical data of the cohort of individuals with severe obesity analyzed in this study are described in Table\nDifferential gene expression analyses of CD11b\nDifferential gene expression summary results between VAT‐ and SAT‐derived CD11b\nBioinformatic analysis was performed to identify the most abundant subtype of macrophages in each depot according to the gene expression levels of different markers. Following the classification described in the current literature [\nOur results indicated that SAT‐isolated CD11b\nVolcano plot with significant differentially expressed genes between VAT‐ and SAT‐derived CD11b\nFinally, when we analyzed the expression levels of the aforementioned LAM marker genes in cohort 2, we observed that they were induced in adipose tissue from patients with obesity compared with lean controls. Moreover, gene expression of these LAM markers was higher in SAT than in VAT (Figure\nRelative transcript levels of selected LAM marker genes and mean relative levels (LAM marker score) in SAT and VAT from C or OB from cohort 2. Data are expressed as mean ± SEM and referenced to C SAT. *\nWhen we analyzed the gene expression of the main LAM markers in our cohort 3 (Table\nAge‐ and sex‐adjusted multiple linear regression analyses for expression levels of selected LAM marker genes and clinical variables of interest in cohort 3 at baseline or 3 months after BS.\n\nAbbreviations: BS, bariatric surgery; CRP, C‐reactive protein; GGT, gamma‐glutamyl aminotransferase; GOT, glutamic‐oxaloacetic transaminase/aspartate aminotransferase; GPT, glutamic‐pyruvic transaminase/alanine aminotransferase; Hb, total hemoglobin; Hb1Ac, glycated hemoglobin; HDL‐c, high‐density lipoprotein cholesterol; HOMA‐IR, homeostasis model assessment of insulin resistance; LAM, lipid‐associated macrophage; LDL‐c, low‐density lipoprotein cholesterol; PD, pre‐dietary intervention; PS, pre‐surgery; TAG, triglycerides; Total‐c, total cholesterol.\nBold: Statistically significant adjusted correlations (\nFinally, when we compared the gene expression levels of LAM markers at baseline and the clinical parameters 3 months after surgery to explore the potential prognosis of our markers in the success of the surgery, an inverse correlation was found between\nThis study is the first to report transcriptomic analysis of SAT‐ and VAT‐infiltrated CD11b\nSAT‐infiltrated CD11b\nPrevious studies showing the cellular landscape of human adipose tissue indicated a higher abundance of LAMs in individuals with obesity compared with lean individuals [\nIn the present study, VAT‐infiltrated CD11b\nConsidering that having a higher amount of VAT is a cardiometabolic risk factor [\nIn addition, considering that the lack of\nIn conclusion, the present study demonstrated that WAT‐infiltrated CD11b\nThis work was supported by grant PID2020‐114953RB‐C21 funded by Ministerio de Ciencia, Innovación y Universidades, Agencia Estatal de Investigación, and the European Regional Development Fund (ERDF), by grant PID2023‐148783OB‐I00 funded by Ministerio de Ciencia, Innovación y Universidades, Agencia Estatal de Investigación, and ERDF, by grant CB06/03/0001 funded by Centro de Investigación Biomédica en Red Fisiopatología de la Obesidad y Nutrición and Instituto de Salud Carlos III, by grant 2021SGR00367 funded by the Government of Catalonia to Laura Herrero, and by grants PI17/00145 and PI20/00807 funded by Instituto de Salud Carlos III and ERDF to David Sánchez‐Infantes. Rubén Cereijo is a Serra Húnter Fellow (Government of Catalonia).\n\n", "content_for_embedding": "\n\nSubcutaneous and visceral adipose tissue (SAT and VAT, respectively) have different biological characteristics.\nObesity triggers adipose tissue remodeling and immune cells infiltration.\n\nWe demonstrate that white adipose tissue–infiltrated CD11b\nWe also observe that SAT‐infiltrated CD11b\n\nOur results regarding how LAMs (phagocytic cells with a lipid‐handling capacity) are more present in SAT to likely address correct adipose tissue remodeling and endocrine function could open a new therapeutic window to fight against obesity‐related metabolic complications.\nObesity is a chronic, relapsing, progressive disease with a multifactorial etiology [\nWhite adipose tissue (WAT) is an organ responsible for energy storage and comprises a heterogeneous cell population, such as preadipocytes, adipocytes, fibroblasts, and immune cells [\nIt has been broadly described that an increase in WAT hypertrophy and hyperplasia causes local and systemic, low‐grade, chronic inflammation, or meta‐inflammation, that triggers the development of severe metabolic diseases [\nPrevious single‐cell studies have characterized the cellular composition of immune cells and furthered our understanding of their involvement in obesity [\nIt has been reported that individuals with obesity show differences in adipose tissue‐infiltrated macrophages (ATMs) and their surface markers compared with normal‐weight individuals [\nAlthough the dynamics of WAT‐infiltrated immune cells during obesity are well documented, the molecular mechanisms regulating immune and metabolic dysfunction and their depot characterization within human WAT remain poorly understood. Here, we focus on WAT‐infiltrated CD11b\nThe study was approved (code PI‐18‐078) by the ethical committee of the Hospital Germans Trias i Pujol (Badalona, Spain) and the ethical committee from Alcorcón Foundation University Hospital and Rey Juan Carlos University and was conducted in accordance with the guidelines of the Helsinki convention. Participants gave written informed consent before clinical data collection.\nThree different cohorts of patients were enrolled (Table\nClinical parameters of cohorts 1, 2, and 3.\n\nAbbreviations: BS, bariatric surgery; CRP, C‐reactive protein; HbA1c, glycated hemoglobin; HDL‐c, high‐density lipoprotein cholesterol; HOMA‐IR, homeostasis model assessment of insulin resistance; LDL‐c, low‐density lipoprotein cholesterol; NS, not significant; Sig., statistical significance; TAG, triglycerides; Total‐c; total cholesterol.\n\n\n\n\nSerum samples were collected after 12‐h fasting and frozen at −20 °C at baseline and at 6 and 24 months after BS. Glucose and insulin levels, as well as lipid profiles (total cholesterol, high‐density lipoprotein cholesterol, low‐density lipoprotein cholesterol, and triglycerides), were measured in the certified core clinical laboratory. Homeostasis model assessment of insulin resistance (HOMA‐IR) was calculated as:\nImmediately after surgical extraction, isolation of the stromal vascular fraction (SVF) from SAT and VAT biopsies was performed under sterile conditions. First, biopsies were washed with Hanks’ Balanced Salt Solution (Capricorn Scientific, HBSS‐2A), minced using a scalpel, and digested using 1 mg/mL of collagenase NB4 (SERVA, S1745401) in Hanks’ Balanced Salt Solution. The digestion was performed at 37°C for 1 h with stirring up every 10 min. Once the tissue was totally digested, digestion was stopped by putting the samples in ice. Then, the solution containing the SVF was filtered through a 100‐μm filter and centrifuged at 500\nMagnetic labeling and separation were performed using a MidiMACS kit with LS column (Miltenyi Biotec, 130‐042‐301) according to the manufacturer's instructions. The eluted fraction enriched with CD11b\nThe aliquots from SAT and VAT were labeled with 7‐AAD (Miltenyi Biotec, 130‐111‐568) and CD11b (Miltenyi Biotec, 130‐113‐797) and incubated with CountBright counting beads (Invitrogen,\nThe total quantity and integrity of the extracted RNA were evaluated using a Bioanalyzer system (Nano 6000 assay on Agilent's 2100 Bioanalyzer). RNA from each sample was used for microarray hybridization using Affymetrix array (Clariom D Assay, human, Thermo Fisher Scientific, Inc.) and processed using the Applied Biosystems GeneChip System 3000 (Thermo Fisher Scientific).\nSample processing was performed at the High Technology Unit facility at Vall d'Hebron Institut de Recerca in Barcelona, Spain, selecting samples with RNA concentrations ≥3 μg and RNA integrity with numbers >7. The cohort of individuals was clustered by glycemia levels and initially assigned to two groups: glycemia ≤100 mg/dL and glycemia >100 mg/dL.\nAll statistical analyses of microarray data were performed using the R‐based software, R version 4.0.3 (R Project for Statistical Computing). Quality control was performed using the arrayQualityMetrics package 3.64 (Bioconductor). Background correction, probe set summarization, and normalization were performed using the oligo package with the most up‐to‐date annotation in Bioconductor version 3.12. A paired‐sample design comparing VAT and SAT from the same individual was applied. Subsequent differential expression analysis was performed using the limma package at the gene level, focusing on known genes (with assigned gene symbols). Transcripts were considered for further analyses if they matched the double criteria or false detection rate (FDR) of <0.05 and log (fold change) VAT versus SAT of >1.5. Exploratory inference of putatively affected biological functions was performed using GOrilla (Multi Knowledge Project) v2, harnessing Gene Ontology categories to perform pathway analyses. In‐depth functional enrichment analyses were performed using Gene Set Enrichment Analysis and the results visualized using the Enrichment Map tool in Cytoscape (Cytoscape Consortium) 2.10.3. Pre‐ranked–based analyses were performed using ranking by log2ratio or signed −log10\nWhole VAT and SAT samples were obtained from cohort 2 at the time of surgery. SAT was obtained from cohort 3 at the time of surgery and 3 months after the intervention. Total RNA was then extracted from whole adipose samples using a standard column‐affinity based methodology (NucleoSpin RNA II, MACHEREY‐NAGEL). An amount of 500 ng of total RNA was retro‐transcribed into complementary DNA (cDNA) using random hexamer primers and MultiScribe Reverse Transcriptase (TaqMan Reverse Transcription Reagents, ThermoFisher Scientific), following the manufacturer's instructions. Platinum Quantitative PCR SuperMix‐UDG with ROX reagent (ThermoFisher Scientific) was used as master mix reagent, and expression levels of each gene of interest were assessed with the specific TaqMan probes (ThermoFisher Scientific). As an endogenous control, peptidylprolyl isomerase A was used. Quantitative reverse transcriptase‐polymerase chain reaction (RT‐PCR) was carried out in an ABI PRISM 7900HT Sequence Detection System (ThermoFisher Scientific) using the following conditions: 2 min at 50 °C, 10 min at 95 °C followed by 40 cycles of 15 s at 95 °C, and 1 min at 60 °C. Relative mRNA levels were determined using the 2\nThe statistical analyses performed indicate a comparison between controls and treatments of each experimental model. One‐way ANOVA was performed when more than two groups were compared, followed by Tukey's post hoc analysis. Correlation analyses were conducted by age‐ and sex‐adjusted multiple linear regression. Multicollinearity was assessed by calculating the variance inflation factor (VIF) for each covariables in all regressions; no significant multicollinearity was detected in any case (VIF < 1.5). Standardized multiple regression model coefficients (\nThe clinical data of the cohort of individuals with severe obesity analyzed in this study are described in Table\nDifferential gene expression analyses of CD11b\nDifferential gene expression summary results between VAT‐ and SAT‐derived CD11b\nBioinformatic analysis was performed to identify the most abundant subtype of macrophages in each depot according to the gene expression levels of different markers. Following the classification described in the current literature [\nOur results indicated that SAT‐isolated CD11b\nVolcano plot with significant differentially expressed genes between VAT‐ and SAT‐derived CD11b\nFinally, when we analyzed the expression levels of the aforementioned LAM marker genes in cohort 2, we observed that they were induced in adipose tissue from patients with obesity compared with lean controls. Moreover, gene expression of these LAM markers was higher in SAT than in VAT (Figure\nRelative transcript levels of selected LAM marker genes and mean relative levels (LAM marker score) in SAT and VAT from C or OB from cohort 2. Data are expressed as mean ± SEM and referenced to C SAT. *\nWhen we analyzed the gene expression of the main LAM markers in our cohort 3 (Table\nAge‐ and sex‐adjusted multiple linear regression analyses for expression levels of selected LAM marker genes and clinical variables of interest in cohort 3 at baseline or 3 months after BS.\n\nAbbreviations: BS, bariatric surgery; CRP, C‐reactive protein; GGT, gamma‐glutamyl aminotransferase; GOT, glutamic‐oxaloacetic transaminase/aspartate aminotransferase; GPT, glutamic‐pyruvic transaminase/alanine aminotransferase; Hb, total hemoglobin; Hb1Ac, glycated hemoglobin; HDL‐c, high‐density lipoprotein cholesterol; HOMA‐IR, homeostasis model assessment of insulin resistance; LAM, lipid‐associated macrophage; LDL‐c, low‐density lipoprotein cholesterol; PD, pre‐dietary intervention; PS, pre‐surgery; TAG, triglycerides; Total‐c, total cholesterol.\nBold: Statistically significant adjusted correlations (\nFinally, when we compared the gene expression levels of LAM markers at baseline and the clinical parameters 3 months after surgery to explore the potential prognosis of our markers in the success of the surgery, an inverse correlation was found between\nThis study is the first to report transcriptomic analysis of SAT‐ and VAT‐infiltrated CD11b\nSAT‐infiltrated CD11b\nPrevious studies showing the cellular landscape of human adipose tissue indicated a higher abundance of LAMs in individuals with obesity compared with lean individuals [\nIn the present study, VAT‐infiltrated CD11b\nConsidering that having a higher amount of VAT is a cardiometabolic risk factor [\nIn addition, considering that the lack of\nIn conclusion, the present study demonstrated that WAT‐infiltrated CD11b\nThis work was supported by grant PID2020‐114953RB‐C21 funded by Ministerio de Ciencia, Innovación y Universidades, Agencia Estatal de Investigación, and the European Regional Development Fund (ERDF), by grant PID2023‐148783OB‐I00 funded by Ministerio de Ciencia, Innovación y Universidades, Agencia Estatal de Investigación, and ERDF, by grant CB06/03/0001 funded by Centro de Investigación Biomédica en Red Fisiopatología de la Obesidad y Nutrición and Instituto de Salud Carlos III, by grant 2021SGR00367 funded by the Government of Catalonia to Laura Herrero, and by grants PI17/00145 and PI20/00807 funded by Instituto de Salud Carlos III and ERDF to David Sánchez‐Infantes. Rubén Cereijo is a Serra Húnter Fellow (Government of Catalonia).\n\n", "topic": "Diagnostic"}
{"pmid": "40566823", "pmcid": "12198473", "title": "Associations between objective sleep metrics and brain structure in cognitively unimpaired adults: interactions with sex and Alzheimer's biomarkers", "publication_year": "N/A", "abstract": "", "full_text": "Aging is associated with an inherent reduction in sleep quality, characterized by increased sleep fragmentation and sleep disturbances that often begin as early as the fifth decade of life.\nRecent literature highlights the role of sleep in AD pathogenesis.\nHowever, subjective sleep measures are limited by recall bias and individual variability in sleep perception.\nDespite evidence linking impaired sleep quality to AD biomarkers, the relationship between objective sleep metrics and brain structural correlates, as well as their connection to AD pathology, remains poorly understood. Few studies have demonstrated correlations between actigraphy‐measured sleep parameters and brain structural markers. For instance, Lim et al. found that greater sleep fragmentation was associated with lower GMv and cortical thickness (CTh) in the orbitofrontal cortex and inferior frontal gyrus pars orbitalis.\nFemale sex is the second most important non‐modifiable risk factor for AD, with females accounting for two‐thirds of all cases.\nTherefore, this study sought to address these knowledge gaps by investigating the association between objectively measured sleep parameters and brain structural metrics, including neurodegenerative signatures of AD, in CU older adults. It also examined the contribution of CSF AD biomarkers to elucidate the potential role of AD pathology in these relationships while exploring sex differences. We hypothesized that poorer objective sleep parameters would correlate with lower CTh in AD‐vulnerable regions, which may be exacerbated in females.\n\n\n\n\nParticipants’ data were obtained from the ALzheimer and FAmilies (ALFA) Sleep study, an observational, cross‐sectional study designed to characterize sleep alterations in preclinical AD.\nParticipants wore an actigraph on the non‐dominant wrist for a continuous period of 2 weeks (Actiwatch2, Philips Respironics), and the actigraph was only removed while bathing or swimming. The sampling frequency was set at 30‐s epochs, and the wake threshold was set at 20 counts.\nWASO represents the total minutes of wakefulness occurring after sleep onset, indicating sustained wakeful periods. FI, also referred to as Index of Restlessness, captures sleep continuity by combining percent of mobile and the proportion of immobile bouts under 1 min to the total immobile bouts, with higher FI values indicating more fragmented and disrupted sleep:\nWASO and FI capture complementary aspects of sleep disruption: WASO reflects the duration of wakefulness, while FI indicates the frequency of brief awakenings. Together, they provide a comprehensive measure of sleep fragmentation and continuity.\nTo enhance accuracy, actigraphy data were processed using a validated scoring algorithm\nOn the first night of actigraphy recording, participants wore a single‐channel portable device (RUSleeping RTS, Philips‐Respironics). The device calculates a respiratory event index (REI) (expressed as an average number of apneas and hypopneas per hour) and the number of respiratory events for each hour of recording. The device has been validated against a standard multichannel PSG to detect OSA.\nDepression and anxiety were assessed using the Hospital Anxiety and Depression Scale (HADS) and the State‐Trait Anxiety Inventory (STAI), respectively. HADS includes two subscales, each scored up to 21,\nMRI scans, conducted on a 3T Philips Ingenia CX scanner, included a high‐resolution 3D T1‐weighted sequence (time to echo /repetition time/inversion time = 4.6/9.9/900 ms, flip angle = 8°; voxel size = 0.75 × 0.75 × 0.75 mm\nCSF levels of Aβ42\nIndividuals were classified into amyloid/tau (AT) groups\nThe time interval between the actigraphy and MRI acquisition was on average 8.75 months (SD 5.82) and between actigraphy and CSF sample collection 6.25 months (SD 5.08).\nExtreme values of sleep parameters and CSF biomarkers defined using Tukey's criteria set at three times the interquartile range were removed. CSF p‐tau181 levels did not follow a normal distribution and were thus log10‐transformed. Pearson's\nTo study the relationship between sleep parameters and CTh, we created several separate general linear models (GLMs) with CTh ROI as a dependent variable and actigraphy‐derived sleep parameters as independent predictors while controlling for age, sex,\nTo account for the presence of nocturnal arousals and alcohol consumption, we performed sensitivity analyses by further correcting our models by REI and weekly alcohol intake (measured in units per week), as reported by participants in their sleep diaries.\nTo explore the modifying effects of sex on these relationships, multivariable linear regressions, including an interaction term for the sleep variables and sex, were conducted for each of the outcome measures. These models were adjusted for the same covariates described earlier. Multiple comparison corrections were applied using the false discovery rate (FDR) approach using the Benjamini–Hochberg method for the main models, maintaining a threshold of 5% (\nThe mean age was 64.6 (SD = 4.66), with 63.7% females and 53.2%\nSample characteristics.\n\nAbbreviations: Aβ, amyloid beta; BMI, body mass index (kg/m^2); CSF, cerebrospinal fluid; HADS, Hospital Anxiety and Depression Scale; p‐tau181, phosphorylated tau at threonine 181; REI, Respiratory Events Index; SD, standard deviation; STAI, State‐Trait Anxiety Inventory.\nAnalysis of sex differences revealed that females spent significantly more time asleep (\nLower sleep efficiency, higher WASO, and higher FI (indicative of worse sleep) were associated with lower CTh in the MTL ROI (standard.β = 0.188;\nAssociations between sleep parameters and MTL ROI CTh.\n\nAbbreviations: Aβ, amyloid beta; CI, confidence interval; CTh, cortical thickness; FDR, false discovery rate; FI, Fragmentation Index; p‐tau181, phosphorylated tau at threonine 181; β, standardized coefficient; SOL, sleep onset latency; TST, total sleep time; WASO, wake after sleep onset.\nExploratory analyses showed lower sleep efficiency to be significantly associated with lower CTh in superior frontal cortex (standard.\nHigher amount of WASO significantly correlated with lower superior frontal cortex (standard.β = −0.184,\nSimilarly, higher FI was associated with lower CTh in supramarginal gyrus (standard.β = −0.212,\nLastly, lower TST was correlated with lower CTh in the precuneus (standard.\nAssociations between sleep parameters and CTh ROIs. Statistical brain maps illustrate (A) lower CTh in precuneus associated with lower TST; (B) lower CTh in precuneus associated with higher SOL; (C) lower CTh in superior frontal cortex, medial orbitofrontal cortex, supramarginal gyrus, precuneus, posterior cingulate cortex, lateral orbitofrontal cortex, and pars orbitalis ROIs associated with lower sleep efficiency; (D) lower CTh in superior frontal cortex, medial orbitofrontal cortex, precuneus, posterior cingulate cortex, lateral orbitofrontal cortex, and pars orbitalis ROIs associated with higher WASO (i.e., worse sleep quality); (E) lower CTh in supramarginal gyrus, precuneus, posterior cingulate cortex, temporal pole, lateral orbitofrontal cortex, and pars orbitalis ROIs associated with higher FI (i.e., worse sleep quality). These findings are visualized on the Desikan–Killiany cortical brain atlas, with the color bar scales representing standardized β coefficient values. The β coefficients are derived from Model 1: ROI ≈ sleep parameter + sex + age +\nSensitivity analyses were conducted to investigate whether the main results could be driven by sleep‐disordered breathing or alcohol consumption. After correcting for the REI, a lower sleep efficiency remained significantly associated with lower CTh in the MTL ROI (standard.β = 0.181,\nA significant interaction effect was found between sex and WASO on MTL composite ROI CTh (β = −0.001,\nAdditionally, significant interactions were observed in the exploratory regions of the supramarginal gyrus and temporal pole, between sex and lower sleep efficiency (β = 0.009,\nInteractions between sleep measures and sex on CTh. (A) Lower sleep efficiency is associated with lower CTh in the supramarginal gyrus in females (β = 0.009,\nSignificant interactions were observed between AT groups and sleep parameters, specifically TST, sleep efficiency, WASO, and FI, across several cortical regions, including the superior frontal cortex, medial orbitofrontal cortex, supramarginal gyrus, posterior cingulate cortex, lateral orbitofrontal cortex, and pars orbitalis (Figure\nPlots illustrating interaction analyses between actigraphy‐derived sleep metrics and AT groups for regions with significant interactions. The\nNotably, in the A−T− and A+T− groups, worse sleep metrics (shorter TST, lower sleep efficiency, higher WASO, or FI) were consistently associated with reduced CTh in all the aforementioned regions except the lateral orbitofrontal cortex and pars orbitalis, where this association was restricted to the A−T− group. Conversely, an opposing trend was observed in the A+T+ group, where worse sleep metrics were linked to higher CTh in most regions, except the lateral orbitofrontal cortex and pars orbitalis (Figure\nStratified analyses revealed that significant associations were predominantly observed in the A−T− group, with sleep efficiency, WASO, and FI showing robust effects across multiple ROIs (Table\nIn the lateral orbitofrontal cortex and pars orbitalis, worse sleep metrics (i.e., shorter TST, lower sleep efficiency, higher WASO, and FI) were significantly associated with reduced CTh only within the A−T− group. No significant associations were identified for these ROIs in the A+T− or A+T+ groups (Table\nThis study provides compelling evidence linking objective sleep disturbances with lower CTh in AD‐vulnerable regions among CU older adults. Our findings demonstrate that lower sleep efficiency, increased WASO, and higher fragmentation are robustly associated with lower CTh in the MTL, a region known to be affected early in the AD continuum.\nThese results are consistent and align with prior research using subjective questionnaires, which have correlated poor sleep quality with widespread gray matter atrophy\nBeyond the significant associations in the MTL, exploratory analyses revealed associations between sleep disturbances and lower CTh in additional brain regions, including frontal, medial orbitofrontal, supramarginal gyrus, posterior cingulate, temporal pole, orbitofrontal cortex, and precuneus. The topography of these findings holds clinical significance as these regions are critical for higher‐order cognitive functions and are particularly vulnerable to AD pathology (e.g., posterior cingulate, precuneus)\nNotably, this study extends previous findings by revealing that the relationships between worse objective sleep parameters and markers of neuronal loss are independent of AD pathology. These results align with our prior work using subjective and PSG assessments\nFurthermore, we observed that AD pathology modified the association between sleep disturbances and CTh, particularly in regions vulnerable to early AD. In the superior frontal, medial orbitofrontal, supramarginal, and posterior cingulate cortices, poorer sleep metrics such as lower sleep efficiency and TST or higher WASO and FI were associated with reduced CTh in the A−T− group and, to a lesser extent, in the A+T− group, where poorer sleep metrics were associated with increased CTh, although most associations in this subgroup were not significant, likely due to its limited sample size.\nIn the lateral orbitofrontal cortex and pars orbitalis significant interactions revealed that worse sleep parameters were associated with cortical thinning, particularly in the absence of AD pathology (A−T−).\nIn contrast, in A+T+ individuals, poorer sleep metrics in the regions of superior frontal, medial orbitofrontal, and supramarginal and posterior cingulate were associated with higher CTh, suggesting that in individuals with both amyloid and tau pathology, worse sleep may not correspond to cortical thinning but instead relate to increases in thickness in specific regions. These counterintuitive findings may reflect several underlying mechanisms. One possibility is that in our cohort CU A+T+ individuals represent a particularly resilient subgroup. Such resilience may be driven by protective biological, lifestyle, or cognitive reserve factors.\nAlternatively, this pattern may reflect early‐stage neuroinflammatory responses to pathology. There is a growing body of literature suggesting that in the early stages of AD pathology, neuroinflammation, including microglial activation and astrogliosis, can lead to transient increases in CTh or volume, especially in regions susceptible to pathology.\nSleep disturbances, on the other hand, have also been implicated in promoting neuroinflammatory processes through several mechanistic pathways, including impaired glymphatic clearance, elevated concentrations of pro‐inflammatory cytokines such as interleukin‐6 (IL‐6) and tumor necrosis factor‐alpha (TNF‐α), and enhanced glial reactivity associated with sleep fragmentation, highlighting the essential role of sleep in preserving neuroimmune homeostasis and brain health.\nThese findings reinforce the existence of an independent association between poorer sleep metrics and cortical thinning. However, they also reveal a distinct pattern in the presence of AD pathology, where poorer sleep may be associated with increased CTh. Aligned with our previous findings,\nOur study also provides novel insights into the sex‐specific effects on the relationship between sleep parameters and CTh. Higher WASO was significantly associated with lower MTL thickness in females but not in males, suggesting increased female vulnerability to poor sleep's adverse effects on brain structure. This pattern extended to other regions, such as the temporal pole, precuneus, and supramarginal cortex, which are early targets of AD‐related neurodegeneration.\nThe strength of this study lies in its robust methodology. First, using objective sleep measurements via actigraphy avoids recall bias and provides ecologically valid data by capturing sleep‐wake disruptions over extended periods, surpassing single‐night polysomnographic recordings. Second, this study uniquely combines multimodal neuroimaging with CSF AD biomarkers, enabling a deeper understanding of the underlying mechanisms and disentangling non‐AD pathology‐dependent effects. Furthermore, the relatively large sample size enhances the generalizability of the findings.\nWhile effect sizes were small to moderate, they align with research on other modifiable risk factors.\nHowever, some limitations warrant consideration. While focusing on traditional metrics of objective sleep quality, the literature indicates that variability in sleep metrics and disturbances in sleep‐wake cycles (e.g., rest‐activity or circadian rhythms) are related to AD pathology and cognitive decline.\nMoreover, actigraphy‐based estimates of SOL may be less accurate, as actigraphy cannot reliably distinguish quiet wakefulness from sleep; therefore, associations between SOL and CTh should be interpreted with caution.\nAdditionally, the absence of objective reproductive hormone‐level markers limits the interpretation of the potential role of the neuroendocrine system alterations in our observed sex‐specific effects, though post‐menopausal status in female participants likely minimizes estrogen's role. Lastly, the cross‐sectional design of this study precludes causal inference, and the associations observed between sleep parameters and CTh should not be interpreted as evidence of a unidirectional effect of poor sleep on brain structure. We acknowledge the growing body of literature suggesting that the relationship between sleep and brain health may be bidirectional. Notably, Fjell et al. proposed that preserved brain structure may facilitate better sleep rather than shorter sleep disruption, necessarily leading to cortical thinning.\nThis study demonstrates that worse objective sleep parameters, such as lower sleep efficiency and higher fragmentation, are robustly associated with lower CTh in regions vulnerable to early AD neurodegeneration. While this effect appears to be independent of traditional AD pathology markers, our findings also suggest that sleep disturbances could enhance brain structural alterations in the presence of AD pathology.\nNotably, the findings suggest greater susceptibility in females, highlighting the need to investigate the underlying mechanisms driving such sex‐specific vulnerabilities. Given that AD pathology can develop decades before symptom onset, addressing sleep disturbances may facilitate early detection and offer a potential target for secondary prevention, particularly for populations at heightened risk.\nO.G.R. receives research funding from F. Hoffmann‐La Roche Ltd. and has given lectures at symposia sponsored by Roche Diagnostics, S.L.U. G.S‐B. worked as a consultant for Roche Farma, S.A. M.S‐C. has given lectures in symposia sponsored by Almirall, Eli Lilly, Novo Nordisk, Roche Diagnostics, and Roche Farma; received consultancy fees (paid to the institution) from Roche Diagnostics; and served on advisory boards of Eli Lilly, Grifols, and Roche Diagnostics. He was granted a project and is a site investigator of a clinical trial (funded to the institution) by Roche Diagnostics. In‐kind support for research (to the institution) was received from ADx Neurosciences, Alamar Biosciences, Avid Radiopharmaceuticals, Eli Lilly, Fujirebio, Janssen Research & Development, and Roche Diagnostics. H.Z. has served on scientific advisory boards and/or as a consultant for Abbvie, Acumen, Alector, Alzinova, ALZPath, Amylyx, Annexon, Apellis, Artery Therapeutics, AZTherapies, Cognito Therapeutics, CogRx, Denali, Eisai, LabCorp, Merry Life, Nervgen, Novo Nordisk, Optoceutics, Passage Bio, Pinteon Therapeutics, Prothena, Red Abbey Labs, reMYND, Roche, Samumed, Siemens Healthineers, Triplet Therapeutics, and Wave; has given lectures in symposia sponsored by Alzecure, Biogen, Cellectricon, Fujirebio, Lilly, Novo Nordisk, and Roche; and is a co‐founder of Brain Biomarker Solutions in Gothenburg AB (BBS), which is a part of the GU Ventures Incubator Program (outside submitted work). K.B. has served as a consultant and on advisory boards for Acumen, ALZPath, BioArctic, Biogen, Eisai, Lilly, Moleac Pte. Ltd., Novartis, Ono Pharma, Prothena, Roche Diagnostics, and Siemens Healthineers; has served on data monitoring committees for Julius Clinical and Novartis; has given lectures, produced educational materials, and participated in educational programs for AC Immune, Biogen, Celdara Medical, Eisai, and Roche Diagnostics; and is a co‐founder of Brain Biomarker Solutions in Gothenburg AB (BBS), which is a part of the GU Ventures Incubator Program, outside the work presented in this paper. J.D.G. receives research funding from Roche Diagnostics and GE Healthcare, has given lectures at symposia sponsored by Biogen and Philips, and is currently an employee of AstraZeneca. J.L.M. is currently a full‐time employee of Lundbeck and previously served as a consultant or on advisory boards for the following for‐profit companies or has given lectures in symposia sponsored by the following for‐profit companies: Roche Diagnostics, Genentech, Novartis, Lundbeck, Oryzon, Biogen, Lilly, Janssen, Green Valley, MSD, Eisai, Alector, BioCross, GE Healthcare, and ProMISNeurosciences. The NeuroToolKit is a panel of exploratory prototype assays designed to robustly evaluate biomarkers associated with key pathologic events characteristic of AD and other neurological disorders, used for research purposes only and not approved for clinical use (Roche Diagnostics International Ltd., Rotkreuz, Switzerland). Elecsys Phospho‐Tau (181P) CSF and Elecsys Total‐Tau CSF immunoassays are approved for clinical use. ELECSYS is a trademark of Roche. The rest of the coauthors have nothing to disclose. S.C.H., T.M., and P.G. are employees of F. Hoffmann‐La Roche Ltd. Author disclosures are available in the\nAll participants provided written informed consent.\nSupporting Information\nSupporting Information", "content_for_embedding": "Aging is associated with an inherent reduction in sleep quality, characterized by increased sleep fragmentation and sleep disturbances that often begin as early as the fifth decade of life.\nRecent literature highlights the role of sleep in AD pathogenesis.\nHowever, subjective sleep measures are limited by recall bias and individual variability in sleep perception.\nDespite evidence linking impaired sleep quality to AD biomarkers, the relationship between objective sleep metrics and brain structural correlates, as well as their connection to AD pathology, remains poorly understood. Few studies have demonstrated correlations between actigraphy‐measured sleep parameters and brain structural markers. For instance, Lim et al. found that greater sleep fragmentation was associated with lower GMv and cortical thickness (CTh) in the orbitofrontal cortex and inferior frontal gyrus pars orbitalis.\nFemale sex is the second most important non‐modifiable risk factor for AD, with females accounting for two‐thirds of all cases.\nTherefore, this study sought to address these knowledge gaps by investigating the association between objectively measured sleep parameters and brain structural metrics, including neurodegenerative signatures of AD, in CU older adults. It also examined the contribution of CSF AD biomarkers to elucidate the potential role of AD pathology in these relationships while exploring sex differences. We hypothesized that poorer objective sleep parameters would correlate with lower CTh in AD‐vulnerable regions, which may be exacerbated in females.\n\n\n\n\nParticipants’ data were obtained from the ALzheimer and FAmilies (ALFA) Sleep study, an observational, cross‐sectional study designed to characterize sleep alterations in preclinical AD.\nParticipants wore an actigraph on the non‐dominant wrist for a continuous period of 2 weeks (Actiwatch2, Philips Respironics), and the actigraph was only removed while bathing or swimming. The sampling frequency was set at 30‐s epochs, and the wake threshold was set at 20 counts.\nWASO represents the total minutes of wakefulness occurring after sleep onset, indicating sustained wakeful periods. FI, also referred to as Index of Restlessness, captures sleep continuity by combining percent of mobile and the proportion of immobile bouts under 1 min to the total immobile bouts, with higher FI values indicating more fragmented and disrupted sleep:\nWASO and FI capture complementary aspects of sleep disruption: WASO reflects the duration of wakefulness, while FI indicates the frequency of brief awakenings. Together, they provide a comprehensive measure of sleep fragmentation and continuity.\nTo enhance accuracy, actigraphy data were processed using a validated scoring algorithm\nOn the first night of actigraphy recording, participants wore a single‐channel portable device (RUSleeping RTS, Philips‐Respironics). The device calculates a respiratory event index (REI) (expressed as an average number of apneas and hypopneas per hour) and the number of respiratory events for each hour of recording. The device has been validated against a standard multichannel PSG to detect OSA.\nDepression and anxiety were assessed using the Hospital Anxiety and Depression Scale (HADS) and the State‐Trait Anxiety Inventory (STAI), respectively. HADS includes two subscales, each scored up to 21,\nMRI scans, conducted on a 3T Philips Ingenia CX scanner, included a high‐resolution 3D T1‐weighted sequence (time to echo /repetition time/inversion time = 4.6/9.9/900 ms, flip angle = 8°; voxel size = 0.75 × 0.75 × 0.75 mm\nCSF levels of Aβ42\nIndividuals were classified into amyloid/tau (AT) groups\nThe time interval between the actigraphy and MRI acquisition was on average 8.75 months (SD 5.82) and between actigraphy and CSF sample collection 6.25 months (SD 5.08).\nExtreme values of sleep parameters and CSF biomarkers defined using Tukey's criteria set at three times the interquartile range were removed. CSF p‐tau181 levels did not follow a normal distribution and were thus log10‐transformed. Pearson's\nTo study the relationship between sleep parameters and CTh, we created several separate general linear models (GLMs) with CTh ROI as a dependent variable and actigraphy‐derived sleep parameters as independent predictors while controlling for age, sex,\nTo account for the presence of nocturnal arousals and alcohol consumption, we performed sensitivity analyses by further correcting our models by REI and weekly alcohol intake (measured in units per week), as reported by participants in their sleep diaries.\nTo explore the modifying effects of sex on these relationships, multivariable linear regressions, including an interaction term for the sleep variables and sex, were conducted for each of the outcome measures. These models were adjusted for the same covariates described earlier. Multiple comparison corrections were applied using the false discovery rate (FDR) approach using the Benjamini–Hochberg method for the main models, maintaining a threshold of 5% (\nThe mean age was 64.6 (SD = 4.66), with 63.7% females and 53.2%\nSample characteristics.\n\nAbbreviations: Aβ, amyloid beta; BMI, body mass index (kg/m^2); CSF, cerebrospinal fluid; HADS, Hospital Anxiety and Depression Scale; p‐tau181, phosphorylated tau at threonine 181; REI, Respiratory Events Index; SD, standard deviation; STAI, State‐Trait Anxiety Inventory.\nAnalysis of sex differences revealed that females spent significantly more time asleep (\nLower sleep efficiency, higher WASO, and higher FI (indicative of worse sleep) were associated with lower CTh in the MTL ROI (standard.β = 0.188;\nAssociations between sleep parameters and MTL ROI CTh.\n\nAbbreviations: Aβ, amyloid beta; CI, confidence interval; CTh, cortical thickness; FDR, false discovery rate; FI, Fragmentation Index; p‐tau181, phosphorylated tau at threonine 181; β, standardized coefficient; SOL, sleep onset latency; TST, total sleep time; WASO, wake after sleep onset.\nExploratory analyses showed lower sleep efficiency to be significantly associated with lower CTh in superior frontal cortex (standard.\nHigher amount of WASO significantly correlated with lower superior frontal cortex (standard.β = −0.184,\nSimilarly, higher FI was associated with lower CTh in supramarginal gyrus (standard.β = −0.212,\nLastly, lower TST was correlated with lower CTh in the precuneus (standard.\nAssociations between sleep parameters and CTh ROIs. Statistical brain maps illustrate (A) lower CTh in precuneus associated with lower TST; (B) lower CTh in precuneus associated with higher SOL; (C) lower CTh in superior frontal cortex, medial orbitofrontal cortex, supramarginal gyrus, precuneus, posterior cingulate cortex, lateral orbitofrontal cortex, and pars orbitalis ROIs associated with lower sleep efficiency; (D) lower CTh in superior frontal cortex, medial orbitofrontal cortex, precuneus, posterior cingulate cortex, lateral orbitofrontal cortex, and pars orbitalis ROIs associated with higher WASO (i.e., worse sleep quality); (E) lower CTh in supramarginal gyrus, precuneus, posterior cingulate cortex, temporal pole, lateral orbitofrontal cortex, and pars orbitalis ROIs associated with higher FI (i.e., worse sleep quality). These findings are visualized on the Desikan–Killiany cortical brain atlas, with the color bar scales representing standardized β coefficient values. The β coefficients are derived from Model 1: ROI ≈ sleep parameter + sex + age +\nSensitivity analyses were conducted to investigate whether the main results could be driven by sleep‐disordered breathing or alcohol consumption. After correcting for the REI, a lower sleep efficiency remained significantly associated with lower CTh in the MTL ROI (standard.β = 0.181,\nA significant interaction effect was found between sex and WASO on MTL composite ROI CTh (β = −0.001,\nAdditionally, significant interactions were observed in the exploratory regions of the supramarginal gyrus and temporal pole, between sex and lower sleep efficiency (β = 0.009,\nInteractions between sleep measures and sex on CTh. (A) Lower sleep efficiency is associated with lower CTh in the supramarginal gyrus in females (β = 0.009,\nSignificant interactions were observed between AT groups and sleep parameters, specifically TST, sleep efficiency, WASO, and FI, across several cortical regions, including the superior frontal cortex, medial orbitofrontal cortex, supramarginal gyrus, posterior cingulate cortex, lateral orbitofrontal cortex, and pars orbitalis (Figure\nPlots illustrating interaction analyses between actigraphy‐derived sleep metrics and AT groups for regions with significant interactions. The\nNotably, in the A−T− and A+T− groups, worse sleep metrics (shorter TST, lower sleep efficiency, higher WASO, or FI) were consistently associated with reduced CTh in all the aforementioned regions except the lateral orbitofrontal cortex and pars orbitalis, where this association was restricted to the A−T− group. Conversely, an opposing trend was observed in the A+T+ group, where worse sleep metrics were linked to higher CTh in most regions, except the lateral orbitofrontal cortex and pars orbitalis (Figure\nStratified analyses revealed that significant associations were predominantly observed in the A−T− group, with sleep efficiency, WASO, and FI showing robust effects across multiple ROIs (Table\nIn the lateral orbitofrontal cortex and pars orbitalis, worse sleep metrics (i.e., shorter TST, lower sleep efficiency, higher WASO, and FI) were significantly associated with reduced CTh only within the A−T− group. No significant associations were identified for these ROIs in the A+T− or A+T+ groups (Table\nThis study provides compelling evidence linking objective sleep disturbances with lower CTh in AD‐vulnerable regions among CU older adults. Our findings demonstrate that lower sleep efficiency, increased WASO, and higher fragmentation are robustly associated with lower CTh in the MTL, a region known to be affected early in the AD continuum.\nThese results are consistent and align with prior research using subjective questionnaires, which have correlated poor sleep quality with widespread gray matter atrophy\nBeyond the significant associations in the MTL, exploratory analyses revealed associations between sleep disturbances and lower CTh in additional brain regions, including frontal, medial orbitofrontal, supramarginal gyrus, posterior cingulate, temporal pole, orbitofrontal cortex, and precuneus. The topography of these findings holds clinical significance as these regions are critical for higher‐order cognitive functions and are particularly vulnerable to AD pathology (e.g., posterior cingulate, precuneus)\nNotably, this study extends previous findings by revealing that the relationships between worse objective sleep parameters and markers of neuronal loss are independent of AD pathology. These results align with our prior work using subjective and PSG assessments\nFurthermore, we observed that AD pathology modified the association between sleep disturbances and CTh, particularly in regions vulnerable to early AD. In the superior frontal, medial orbitofrontal, supramarginal, and posterior cingulate cortices, poorer sleep metrics such as lower sleep efficiency and TST or higher WASO and FI were associated with reduced CTh in the A−T− group and, to a lesser extent, in the A+T− group, where poorer sleep metrics were associated with increased CTh, although most associations in this subgroup were not significant, likely due to its limited sample size.\nIn the lateral orbitofrontal cortex and pars orbitalis significant interactions revealed that worse sleep parameters were associated with cortical thinning, particularly in the absence of AD pathology (A−T−).\nIn contrast, in A+T+ individuals, poorer sleep metrics in the regions of superior frontal, medial orbitofrontal, and supramarginal and posterior cingulate were associated with higher CTh, suggesting that in individuals with both amyloid and tau pathology, worse sleep may not correspond to cortical thinning but instead relate to increases in thickness in specific regions. These counterintuitive findings may reflect several underlying mechanisms. One possibility is that in our cohort CU A+T+ individuals represent a particularly resilient subgroup. Such resilience may be driven by protective biological, lifestyle, or cognitive reserve factors.\nAlternatively, this pattern may reflect early‐stage neuroinflammatory responses to pathology. There is a growing body of literature suggesting that in the early stages of AD pathology, neuroinflammation, including microglial activation and astrogliosis, can lead to transient increases in CTh or volume, especially in regions susceptible to pathology.\nSleep disturbances, on the other hand, have also been implicated in promoting neuroinflammatory processes through several mechanistic pathways, including impaired glymphatic clearance, elevated concentrations of pro‐inflammatory cytokines such as interleukin‐6 (IL‐6) and tumor necrosis factor‐alpha (TNF‐α), and enhanced glial reactivity associated with sleep fragmentation, highlighting the essential role of sleep in preserving neuroimmune homeostasis and brain health.\nThese findings reinforce the existence of an independent association between poorer sleep metrics and cortical thinning. However, they also reveal a distinct pattern in the presence of AD pathology, where poorer sleep may be associated with increased CTh. Aligned with our previous findings,\nOur study also provides novel insights into the sex‐specific effects on the relationship between sleep parameters and CTh. Higher WASO was significantly associated with lower MTL thickness in females but not in males, suggesting increased female vulnerability to poor sleep's adverse effects on brain structure. This pattern extended to other regions, such as the temporal pole, precuneus, and supramarginal cortex, which are early targets of AD‐related neurodegeneration.\nThe strength of this study lies in its robust methodology. First, using objective sleep measurements via actigraphy avoids recall bias and provides ecologically valid data by capturing sleep‐wake disruptions over extended periods, surpassing single‐night polysomnographic recordings. Second, this study uniquely combines multimodal neuroimaging with CSF AD biomarkers, enabling a deeper understanding of the underlying mechanisms and disentangling non‐AD pathology‐dependent effects. Furthermore, the relatively large sample size enhances the generalizability of the findings.\nWhile effect sizes were small to moderate, they align with research on other modifiable risk factors.\nHowever, some limitations warrant consideration. While focusing on traditional metrics of objective sleep quality, the literature indicates that variability in sleep metrics and disturbances in sleep‐wake cycles (e.g., rest‐activity or circadian rhythms) are related to AD pathology and cognitive decline.\nMoreover, actigraphy‐based estimates of SOL may be less accurate, as actigraphy cannot reliably distinguish quiet wakefulness from sleep; therefore, associations between SOL and CTh should be interpreted with caution.\nAdditionally, the absence of objective reproductive hormone‐level markers limits the interpretation of the potential role of the neuroendocrine system alterations in our observed sex‐specific effects, though post‐menopausal status in female participants likely minimizes estrogen's role. Lastly, the cross‐sectional design of this study precludes causal inference, and the associations observed between sleep parameters and CTh should not be interpreted as evidence of a unidirectional effect of poor sleep on brain structure. We acknowledge the growing body of literature suggesting that the relationship between sleep and brain health may be bidirectional. Notably, Fjell et al. proposed that preserved brain structure may facilitate better sleep rather than shorter sleep disruption, necessarily leading to cortical thinning.\nThis study demonstrates that worse objective sleep parameters, such as lower sleep efficiency and higher fragmentation, are robustly associated with lower CTh in regions vulnerable to early AD neurodegeneration. While this effect appears to be independent of traditional AD pathology markers, our findings also suggest that sleep disturbances could enhance brain structural alterations in the presence of AD pathology.\nNotably, the findings suggest greater susceptibility in females, highlighting the need to investigate the underlying mechanisms driving such sex‐specific vulnerabilities. Given that AD pathology can develop decades before symptom onset, addressing sleep disturbances may facilitate early detection and offer a potential target for secondary prevention, particularly for populations at heightened risk.\nO.G.R. receives research funding from F. Hoffmann‐La Roche Ltd. and has given lectures at symposia sponsored by Roche Diagnostics, S.L.U. G.S‐B. worked as a consultant for Roche Farma, S.A. M.S‐C. has given lectures in symposia sponsored by Almirall, Eli Lilly, Novo Nordisk, Roche Diagnostics, and Roche Farma; received consultancy fees (paid to the institution) from Roche Diagnostics; and served on advisory boards of Eli Lilly, Grifols, and Roche Diagnostics. He was granted a project and is a site investigator of a clinical trial (funded to the institution) by Roche Diagnostics. In‐kind support for research (to the institution) was received from ADx Neurosciences, Alamar Biosciences, Avid Radiopharmaceuticals, Eli Lilly, Fujirebio, Janssen Research & Development, and Roche Diagnostics. H.Z. has served on scientific advisory boards and/or as a consultant for Abbvie, Acumen, Alector, Alzinova, ALZPath, Amylyx, Annexon, Apellis, Artery Therapeutics, AZTherapies, Cognito Therapeutics, CogRx, Denali, Eisai, LabCorp, Merry Life, Nervgen, Novo Nordisk, Optoceutics, Passage Bio, Pinteon Therapeutics, Prothena, Red Abbey Labs, reMYND, Roche, Samumed, Siemens Healthineers, Triplet Therapeutics, and Wave; has given lectures in symposia sponsored by Alzecure, Biogen, Cellectricon, Fujirebio, Lilly, Novo Nordisk, and Roche; and is a co‐founder of Brain Biomarker Solutions in Gothenburg AB (BBS), which is a part of the GU Ventures Incubator Program (outside submitted work). K.B. has served as a consultant and on advisory boards for Acumen, ALZPath, BioArctic, Biogen, Eisai, Lilly, Moleac Pte. Ltd., Novartis, Ono Pharma, Prothena, Roche Diagnostics, and Siemens Healthineers; has served on data monitoring committees for Julius Clinical and Novartis; has given lectures, produced educational materials, and participated in educational programs for AC Immune, Biogen, Celdara Medical, Eisai, and Roche Diagnostics; and is a co‐founder of Brain Biomarker Solutions in Gothenburg AB (BBS), which is a part of the GU Ventures Incubator Program, outside the work presented in this paper. J.D.G. receives research funding from Roche Diagnostics and GE Healthcare, has given lectures at symposia sponsored by Biogen and Philips, and is currently an employee of AstraZeneca. J.L.M. is currently a full‐time employee of Lundbeck and previously served as a consultant or on advisory boards for the following for‐profit companies or has given lectures in symposia sponsored by the following for‐profit companies: Roche Diagnostics, Genentech, Novartis, Lundbeck, Oryzon, Biogen, Lilly, Janssen, Green Valley, MSD, Eisai, Alector, BioCross, GE Healthcare, and ProMISNeurosciences. The NeuroToolKit is a panel of exploratory prototype assays designed to robustly evaluate biomarkers associated with key pathologic events characteristic of AD and other neurological disorders, used for research purposes only and not approved for clinical use (Roche Diagnostics International Ltd., Rotkreuz, Switzerland). Elecsys Phospho‐Tau (181P) CSF and Elecsys Total‐Tau CSF immunoassays are approved for clinical use. ELECSYS is a trademark of Roche. The rest of the coauthors have nothing to disclose. S.C.H., T.M., and P.G. are employees of F. Hoffmann‐La Roche Ltd. Author disclosures are available in the\nAll participants provided written informed consent.\nSupporting Information\nSupporting Information", "topic": "Diagnostic"}
{"pmid": "40541209", "pmcid": "12302399", "title": "Exploring the interplay between pain processing mechanisms, psychosocial factors, and functional outcomes in patients with chronic low back pain: an exploratory study", "publication_year": "2025", "abstract": "", "full_text": "Chronic low back pain (CLBP) is one of the leading causes of disability worldwide and significantly affects healthcare services [\nWithin the biopsychosocial framework for understanding chronic pain, several more specific mechanism-oriented models have been developed to describe the factors that may influence pain [\nOver the past decade, there has been a substantial increase in research not only investigating the Fear-Avoidance Model but also exploring the mechanisms that promote and inhibit nociception in individuals experiencing chronic pain. Thus, the profound interconnection and influence between the CNS and mechanisms that underlie pain processing in cases of CLBP has been studied [\nCS is defined as increased responsiveness of spinal nociceptive neurons, where their cortical projections can outlast tissue-based input or be sustained by a normally subthreshold tissue-based input [\nQuantitative sensory testing (QST) is used to measure some mechanisms of pain. QST is an umbrella term for non-invasive psychophysical tissue-stimulation tests that provide information about altered sensory processing such as sensitivity and dysregulation of pro-nociceptive and anti-nociceptive pathways, thereby providing insights into pain mechanisms [\nPrevious narrative reviews have reported differences between people with CLBP and healthy controls in terms of several QST metrics. Higher PPTs at remote body parts from pain, facilitated TS, and low CPM were interpreted as signs of CS and were present in individuals with CLBP [\nMoreover, people with CLBP often experience pain during functional activities which, in turn, reduces their functional capacity [\nActivity-related pain metrics such as movement-evoked pain thresholds have been used to capture information on distinct aspects of activity-related pain [\nThese variables have only been studied collectively in knee osteoarthritis. However, while they have been examined individually in patients with CLBP, these studies lacked a more holistic perspective. To the best of our knowledge, no research to date has investigated the correlations between pain intensity, pain processing mechanisms in conjunction with various psychosocial factors, and functional outcomes in CLBP. Thus, the primary objective of this exploratory study was to investigate potential correlations between pain intensity and pain processing mechanisms (QST parameters [PPT, TS, and CPM]), psychological factors (kinesiophobia, catastrophising, and anxiety), and functional outcomes (lumbar movement-evoked pain thresholds and functional capacity) in individuals with CLBP. We hypothesised that higher levels of pain intensity are associated with CS QST indices, poorer psychological factor outcomes, and lower lumbar movement-evoked pain thresholds and functional capacity in individuals with CLBP. A secondary aim was to explore which variables were most strongly associated with pain intensity and kinesiophobia, a key component of the Fear-Avoidance Model given its recognised impact on pain-related disability and behavioural avoidance in individuals with CLBP, with the goal of identifying potential predictors for future hypothesis-driven research.\nThis observational study recruited participants from the Orthopaedic Surgery Service and Physical Medicine and Rehabilitation Service at Arnau de Vilanova Hospital in Valencia, Spain. The study was approved by the Ethics Committee at the Arnau de Vilanova Hospital in Valencia, Spain, (reference: CEIm:30/2021) as well as by the CEU Cardenal Herrera University in Valencia, Spain, (reference: CEEI21/203) in accordance with the fundamental principles established in the Declaration of Helsinki. Prior to commencing the study, all the participants received an information letter and provided their written consent to participation. Additionally, this study was conducted in compliance with the STROBE reporting guidelines for observational studies [\nFifty patients diagnosed with non-specific CLBP, according to the COST B13 European guideline, [\nIn this observational study, the sample size was calculated using G*Power 3 software [\nParticipants completed all the questionnaires related to pain and psychological factors online. Subsequently, patients attended the physiotherapy department at Arnau de Vilanova Hospital, where the same physical therapist evaluated their pain processing mechanisms and functional outcomes. The outcomes measured in this study included pain (pain intensity), pain processing mechanisms (QST parameters [PPT, TS, and CPM]), psychological factors (kinesiophobia, catastrophising, and anxiety), and functional outcomes (lumbar movement-evoked pain thresholds and functional capacity).\n\nThe pain severity perceived by participants was measured using the Numerical Pain Rating Scale (NPRS-11) asking participants to rate their average low back pain over the past week. Its validity and reliability has been well-documented. The NPRS-11 is a Likert-type scale ranging from 0 (no pain) to 10 (worst imaginable pain), where the patient verbally selects the value that best describes their perceived pain intensity [\nQST: PPT, TS, and CPM are indices of central nociceptive processing. First, baseline PPTs were assessed using algometry on the index finger (dorsal aspect of the distal phalanx) and 5 cm to the right of the spinous process of L3. The PPT is defined as the lowest pressure that, under standardised testing conditions, elicits the first sensation of pain. It is a reliable and widely used metric for assessing pain sensitivity [\nTo avoid carryover effects, TS and CPM were measured two minutes after the PPT measurements to evaluate nociceptive facilitation and descending inhibition, respectively. The degree of TS, or wind-up, was assessed in response to 10 pulses of the algometer, with an approximate pressure increase rate of 2 kg/s, at the previously defined index finger PPT. Participants were asked to use the NPRS-11 to intuitively rate the severity and discomfort of the pain associated with the first and tenth pulses. The degree of TS, reflecting the level of pain facilitation, was calculated as the difference between the final and the first PPT values during a series of three consecutive stimuli applied to the index finger region. A positive TS value indicates increased pain facilitation over repeated stimulation [\nFollowing a five-minute interval, CPM was assessed by replicating the TS evaluation in association with a conditioning stimulus used to induce CPM. To create said stimulus, an occlusion cuff was applied to the left arm and inflated at a rate of 20 mmHg/s until the patient reported the ‘first sensation of pain.’ The pressure reached at this point was then maintained for 30 s and the participant was asked to use the NPRS-11 to describe the severity of pain related to the occlusion in the arm. Subsequently, the cuff inflation was adjusted until the pain intensity reached 3/10 on the NPRS. The previously described TS procedure was then repeated with the cuff inflated at this lower level, with the arm relaxed. CPM was calculated by subtracting the post-conditioning PPT from the baseline PPT at the index finger region (CPM = PPT_post – PPT_pre). A positive CPM value reflects an effective endogenous inhibitory response, while lower or negative CPM values indicate reduced inhibitory capacity [\n\n3. To assess kinesiophobia, we used the reliable and validated version of the Fear Avoidance Beliefs Questionnaire (FABQ). This questionnaire consists of 16 statements rated on a 7-point scale (from 0 = totally agree to 6 = totally disagree) with a total score range of 0–66. Higher scores indicate higher levels of fear-avoidance beliefs [\n4. To evaluate catastrophising in patients with CLBP, we utilised the validated Pain Catastrophizing Scale (PCS), which has shown internal consistency, test-retest reliability, and sensitivity to change. The PCS comprises 13 items rated on a 5-point scale ranging from 0 (never) to 4 (always) with a total score range of 0–52, measuring three components of catastrophising: rumination, magnification, and helplessness; higher scores indicate greater levels of pain-related catastrophising [\n5. To evaluate anxiety, only the Anxiety subscale of the Hospital Anxiety and Depression Scale (HADS-A) was administered. This is a 7-item self-reported screening scale. Each item is scored on a 4-point Likert scale (0 = ‘as much as I always do’; 1 = ‘not quite so much’; 2 = ‘definitely not so much’; and 3 = ‘not at all’), resulting in maximum scores for anxiety of 21 points, with higher scores indicating greater levels of anxiety [\n\n6. The lumbar flexion-evoked pain threshold was measured using a 3-Space Fastrack motion analysis system for the observational study. This system is a validated electro-goniometer for assessing lumbar mobility in patients with LBP and has demonstrated high reliability. Two motion sensors were placed on the spinous processes of T12 and S1 to monitor lumbar spine movements [\n7. Functional capacity was evaluated using the STS60 test which required individuals with CLBP to stand up and sit down on a chair without arm rests as many times as possible within 1 minute. The participants were informed when 15 seconds remained, but no encouragement was provided by the instructor during the test. The number of correct STS cycles fully completed within 1 minute was recorded for further analysis [\nStatistical analysis was performed using SPSS software (version 27.0, Macintosh OS, IBM Corp., Armonk, NY, USA). Normality of all variables was confirmed using the Shapiro–Wilk test, which supported the use of parametric analyses, including Pearson’s correlation coefficients. Therefore, we employed Pearson’s correlation analysis to examine the relationships between variables (pain intensity, QST parameters, psychological factors, lumbar flexion-evoked pain threshold, and functional capacity). The correlation coefficient was stratified into five levels according to the following cut-off points: a correlation coefficient of\nFifty individuals with CLBP voluntarily participated in this observational study.\nOverview of the participant characteristics.\nValues are expressed as the mean ± the standard deviation. N: number of participants; PPT_LUMBAR: lumbar pain pressure threshold; TS: temporal summation; CPM: conditioned pain modulation; LFEPT: lumbar flexion-evoked pain threshold; STS60: 1-Minute Sit-to-Stand test.\nTabulation of Pearson correlation coefficients, pain, QST parameters, lumbar movement-evoked pain, disability, and psychological factors.\n*Correlations considered significant at the 0.05 level (bilateral). ** Correlations considered significant at the 0.01 level (bilateral). NPRS-11: Pain Numerical Rating Scale; PPT_LUMBAR: lumbar pain pressure threshold; TS: temporal summation; CPM: conditioned pain modulation; LFEPT: lumbar flexion-evoked pain threshold; STS60: 1-Minute Sit-to-Stand test. Note: PPT at the index finger was used to calculate TS and CPM values and was not analysed independently in relation to clinical outcomes.\nMultiple stepwise linear regression analyses in lumbar pain and kinesiophobia as dependent variables.\nPPT_LUMBAR: Pain Pressure Threshold in Lumbar; STS60: Sit to Stand 60 s; VIF: variance inflation factor.\nTo the best of our knowledge, this is the first study to investigate, from a holistic perspective, the correlations between pain intensity, pain processing mechanisms in conjunction with various psychosocial factors, and functional outcomes in patients with CLBP. Our exploratory findings revealed associations between pain intensity and various aspects of central pain processing, psychological factors, and functional outcomes in patients with CLBP.\nThis current study demonstrated significant correlations between pain intensity and several variables, including PPT_lumbar, CPM, lumbar flexion-evoked pain threshold, kinesiophobia, catastrophising, anxiety, and STS60 scores. These preliminary results support the relevance of a biopsychosocial framework in understanding CLBP, suggesting a complex interplay of physical, physiological, and psychological factors. Until now, no study had comprehensively examined these correlations in their entirety within a specific population with CLBP. Rather, previous research had only investigated these factors separately, except for movement-evoked pain, which to date, has only been explored in patients with chronic knee pain.\nSimilar to our findings, previous studies have identified correlations between pain sensitivity, PPT_lumbar, and CPM [\nIn turn, the significant negative correlation we found between pain and CPM implies that reduced descending inhibitory pathways may contribute to increased pain perception, as shown in previous studies demonstrating differences in CPM between individuals with and without chronic pain [\nInterestingly, our findings revealed that TS did not significantly correlate with pain sensitivity. As in previous studies, this lack of meaningful correlation might suggest that TS, as a measure of CS, operates independently from other pain-related factors such as pain intensity, psychological factors, and functional outcomes [\nWe found associations between pain and kinesiophobia, in line with previous studies that have similarly identified significant correlations between pain intensity and psychosocial factors such as kinesiophobia, [\nFinally, catastrophising, characterised by an exaggerated negative mindset towards pain, exacerbates fear-avoidance behaviours, leading to greater kinesiophobia and functional limitations [\nMoreover, our findings further indicated a negative correlation between lumbar pain and STS60 performance. Indeed, the inclusion of the STS60 alongside PPT_lumbar in the regression model significantly increased the explained variance in lumbar pain to 39.7%. This finding line up with previous research suggesting a negative association between functional capacity and pain intensity in chronic musculoskeletal conditions [\nThis aforementioned association also highlights the utility of the STS60 as a quick, simple and clinically meaningful metric for functional capacity in individuals with CLBP. Furthermore, the Fear-Avoidance Model highlights how reduced physical function may increase fear-avoidance behaviours, leading to further deconditioning and worsening pain perception over time [\nMoreover, the significant negative correlation between pain and the flexion-evoked pain threshold identified in this current work indicates that lower thresholds for pain during lumbar flexion are associated with higher levels of overall pain. This finding aligns with previous research in knee osteoarthritis [\nOur results showed significant correlations between PPT and several key factors in patients with CLBP, including CPM, flexion-evoked pain threshold, and STS60 scores. Firstly, the significant correlation between PPT and CPM underscores the intricate balance between pain sensitivity and descending inhibitory pathways in patients with CLBP. This finding aligns with previous research indicating that individuals with reduced pain thresholds often exhibit low endogenous pain inhibition, suggesting a potential dysfunction in the central processing of nociceptive signals (CS) [\nThe positive correlation between PPT and functional capacity (STS60), indicates that increased pain sensitivity is associated with greater functional impairment. This is consistent with the notion that heightened pain perception can limit physical activity and daily functioning. Similar findings in previous studies support this relationship, suggesting that interventions aimed at reducing pain sensitivity could potentially improve functional outcomes in individuals with CLBP [\nFinally, our analysis indicated that CPM showed significant correlations with both the flexion-evoked pain threshold and STS60 score. These findings concur with a previous study and suggest that the efficiency of descending pain inhibitory pathways, as measured by CPM, is linked to higher thresholds for pain during lumbar flexion and with better functional capacity [\nIt is worth mentioning that this observational study may be susceptible to selection bias. The correlational analyses presented are exploratory in nature and serve to identify preliminary associations without adjustment for confounders. These results should be interpreted with caution and are intended to guide future confirmatory research using multivariable modelling. Furthermore, the design of this work limits the ability to infer causality. Therefore, future research should involve larger, randomised, longitudinal studies to better understand causal relationships and explore the effectiveness of interventions aimed at modulating pain sensitivity and improving pain modulatory mechanisms in patients with CLBP. Moreover, the exclusion of participants over 65 years may limit the generalisability of our findings to older populations with CLBP. Finally, given the exploratory nature of this study, we focused on identifying potential associations using a feasible sample size, which still provided adequate power to detect medium effect sizes. These findings should be interpreted with caution and considered preliminary until validated in larger samples.\nNevertheless, this study is noteworthy because it is the first to investigate, from a holistic perspective, the correlations between pain intensity, pain processing mechanisms, and various psychosocial factors in individuals with CLBP. Pain intensity and kinesiophobia were associated with various central processing mechanisms of chronic pain (QST), psychological factors, and functional outcomes in individuals with CLBP, and could be predicted by lumbar PPT, STS60 performance, and catastrophising. Moreover, the identification of significant variables in our regression analysis provides evidence for their roles in chronic pain. Furthermore, the comprehensive analysis of the interplay between biophysical, psychological, and functional factors underscores the multifaceted nature of CLBP, which may inform more integrated and effective assessments and intervention strategies in cases of CLBP in the future. Additionally, incorporating PPT_Lumbar and STS60 assessments into clinical settings may enhance the identification of patients at risk of more severe pain and kinesiophobia presentations, ultimately facilitating targeted interventions aimed at modulating CS.\nIn summary, these correlations highlight the intricate interplay between pain sensitivity, pain modulatory mechanisms, psychological factors, and functional outcomes in individuals with CLBP. These exploratory results underscore the complex and multifactorial nature of chronic pain and suggest that future research should further investigate these relationships to inform comprehensive assessment and treatment approaches. Moreover, new functional and physiological predictors of pain and kinesiophobia may contribute to the development of better assessment and treatment protocols for CLBP. From a clinical perspective, lumbar PPT assessments and the STS60 test could serve as accessible, time-efficient screening tools to inform individualised treatment planning. For instance, lower PPTs may indicate a need for interventions targeting altered pain processing, such as graded exposure or sensory desensitisation strategies, whereas reduced STS60 performance may suggest the importance of physical reconditioning and exercise-based approaches [", "content_for_embedding": "Chronic low back pain (CLBP) is one of the leading causes of disability worldwide and significantly affects healthcare services [\nWithin the biopsychosocial framework for understanding chronic pain, several more specific mechanism-oriented models have been developed to describe the factors that may influence pain [\nOver the past decade, there has been a substantial increase in research not only investigating the Fear-Avoidance Model but also exploring the mechanisms that promote and inhibit nociception in individuals experiencing chronic pain. Thus, the profound interconnection and influence between the CNS and mechanisms that underlie pain processing in cases of CLBP has been studied [\nCS is defined as increased responsiveness of spinal nociceptive neurons, where their cortical projections can outlast tissue-based input or be sustained by a normally subthreshold tissue-based input [\nQuantitative sensory testing (QST) is used to measure some mechanisms of pain. QST is an umbrella term for non-invasive psychophysical tissue-stimulation tests that provide information about altered sensory processing such as sensitivity and dysregulation of pro-nociceptive and anti-nociceptive pathways, thereby providing insights into pain mechanisms [\nPrevious narrative reviews have reported differences between people with CLBP and healthy controls in terms of several QST metrics. Higher PPTs at remote body parts from pain, facilitated TS, and low CPM were interpreted as signs of CS and were present in individuals with CLBP [\nMoreover, people with CLBP often experience pain during functional activities which, in turn, reduces their functional capacity [\nActivity-related pain metrics such as movement-evoked pain thresholds have been used to capture information on distinct aspects of activity-related pain [\nThese variables have only been studied collectively in knee osteoarthritis. However, while they have been examined individually in patients with CLBP, these studies lacked a more holistic perspective. To the best of our knowledge, no research to date has investigated the correlations between pain intensity, pain processing mechanisms in conjunction with various psychosocial factors, and functional outcomes in CLBP. Thus, the primary objective of this exploratory study was to investigate potential correlations between pain intensity and pain processing mechanisms (QST parameters [PPT, TS, and CPM]), psychological factors (kinesiophobia, catastrophising, and anxiety), and functional outcomes (lumbar movement-evoked pain thresholds and functional capacity) in individuals with CLBP. We hypothesised that higher levels of pain intensity are associated with CS QST indices, poorer psychological factor outcomes, and lower lumbar movement-evoked pain thresholds and functional capacity in individuals with CLBP. A secondary aim was to explore which variables were most strongly associated with pain intensity and kinesiophobia, a key component of the Fear-Avoidance Model given its recognised impact on pain-related disability and behavioural avoidance in individuals with CLBP, with the goal of identifying potential predictors for future hypothesis-driven research.\nThis observational study recruited participants from the Orthopaedic Surgery Service and Physical Medicine and Rehabilitation Service at Arnau de Vilanova Hospital in Valencia, Spain. The study was approved by the Ethics Committee at the Arnau de Vilanova Hospital in Valencia, Spain, (reference: CEIm:30/2021) as well as by the CEU Cardenal Herrera University in Valencia, Spain, (reference: CEEI21/203) in accordance with the fundamental principles established in the Declaration of Helsinki. Prior to commencing the study, all the participants received an information letter and provided their written consent to participation. Additionally, this study was conducted in compliance with the STROBE reporting guidelines for observational studies [\nFifty patients diagnosed with non-specific CLBP, according to the COST B13 European guideline, [\nIn this observational study, the sample size was calculated using G*Power 3 software [\nParticipants completed all the questionnaires related to pain and psychological factors online. Subsequently, patients attended the physiotherapy department at Arnau de Vilanova Hospital, where the same physical therapist evaluated their pain processing mechanisms and functional outcomes. The outcomes measured in this study included pain (pain intensity), pain processing mechanisms (QST parameters [PPT, TS, and CPM]), psychological factors (kinesiophobia, catastrophising, and anxiety), and functional outcomes (lumbar movement-evoked pain thresholds and functional capacity).\n\nThe pain severity perceived by participants was measured using the Numerical Pain Rating Scale (NPRS-11) asking participants to rate their average low back pain over the past week. Its validity and reliability has been well-documented. The NPRS-11 is a Likert-type scale ranging from 0 (no pain) to 10 (worst imaginable pain), where the patient verbally selects the value that best describes their perceived pain intensity [\nQST: PPT, TS, and CPM are indices of central nociceptive processing. First, baseline PPTs were assessed using algometry on the index finger (dorsal aspect of the distal phalanx) and 5 cm to the right of the spinous process of L3. The PPT is defined as the lowest pressure that, under standardised testing conditions, elicits the first sensation of pain. It is a reliable and widely used metric for assessing pain sensitivity [\nTo avoid carryover effects, TS and CPM were measured two minutes after the PPT measurements to evaluate nociceptive facilitation and descending inhibition, respectively. The degree of TS, or wind-up, was assessed in response to 10 pulses of the algometer, with an approximate pressure increase rate of 2 kg/s, at the previously defined index finger PPT. Participants were asked to use the NPRS-11 to intuitively rate the severity and discomfort of the pain associated with the first and tenth pulses. The degree of TS, reflecting the level of pain facilitation, was calculated as the difference between the final and the first PPT values during a series of three consecutive stimuli applied to the index finger region. A positive TS value indicates increased pain facilitation over repeated stimulation [\nFollowing a five-minute interval, CPM was assessed by replicating the TS evaluation in association with a conditioning stimulus used to induce CPM. To create said stimulus, an occlusion cuff was applied to the left arm and inflated at a rate of 20 mmHg/s until the patient reported the ‘first sensation of pain.’ The pressure reached at this point was then maintained for 30 s and the participant was asked to use the NPRS-11 to describe the severity of pain related to the occlusion in the arm. Subsequently, the cuff inflation was adjusted until the pain intensity reached 3/10 on the NPRS. The previously described TS procedure was then repeated with the cuff inflated at this lower level, with the arm relaxed. CPM was calculated by subtracting the post-conditioning PPT from the baseline PPT at the index finger region (CPM = PPT_post – PPT_pre). A positive CPM value reflects an effective endogenous inhibitory response, while lower or negative CPM values indicate reduced inhibitory capacity [\n\n3. To assess kinesiophobia, we used the reliable and validated version of the Fear Avoidance Beliefs Questionnaire (FABQ). This questionnaire consists of 16 statements rated on a 7-point scale (from 0 = totally agree to 6 = totally disagree) with a total score range of 0–66. Higher scores indicate higher levels of fear-avoidance beliefs [\n4. To evaluate catastrophising in patients with CLBP, we utilised the validated Pain Catastrophizing Scale (PCS), which has shown internal consistency, test-retest reliability, and sensitivity to change. The PCS comprises 13 items rated on a 5-point scale ranging from 0 (never) to 4 (always) with a total score range of 0–52, measuring three components of catastrophising: rumination, magnification, and helplessness; higher scores indicate greater levels of pain-related catastrophising [\n5. To evaluate anxiety, only the Anxiety subscale of the Hospital Anxiety and Depression Scale (HADS-A) was administered. This is a 7-item self-reported screening scale. Each item is scored on a 4-point Likert scale (0 = ‘as much as I always do’; 1 = ‘not quite so much’; 2 = ‘definitely not so much’; and 3 = ‘not at all’), resulting in maximum scores for anxiety of 21 points, with higher scores indicating greater levels of anxiety [\n\n6. The lumbar flexion-evoked pain threshold was measured using a 3-Space Fastrack motion analysis system for the observational study. This system is a validated electro-goniometer for assessing lumbar mobility in patients with LBP and has demonstrated high reliability. Two motion sensors were placed on the spinous processes of T12 and S1 to monitor lumbar spine movements [\n7. Functional capacity was evaluated using the STS60 test which required individuals with CLBP to stand up and sit down on a chair without arm rests as many times as possible within 1 minute. The participants were informed when 15 seconds remained, but no encouragement was provided by the instructor during the test. The number of correct STS cycles fully completed within 1 minute was recorded for further analysis [\nStatistical analysis was performed using SPSS software (version 27.0, Macintosh OS, IBM Corp., Armonk, NY, USA). Normality of all variables was confirmed using the Shapiro–Wilk test, which supported the use of parametric analyses, including Pearson’s correlation coefficients. Therefore, we employed Pearson’s correlation analysis to examine the relationships between variables (pain intensity, QST parameters, psychological factors, lumbar flexion-evoked pain threshold, and functional capacity). The correlation coefficient was stratified into five levels according to the following cut-off points: a correlation coefficient of\nFifty individuals with CLBP voluntarily participated in this observational study.\nOverview of the participant characteristics.\nValues are expressed as the mean ± the standard deviation. N: number of participants; PPT_LUMBAR: lumbar pain pressure threshold; TS: temporal summation; CPM: conditioned pain modulation; LFEPT: lumbar flexion-evoked pain threshold; STS60: 1-Minute Sit-to-Stand test.\nTabulation of Pearson correlation coefficients, pain, QST parameters, lumbar movement-evoked pain, disability, and psychological factors.\n*Correlations considered significant at the 0.05 level (bilateral). ** Correlations considered significant at the 0.01 level (bilateral). NPRS-11: Pain Numerical Rating Scale; PPT_LUMBAR: lumbar pain pressure threshold; TS: temporal summation; CPM: conditioned pain modulation; LFEPT: lumbar flexion-evoked pain threshold; STS60: 1-Minute Sit-to-Stand test. Note: PPT at the index finger was used to calculate TS and CPM values and was not analysed independently in relation to clinical outcomes.\nMultiple stepwise linear regression analyses in lumbar pain and kinesiophobia as dependent variables.\nPPT_LUMBAR: Pain Pressure Threshold in Lumbar; STS60: Sit to Stand 60 s; VIF: variance inflation factor.\nTo the best of our knowledge, this is the first study to investigate, from a holistic perspective, the correlations between pain intensity, pain processing mechanisms in conjunction with various psychosocial factors, and functional outcomes in patients with CLBP. Our exploratory findings revealed associations between pain intensity and various aspects of central pain processing, psychological factors, and functional outcomes in patients with CLBP.\nThis current study demonstrated significant correlations between pain intensity and several variables, including PPT_lumbar, CPM, lumbar flexion-evoked pain threshold, kinesiophobia, catastrophising, anxiety, and STS60 scores. These preliminary results support the relevance of a biopsychosocial framework in understanding CLBP, suggesting a complex interplay of physical, physiological, and psychological factors. Until now, no study had comprehensively examined these correlations in their entirety within a specific population with CLBP. Rather, previous research had only investigated these factors separately, except for movement-evoked pain, which to date, has only been explored in patients with chronic knee pain.\nSimilar to our findings, previous studies have identified correlations between pain sensitivity, PPT_lumbar, and CPM [\nIn turn, the significant negative correlation we found between pain and CPM implies that reduced descending inhibitory pathways may contribute to increased pain perception, as shown in previous studies demonstrating differences in CPM between individuals with and without chronic pain [\nInterestingly, our findings revealed that TS did not significantly correlate with pain sensitivity. As in previous studies, this lack of meaningful correlation might suggest that TS, as a measure of CS, operates independently from other pain-related factors such as pain intensity, psychological factors, and functional outcomes [\nWe found associations between pain and kinesiophobia, in line with previous studies that have similarly identified significant correlations between pain intensity and psychosocial factors such as kinesiophobia, [\nFinally, catastrophising, characterised by an exaggerated negative mindset towards pain, exacerbates fear-avoidance behaviours, leading to greater kinesiophobia and functional limitations [\nMoreover, our findings further indicated a negative correlation between lumbar pain and STS60 performance. Indeed, the inclusion of the STS60 alongside PPT_lumbar in the regression model significantly increased the explained variance in lumbar pain to 39.7%. This finding line up with previous research suggesting a negative association between functional capacity and pain intensity in chronic musculoskeletal conditions [\nThis aforementioned association also highlights the utility of the STS60 as a quick, simple and clinically meaningful metric for functional capacity in individuals with CLBP. Furthermore, the Fear-Avoidance Model highlights how reduced physical function may increase fear-avoidance behaviours, leading to further deconditioning and worsening pain perception over time [\nMoreover, the significant negative correlation between pain and the flexion-evoked pain threshold identified in this current work indicates that lower thresholds for pain during lumbar flexion are associated with higher levels of overall pain. This finding aligns with previous research in knee osteoarthritis [\nOur results showed significant correlations between PPT and several key factors in patients with CLBP, including CPM, flexion-evoked pain threshold, and STS60 scores. Firstly, the significant correlation between PPT and CPM underscores the intricate balance between pain sensitivity and descending inhibitory pathways in patients with CLBP. This finding aligns with previous research indicating that individuals with reduced pain thresholds often exhibit low endogenous pain inhibition, suggesting a potential dysfunction in the central processing of nociceptive signals (CS) [\nThe positive correlation between PPT and functional capacity (STS60), indicates that increased pain sensitivity is associated with greater functional impairment. This is consistent with the notion that heightened pain perception can limit physical activity and daily functioning. Similar findings in previous studies support this relationship, suggesting that interventions aimed at reducing pain sensitivity could potentially improve functional outcomes in individuals with CLBP [\nFinally, our analysis indicated that CPM showed significant correlations with both the flexion-evoked pain threshold and STS60 score. These findings concur with a previous study and suggest that the efficiency of descending pain inhibitory pathways, as measured by CPM, is linked to higher thresholds for pain during lumbar flexion and with better functional capacity [\nIt is worth mentioning that this observational study may be susceptible to selection bias. The correlational analyses presented are exploratory in nature and serve to identify preliminary associations without adjustment for confounders. These results should be interpreted with caution and are intended to guide future confirmatory research using multivariable modelling. Furthermore, the design of this work limits the ability to infer causality. Therefore, future research should involve larger, randomised, longitudinal studies to better understand causal relationships and explore the effectiveness of interventions aimed at modulating pain sensitivity and improving pain modulatory mechanisms in patients with CLBP. Moreover, the exclusion of participants over 65 years may limit the generalisability of our findings to older populations with CLBP. Finally, given the exploratory nature of this study, we focused on identifying potential associations using a feasible sample size, which still provided adequate power to detect medium effect sizes. These findings should be interpreted with caution and considered preliminary until validated in larger samples.\nNevertheless, this study is noteworthy because it is the first to investigate, from a holistic perspective, the correlations between pain intensity, pain processing mechanisms, and various psychosocial factors in individuals with CLBP. Pain intensity and kinesiophobia were associated with various central processing mechanisms of chronic pain (QST), psychological factors, and functional outcomes in individuals with CLBP, and could be predicted by lumbar PPT, STS60 performance, and catastrophising. Moreover, the identification of significant variables in our regression analysis provides evidence for their roles in chronic pain. Furthermore, the comprehensive analysis of the interplay between biophysical, psychological, and functional factors underscores the multifaceted nature of CLBP, which may inform more integrated and effective assessments and intervention strategies in cases of CLBP in the future. Additionally, incorporating PPT_Lumbar and STS60 assessments into clinical settings may enhance the identification of patients at risk of more severe pain and kinesiophobia presentations, ultimately facilitating targeted interventions aimed at modulating CS.\nIn summary, these correlations highlight the intricate interplay between pain sensitivity, pain modulatory mechanisms, psychological factors, and functional outcomes in individuals with CLBP. These exploratory results underscore the complex and multifactorial nature of chronic pain and suggest that future research should further investigate these relationships to inform comprehensive assessment and treatment approaches. Moreover, new functional and physiological predictors of pain and kinesiophobia may contribute to the development of better assessment and treatment protocols for CLBP. From a clinical perspective, lumbar PPT assessments and the STS60 test could serve as accessible, time-efficient screening tools to inform individualised treatment planning. For instance, lower PPTs may indicate a need for interventions targeting altered pain processing, such as graded exposure or sensory desensitisation strategies, whereas reduced STS60 performance may suggest the importance of physical reconditioning and exercise-based approaches [", "topic": "Diagnostic"}
{"pmid": "40533775", "pmcid": "12299368", "title": "High-Protein Dietary Interventions in Heart Failure: A Systematic Review of Clinical and Functional Outcomes", "publication_year": "N/A", "abstract": "", "full_text": "Heart failure (HF) is typically linked to protein–energy deficiency and muscle loss (sarcopenia or cachexia), which contribute to reduced functional capacity and higher mortality [\nStudies suggest that people with chronic HF may gain advantages from elevated protein intake. A study involving more than 400 individuals with HF indicated that participants with the lowest protein intake had a mortality rate of over 50% over 2.5 years. In contrast, those with elevated protein consumption had a mortality rate of approximately 27% [\nThere is a lack of studies on how protein intake can aid with HF, so we conducted a systematic review to see what high-protein meals or supplements may be beneficial for this condition. We examined clinical outcomes (including death and hospitalization), functional capacity, and nutritional status measurements (such as body composition and muscle strength) to assess the strength of the evidence. We also looked closely at each study to make sure there was no bias.\nWe reviewed many electronic databases and search engines to discover studies that examined high-protein diets or protein supplements in HF. The literature was updated to June 2025. Some of the keywords utilized were “heart failure,” “protein intake,” “high-protein diet,” “protein supplement,” and “nutrition.” We also searched the reference lists of reviews and guidelines that were related to our topic to identify more publications. We did not establish any boundaries on when the research might be published, but we only considered studies that were published in English and involved adults. We examined both randomized controlled trials (RCTs) and other controlled intervention studies, since we were uncertain that RCTs would have adequate evidence. This rigorous method follows the standards for systematic reviews that have been put in place to decrease the risk of missing key studies and publication bias [\nThe inclusion criteria for this systematic review encompassed studies involving adults aged 18 years and older with HF, irrespective of the underlying cause or classification (such as heart failure with reduced ejection fraction [HFrEF] or heart failure with preserved ejection fraction [HFpEF]), and included participants in both stable chronic states and the early post-discharge period. Studies may be included with or without the absence of specific nutritional hazards, such as malnutrition or cachexia. The intervention of interest involved the administration of a high-protein diet, which may be achieved through meal modifications, oral nutritional supplements, or the incorporation of amino acids into the diet. This study defined a high-protein intervention relative to a control condition, typically aiming for an intake exceeding standard recommendations, such as 1.2–1.5 g/kg/day or a significant increase in daily protein intake in absolute grams [\nComparators included usual care or a diet with standard protein content, with some studies utilizing a placebo supplement or simply continuing a regular diet as the control condition. To capture meaningful efficacy data, studies were required to report on at least one pertinent outcome. These outcomes ranged from clinical endpoints—such as mortality or HF hospitalizations—to measures of functional capacity (including peak VO\nTwo reviewers independently examined titles, abstracts, and complete texts to locate studies that fulfilled the criteria, resolving any disagreements through consensus [\nFollowing study selection, two reviewers extracted key data (author, year, sample size, HF classification, intervention dose and modality, comparator, outcomes, effect sizes, follow-up duration, and risk of bias) into a standardized form. We initially considered quantitative pooling for outcomes reported by multiple trials; however, substantial clinical and methodological heterogeneity—reflected in variation in protein dosing (1.1–1.5 g/kg/day or 25–30% energy), supplement types (oral formulas, amino acid mixtures, whole-food modifications), patient subgroups (HFrEF vs. HFpEF; stable vs. post-discharge), outcome measures (six-minute walk distance, lean body mass, muscle strength, quality-of-life scales, readmission rates), and follow-up periods (2–12 months)—precluded meta-analysis. Instead, we employed a structured narrative synthesis, grouping studies by outcome domain (functional capacity, body composition, muscle strength, clinical endpoints) to compare direction and magnitude of effects. Where at least three trials reported comparable outcomes under similar intervention conditions, we summarized mean changes and ranges. To explore potential sources of variability, we examined the impact of protein dose, supplement modality, intervention duration, and study quality on reported outcomes, interpreting effect patterns in light of each trial’s risk-of-bias assessment.\nWe evaluated the internal validity of the included studies using the Cochrane Risk of Bias tool (Version 2) for RCTs [\nGiven anticipated heterogeneity in interventions (e.g., varied diet schemes, different durations) and outcomes, a qualitative, narrative synthesis was performed. Where outcomes were sufficiently homogeneous (e.g., body weight change), we considered a meta-analysis; however, differences in study designs and reporting limited quantitative pooling [\nThe search yielded ten primary papers that satisfied the criteria for high-protein diet treatments in HF, including nine RCTs and one controlled pilot study (\nAll trials examined methods to augment daily protein consumption, typically through the utilization of oral nutritional supplements. A research study, for instance, provided individuals with a high-calorie, protein-dense supplement (about 750 kcal/day containing 30 g of protein) with their regular diet [\nAlterations in body weight and lean mass, exercise capacity (assessed by maximum oxygen uptake [VO\nAcross 10 controlled trials enrolling 1080 patients with HF, high-protein interventions delivered consistently meaningful gains across several domains. The mean distance traversed by participants in the six-minute walk test was 32 ± 14 m greater than the mean distance covered by participants in the six-minute walk test, with individual study enhancements varying from +8 to +58 m. This exceeds the 25 m criterion for clinical significance. The mean augmentation in lean body mass was 1.6 ± 0.9 kg (ranging from +0.5 to +2.3 kg), which mitigated the prevalent muscular atrophy in this demographic. Patient-reported quality-of-life scores rose by approximately 9 ± 4%, signaling tangible improvements in daily well-being. Two trials demonstrated an 18% reduction in HF readmissions (\nInterpretation of these findings must consider the considerable clinical and methodological heterogeneity across trials—variation in protein dosing (1.1–1.5 g/kg/day or 25–30% energy), supplement formulations, patient subgroups (HFrEF vs. HFpEF; stable vs. post-discharge), outcome measures, and follow-up durations—which precluded meta-analysis and may limit the generalizability of the reported effect sizes.\nThe risk of bias in the included studies varied from low to high, with the majority of trials being classified as having a moderate risk of bias due to methodological restrictions.\nAdditionally, the rate of incomplete outcome data (drop-outs) was generally low, except for one trial with unclear attrition reporting [\nSeveral studies indicate that increasing protein intake in patients with HF can enhance their nutritional status. Broqvist et al. (1994) discovered that patients who consumed protein-rich supplements for eight weeks saw weight gain, predominantly as adipose tissue [\nHigh-protein diets have been associated with improvements in visceral protein markers, such as serum albumin and prealbumin, indicating enhanced nutritional status in patients with HF. In Broqvist’s study, serum albumin levels increased in the intervention group despite advanced HF, suggesting a positive nutritional effect [\nThe effects of high-protein diets on functional outcomes, such as exercise capacity, have not always been mixed. Pineda-Juárez et al. (2016) [\nSome trials showed that the inclusion of protein in the diet enhances functional outcomes. Bonilla-Palomas et al. demonstrated that patients receiving dietary support exhibited improved handgrip strength and reported enhanced quality of life after six months compared to those who did not receive assistance [\nSeveral included trials lacked sufficient size or duration to assess clinical outcomes, such as mortality or hospital readmissions, adequately. The RCT conducted by Bonilla-Palomas et al. demonstrated that comprehensive nutritional support significantly decreased adverse outcomes. In the trial, malnourished individuals with HF were randomly assigned to receive either dietary counseling along with high-protein, high-calorie oral nutritional supplements or standard treatment following hospital discharge. The intervention group exhibited significantly lower rates of the composite endpoint, which includes all-cause mortality and HF hospitalization, over approximately six months [\nAlthough large-scale evidence is limited, moderate-sized RCTs have shown that high-protein dietary therapies produce short-term gains in nutritional and functional status and significantly reduce readmissions and mortality among malnourished or high-risk HF patients [\nThis systematic analysis demonstrates that high-protein dietary therapies in individuals with HF typically enhance individuals’ nutritional status (body weight, albumin levels) and may provide advantages in functional ability and clinical outcomes, especially in malnourished individuals. Nonetheless, the database is derived from relatively small and varied research, and the risk-of-bias evaluation uncovers significant limitations that diminish our confidence in the findings.\nMultiple trials indicate that elevating protein intake in HF exerts benefits through intertwined mechanisms—essential amino acids (notably leucine) activate mTOR signaling to boost muscle protein synthesis [\nThe mixed results on exercise capacity improvement suggest that adding protein alone may not significantly improve functional status unless combined with exercise training or rehabilitation [\nA promising sign from other analyses is that individuals who consume more protein tend to derive greater functional gains, suggesting a synergy between nutrition and exercise [\nOur research indicates that individuals with HF who consume higher amounts of protein exhibit improved functional ability, enhanced nutritional indicators, and, in certain studies, a reduced risk of hospital readmission and mortality. The findings support the notion that diet is a critical component in the management of HF, particularly for individuals at risk of malnutrition, cachexia, or sarcopenia [\nOur review reveals that the quality of available evidence is generally moderate. Numerous trials exhibited insufficient power and were vulnerable to multiple biases. The absence of masking in nutrition trials presents a fundamental challenge, as participants and caregivers frequently possess knowledge of who is receiving additional supplements, potentially affecting adherence and management. While objective endpoints, such as mortality, are less prone to bias, subjective outcomes (appetite, quality of life) and even functional tests can be biased without masking. Additionally, several studies did not pre-specify their outcomes or analytic methods, raising the risk of selective reporting (e.g., only reporting favorable changes within the intervention group). The risk-of-bias table (\nOur findings align with those of other studies, indicating that, despite the limited number of significant trials, nutritional support may be advantageous for individuals with HF. Habaybeh et al.’s 2020 [\nIn practice, ensuring adequate protein intake in HF appears to be beneficial and is unlikely to cause harm in most individuals [\nSubsequent iterations of HF guidelines must transcend general dietary recommendations and integrate specific, evidence-based protein objectives and care protocols. We propose explicit protein intake objectives grounded in the interdisciplinary framework of the American College of Cardiology, the American Heart Association, and the European Society of Cardiology. The recommended protein intake is 1.2–1.5 g/kg/day for stable HF patients and up to 1.5 g/kg/day for individuals who are malnourished or experiencing cachexia [\nThe quality of the underlying studies limits this systematic review. The total sample size across trials is small, and patient populations and interventions vary, making it challenging to generalize the findings to all HF settings. We also note that most studies have focused on under-nourished or sarcopenic individuals; thus, the benefits of adding protein might be most pronounced in this group, and it remains less clear whether individuals who are already well nourished would gain additional benefits from protein loading [\nThe current trials, despite their limited size and duration, indicate that consistently increasing dietary protein preserves or enhances lean mass, improves functional capacity, and, in some studies, correlates with reduced mortality and rehospitalization in patients with HF and cachexia. However, significant questions remain to be addressed: What is the optimal daily dosage? Is it 1.2, 1.5, or greater grams per kilogram? At what time should it be administered? Should it be administered throughout meals or provided in a single bolus supplement? What are the optimal protein sources or combinations—such as whey, casein, or leucine-enriched options—for initiating muscle growth while minimizing stress on the kidneys and blood flow?\nFuture research must extend beyond small pilot studies to conduct large, well-designed RCTs that encompass a broad spectrum of HF symptoms and monitor patients over an adequate duration to observe definitive endpoints. Embedded mechanistic substudies should monitor mTOR activation, indicators of proteolysis, inflammatory cytokines, and kidney function. This will assist in determining the precise mechanisms by which protein counteracts the catabolic environment associated with HF. At the same time, we must refine practical approaches within multidisciplinary care teams, including routine nutritional screening at diagnosis and discharge, telehealth-supported dietetic counseling, and dynamic, patient-specific plans that account for age, comorbidity, and changing clinical status. Until such evidence arrives, clinicians should embrace current guideline targets—aiming for 1.2–1.5 g/kg/day in stable patients and higher in those with overt malnutrition—while tailoring protein prescriptions through close monitoring of weight, muscle strength, renal markers, and patient preferences. By combining scientific rigor with individualized nutrition care, we stand poised not only to enhance functional resilience and quality of life but ultimately to improve survival in the millions living with HF.", "content_for_embedding": "Heart failure (HF) is typically linked to protein–energy deficiency and muscle loss (sarcopenia or cachexia), which contribute to reduced functional capacity and higher mortality [\nStudies suggest that people with chronic HF may gain advantages from elevated protein intake. A study involving more than 400 individuals with HF indicated that participants with the lowest protein intake had a mortality rate of over 50% over 2.5 years. In contrast, those with elevated protein consumption had a mortality rate of approximately 27% [\nThere is a lack of studies on how protein intake can aid with HF, so we conducted a systematic review to see what high-protein meals or supplements may be beneficial for this condition. We examined clinical outcomes (including death and hospitalization), functional capacity, and nutritional status measurements (such as body composition and muscle strength) to assess the strength of the evidence. We also looked closely at each study to make sure there was no bias.\nWe reviewed many electronic databases and search engines to discover studies that examined high-protein diets or protein supplements in HF. The literature was updated to June 2025. Some of the keywords utilized were “heart failure,” “protein intake,” “high-protein diet,” “protein supplement,” and “nutrition.” We also searched the reference lists of reviews and guidelines that were related to our topic to identify more publications. We did not establish any boundaries on when the research might be published, but we only considered studies that were published in English and involved adults. We examined both randomized controlled trials (RCTs) and other controlled intervention studies, since we were uncertain that RCTs would have adequate evidence. This rigorous method follows the standards for systematic reviews that have been put in place to decrease the risk of missing key studies and publication bias [\nThe inclusion criteria for this systematic review encompassed studies involving adults aged 18 years and older with HF, irrespective of the underlying cause or classification (such as heart failure with reduced ejection fraction [HFrEF] or heart failure with preserved ejection fraction [HFpEF]), and included participants in both stable chronic states and the early post-discharge period. Studies may be included with or without the absence of specific nutritional hazards, such as malnutrition or cachexia. The intervention of interest involved the administration of a high-protein diet, which may be achieved through meal modifications, oral nutritional supplements, or the incorporation of amino acids into the diet. This study defined a high-protein intervention relative to a control condition, typically aiming for an intake exceeding standard recommendations, such as 1.2–1.5 g/kg/day or a significant increase in daily protein intake in absolute grams [\nComparators included usual care or a diet with standard protein content, with some studies utilizing a placebo supplement or simply continuing a regular diet as the control condition. To capture meaningful efficacy data, studies were required to report on at least one pertinent outcome. These outcomes ranged from clinical endpoints—such as mortality or HF hospitalizations—to measures of functional capacity (including peak VO\nTwo reviewers independently examined titles, abstracts, and complete texts to locate studies that fulfilled the criteria, resolving any disagreements through consensus [\nFollowing study selection, two reviewers extracted key data (author, year, sample size, HF classification, intervention dose and modality, comparator, outcomes, effect sizes, follow-up duration, and risk of bias) into a standardized form. We initially considered quantitative pooling for outcomes reported by multiple trials; however, substantial clinical and methodological heterogeneity—reflected in variation in protein dosing (1.1–1.5 g/kg/day or 25–30% energy), supplement types (oral formulas, amino acid mixtures, whole-food modifications), patient subgroups (HFrEF vs. HFpEF; stable vs. post-discharge), outcome measures (six-minute walk distance, lean body mass, muscle strength, quality-of-life scales, readmission rates), and follow-up periods (2–12 months)—precluded meta-analysis. Instead, we employed a structured narrative synthesis, grouping studies by outcome domain (functional capacity, body composition, muscle strength, clinical endpoints) to compare direction and magnitude of effects. Where at least three trials reported comparable outcomes under similar intervention conditions, we summarized mean changes and ranges. To explore potential sources of variability, we examined the impact of protein dose, supplement modality, intervention duration, and study quality on reported outcomes, interpreting effect patterns in light of each trial’s risk-of-bias assessment.\nWe evaluated the internal validity of the included studies using the Cochrane Risk of Bias tool (Version 2) for RCTs [\nGiven anticipated heterogeneity in interventions (e.g., varied diet schemes, different durations) and outcomes, a qualitative, narrative synthesis was performed. Where outcomes were sufficiently homogeneous (e.g., body weight change), we considered a meta-analysis; however, differences in study designs and reporting limited quantitative pooling [\nThe search yielded ten primary papers that satisfied the criteria for high-protein diet treatments in HF, including nine RCTs and one controlled pilot study (\nAll trials examined methods to augment daily protein consumption, typically through the utilization of oral nutritional supplements. A research study, for instance, provided individuals with a high-calorie, protein-dense supplement (about 750 kcal/day containing 30 g of protein) with their regular diet [\nAlterations in body weight and lean mass, exercise capacity (assessed by maximum oxygen uptake [VO\nAcross 10 controlled trials enrolling 1080 patients with HF, high-protein interventions delivered consistently meaningful gains across several domains. The mean distance traversed by participants in the six-minute walk test was 32 ± 14 m greater than the mean distance covered by participants in the six-minute walk test, with individual study enhancements varying from +8 to +58 m. This exceeds the 25 m criterion for clinical significance. The mean augmentation in lean body mass was 1.6 ± 0.9 kg (ranging from +0.5 to +2.3 kg), which mitigated the prevalent muscular atrophy in this demographic. Patient-reported quality-of-life scores rose by approximately 9 ± 4%, signaling tangible improvements in daily well-being. Two trials demonstrated an 18% reduction in HF readmissions (\nInterpretation of these findings must consider the considerable clinical and methodological heterogeneity across trials—variation in protein dosing (1.1–1.5 g/kg/day or 25–30% energy), supplement formulations, patient subgroups (HFrEF vs. HFpEF; stable vs. post-discharge), outcome measures, and follow-up durations—which precluded meta-analysis and may limit the generalizability of the reported effect sizes.\nThe risk of bias in the included studies varied from low to high, with the majority of trials being classified as having a moderate risk of bias due to methodological restrictions.\nAdditionally, the rate of incomplete outcome data (drop-outs) was generally low, except for one trial with unclear attrition reporting [\nSeveral studies indicate that increasing protein intake in patients with HF can enhance their nutritional status. Broqvist et al. (1994) discovered that patients who consumed protein-rich supplements for eight weeks saw weight gain, predominantly as adipose tissue [\nHigh-protein diets have been associated with improvements in visceral protein markers, such as serum albumin and prealbumin, indicating enhanced nutritional status in patients with HF. In Broqvist’s study, serum albumin levels increased in the intervention group despite advanced HF, suggesting a positive nutritional effect [\nThe effects of high-protein diets on functional outcomes, such as exercise capacity, have not always been mixed. Pineda-Juárez et al. (2016) [\nSome trials showed that the inclusion of protein in the diet enhances functional outcomes. Bonilla-Palomas et al. demonstrated that patients receiving dietary support exhibited improved handgrip strength and reported enhanced quality of life after six months compared to those who did not receive assistance [\nSeveral included trials lacked sufficient size or duration to assess clinical outcomes, such as mortality or hospital readmissions, adequately. The RCT conducted by Bonilla-Palomas et al. demonstrated that comprehensive nutritional support significantly decreased adverse outcomes. In the trial, malnourished individuals with HF were randomly assigned to receive either dietary counseling along with high-protein, high-calorie oral nutritional supplements or standard treatment following hospital discharge. The intervention group exhibited significantly lower rates of the composite endpoint, which includes all-cause mortality and HF hospitalization, over approximately six months [\nAlthough large-scale evidence is limited, moderate-sized RCTs have shown that high-protein dietary therapies produce short-term gains in nutritional and functional status and significantly reduce readmissions and mortality among malnourished or high-risk HF patients [\nThis systematic analysis demonstrates that high-protein dietary therapies in individuals with HF typically enhance individuals’ nutritional status (body weight, albumin levels) and may provide advantages in functional ability and clinical outcomes, especially in malnourished individuals. Nonetheless, the database is derived from relatively small and varied research, and the risk-of-bias evaluation uncovers significant limitations that diminish our confidence in the findings.\nMultiple trials indicate that elevating protein intake in HF exerts benefits through intertwined mechanisms—essential amino acids (notably leucine) activate mTOR signaling to boost muscle protein synthesis [\nThe mixed results on exercise capacity improvement suggest that adding protein alone may not significantly improve functional status unless combined with exercise training or rehabilitation [\nA promising sign from other analyses is that individuals who consume more protein tend to derive greater functional gains, suggesting a synergy between nutrition and exercise [\nOur research indicates that individuals with HF who consume higher amounts of protein exhibit improved functional ability, enhanced nutritional indicators, and, in certain studies, a reduced risk of hospital readmission and mortality. The findings support the notion that diet is a critical component in the management of HF, particularly for individuals at risk of malnutrition, cachexia, or sarcopenia [\nOur review reveals that the quality of available evidence is generally moderate. Numerous trials exhibited insufficient power and were vulnerable to multiple biases. The absence of masking in nutrition trials presents a fundamental challenge, as participants and caregivers frequently possess knowledge of who is receiving additional supplements, potentially affecting adherence and management. While objective endpoints, such as mortality, are less prone to bias, subjective outcomes (appetite, quality of life) and even functional tests can be biased without masking. Additionally, several studies did not pre-specify their outcomes or analytic methods, raising the risk of selective reporting (e.g., only reporting favorable changes within the intervention group). The risk-of-bias table (\nOur findings align with those of other studies, indicating that, despite the limited number of significant trials, nutritional support may be advantageous for individuals with HF. Habaybeh et al.’s 2020 [\nIn practice, ensuring adequate protein intake in HF appears to be beneficial and is unlikely to cause harm in most individuals [\nSubsequent iterations of HF guidelines must transcend general dietary recommendations and integrate specific, evidence-based protein objectives and care protocols. We propose explicit protein intake objectives grounded in the interdisciplinary framework of the American College of Cardiology, the American Heart Association, and the European Society of Cardiology. The recommended protein intake is 1.2–1.5 g/kg/day for stable HF patients and up to 1.5 g/kg/day for individuals who are malnourished or experiencing cachexia [\nThe quality of the underlying studies limits this systematic review. The total sample size across trials is small, and patient populations and interventions vary, making it challenging to generalize the findings to all HF settings. We also note that most studies have focused on under-nourished or sarcopenic individuals; thus, the benefits of adding protein might be most pronounced in this group, and it remains less clear whether individuals who are already well nourished would gain additional benefits from protein loading [\nThe current trials, despite their limited size and duration, indicate that consistently increasing dietary protein preserves or enhances lean mass, improves functional capacity, and, in some studies, correlates with reduced mortality and rehospitalization in patients with HF and cachexia. However, significant questions remain to be addressed: What is the optimal daily dosage? Is it 1.2, 1.5, or greater grams per kilogram? At what time should it be administered? Should it be administered throughout meals or provided in a single bolus supplement? What are the optimal protein sources or combinations—such as whey, casein, or leucine-enriched options—for initiating muscle growth while minimizing stress on the kidneys and blood flow?\nFuture research must extend beyond small pilot studies to conduct large, well-designed RCTs that encompass a broad spectrum of HF symptoms and monitor patients over an adequate duration to observe definitive endpoints. Embedded mechanistic substudies should monitor mTOR activation, indicators of proteolysis, inflammatory cytokines, and kidney function. This will assist in determining the precise mechanisms by which protein counteracts the catabolic environment associated with HF. At the same time, we must refine practical approaches within multidisciplinary care teams, including routine nutritional screening at diagnosis and discharge, telehealth-supported dietetic counseling, and dynamic, patient-specific plans that account for age, comorbidity, and changing clinical status. Until such evidence arrives, clinicians should embrace current guideline targets—aiming for 1.2–1.5 g/kg/day in stable patients and higher in those with overt malnutrition—while tailoring protein prescriptions through close monitoring of weight, muscle strength, renal markers, and patient preferences. By combining scientific rigor with individualized nutrition care, we stand poised not only to enhance functional resilience and quality of life but ultimately to improve survival in the millions living with HF.", "topic": "Diagnostic"}
{"pmid": "40526870", "pmcid": "12293788", "title": "Sleep and Risk of Multiple Sclerosis: Bridging the Gap Between Inflammation and Neurodegeneration via Glymphatic Failure", "publication_year": "N/A", "abstract": "Epidemiological studies identified insufficient and poor-quality sleep as independent risk factors for multiple sclerosis (MS). The glymphatic system, active during slow-wave sleep, clears brain waste through perivascular astrocytic aquaporin-4 (AQP4) channels. The presence of antigens induces a transient, physiological lowering of glymphatic flux as a first step of an inflammatory response. A possible hypothesis linking infection with the Epstein–Barr virus, a well identified causal step in MS, and the development of the disease is that mechanisms such as poor sleep or less functional AQP4 polymorphisms may sustain glymphatic flow reduction. Such chronic glymphatic reduction would trigger a vicious circle in which the persistence of antigens and an inflammatory response maintains glymphatic dysfunction. In addition, viral proteins that persist in demyelinated plaques can depolarize AQP4, further restricting waste elimination and sustaining local inflammation. This review examines the epidemiological evidence connecting sleep and MS risk, and the mechanistic findings showing how poor sleep and other glymphatic modulators heighten inflammatory signaling implicated in MS pathogenesis. Deepening knowledge of glymphatic functioning in MS could open new avenues for personalized prevention and therapy.", "full_text": "Multiple sclerosis (MS) is more than a purely immune-mediated demyelinating disease; it sits at the crossroads of viral persistence, sleep biology, inflammation, and brain-waste clearance. In this review, first, we review the epidemiological and molecular evidence that links Epstein–Barr virus (EBV) infection, genetic risk, and sleep loss to the onset of MS. Second, we outline the physiological roles of sleep, especially slow-wave sleep. Third, we examine how the glymphatic pathway operates, what fails in chronic inflammation, and how those failures amplify brain injury, drawing lessons from MS and other disorders, such as Alzheimer’s disease (AD). Finally, we discuss modulators of the system, from non-modifiable aquaporin-4 (AQP4) polymorphisms to modifiable factors such as sleep quality, nocturnal blood-pressure patterns, and pharmacological and non-pharmacological interventions.\nMultiple sclerosis (MS) is a chronic, immune-mediated disorder of the central nervous system in which focal demyelination co-exists with diffuse neurodegeneration. Twin and family studies indicate that heritability explains roughly one-quarter of susceptibility, with the class II allele HLA-DRB1*15:01 exerting the largest single genetic effect [\nThe clearest trigger is infection with EBV. The role of EBV in the pathogenesis of MS was proposed four decades ago [\nSeveral modifiable factors consistently modulate risk. Prospective cohorts link low serum 25-hydroxy vitamin D to higher MS incidence [\nSleep is a basic need shared by nearly every mammal. During non-REM sleep the cortex produces slow waves that permit synapse restoration, saving energy and preventing circuits from saturating [\nMounting evidence indicates that the efficiency of the brain’s nocturnal clearance pathway links to key graphoelements of non-REM sleep. Reduced clearance is associated with lower slow-wave activity (SWA), diminished spindle density, and weaker phase coupling changes that predict poorer memory consolidation overnight [\nThe glymphatic system is a brain-wide pathway that moves cerebrospinal fluid (CSF) from peri-arterial spaces into the parenchyma, mixes it with interstitial fluid, and directs the mixture toward peri-venous routes for clearance. Astrocytic end-feet that surround cerebral vessels are rich in the water channel AQP4. This polarized (asymmetric, well-organized localization of channels) AQP4 arrangement is essential, because it lets CSF flow through the perivascular sheath and into the interstitium [\nFlow is not constant. Arterial pulsations, respiration, and slow vasomotor waves act as pumps, but the most powerful switch is behavioral state. During deep non-REM sleep, cortical slow waves reduce cell volume and widen the extracellular space by about 60%, lowering resistance and doubling bulk fluid movement compared with quiet wakefulness [\nSeveral factors modulate the system performance. Age and vascular stiffening dampen arterial driving forces, reducing clearance [\nThese factors have direct relevance for MS. Experimental autoimmune encephalomyelitis mice models show early AQP4 depolarization and a 40–50% fall in glymphatic inflow [\nInflammation in MS does not simply damage myelin; it progressively reshapes the brain’s fluid-clearance network. The “enduring inflammation” model derived from rodent and human data proposes a series of events initiated by a new antigen. Within this model, Mogensen and colleagues [\nIn most infections this process resolves within hours, but when the antigen persists, as can occur with latent EBV in meningeal B cells, reactive astrocytes lose their end-feet polarization of AQP4 water channels, arterial pulsations weaken, and leukocytes accumulate in the same perivascular tunnels that normally drive CSF into the parenchyma. Experimental work had demonstrated that EBV proteins can depolarize AQP4, compounding the mechanical blockade [\nA recent proteomic investigation in amnestic mild cognitive impairment (MCI) patients assessed glymphatic performance with serial 3T gadolinium-enhanced MRI, and related regional clearance half-times to 7000 cerebrospinal-fluid proteins quantified on an aptamer panel. Top associations were verified in an independent group of MCI cases and controls. Only seven proteins displayed consistent, region-wide correlations with clearance speed, and pathway enrichment highlighted B-cell activation, JAK/STAT, histamine and angiotensin signaling—canonical inflammatory routes. Faster wash-out coincided with lower concentrations of these immune markers, whereas slower clearance aligned with an inflammatory profile, supporting an inverse relationship between immune activation and glymphatic efficiency [\nSleep loss intensifies every step in this cascade. Deep non-REM oscillations are the principal pump for glymphatic inflow and reducing sleep by just two hours a night halves flow in animals and boosts inflammatory transcripts in humans [\nNeuromyelitis optica (NO) illustrates what happens when AQP4 becomes the direct target of immunity. Serum IgG1 antibodies against AQP4 bind the channel’s extracellular loops, activate complement, and trigger antibody-dependent cytotoxicity [\nIn our view, the glymphatic system plays a key role in the observed association between poor sleep, inflammation, and neurodegeneration, not only in MS but also in other diseases such as AD.\nNeurodegeneration and progressive tissue loss in MS seems to relate to local inflammation inside the brain and the re-programming of support cells. After the acute relapse declines, disease-associated microglia and reactive astrocytes up-regulate and secrete complement components, iron-handling proteins such as ferritin heavy chain, oxidative-stress-related molecules, and pro-inflammatory cytokines that can perpetuate local neurodegeneration [\nAD is the most common form of dementing diseases. It is a progressive disorder where neurons and synapses gradually degenerate, leading to cognitive decline and memory loss. This process is driven by an abnormal buildup of Aβ plaques and tau protein tangles in the brain. These aggregates disrupt synaptic communication, cause neuronal dysfunction, and are tightly linked with a chronic inflammatory response. Microglial cells, the brain’s immune sentinels, react by releasing pro-inflammatory cytokines, complement proteins, and reactive oxygen species, which further damage surrounding tissue [\nThere is a clear link between a chronic inflammatory response and neurodegeneration. Alghanimy and colleagues recently proposed that MS could be seen as a “glymphaticopathy” [\nAmong glymphatic modulators, AQP4 single nucleotide polymorphisms (SNPs) would represent the main non-modifiable factor. In cognitively healthy adults, carriers of the minor allele at\nThe main potentially modifiable glymphatic factors are sleep micro- and macro-structure, vascular pulsatility, and pharmacological modulation. During the slow-wave (<4 Hz) sleep phase, cortical neurons fire in large, synchronous patterns that are coupled to low-frequency changes in arteriole diameter [\nPharmacology offers two complementary ways to restore sleep haemodynamic profile. First, β-adrenergic antagonists that readily cross the blood–brain barrier, such as propranolol and carvedilol, shrink astrocytic volume, expand the interstitial space, and are associated with higher CSF Aβ42 in non-demented adults [\nThe evidence presented converges on the following sequence: a latent or recurrent antigen (EBV in MS) initiates a compartmentalized inflammatory response. That response depolarizes AQP4 and narrows perivascular spaces, slowing glymphatic flow; poor or fragmented slow-wave sleep prevents nightly recovery of clearance and retained antigens and cytokines then fuel further inflammation, locking the system into an “enduring-inflammation” loop that ultimately damages axons and neurons. The same framework helps explain why chronic sleep loss, vascular stiffening, and airborne pollutants and other antigens promote other neurodegenerative diseases, such as AD and related dementias (see\nThis model points to four therapeutic points that may help to prevent or ameliorate MS and other neurodegenerative disorders in which chronic inflammation alters glymphatic function:\nRemove or silence the antigen. EBV vaccination, antiviral strategies, and broader pathogen-based prevention (e.g., shingles, influenza, pneumococcal vaccines) merit prospective trials that include imaging markers of glymphatic function.\nEnsure and restore deep sleep architecture. Behavioral sleep optimization, treatment of sleep-disordered breathing, and if needed, pharmacological consolidation with dual orexin-receptor antagonists such as lemborexant or daridorexant may be evaluated for their ability to boost slow-wave power and, in turn, glymphatic inflow. Strategies globally improving sleep quality may also positively impact the entire physiological process that supports memory consolidation.\nNormalize nocturnal haemodynamics. Although not so relevant in MS due to age of onset, controlling riser or non-dipping sleep blood-pressure patterns, particularly with blood–brain barrier-permeable β-blockers that also shrink astrocytic volume, could enhance perivascular pulsatility and widen interstitial space.\nRepolarize or augment AQP4 function. Small molecules that stabilize AQP4 at end-feet may help polarization and glymphatic flow.\nNon-pharmacological frequency-based interventions. Neuromodulation therapies enhancing glymphatic functioning, such as 40 Hz multisensory stimulation and others, may durably boost clearance and dampen inflammation.\nFuture studies combining overnight sleep EEG, blood-pressure monitoring, and advanced diffusion MRI would test how these interventions influence clearance and clinical outcomes. As glymphatic impairment emerges early, often preceding overt neurodegeneration, multimodal, time-sensitive strategies may help slow disease progression and address its underlying mechanisms.", "content_for_embedding": "Multiple sclerosis (MS) is more than a purely immune-mediated demyelinating disease; it sits at the crossroads of viral persistence, sleep biology, inflammation, and brain-waste clearance. In this review, first, we review the epidemiological and molecular evidence that links Epstein–Barr virus (EBV) infection, genetic risk, and sleep loss to the onset of MS. Second, we outline the physiological roles of sleep, especially slow-wave sleep. Third, we examine how the glymphatic pathway operates, what fails in chronic inflammation, and how those failures amplify brain injury, drawing lessons from MS and other disorders, such as Alzheimer’s disease (AD). Finally, we discuss modulators of the system, from non-modifiable aquaporin-4 (AQP4) polymorphisms to modifiable factors such as sleep quality, nocturnal blood-pressure patterns, and pharmacological and non-pharmacological interventions.\nMultiple sclerosis (MS) is a chronic, immune-mediated disorder of the central nervous system in which focal demyelination co-exists with diffuse neurodegeneration. Twin and family studies indicate that heritability explains roughly one-quarter of susceptibility, with the class II allele HLA-DRB1*15:01 exerting the largest single genetic effect [\nThe clearest trigger is infection with EBV. The role of EBV in the pathogenesis of MS was proposed four decades ago [\nSeveral modifiable factors consistently modulate risk. Prospective cohorts link low serum 25-hydroxy vitamin D to higher MS incidence [\nSleep is a basic need shared by nearly every mammal. During non-REM sleep the cortex produces slow waves that permit synapse restoration, saving energy and preventing circuits from saturating [\nMounting evidence indicates that the efficiency of the brain’s nocturnal clearance pathway links to key graphoelements of non-REM sleep. Reduced clearance is associated with lower slow-wave activity (SWA), diminished spindle density, and weaker phase coupling changes that predict poorer memory consolidation overnight [\nThe glymphatic system is a brain-wide pathway that moves cerebrospinal fluid (CSF) from peri-arterial spaces into the parenchyma, mixes it with interstitial fluid, and directs the mixture toward peri-venous routes for clearance. Astrocytic end-feet that surround cerebral vessels are rich in the water channel AQP4. This polarized (asymmetric, well-organized localization of channels) AQP4 arrangement is essential, because it lets CSF flow through the perivascular sheath and into the interstitium [\nFlow is not constant. Arterial pulsations, respiration, and slow vasomotor waves act as pumps, but the most powerful switch is behavioral state. During deep non-REM sleep, cortical slow waves reduce cell volume and widen the extracellular space by about 60%, lowering resistance and doubling bulk fluid movement compared with quiet wakefulness [\nSeveral factors modulate the system performance. Age and vascular stiffening dampen arterial driving forces, reducing clearance [\nThese factors have direct relevance for MS. Experimental autoimmune encephalomyelitis mice models show early AQP4 depolarization and a 40–50% fall in glymphatic inflow [\nInflammation in MS does not simply damage myelin; it progressively reshapes the brain’s fluid-clearance network. The “enduring inflammation” model derived from rodent and human data proposes a series of events initiated by a new antigen. Within this model, Mogensen and colleagues [\nIn most infections this process resolves within hours, but when the antigen persists, as can occur with latent EBV in meningeal B cells, reactive astrocytes lose their end-feet polarization of AQP4 water channels, arterial pulsations weaken, and leukocytes accumulate in the same perivascular tunnels that normally drive CSF into the parenchyma. Experimental work had demonstrated that EBV proteins can depolarize AQP4, compounding the mechanical blockade [\nA recent proteomic investigation in amnestic mild cognitive impairment (MCI) patients assessed glymphatic performance with serial 3T gadolinium-enhanced MRI, and related regional clearance half-times to 7000 cerebrospinal-fluid proteins quantified on an aptamer panel. Top associations were verified in an independent group of MCI cases and controls. Only seven proteins displayed consistent, region-wide correlations with clearance speed, and pathway enrichment highlighted B-cell activation, JAK/STAT, histamine and angiotensin signaling—canonical inflammatory routes. Faster wash-out coincided with lower concentrations of these immune markers, whereas slower clearance aligned with an inflammatory profile, supporting an inverse relationship between immune activation and glymphatic efficiency [\nSleep loss intensifies every step in this cascade. Deep non-REM oscillations are the principal pump for glymphatic inflow and reducing sleep by just two hours a night halves flow in animals and boosts inflammatory transcripts in humans [\nNeuromyelitis optica (NO) illustrates what happens when AQP4 becomes the direct target of immunity. Serum IgG1 antibodies against AQP4 bind the channel’s extracellular loops, activate complement, and trigger antibody-dependent cytotoxicity [\nIn our view, the glymphatic system plays a key role in the observed association between poor sleep, inflammation, and neurodegeneration, not only in MS but also in other diseases such as AD.\nNeurodegeneration and progressive tissue loss in MS seems to relate to local inflammation inside the brain and the re-programming of support cells. After the acute relapse declines, disease-associated microglia and reactive astrocytes up-regulate and secrete complement components, iron-handling proteins such as ferritin heavy chain, oxidative-stress-related molecules, and pro-inflammatory cytokines that can perpetuate local neurodegeneration [\nAD is the most common form of dementing diseases. It is a progressive disorder where neurons and synapses gradually degenerate, leading to cognitive decline and memory loss. This process is driven by an abnormal buildup of Aβ plaques and tau protein tangles in the brain. These aggregates disrupt synaptic communication, cause neuronal dysfunction, and are tightly linked with a chronic inflammatory response. Microglial cells, the brain’s immune sentinels, react by releasing pro-inflammatory cytokines, complement proteins, and reactive oxygen species, which further damage surrounding tissue [\nThere is a clear link between a chronic inflammatory response and neurodegeneration. Alghanimy and colleagues recently proposed that MS could be seen as a “glymphaticopathy” [\nAmong glymphatic modulators, AQP4 single nucleotide polymorphisms (SNPs) would represent the main non-modifiable factor. In cognitively healthy adults, carriers of the minor allele at\nThe main potentially modifiable glymphatic factors are sleep micro- and macro-structure, vascular pulsatility, and pharmacological modulation. During the slow-wave (<4 Hz) sleep phase, cortical neurons fire in large, synchronous patterns that are coupled to low-frequency changes in arteriole diameter [\nPharmacology offers two complementary ways to restore sleep haemodynamic profile. First, β-adrenergic antagonists that readily cross the blood–brain barrier, such as propranolol and carvedilol, shrink astrocytic volume, expand the interstitial space, and are associated with higher CSF Aβ42 in non-demented adults [\nThe evidence presented converges on the following sequence: a latent or recurrent antigen (EBV in MS) initiates a compartmentalized inflammatory response. That response depolarizes AQP4 and narrows perivascular spaces, slowing glymphatic flow; poor or fragmented slow-wave sleep prevents nightly recovery of clearance and retained antigens and cytokines then fuel further inflammation, locking the system into an “enduring-inflammation” loop that ultimately damages axons and neurons. The same framework helps explain why chronic sleep loss, vascular stiffening, and airborne pollutants and other antigens promote other neurodegenerative diseases, such as AD and related dementias (see\nThis model points to four therapeutic points that may help to prevent or ameliorate MS and other neurodegenerative disorders in which chronic inflammation alters glymphatic function:\nRemove or silence the antigen. EBV vaccination, antiviral strategies, and broader pathogen-based prevention (e.g., shingles, influenza, pneumococcal vaccines) merit prospective trials that include imaging markers of glymphatic function.\nEnsure and restore deep sleep architecture. Behavioral sleep optimization, treatment of sleep-disordered breathing, and if needed, pharmacological consolidation with dual orexin-receptor antagonists such as lemborexant or daridorexant may be evaluated for their ability to boost slow-wave power and, in turn, glymphatic inflow. Strategies globally improving sleep quality may also positively impact the entire physiological process that supports memory consolidation.\nNormalize nocturnal haemodynamics. Although not so relevant in MS due to age of onset, controlling riser or non-dipping sleep blood-pressure patterns, particularly with blood–brain barrier-permeable β-blockers that also shrink astrocytic volume, could enhance perivascular pulsatility and widen interstitial space.\nRepolarize or augment AQP4 function. Small molecules that stabilize AQP4 at end-feet may help polarization and glymphatic flow.\nNon-pharmacological frequency-based interventions. Neuromodulation therapies enhancing glymphatic functioning, such as 40 Hz multisensory stimulation and others, may durably boost clearance and dampen inflammation.\nFuture studies combining overnight sleep EEG, blood-pressure monitoring, and advanced diffusion MRI would test how these interventions influence clearance and clinical outcomes. As glymphatic impairment emerges early, often preceding overt neurodegeneration, multimodal, time-sensitive strategies may help slow disease progression and address its underlying mechanisms.", "topic": "Diagnostic"}
{"pmid": "40518733", "pmcid": "12301117", "title": "Mechanisms and Clinical Application Prospects of Curcumin in the Treatment of Sepsis", "publication_year": "N/A", "abstract": "Sepsis is a systemic inflammatory response syndrome caused by pathogenic microorganisms such as bacteria, fungi, viruses, and parasites invading the body. It is primarily characterized by an immune dysregulation in response to infection, leading to severe complications such as dysfunction of vital organs, shock, and disseminated intravascular coagulation (DIC), thereby threatening the patient’s life. Additionally, approximately 3 million surviving patients suffer from cognitive impairment, severely affecting their quality of life. Curcumin, a monomer of traditional Chinese medicine, has extensive pharmacological activity. Numerous studies have shown that curcumin can counteract the inflammatory response in sepsis and protect against organ damage caused by sepsis, suggesting that curcumin may become a new direction for sepsis treatment. In this review, we summarize the therapeutic effects and detailed mechanisms of curcumin in the treatment of sepsis based on current research.", "full_text": "Sepsis is a life-threatening disease caused by immune dysregulation in response to infection by pathogens such as bacteria and fungi, resulting in multiple organ dysfunction.\nCurcumin is a natural small-molecule polyphenolic compound extracted from the rhizome of turmeric,\nThe Protective Mechanism of Curcumin on Vital Organs\nCurcumin Modulates Various Cell Types Involved in Sepsis\nThe Therapeutic Effects of Curcumin in Sepsis. The molecular structure of curcumin and its therapeutic effects on sepsis-induced injury, which mainly include Anti-inflammatory, Antioxidant stress, Anti-Pyroptosis, Protection of vascular endothelium, Protection of mitochondrial integrity, and Regulation of immune cells.\nThe inflammatory response is the main foundation for the occurrence and development of sepsis (\nAnti-inflammatory Mechanisms of Curcumin.\nExtensive experiments have demonstrated that curcumin has a strong anti-inflammatory effect, which has been validated in various sepsis models.\nThe anti-inflammatory effects of curcumin in sepsis models have been widely validated by scholars, and further detailed mechanisms are still under exploration.\nOxidative stress in sepsis is a complex process wherein the body, when subjected to harmful stimuli, produces excessive amounts of highly reactive molecules such as reactive oxygen species (ROS) and reactive nitrogen species (RNS).\nCurcumin, as an effective antioxidant, can neutralize oxygen free radicals and enhance the activity of antioxidant enzymes in the body.\nOxidative stress is considered the fundamental mechanism of multi-organ and multi-system damage in sepsis. As an effective antioxidant, curcumin may offer new strategies for the treatment of sepsis.\nPyroptosis is an important process in the pathogenesis of sepsis.\nThe specific mechanisms by which curcumin affects pyroptosis in sepsis are not yet fully understood. However, according to research reports, curcumin may regulate pyroptosis through the following mechanisms: first, curcumin significantly inhibits the production of mature IL-1β in macrophages triggered by LPS and various NLRP3 inflammasome activators. Curcumin suppresses the activation of inflammasomes, reducing the production of pro-inflammatory factors and thereby alleviating the inflammatory response.\nPyroptosis plays an important role in the pathogenesis of sepsis. Curcumin, as a natural compound with multiple biological activities, may exert therapeutic effects by regulating the process of pyroptosis. In the future, further in-depth research on the specific mechanisms of curcumin in sepsis-induced pyroptosis can provide new effective strategies for the treatment of sepsis and other infectious diseases.\nSepsis, as a systemic inflammatory response syndrome caused by infection, often leads to impaired vascular endothelial function.\nAs a natural active compound, curcumin has garnered extensive attention in recent years for its protective effects on vascular endothelium in sepsis. Studies have shown that curcumin can significantly improve vascular endothelial function in sepsis patients (\nCurcumin Protects Vascular Endothelial Function.\nClinically, sepsis patients often exhibit vascular endothelial dysfunction, characterized by increased vascular permeability, coagulation system disorders, and microcirculation disturbances.\nMitochondria, being the primary site of intracellular energy production, are crucial for normal cellular physiological activities. When mitochondrial function is impaired, it can lead to cellular dysfunction and subsequently various diseases.\nResearch has found that during sepsis treatment, curcumin can inhibit mitochondrial membrane permeability transition, reduce mitochondrial swelling, and improve cell viability. This mechanism may be related to the reduction of intracellular calcium ion concentration, promotion of anti-apoptotic Bcl-2 gene expression, inhibition of caspase-3 activation, and Bax gene expression.\nMitochondria are the “powerhouses” of the cell, responsible for converting nutrients into usable energy. In sepsis, mitochondrial energy metabolism can be disrupted, leading to insufficient cellular energy supply. Curcumin might alleviate the impact of sepsis on cellular energy metabolism by improving mitochondrial function integrity and influencing mitochondrial biogenesis, thereby enhancing organ function.\nThe quantity and activity of immune cells are crucial for maintaining overall health, as dysfunction or insufficient numbers of immune cells can lead to immune system imbalance. The immunoregulation of sepsis is a complex and multifaceted process involving various immune cells. Effective regulation of these immune cells can significantly reduce inflammatory responses and tissue damage.\nCurcumin can modulate the polarization state of macrophages, promoting their polarization towards an anti-inflammatory type and reducing the number and function of pro-inflammatory macrophages.\nChanges in immune function play a critical role in the occurrence and development of sepsis.\nAt present, the clinical research on curcumin in the treatment of sepsis is still in its early stages. A few small-scale human studies have shown that, compared with placebo, curcumin significantly reduces levels of leukocytes, neutrophils, erythrocyte sedimentation rate (ESR), and interleukin-8 (IL-8).\nSepsis is a systemic inflammatory response syndrome caused by infection, with a complex pathogenesis involving various cytokines and chemical mediators. During sepsis, endotoxins and other stimuli activate inflammatory cells, producing large amounts of inflammatory mediators and lipid metabolites. This promotes the recruitment and activation of inflammatory response cells in target organs, further inducing the production of cytokines, chemokines, reactive oxygen species, and proteases. This cascade reaction leads to tissue damage and organ dysfunction.\nIn recent years, research on the therapeutic potential of curcumin in sepsis has been steadily increasing. As a natural compound with multiple biological properties, curcumin has demonstrated promising potential in the treatment of sepsis. Curcumin can inhibit the cytokine storm and alleviate sepsis-induced organ damage through various mechanisms, including anti-inflammatory and antioxidant effects, inhibition of inflammatory cell death, protection of vascular endothelial cells, maintenance of mitochondrial function, and modulation of immune cells. However, discrepancies in preclinical studies have been observed due to differences in sepsis models, curcumin dosage, routes of administration, as well as species and strains of experimental animals. These variations have led to inconsistent experimental outcomes.\nIn the future, with a deeper understanding of curcumin’s mechanisms of action and the continuous advancement of clinical research, curcumin is expected to become an important drug in the treatment of sepsis.", "content_for_embedding": "Sepsis is a life-threatening disease caused by immune dysregulation in response to infection by pathogens such as bacteria and fungi, resulting in multiple organ dysfunction.\nCurcumin is a natural small-molecule polyphenolic compound extracted from the rhizome of turmeric,\nThe Protective Mechanism of Curcumin on Vital Organs\nCurcumin Modulates Various Cell Types Involved in Sepsis\nThe Therapeutic Effects of Curcumin in Sepsis. The molecular structure of curcumin and its therapeutic effects on sepsis-induced injury, which mainly include Anti-inflammatory, Antioxidant stress, Anti-Pyroptosis, Protection of vascular endothelium, Protection of mitochondrial integrity, and Regulation of immune cells.\nThe inflammatory response is the main foundation for the occurrence and development of sepsis (\nAnti-inflammatory Mechanisms of Curcumin.\nExtensive experiments have demonstrated that curcumin has a strong anti-inflammatory effect, which has been validated in various sepsis models.\nThe anti-inflammatory effects of curcumin in sepsis models have been widely validated by scholars, and further detailed mechanisms are still under exploration.\nOxidative stress in sepsis is a complex process wherein the body, when subjected to harmful stimuli, produces excessive amounts of highly reactive molecules such as reactive oxygen species (ROS) and reactive nitrogen species (RNS).\nCurcumin, as an effective antioxidant, can neutralize oxygen free radicals and enhance the activity of antioxidant enzymes in the body.\nOxidative stress is considered the fundamental mechanism of multi-organ and multi-system damage in sepsis. As an effective antioxidant, curcumin may offer new strategies for the treatment of sepsis.\nPyroptosis is an important process in the pathogenesis of sepsis.\nThe specific mechanisms by which curcumin affects pyroptosis in sepsis are not yet fully understood. However, according to research reports, curcumin may regulate pyroptosis through the following mechanisms: first, curcumin significantly inhibits the production of mature IL-1β in macrophages triggered by LPS and various NLRP3 inflammasome activators. Curcumin suppresses the activation of inflammasomes, reducing the production of pro-inflammatory factors and thereby alleviating the inflammatory response.\nPyroptosis plays an important role in the pathogenesis of sepsis. Curcumin, as a natural compound with multiple biological activities, may exert therapeutic effects by regulating the process of pyroptosis. In the future, further in-depth research on the specific mechanisms of curcumin in sepsis-induced pyroptosis can provide new effective strategies for the treatment of sepsis and other infectious diseases.\nSepsis, as a systemic inflammatory response syndrome caused by infection, often leads to impaired vascular endothelial function.\nAs a natural active compound, curcumin has garnered extensive attention in recent years for its protective effects on vascular endothelium in sepsis. Studies have shown that curcumin can significantly improve vascular endothelial function in sepsis patients (\nCurcumin Protects Vascular Endothelial Function.\nClinically, sepsis patients often exhibit vascular endothelial dysfunction, characterized by increased vascular permeability, coagulation system disorders, and microcirculation disturbances.\nMitochondria, being the primary site of intracellular energy production, are crucial for normal cellular physiological activities. When mitochondrial function is impaired, it can lead to cellular dysfunction and subsequently various diseases.\nResearch has found that during sepsis treatment, curcumin can inhibit mitochondrial membrane permeability transition, reduce mitochondrial swelling, and improve cell viability. This mechanism may be related to the reduction of intracellular calcium ion concentration, promotion of anti-apoptotic Bcl-2 gene expression, inhibition of caspase-3 activation, and Bax gene expression.\nMitochondria are the “powerhouses” of the cell, responsible for converting nutrients into usable energy. In sepsis, mitochondrial energy metabolism can be disrupted, leading to insufficient cellular energy supply. Curcumin might alleviate the impact of sepsis on cellular energy metabolism by improving mitochondrial function integrity and influencing mitochondrial biogenesis, thereby enhancing organ function.\nThe quantity and activity of immune cells are crucial for maintaining overall health, as dysfunction or insufficient numbers of immune cells can lead to immune system imbalance. The immunoregulation of sepsis is a complex and multifaceted process involving various immune cells. Effective regulation of these immune cells can significantly reduce inflammatory responses and tissue damage.\nCurcumin can modulate the polarization state of macrophages, promoting their polarization towards an anti-inflammatory type and reducing the number and function of pro-inflammatory macrophages.\nChanges in immune function play a critical role in the occurrence and development of sepsis.\nAt present, the clinical research on curcumin in the treatment of sepsis is still in its early stages. A few small-scale human studies have shown that, compared with placebo, curcumin significantly reduces levels of leukocytes, neutrophils, erythrocyte sedimentation rate (ESR), and interleukin-8 (IL-8).\nSepsis is a systemic inflammatory response syndrome caused by infection, with a complex pathogenesis involving various cytokines and chemical mediators. During sepsis, endotoxins and other stimuli activate inflammatory cells, producing large amounts of inflammatory mediators and lipid metabolites. This promotes the recruitment and activation of inflammatory response cells in target organs, further inducing the production of cytokines, chemokines, reactive oxygen species, and proteases. This cascade reaction leads to tissue damage and organ dysfunction.\nIn recent years, research on the therapeutic potential of curcumin in sepsis has been steadily increasing. As a natural compound with multiple biological properties, curcumin has demonstrated promising potential in the treatment of sepsis. Curcumin can inhibit the cytokine storm and alleviate sepsis-induced organ damage through various mechanisms, including anti-inflammatory and antioxidant effects, inhibition of inflammatory cell death, protection of vascular endothelial cells, maintenance of mitochondrial function, and modulation of immune cells. However, discrepancies in preclinical studies have been observed due to differences in sepsis models, curcumin dosage, routes of administration, as well as species and strains of experimental animals. These variations have led to inconsistent experimental outcomes.\nIn the future, with a deeper understanding of curcumin’s mechanisms of action and the continuous advancement of clinical research, curcumin is expected to become an important drug in the treatment of sepsis.", "topic": "Diagnostic"}
{"pmid": "40476752", "pmcid": "12293317", "title": "Single-Round LDCT Screening in Men Aged ≥ 70 Years: Prevalence of Pulmonary Nodules and Lung Cancer Detection", "publication_year": "N/A", "abstract": "Lung cancer screening with low-dose computed tomography (LDCT) has proven effective, yet its application in older adults (aged 70+) remains underexplored. This study investigated a single round of LDCT screening in 1409 elderly Korean men (average age 74.2 years) to assess pulmonary nodule prevalence and lung cancer detection. We found a high prevalence of pulmonary nodules (55.8%), with 12.7% classified as positive. Crucially, a lung cancer detection rate of 2.2% was observed, which is higher than rates reported in major trials. Over half of these cancers were diagnosed at an early stage (I or II). While these findings suggest a potential benefit of early detection in this older, predominantly male cohort, the retrospective nature and inherent population bias necessitate further prospective studies to confirm these promising results and inform broader screening guidelines.", "full_text": "Lung cancer remains the leading cause of cancer-related death worldwide [\nThis exclusion is especially concerning given the high burden of disease in older adults: 37% of lung cancer cases occur in those aged 75–84, and 9% in those aged ≥85 [\nRecent guidelines are beginning to reflect a shift toward more individualized screening strategies. The National Comprehensive Cancer Network (NCCN) has removed its upper age limits for lung cancer screening, emphasizing clinical judgment and individualized risk assessment [\nAs the global population ages rapidly, there is an urgent need to reconsider lung cancer screening approaches for older adults. Emerging evidence suggests that many older patients remain eligible for and benefit from curative-intent treatment [\nWhile LDCT screening has been extensively studied in smoking and non-smoking populations, evidence that specifically focuses on elderly individuals remains scarce. This demographic, however, bears a disproportionate burden of lung cancer and is often excluded from guideline-based screening. Instead of rigid age-based restrictions, screening strategies that account for biological risk and functional status are needed [\nThis retrospective single-center cohort study was conducted at the Veterans Health Service Medical Center in Seoul, Republic of Korea. We included male patients aged 70 years or older who underwent their first LDCT scan for lung cancer screening between January 2012 and June 2020.\nInclusion criteria were as follows: (1) age ≥70 years at the time of screening; (2) no symptoms suggestive of lung cancer (e.g., chronic cough, hemoptysis, unexplained weight loss, or dyspnea); (3) underwent LDCT for lung cancer screening either at their own request or upon the recommendation of a physician as part of routine health screening.\nIn the Korean healthcare system, opportunistic LDCT screening is available for individuals regardless of guideline-defined eligibility (e.g., smoking history). Therefore, even patients who do not meet formal screening criteria—such as never-smokers—may undergo LDCT if they or their physician wish to pursue early detection.\nThe exclusion criteria were as follows: (1) Prior imaging abnormalities suspicious for cancer that prompted LDCT (e.g., suspicious nodules or consolidations on chest X-ray or CT). (2) Symptoms suspicious for lung cancer present at the time of LDCT. (3) History of prior lung cancer. (4) Missing data on smoking status.\nComorbidity information including chronic obstructive pulmonary disease (COPD) and radiographic emphysema was collected from electronic medical records and radiology reports. Final inclusion flow is illustrated in\nFollow-up data were obtained until either loss to follow-up or the study cutoff date (30 September 2021), whichever occurred first. Baseline demographic and clinical characteristics, including age, sex, body mass index (BMI), smoking status (current/former/never), and COPD diagnosis, were assessed using electronic health records.\nA preliminary evaluation of the initial low-dose chest CT images was conducted, with a focus on the identification of lung nodules or the presence of lung cancer. Lung nodules were defined as non-calcified lumps with a diameter of at least 4 mm [\nThe diagnosis of lung cancer in this study was primarily confirmed through histological diagnosis. However, for patients with a systemic condition classified as Eastern Cooperative Oncology Group (ECOG) performance status 3 or higher, for whom biopsy was deemed infeasible, diagnosis was established based on serial follow-up CT imaging and multidisciplinary evaluation involving pulmonologists and radiologists. The interval between initial screening and lung cancer diagnosis was determined, and cancer characteristics—including diagnostic methods, histopathological classification, stage, and treatment modalities—were analyzed. Diagnostic and therapeutic decisions were made by the attending specialists and, when necessary, confirmed by a multidisciplinary team.\nIn order to examine the consistency of the findings in a clinically relevant high-risk group, we conducted a sensitivity analysis restricted to smokers. Comparative data from never-smokers were reported for completeness, although formal inference was limited due to the small sample size and event rate.\nCategorical variables were presented as numbers and percentages. Differences between groups were assessed using Pearson’s chi-squared test or Fisher’s exact test, as appropriate. Continuous variables with a normal distribution were presented as means ± standard deviations and compared using Student’s\nThis study was approved by the Institutional Review Board of the Veteran Healthcare Service Medical Center (Approval No. BOHUN 2023-02-004-003). The requirement for informed consent was waived due to the retrospective nature of this study.\nA total of 1409 participants aged 70 years or older underwent LDCT screening. Initially, 7836 individuals were assessed for eligibility; of these, 45 with a history of lung cancer, 6356 who underwent LDCT due to cancer-suspected symptoms or prior imaging findings, and 26 with missing smoking-related data were excluded (\nLung nodules were identified in 786 participants (55.8%), with 179 cases (22.8%) being classified as positive (Lung-RADS category ≥ 3). The positive nodules were significantly larger than the non-positive nodules (12.6 ± 10.4 mm vs. 6.6 ± 6.2 mm,\nAmong the 786 detected nodules, the majority (n = 755, 96.1%) were ultimately non-cancerous. These benign nodules were typically small (mean size: 5.8 ± 3.6 mm), with most being classified as solid (81.5%), followed by the ground-glass opacity (11.0%) and part-solid (7.6%), types. Half of the non-cancerous nodules (50.6%) were solitary, while the other half appeared as multiple lesions. Based on Lung-RADS categorization, 79.7% were assessed as category 2, which indicates minimal concern for malignancy, and only a small proportion fell into higher-risk categories: 12.3% in category 3, 6.1% in 4A, and 1.9% in 4B. None of the non-cancerous nodules were classified as 4X. Regarding the follow-up outcomes, 9.1% of these nodules disappeared and 11.1% decreased in size, which is consistent with a benign natural course. However, 4.9% demonstrated interval growth, which underscores the importance of radiological surveillance, even for nodules that are initially assessed as low risk (\nAmong the 1409 participants who underwent baseline LDCT screening, 31 (2.2%) were diagnosed with lung cancer (\nBy smoking status, the current smokers had the highest detection rate (3.6%), followed by the never-smokers (1.9%) and former smokers (1.5%;\nLung cancer detection was strongly correlated with the Lung-RADS category: 0.8% for category 2, 2.1% for category 3, 16.4% for 4A, 36.4% for 4B, and 100% for 4X (7/7 patients).\nThe lung cancer detection rates varied significantly by initial nodule type: 3.5% for solid nodules (22/637), 12.3% for part-solid nodules (8/65), and 1.2% for ground-glass opacity nodules (1/84) (\nThe detection rate of 2.2% in this study exceeds those reported in the NLST (1.0%), the first round of the NELSON trial (0.9%), the UKLS (2.1%), and the I-ELCAP study [\nThe median time from baseline screening to lung cancer diagnosis was 9.3 months (IQR 1.5–15.0). The patients diagnosed with lung cancer underwent an average of 3.2 CT scans, compared to 2.8 scans in those without a cancer diagnosis, with there being no significant difference between the groups (\nHistologically, adenocarcinoma was the most common type of cancer (14 patients, 45.2%), followed by squamous cell carcinoma (12 patients, 38.7%). Small-cell lung cancer and the other NSCLC types were each diagnosed in one patient (3.2%), and three cases (9.7%) had an unknown histology. Nearly half of the patients (n = 15, 48.4%) were diagnosed at stage I; the remainder were diagnosed at stage II (n = 4, 12.9%), stage III (n = 5, 16.1%), and stage IV (n = 7, 22.6%).\nSurgical resection was the most frequent initial treatment (n = 17, 54.8%), followed by palliative chemotherapy (n = 7, 22.6%) and definitive radiation therapy (n = 3, 9.7%). Concurrent chemoradiation therapy (CCRT) was given to two patients (6.5%), and one patient (3.2%) received best supportive care. The appropriate treatment was defined as therapy consistent with the NCCN guidelines based on cancer stage. Overall, 28 patients (90.3%) received treatment that was appropriate for their cancer stage, which indicates the adherence to clinical guidelines in this screened cohort.\nIn the sensitivity analysis restricted to smokers, the trends in the lung cancer detection rates, cancer stage, and treatment patterns were generally consistent with those observed in the overall cohort. Among the 1304 smokers (mean age 74.2 years), the prevalence of COPD was 43.2% (\nFor comparison, data from 105 never-smokers were also presented. This group was slightly older (mean age 75.5 years) and had a lower prevalence of COPD (23.8%). Two cases of lung cancer (1.9%) were detected, both of which were stage I adenocarcinomas that were managed with surgical resection. No statistically significant difference in lung cancer detection rates was observed between the smokers and never-smokers (\nWhile major RCTs have established the efficacy of lung cancer screening, our study provides crucial real-world data on a largely underexplored population: elderly individuals (≥ 70 years) who often fall outside strict guideline-defined eligibility. This opportunistic screening context offers a unique perspective, filling a significant knowledge gap by demonstrating the feasibility and actual outcomes of LDCT in a demographic facing an increasing lung cancer burden but which is frequently excluded from large-scale, controlled studies. Our findings thus contribute to a nuanced understanding of the screening effectiveness and challenges specifically within older, diverse cohorts, moving beyond the idealized settings of clinical trials.\nIn this retrospective cohort study of elderly male smokers aged 70 years or older, a single LDCT screening detected lung nodules in 55.8% of the participants, with 12.7% being identified as positive nodules. With appropriate follow-up, the screening yielded a lung cancer detection rate of 2.2%, and the majority of detected cases (61.3%) were diagnosed at an early stage (I or II). Notably, over 60% of these cancers were treated with curative surgery, which underscores the clinical value of early detection in this underrepresented, high-risk group. These findings suggest that even a one-time LDCT screening can provide meaningful diagnostic and therapeutic benefits for these elderly individuals.\nWhile the benefits of annual LDCT screening are well established, our findings suggest that even a single screening round may provide meaningful benefits in select elderly populations—particularly when repeated screening is limited by life expectancy, comorbidities, or resource constraints. This approach may be especially relevant in settings where full-scale programs are not feasible. Although our study does not introduce new biomarkers or imaging tools, it addresses a critical evidence gap by demonstrating the feasibility and potential impact of screening in older adults. Future research should incorporate objective metrics—such as frailty indices, ECOG performance status, and long-term outcomes—to better define which elderly individuals are most likely to benefit and to guide optimal screening strategies in this high-risk group.\nMore than half (55.9%) of our cohort had lung nodules ≥4 mm—substantially higher than the 27.3% reported in the NLST using the same threshold [\nFurthermore, our findings suggest that participants without prior imaging and those presenting with larger nodules at baseline had a higher likelihood of lung cancer diagnosis. This underscores the need for individualized follow-up strategies after the initial LDCT. Tailored surveillance intervals—particularly for individuals with no imaging history or with newly identified large nodules—may enhance early detection, even in single-screen settings.\nAlthough not statistically significant, we observed a trend toward a shorter time from screening to lung cancer diagnosis with increasing age. This may be due to the predominance of solid nodules in older patients, which are more likely to be invasive and prompt faster diagnostic work-up than subsolid or ground-glass lesions, which often undergo surveillance. In our cohort, all cancers in patients aged ≥80 were linked to solid nodules, whereas younger patients had cancers arising from both solid and subsolid nodules. Clinical decisions to prioritize suspicious lesions in very elderly patients and to avoid the aggressive evaluation of indolent lesions like ground-glass opacities—considering limited life expectancy—may contribute to the shorter diagnostic intervals seen in the oldest group.\nOur lung cancer detection rate of 2.2% was higher than those of the first screening rounds of the NLST (1.0%) and NELSON (0.9%), and comparable to that of UKLS (2.1%) (\nThe issue of overdiagnosis remains a significant concern in lung cancer screening. However, our data suggest that this issue may be less pronounced in our cohort. First, the histopathologic spectrum showed a predominance of solid and invasive histology (84%), with minimal detection of indolent ground-glass nodules (only one GGO cancer). Notably, no cases of adenocarcinoma in situ (AIS)—a subtype frequently linked to overdiagnosis [\nIn terms of the stage distribution, 61% of the detected lung cancers in our study were diagnosed at early stages (stage I–II), a proportion that is comparable or higher to those of DANTE (67.8%) [\nIn terms of histologic subtype, adenocarcinoma was the most commonly diagnosed type in our cohort (41%), similar to in other LDCT trials where adenocarcinoma predominated—such as the NLST (55%, including bronchioloalveolar carcinoma [BAC]) [\nOur study suggests that LDCT screening in older adults can lead to early detection and timely, stage-appropriate treatment. Nearly half of the patients underwent curative surgery for early-stage disease, which supports the potential of screening to improve outcomes in the elderly. These findings highlight the importance of considering patients’ physiologic status and individual risk, rather than age alone, when making screening decisions.\nIn line with previous LDCT screening studies, we also analyzed the outcomes among smokers. The lung cancer detection rate in this group was 2.2%, with a higher proportion of advanced-stage diagnoses compared to never-smokers. In contrast, all cancers in never-smokers were early-stage adenocarcinomas that were treated with curative surgery, which is consistent with prior findings that never-smokers tend to develop indolent tumors [\nOur findings highlight several distinct features of lung cancer screening in the elderly population. First, lung cancers were predominantly detected in solid nodules, particularly among individuals aged 80 years or older. This contrasts with previous trials, where subsolid nodules—including part-solid and ground-glass nodules—contributed significantly to the cancer diagnoses [\nA key strength of this study is its use of real-world data that are focused on an underrepresented, high-risk group—elderly male smokers—as well as including non-smoker data that are relevant to the Asian population, where non-smoking lung cancer is more prevalent. By analyzing the screening outcomes by age and detailing nodule characteristics and clinical results, we provide practical insights into the effectiveness of LDCT screening in routine clinical settings. Despite concerns about frailty and limited life expectancy, our findings demonstrate that even a single LDCT screen can detect a significant number of treatable lung cancers in this population.\nSeveral limitations should be considered. First, the retrospective, single-center design may limit the generalizability of our findings to broader populations. Second, the age distribution was skewed toward individuals in their 70s, with relatively few participants being aged 90 or older, which limits insights into outcomes among the very elderly. Third, the median follow-up duration after initial LDCT screening was relatively short, potentially limiting the detection of indolent cancers and the evaluation of long-term outcomes. Lastly, due to the retrospective design and limited clinical follow-up data, we could not assess downstream outcomes such as survival, biopsy-related complications, screening-related overdiagnosis, patient anxiety, or treatment decisions. Future prospective studies with control groups and longer follow-up are needed to clarify the long-term benefits and potential harms of LDCT screening in older adults.\nOur study contributes unique real-world evidence on the utility of LDCT screening in a demographically older and clinically distinct population, in contrast to previous trials such as the NLST and NELSON, which excluded individuals aged ≥75 years or never-smokers. By including both elderly smokers and never-smokers, our study provides a more comprehensive view of the screening performance across varying risk profiles. Meaningful detection rates and substantial treatment uptake—even among those aged ≥80 years—highlight the feasibility and clinical value of individualized screening strategies in routine practice.\nHowever, caution is still warranted when applying our data to clinical practice, and several limitations should be carefully considered. This cohort, due to the inclusion of some never-smokers, cannot be considered fully representative of the entire smoking population, nor does it represent the full spectrum of never-smokers. Never-smokers were incorporated into our study design to generate much-needed screening data for this underrepresented population in current trials, but their number and the absence of survival rates necessitate careful interpretation of this study’s findings. Furthermore, our study does not provide absolute evidence that lung cancer screening will yield benefits in this specific population. Importantly, the all-male, older study population limits the generalizability of these findings to women and younger individuals. Additionally, the participants were able to visit a clinic for screening, which indicates that they likely represent a healthier and more health-conscious subset of the elderly—particularly the smokers who willing and able to attend a pulmonology clinic—and thus introduces potential selection bias. These factors should be meticulously considered when interpreting detection rates and applying our findings to broader lung cancer screening policies. Therefore, future prospective studies with comprehensive data on both smokers and never-smokers, including long-term survival outcomes, are essential to validate and expand upon our findings.\nThis study highlights the significant clinical advantage of a single low-dose CT screening in elderly males, primarily smokers, by effectively identifying a substantial number of early-stage lung cancers, many of which are potentially curable. Early detection in this high-risk population has important clinical implications, supporting the expansion of lung cancer screening guidelines to more inclusively consider elderly smokers. These findings support the implementation of individualized LDCT screening protocols that prioritize patients’ physiologic reserve and risk profile over age, which would ensure that high-risk elderly populations are not unjustly excluded from potentially life-saving early detection.\nFuture prospective studies with well-designed, risk-adaptive protocols—such as randomized controlled trials or longitudinal cohort studies that incorporate frailty and comorbidity assessments—are essential to evaluate long-term clinical outcomes and optimize screening intervals for this vulnerable group.", "content_for_embedding": "Lung cancer remains the leading cause of cancer-related death worldwide [\nThis exclusion is especially concerning given the high burden of disease in older adults: 37% of lung cancer cases occur in those aged 75–84, and 9% in those aged ≥85 [\nRecent guidelines are beginning to reflect a shift toward more individualized screening strategies. The National Comprehensive Cancer Network (NCCN) has removed its upper age limits for lung cancer screening, emphasizing clinical judgment and individualized risk assessment [\nAs the global population ages rapidly, there is an urgent need to reconsider lung cancer screening approaches for older adults. Emerging evidence suggests that many older patients remain eligible for and benefit from curative-intent treatment [\nWhile LDCT screening has been extensively studied in smoking and non-smoking populations, evidence that specifically focuses on elderly individuals remains scarce. This demographic, however, bears a disproportionate burden of lung cancer and is often excluded from guideline-based screening. Instead of rigid age-based restrictions, screening strategies that account for biological risk and functional status are needed [\nThis retrospective single-center cohort study was conducted at the Veterans Health Service Medical Center in Seoul, Republic of Korea. We included male patients aged 70 years or older who underwent their first LDCT scan for lung cancer screening between January 2012 and June 2020.\nInclusion criteria were as follows: (1) age ≥70 years at the time of screening; (2) no symptoms suggestive of lung cancer (e.g., chronic cough, hemoptysis, unexplained weight loss, or dyspnea); (3) underwent LDCT for lung cancer screening either at their own request or upon the recommendation of a physician as part of routine health screening.\nIn the Korean healthcare system, opportunistic LDCT screening is available for individuals regardless of guideline-defined eligibility (e.g., smoking history). Therefore, even patients who do not meet formal screening criteria—such as never-smokers—may undergo LDCT if they or their physician wish to pursue early detection.\nThe exclusion criteria were as follows: (1) Prior imaging abnormalities suspicious for cancer that prompted LDCT (e.g., suspicious nodules or consolidations on chest X-ray or CT). (2) Symptoms suspicious for lung cancer present at the time of LDCT. (3) History of prior lung cancer. (4) Missing data on smoking status.\nComorbidity information including chronic obstructive pulmonary disease (COPD) and radiographic emphysema was collected from electronic medical records and radiology reports. Final inclusion flow is illustrated in\nFollow-up data were obtained until either loss to follow-up or the study cutoff date (30 September 2021), whichever occurred first. Baseline demographic and clinical characteristics, including age, sex, body mass index (BMI), smoking status (current/former/never), and COPD diagnosis, were assessed using electronic health records.\nA preliminary evaluation of the initial low-dose chest CT images was conducted, with a focus on the identification of lung nodules or the presence of lung cancer. Lung nodules were defined as non-calcified lumps with a diameter of at least 4 mm [\nThe diagnosis of lung cancer in this study was primarily confirmed through histological diagnosis. However, for patients with a systemic condition classified as Eastern Cooperative Oncology Group (ECOG) performance status 3 or higher, for whom biopsy was deemed infeasible, diagnosis was established based on serial follow-up CT imaging and multidisciplinary evaluation involving pulmonologists and radiologists. The interval between initial screening and lung cancer diagnosis was determined, and cancer characteristics—including diagnostic methods, histopathological classification, stage, and treatment modalities—were analyzed. Diagnostic and therapeutic decisions were made by the attending specialists and, when necessary, confirmed by a multidisciplinary team.\nIn order to examine the consistency of the findings in a clinically relevant high-risk group, we conducted a sensitivity analysis restricted to smokers. Comparative data from never-smokers were reported for completeness, although formal inference was limited due to the small sample size and event rate.\nCategorical variables were presented as numbers and percentages. Differences between groups were assessed using Pearson’s chi-squared test or Fisher’s exact test, as appropriate. Continuous variables with a normal distribution were presented as means ± standard deviations and compared using Student’s\nThis study was approved by the Institutional Review Board of the Veteran Healthcare Service Medical Center (Approval No. BOHUN 2023-02-004-003). The requirement for informed consent was waived due to the retrospective nature of this study.\nA total of 1409 participants aged 70 years or older underwent LDCT screening. Initially, 7836 individuals were assessed for eligibility; of these, 45 with a history of lung cancer, 6356 who underwent LDCT due to cancer-suspected symptoms or prior imaging findings, and 26 with missing smoking-related data were excluded (\nLung nodules were identified in 786 participants (55.8%), with 179 cases (22.8%) being classified as positive (Lung-RADS category ≥ 3). The positive nodules were significantly larger than the non-positive nodules (12.6 ± 10.4 mm vs. 6.6 ± 6.2 mm,\nAmong the 786 detected nodules, the majority (n = 755, 96.1%) were ultimately non-cancerous. These benign nodules were typically small (mean size: 5.8 ± 3.6 mm), with most being classified as solid (81.5%), followed by the ground-glass opacity (11.0%) and part-solid (7.6%), types. Half of the non-cancerous nodules (50.6%) were solitary, while the other half appeared as multiple lesions. Based on Lung-RADS categorization, 79.7% were assessed as category 2, which indicates minimal concern for malignancy, and only a small proportion fell into higher-risk categories: 12.3% in category 3, 6.1% in 4A, and 1.9% in 4B. None of the non-cancerous nodules were classified as 4X. Regarding the follow-up outcomes, 9.1% of these nodules disappeared and 11.1% decreased in size, which is consistent with a benign natural course. However, 4.9% demonstrated interval growth, which underscores the importance of radiological surveillance, even for nodules that are initially assessed as low risk (\nAmong the 1409 participants who underwent baseline LDCT screening, 31 (2.2%) were diagnosed with lung cancer (\nBy smoking status, the current smokers had the highest detection rate (3.6%), followed by the never-smokers (1.9%) and former smokers (1.5%;\nLung cancer detection was strongly correlated with the Lung-RADS category: 0.8% for category 2, 2.1% for category 3, 16.4% for 4A, 36.4% for 4B, and 100% for 4X (7/7 patients).\nThe lung cancer detection rates varied significantly by initial nodule type: 3.5% for solid nodules (22/637), 12.3% for part-solid nodules (8/65), and 1.2% for ground-glass opacity nodules (1/84) (\nThe detection rate of 2.2% in this study exceeds those reported in the NLST (1.0%), the first round of the NELSON trial (0.9%), the UKLS (2.1%), and the I-ELCAP study [\nThe median time from baseline screening to lung cancer diagnosis was 9.3 months (IQR 1.5–15.0). The patients diagnosed with lung cancer underwent an average of 3.2 CT scans, compared to 2.8 scans in those without a cancer diagnosis, with there being no significant difference between the groups (\nHistologically, adenocarcinoma was the most common type of cancer (14 patients, 45.2%), followed by squamous cell carcinoma (12 patients, 38.7%). Small-cell lung cancer and the other NSCLC types were each diagnosed in one patient (3.2%), and three cases (9.7%) had an unknown histology. Nearly half of the patients (n = 15, 48.4%) were diagnosed at stage I; the remainder were diagnosed at stage II (n = 4, 12.9%), stage III (n = 5, 16.1%), and stage IV (n = 7, 22.6%).\nSurgical resection was the most frequent initial treatment (n = 17, 54.8%), followed by palliative chemotherapy (n = 7, 22.6%) and definitive radiation therapy (n = 3, 9.7%). Concurrent chemoradiation therapy (CCRT) was given to two patients (6.5%), and one patient (3.2%) received best supportive care. The appropriate treatment was defined as therapy consistent with the NCCN guidelines based on cancer stage. Overall, 28 patients (90.3%) received treatment that was appropriate for their cancer stage, which indicates the adherence to clinical guidelines in this screened cohort.\nIn the sensitivity analysis restricted to smokers, the trends in the lung cancer detection rates, cancer stage, and treatment patterns were generally consistent with those observed in the overall cohort. Among the 1304 smokers (mean age 74.2 years), the prevalence of COPD was 43.2% (\nFor comparison, data from 105 never-smokers were also presented. This group was slightly older (mean age 75.5 years) and had a lower prevalence of COPD (23.8%). Two cases of lung cancer (1.9%) were detected, both of which were stage I adenocarcinomas that were managed with surgical resection. No statistically significant difference in lung cancer detection rates was observed between the smokers and never-smokers (\nWhile major RCTs have established the efficacy of lung cancer screening, our study provides crucial real-world data on a largely underexplored population: elderly individuals (≥ 70 years) who often fall outside strict guideline-defined eligibility. This opportunistic screening context offers a unique perspective, filling a significant knowledge gap by demonstrating the feasibility and actual outcomes of LDCT in a demographic facing an increasing lung cancer burden but which is frequently excluded from large-scale, controlled studies. Our findings thus contribute to a nuanced understanding of the screening effectiveness and challenges specifically within older, diverse cohorts, moving beyond the idealized settings of clinical trials.\nIn this retrospective cohort study of elderly male smokers aged 70 years or older, a single LDCT screening detected lung nodules in 55.8% of the participants, with 12.7% being identified as positive nodules. With appropriate follow-up, the screening yielded a lung cancer detection rate of 2.2%, and the majority of detected cases (61.3%) were diagnosed at an early stage (I or II). Notably, over 60% of these cancers were treated with curative surgery, which underscores the clinical value of early detection in this underrepresented, high-risk group. These findings suggest that even a one-time LDCT screening can provide meaningful diagnostic and therapeutic benefits for these elderly individuals.\nWhile the benefits of annual LDCT screening are well established, our findings suggest that even a single screening round may provide meaningful benefits in select elderly populations—particularly when repeated screening is limited by life expectancy, comorbidities, or resource constraints. This approach may be especially relevant in settings where full-scale programs are not feasible. Although our study does not introduce new biomarkers or imaging tools, it addresses a critical evidence gap by demonstrating the feasibility and potential impact of screening in older adults. Future research should incorporate objective metrics—such as frailty indices, ECOG performance status, and long-term outcomes—to better define which elderly individuals are most likely to benefit and to guide optimal screening strategies in this high-risk group.\nMore than half (55.9%) of our cohort had lung nodules ≥4 mm—substantially higher than the 27.3% reported in the NLST using the same threshold [\nFurthermore, our findings suggest that participants without prior imaging and those presenting with larger nodules at baseline had a higher likelihood of lung cancer diagnosis. This underscores the need for individualized follow-up strategies after the initial LDCT. Tailored surveillance intervals—particularly for individuals with no imaging history or with newly identified large nodules—may enhance early detection, even in single-screen settings.\nAlthough not statistically significant, we observed a trend toward a shorter time from screening to lung cancer diagnosis with increasing age. This may be due to the predominance of solid nodules in older patients, which are more likely to be invasive and prompt faster diagnostic work-up than subsolid or ground-glass lesions, which often undergo surveillance. In our cohort, all cancers in patients aged ≥80 were linked to solid nodules, whereas younger patients had cancers arising from both solid and subsolid nodules. Clinical decisions to prioritize suspicious lesions in very elderly patients and to avoid the aggressive evaluation of indolent lesions like ground-glass opacities—considering limited life expectancy—may contribute to the shorter diagnostic intervals seen in the oldest group.\nOur lung cancer detection rate of 2.2% was higher than those of the first screening rounds of the NLST (1.0%) and NELSON (0.9%), and comparable to that of UKLS (2.1%) (\nThe issue of overdiagnosis remains a significant concern in lung cancer screening. However, our data suggest that this issue may be less pronounced in our cohort. First, the histopathologic spectrum showed a predominance of solid and invasive histology (84%), with minimal detection of indolent ground-glass nodules (only one GGO cancer). Notably, no cases of adenocarcinoma in situ (AIS)—a subtype frequently linked to overdiagnosis [\nIn terms of the stage distribution, 61% of the detected lung cancers in our study were diagnosed at early stages (stage I–II), a proportion that is comparable or higher to those of DANTE (67.8%) [\nIn terms of histologic subtype, adenocarcinoma was the most commonly diagnosed type in our cohort (41%), similar to in other LDCT trials where adenocarcinoma predominated—such as the NLST (55%, including bronchioloalveolar carcinoma [BAC]) [\nOur study suggests that LDCT screening in older adults can lead to early detection and timely, stage-appropriate treatment. Nearly half of the patients underwent curative surgery for early-stage disease, which supports the potential of screening to improve outcomes in the elderly. These findings highlight the importance of considering patients’ physiologic status and individual risk, rather than age alone, when making screening decisions.\nIn line with previous LDCT screening studies, we also analyzed the outcomes among smokers. The lung cancer detection rate in this group was 2.2%, with a higher proportion of advanced-stage diagnoses compared to never-smokers. In contrast, all cancers in never-smokers were early-stage adenocarcinomas that were treated with curative surgery, which is consistent with prior findings that never-smokers tend to develop indolent tumors [\nOur findings highlight several distinct features of lung cancer screening in the elderly population. First, lung cancers were predominantly detected in solid nodules, particularly among individuals aged 80 years or older. This contrasts with previous trials, where subsolid nodules—including part-solid and ground-glass nodules—contributed significantly to the cancer diagnoses [\nA key strength of this study is its use of real-world data that are focused on an underrepresented, high-risk group—elderly male smokers—as well as including non-smoker data that are relevant to the Asian population, where non-smoking lung cancer is more prevalent. By analyzing the screening outcomes by age and detailing nodule characteristics and clinical results, we provide practical insights into the effectiveness of LDCT screening in routine clinical settings. Despite concerns about frailty and limited life expectancy, our findings demonstrate that even a single LDCT screen can detect a significant number of treatable lung cancers in this population.\nSeveral limitations should be considered. First, the retrospective, single-center design may limit the generalizability of our findings to broader populations. Second, the age distribution was skewed toward individuals in their 70s, with relatively few participants being aged 90 or older, which limits insights into outcomes among the very elderly. Third, the median follow-up duration after initial LDCT screening was relatively short, potentially limiting the detection of indolent cancers and the evaluation of long-term outcomes. Lastly, due to the retrospective design and limited clinical follow-up data, we could not assess downstream outcomes such as survival, biopsy-related complications, screening-related overdiagnosis, patient anxiety, or treatment decisions. Future prospective studies with control groups and longer follow-up are needed to clarify the long-term benefits and potential harms of LDCT screening in older adults.\nOur study contributes unique real-world evidence on the utility of LDCT screening in a demographically older and clinically distinct population, in contrast to previous trials such as the NLST and NELSON, which excluded individuals aged ≥75 years or never-smokers. By including both elderly smokers and never-smokers, our study provides a more comprehensive view of the screening performance across varying risk profiles. Meaningful detection rates and substantial treatment uptake—even among those aged ≥80 years—highlight the feasibility and clinical value of individualized screening strategies in routine practice.\nHowever, caution is still warranted when applying our data to clinical practice, and several limitations should be carefully considered. This cohort, due to the inclusion of some never-smokers, cannot be considered fully representative of the entire smoking population, nor does it represent the full spectrum of never-smokers. Never-smokers were incorporated into our study design to generate much-needed screening data for this underrepresented population in current trials, but their number and the absence of survival rates necessitate careful interpretation of this study’s findings. Furthermore, our study does not provide absolute evidence that lung cancer screening will yield benefits in this specific population. Importantly, the all-male, older study population limits the generalizability of these findings to women and younger individuals. Additionally, the participants were able to visit a clinic for screening, which indicates that they likely represent a healthier and more health-conscious subset of the elderly—particularly the smokers who willing and able to attend a pulmonology clinic—and thus introduces potential selection bias. These factors should be meticulously considered when interpreting detection rates and applying our findings to broader lung cancer screening policies. Therefore, future prospective studies with comprehensive data on both smokers and never-smokers, including long-term survival outcomes, are essential to validate and expand upon our findings.\nThis study highlights the significant clinical advantage of a single low-dose CT screening in elderly males, primarily smokers, by effectively identifying a substantial number of early-stage lung cancers, many of which are potentially curable. Early detection in this high-risk population has important clinical implications, supporting the expansion of lung cancer screening guidelines to more inclusively consider elderly smokers. These findings support the implementation of individualized LDCT screening protocols that prioritize patients’ physiologic reserve and risk profile over age, which would ensure that high-risk elderly populations are not unjustly excluded from potentially life-saving early detection.\nFuture prospective studies with well-designed, risk-adaptive protocols—such as randomized controlled trials or longitudinal cohort studies that incorporate frailty and comorbidity assessments—are essential to evaluate long-term clinical outcomes and optimize screening intervals for this vulnerable group.", "topic": "Diagnostic"}
{"pmid": "40459533", "pmcid": "12294060", "title": "The Future of Tumor Markers: Advancing Early Malignancy Detection Through Omics Technologies, Continuous Monitoring, and Personalized Reference Intervals", "publication_year": "N/A", "abstract": "Malignant diseases represent a major global health challenge and are among the leading causes of death worldwide. Accurate early diagnosis is essential for improving outcomes and combating these conditions effectively. Currently, the diagnosis of malignancies relies heavily on radiological imaging and pathological examinations, which are often invasive and not cost-effective. As such, there is a growing need for non-invasive and accessible methods to detect cancer in its early stages. Tumor markers—biomolecules whose levels increase in malignancy and can be measured in blood or other biological tissues and fluids—offer a promising tool. However, the sensitivity and specificity of currently available tumor markers are insufficient for early detection, limiting their use primarily to disease monitoring rather than diagnosis. While ongoing research continues to identify novel tumor markers, the development of more effective early detection strategies requires more than the discovery of new biomarkers. The continuous monitoring of patients and individuals with a high tumor risk and the personalization of tumor marker interpretation are also critical. In this review, we (i) summarize the most commonly used tumor markers, (ii) examine strategies for developing novel biomarkers, particularly through omics technologies, (iii) explore the potential of continuous monitoring using wearable biosensors for early tumor detection, and (iv) discuss approaches to personalizing tumor marker interpretation to support early diagnosis and improve treatment outcomes.", "full_text": "Malignancies have caused profound devastation to human life, emotions, hopes, resources, and economies—few other conditions have had such a widespread and multifaceted impact. According to the World Health Organization, malignant diseases represent the second leading cause of death globally, following cardiovascular diseases [\nNew strategies for the early detection of tumors should be cost-effective, non-invasive, and user-friendly, enabling their integration into routine clinical practice without causing significant discomfort or requiring extensive time. Although many tumor markers are widely employed in clinical practice, most of them lack specificity and their levels can be also elevated in non-malignant conditions (\nTumor metabolism is also prone to inter-individual variances; therefore, genetic analysis is essential for selecting the most effective drugs or treatment strategies [\nIn this review, we (i) briefly overview the most commonly used tumor markers, (ii) present strategies for the development of novel markers, (iii) explore the potential of continuous monitoring to detect tumors at an early stage, and (iv) discuss how the interpretation of tumor markers can be personalized to facilitate early detection and thereby enable more effective treatment.\nTumor markers are biomolecules that are overproduced or structurally altered as a cause or consequence of malignant processes. Tumor markers can be found intracellularly or extracellularly, the latter are often released into the circulation. Many of them can also be detected in other body fluids such as interstitial fluid (ISF), urine, seminal fluid, tears, and saliva. Tumor-associated molecules exhibit wide structural variation—they are proteins (peptides, enzymes, transporters, and hormones), carbohydrates, or even lipids. Additionally, CTCs have gained attention for their diagnostic and prognostic potential in cancer. This review focuses primarily on tumor markers that can be detected in blood or other body fluids.\nThe majority of tumor markers used in clinical practice are proteins. Although enzymes are proteins and several hormones are peptides or proteins, they are often classified separately due to their distinct biological functions. Proteins in use as tumor markers include oncofetal proteins such as alpha-fetoprotein (AFP) and carcinoembryonic antigen (CEA); protein fragments such as tissue polypeptide antigen and cytokeratin-19 fragment antigen 21-1 (CYFRA 21-1); and various immunoglobulins including Bence Jones proteins, as well as other proteins such as β2-microglobulin, chromogranin A, human epididymis protein 4 (HE4), thyroglobulin, squamous cell carcinoma antigen (SCC), and S100 protein (\nAlthough the abovementioned markers are primarily used for the monitoring of cancer patients, a few have relatively higher diagnostic value, such as AFP and Bence Jones proteins [\nAFP and CEA are the most commonly used protein tumor markers and are briefly described in the following text.\nAFP is an oncofetal protein and is the most widely used biomarker for hepatocellular carcinoma (HCC) [\nCEA was initially identified in human colorectal cancer (CRC) [\nIn oncology, enzymes are generally used as non-specific tumor markers, since they reflect tissue damage rather than indicating a specific malignancy. As an exception to this, tissue-specific isoenzymes are more typical for certain tumors. For example, prostate-specific antigen (PSA) is specific to prostate tissue and is consequently used in the management of prostate cancer and NSE is highly specific for tumors of neuroendocrine origin (also tumors with neuroendocrine differentiation) [\nPSA stands out among all enzyme tumor markers due to its unique specificity for the prostate, and it is described below.\nPSA, first isolated from prostate tissue [\nHormones, resulting from either excessive production by the original endocrine tissue or ectopic synthesis by non-endocrine tissues, can also serve as cancer biomarkers [\nThe first association between the hormone calcitonin and cancer was established when elevated levels were detected in patients with medullary thyroid carcinoma (MTC) [\nTumor-associated carbohydrate antigens are glycans covalently bound to proteins (glycoproteins) or lipids (glycolipids), which are expressed on the surface of the tumor cells [\nCA 19-9, also known as sialyl Lewis antigen A, is the best tumor marker available for monitoring pancreatic cancer [\nCA 125 is a well-established tumor marker that represents an epitope derived from the transmembrane mucin 16 (MUC 16) [\nCA 15-3 is a glycoprotein fragment derived from MUC1, the latter being a protein product of the breast cancer-associated\nRecently, Sekacheva et al. reported that the combined use of the novel biomarker CA-62 with CA 15-3 significantly enhances diagnostic accuracy in breast cancer [\nCTCs detach from the primary tumor or metastases and enter the circulation, thus contributing to metastasis [\nDespite the availability of numerous tumor markers (\nTo detect malignancies at an early stage, the metabolic activities of tumor cells—which serve as traces indicating the presence of tumors—should first be identified. The basic structural units of living systems are biomolecules; therefore, the transformation of a normal cell into a malignant one is accompanied by changes in the activities of biomolecules or alterations in their abundance. During the malignant transformation of a cell, some silent genes may become activated, leading to an increased expression of specific proteins and/or elevated biosynthesis or degradation of other biomolecules such as oligosaccharides, lipids, and metabolites. This way, certain biomolecules may appear at much greater concentrations than in healthy individuals. It is not enough to discover novel tumor-specific biomolecules, they must be clinically validated. Unfortunately, despite the discovery of dozens of cancer-associated biomolecules, a small number of them have been clinically validated as tumor markers. Moreover, most of these were investigated before the advent of the omics era (\nThe first tumor marker to be identified was the Bence Jones protein, discovered in 1847, which is still widely used today in the diagnosis of multiple myeloma [\nIronically, despite great expectations, omics technologies have so far not yielded the anticipated tumor-specific and sensitive biomarkers suitable for early stage detection in clinical laboratories. However, this does not preclude the possibility that such biomarkers or panels thereof will eventually be identified, and there is hope that omics technologies will ultimately fulfill this promise.\nThe term “-omics” refers to the comprehensive analysis of various molecular components within biological systems [\nIn the omics-based approaches, the process of translating a newly discovered biomarker from initial identification to clinical application involves four main stages: discovery, analytical validation, an assessment of clinical utility, and clinical implementation, along with several intermediate steps [\nThe availability of The Cancer Genome Atlas, Human Protein Atlas, and other large-scale databases enables in silico approaches for screening gene expression and protein profiles, identifying tumor-specific genetic and molecular signatures, and detecting novel biomarker candidates [\nDespite the vast amount of genetic and transcriptomic data that has already been collected, this information cannot be directly translated into protein-level expression. Proteomic studies, leveraging new technologies, have uncovered the early diagnostic potential of various proteins. For instance, many proteins, including osteopontin, midkine, galectin-3, and annexin A2, were initially discovered before the emergence of omics technologies, yet large-scale proteomic analyses later revealed their potential for the early detection of malignancy [\nAlthough examples of such protein biomarkers can be substantially expanded across different cancer types, the overall diagnostic potential of these emerging markers rarely exceeds that of conventional biomarkers currently used in clinical practice. The main reason is that the superiority of novel protein biomarkers is typically demonstrated in small-scale studies with limited patient cohorts. In response to these limitations, a growing body of research has focused on the combined use of established biomarkers and newly identified candidates derived from omics-based analyses, aiming to improve diagnostic performance through complementary biomarker panels. As an example, Gao et al. identified, through proteomics, a novel bile biomarker, clusterin (CLU), to improve the diagnosis of cholangiocarcinoma. The reported sensitivity of CLU was 73.6% and its specificity was 90.1%. Subsequently, a seven-marker diagnostic panel was developed by combining CLU with serum CA 19-9 and five additional biochemical parameters, including indirect bilirubin and gamma-glutamyl transferase. This panel demonstrated improved diagnostic performance, achieving 90.3% sensitivity in an independent validation cohort [\nOn the other hand, individual metabolomes reflect the individual conditions in a highly personalized and dynamic way, as they result from a wide variety of factors, such as genetics, comorbidities, and lifestyle. Tumor markers derived from metabolomic studies are typically organized into comprehensive panels comprising numerous metabolites, due to the inherent complexity and dynamic nature of metabolic pathways, which rarely allow a single metabolite to fully represent tumor-specific alterations. Nevertheless, even within panels, individual metabolites that enhance the potential to indicate tumor development have been identified in certain cancers. As an example, elevated levels of sarcosine have been associated with prostate cancer [\nAnalyses based on a single omics layer (such as genomics, transcriptomics, or proteomics) are often insufficient to reflect the molecular complexity of cancer. While genomic analyses are valuable for revealing an individual’s genetic predisposition, the functional consequences of such variants often remain unclear [\nMany novel biomarkers emerged through multi-omics technologies such as\nInvasive tissue biopsies, commonly used for omics analyses, are not suited for cancer screening or early diagnostics [\nAnother notable example is the detection of\nStudies conducted over many years have accumulated extensive data across multiple omics layers. Multi-omics approaches provide a comprehensive molecular landscape by enabling cross-validation across different omics layers. However, the integration of multi-omics data requires dedicated strategies to manage, harmonize, and effectively interpret diverse omics layers [\nTo date, various omics-based studies supported by artificial intelligence have been carried out for diagnostic purposes. These include the identification of novel miRNA signatures related to renal cell carcinoma [\nRecently, Nagarkar et al. developed a multi-cancer early detection test based on the serum metabolome with the aid of machine learning [\nAs discussed above, since the early 2000s, significant efforts and extensive research have been undertaken to enable early cancer detection through the use of omics technologies. Numerous candidate tumor biomarkers have been rapidly discovered and reported in preclinical studies; however, translating these biomarkers into clinical applications requires large-scale validation efforts that follow a longer timeline. Many biomarkers reported to exhibit high performance were initially identified in small, single-center studies with limited patient populations, and are often subject to reproducibility limitations. For example, a recent study with approximately 12 years of follow-up investigated the association between 1463 plasma proteins and the risk of 19 different cancers, including CRC [\nConsidering cancer’s major global impact on health, monitoring techniques for early cancer diagnosis have consistently attracted significant interest. Although traditional diagnostic methods such as imaging and biopsies are essential in the current state of healthcare technologies for cancer, they have fundamental limitations, including healthcare professional and laboratory resource requirements, the invasiveness of procedures, and high costs. The requirement for patients to visit specialized laboratories for measurements limits accessibility and the feasible testing frequency for screening, early diagnosis, and monitoring—particularly in high-risk individuals and those with rapidly progressing malignancies characterized by short tumor doubling times (\nIn recent years, wearable sensor technologies have been significantly improved and are now actively used in health and disease management [\nWith today’s advanced technology, tumor marker biosensors can perform rapid and sensitive on-site measurements using miniature devices. In the early stages of tumor development, due to the localized settlement of cancer cells, tumor marker concentrations in blood remain low, while levels in biological fluids such as sweat, tears, and ISF are typically even lower [\nMoreover, biosensors enable a rapid sample analysis, i.e., an instantaneous assessment of biomarker levels [\nBiosensor technologies based on the sampling of blood and other body fluids are discussed below.\nSince a great majority of clinically validated tumor biomarkers originate from the blood (\nAFP is routinely measured by immunological assays (\nA recent comprehensive review of Foroozandeh et al. covered analytical features of biosensors for ovarian cancer diagnosis [\nBiosensors developed for CTCs are also becoming popular in early cancer diagnosis [\nBiosensors based on blood sampling are not entirely suitable for continuous or frequent monitoring. However, for many biosensors that have not yet been standardized for clinical use, using blood as a sample enables their performance to be validated by comparison with conventional diagnostic tests [\nAlternatively, biomarker measurements based on easily accessible body fluids are considered more feasible approaches for non-invasive, continuous monitoring.\nEarly cancer detection efforts are increasingly focused on non-invasive technologies that enable continuous monitoring. Wearable or portable sensors that can analyze easily accessible body fluids such as sweat, saliva, urine, tears, and ISF offer suitable platforms for more frequent measurements. However, clinical application of these fluids for early diagnosis requires validated cancer biomarkers and standardized measurement methods [\nISF is the body fluid that surrounds tissue cells and has a composition quite similar to blood plasma [\nSaliva is another easily accessible body fluid enriched in numerous tumor-associated biomarkers. Various biosensors have been developed for the saliva-based measurement of tumor markers, including PSA, CA 125, CA 72-4, CA 19-9, CEA, CYFRA 21-1, p53, TNF-α, IL-1β, and matrix metalloproteinase-9 [\nUrine has been used for many years for the detection of various diseases including cancer, due to its non-invasive collection and the presence of a wide range of biological markers.\nBiosensors designed for urine analysis generally operate by using small (1 cm) microfluidic/disposable chip-structured sensors [\nSweat, as a body fluid with a rich composition and easy accessibility, has shown a rising trend in biomarker analysis. Numerous wearable biosensors have already been developed for the detection of various biomarkers, including proteins, metabolites, and electrolytes [\nTears contain various molecules with the potential to reflect the physiological state of the body [\nExhaled breath contains thousands of distinct organic molecules, and the profile of volatile organic compounds (VOCs) varies between healthy and diseased states [\nRecent biosensors have significantly improved by offering a broad linear range, a high sensitivity, and a low detection limit, thus enabling biomarker detection in early stages [\nFor instance, non-invasive wearable glucose sensors based on ISF sampling are in use for diabetes management [\nBiosensor applications still face technical challenges such as ensuring stability, standardization, and reproducibility, as well as dealing with rapid degradation, cross-reactivity, and non-specific interference. The complexity of biological samples can affect detection performance, and structural similarity between molecules may cause false positives. Reliable performance requires strategies that reduce non-specific measurements [\nNonetheless, elevated levels of tumor markers in non-malignant conditions remain key challenges, leading to diagnostic uncertainty. Advances in wearable biosensor technologies that allow the continuous measurement of tumor markers, along with other developments involving the identification and personalization of cancer-specific tumor markers, are likely to facilitate early stage cancer diagnosis.\nThe interpretation of laboratory data, including tumor markers, relies on a comparison with the reference data, so the latter must be reliable. Despite considerable variance across different individuals having the same tumor, common reference intervals (RIs) are still widely used to interpret tumor marker levels. It should be noted that RIs are derived from population data and reflect population-level characteristics rather than individual-specific values [\nThe concentration of biomolecules, including tumor markers, fluctuates around a set point [\nAn analyte RI has upper and lower limits, thus representing the fluctuation of that analytes around a homeostatic set point (HSP). A prRI is estimated using an individual’s own data. Metabolically, the fluctuation of an analyte corresponds to its CV\nThe variation around the HSP is the Gaussian combination of the CV\nThe prRI can be considered as the prediction interval for the next measurement and can be calculated as shown below [\nThe use of prediction intervals is described in more detail in the literature, e.g., [\nWhen calculating the prRI value, the number of serial measurements is crucial; the higher the n, the more certain and reliable is the value [\nIn the clinical context, RIs are used to distinguish healthy individuals, and corresponds to the specificity of the algorithm used to estimate the RIs. Specificity can be calculated from the following formula:\nAs shown in\nThe HSP may vary among individuals, reflecting the population heterogeneity. Therefore, prRIs for tumor markers reflect individual variation and differ significantly from the fixed popRI values commonly used in routine clinical practice. This example illustrates why the specificity of tumor markers is often suboptimal and why they are not commonly employed for the diagnosis of malignant conditions—the reliance on popRIs limits their diagnostic utility. However, if tumor markers were personalized, they could offer significant potential for the early diagnosis of malignancies with high specificity and sensitivity, as detailed below.\nAlthough RIs are widely used in clinical practice, they are primarily intended to distinguish healthy individuals rather than to diagnose diseases. Therefore, RIs may not be suitable tools for disease diagnosis, which is instead based on decision limits (DL). The estimation of DLs is more complex than the estimation of RIs [\nAlthough theoretically possible, the estimation of DLs for individuals is challenging in practice due to the complexity involved in defining DLs for disease diagnosis. However, this does not imply that DLs cannot be personalized. In fact, they can be individualized through an indirect approach, such as simulation studies utilizing popRIs, population-based decision limits (popDLs), and prRIs, provided that the DLs for tumor markers are well established for specific cancer types [\nThe difference between the upper limit of the popRI and the popDL represents the critical difference, illustrating the minimum concentration gap of tumor markers between healthy individuals and those diagnosed with cancer (\nHere,\nThe specificity of an analyte pertains to its ability to correctly identify healthy individuals and is therefore associated with RIs, whereas sensitivity refers to its ability to correctly identify diseased individuals and is related to the DLs of the analyte used for disease diagnosis, as formulated below.\nAs shown in\nRIs can be used to distinguish healthy individuals based on analyte levels; however, monitoring individuals for disease progression, evaluating treatment effectiveness, and assessing treatment side effects cannot rely solely on RIs. Therefore, a new algorithm is needed for the objective evaluation of individual monitoring in both healthy and diseased conditions. The monitoring of individuals can be performed using serial measurements of analytes during the course of disease. The significance of changes in analyte concentrations can be assessed using the reference change value (RCV), which is calculated as shown below.\nIf the difference between two measurements obtained from different samples taken at the same time on different days, weeks, or months (i.e., the delta value) is lower than the RCV, then this difference can be considered insignificant at a specified probability level, such as 95% [\nAlthough tumor markers are currently used primarily for monitoring malignant diseases, they possess significant potential in the broader management of cancer. More than a century of experience has shown that relying on a single biomarker is often insufficient for the early and accurate diagnosis of malignancies due to limitations in sensitivity and specificity. Therefore, combining multiple tumor markers provides a more robust diagnostic strategy. This insight calls for a new paradigm in the use of tumor markers—one that redefines their role in the early detection, monitoring, and personalized treatment of malignant diseases.\nEmerging technologies such as omics platforms offer powerful avenues for the discovery of novel biomarkers for malignant diseases, while wearable biosensors enable the continuous, real-time monitoring of individuals. Given the biological heterogeneity of tumors, personalizing tumor marker interpretation becomes essential. Furthermore, artificial intelligence can integrate personal health data with wearable biosensor outputs to develop individualized algorithms for the early detection and effective management of malignancies. Together, these innovations promise to transform tumor marker applications and significantly advance personalized oncology.", "content_for_embedding": "Malignancies have caused profound devastation to human life, emotions, hopes, resources, and economies—few other conditions have had such a widespread and multifaceted impact. According to the World Health Organization, malignant diseases represent the second leading cause of death globally, following cardiovascular diseases [\nNew strategies for the early detection of tumors should be cost-effective, non-invasive, and user-friendly, enabling their integration into routine clinical practice without causing significant discomfort or requiring extensive time. Although many tumor markers are widely employed in clinical practice, most of them lack specificity and their levels can be also elevated in non-malignant conditions (\nTumor metabolism is also prone to inter-individual variances; therefore, genetic analysis is essential for selecting the most effective drugs or treatment strategies [\nIn this review, we (i) briefly overview the most commonly used tumor markers, (ii) present strategies for the development of novel markers, (iii) explore the potential of continuous monitoring to detect tumors at an early stage, and (iv) discuss how the interpretation of tumor markers can be personalized to facilitate early detection and thereby enable more effective treatment.\nTumor markers are biomolecules that are overproduced or structurally altered as a cause or consequence of malignant processes. Tumor markers can be found intracellularly or extracellularly, the latter are often released into the circulation. Many of them can also be detected in other body fluids such as interstitial fluid (ISF), urine, seminal fluid, tears, and saliva. Tumor-associated molecules exhibit wide structural variation—they are proteins (peptides, enzymes, transporters, and hormones), carbohydrates, or even lipids. Additionally, CTCs have gained attention for their diagnostic and prognostic potential in cancer. This review focuses primarily on tumor markers that can be detected in blood or other body fluids.\nThe majority of tumor markers used in clinical practice are proteins. Although enzymes are proteins and several hormones are peptides or proteins, they are often classified separately due to their distinct biological functions. Proteins in use as tumor markers include oncofetal proteins such as alpha-fetoprotein (AFP) and carcinoembryonic antigen (CEA); protein fragments such as tissue polypeptide antigen and cytokeratin-19 fragment antigen 21-1 (CYFRA 21-1); and various immunoglobulins including Bence Jones proteins, as well as other proteins such as β2-microglobulin, chromogranin A, human epididymis protein 4 (HE4), thyroglobulin, squamous cell carcinoma antigen (SCC), and S100 protein (\nAlthough the abovementioned markers are primarily used for the monitoring of cancer patients, a few have relatively higher diagnostic value, such as AFP and Bence Jones proteins [\nAFP and CEA are the most commonly used protein tumor markers and are briefly described in the following text.\nAFP is an oncofetal protein and is the most widely used biomarker for hepatocellular carcinoma (HCC) [\nCEA was initially identified in human colorectal cancer (CRC) [\nIn oncology, enzymes are generally used as non-specific tumor markers, since they reflect tissue damage rather than indicating a specific malignancy. As an exception to this, tissue-specific isoenzymes are more typical for certain tumors. For example, prostate-specific antigen (PSA) is specific to prostate tissue and is consequently used in the management of prostate cancer and NSE is highly specific for tumors of neuroendocrine origin (also tumors with neuroendocrine differentiation) [\nPSA stands out among all enzyme tumor markers due to its unique specificity for the prostate, and it is described below.\nPSA, first isolated from prostate tissue [\nHormones, resulting from either excessive production by the original endocrine tissue or ectopic synthesis by non-endocrine tissues, can also serve as cancer biomarkers [\nThe first association between the hormone calcitonin and cancer was established when elevated levels were detected in patients with medullary thyroid carcinoma (MTC) [\nTumor-associated carbohydrate antigens are glycans covalently bound to proteins (glycoproteins) or lipids (glycolipids), which are expressed on the surface of the tumor cells [\nCA 19-9, also known as sialyl Lewis antigen A, is the best tumor marker available for monitoring pancreatic cancer [\nCA 125 is a well-established tumor marker that represents an epitope derived from the transmembrane mucin 16 (MUC 16) [\nCA 15-3 is a glycoprotein fragment derived from MUC1, the latter being a protein product of the breast cancer-associated\nRecently, Sekacheva et al. reported that the combined use of the novel biomarker CA-62 with CA 15-3 significantly enhances diagnostic accuracy in breast cancer [\nCTCs detach from the primary tumor or metastases and enter the circulation, thus contributing to metastasis [\nDespite the availability of numerous tumor markers (\nTo detect malignancies at an early stage, the metabolic activities of tumor cells—which serve as traces indicating the presence of tumors—should first be identified. The basic structural units of living systems are biomolecules; therefore, the transformation of a normal cell into a malignant one is accompanied by changes in the activities of biomolecules or alterations in their abundance. During the malignant transformation of a cell, some silent genes may become activated, leading to an increased expression of specific proteins and/or elevated biosynthesis or degradation of other biomolecules such as oligosaccharides, lipids, and metabolites. This way, certain biomolecules may appear at much greater concentrations than in healthy individuals. It is not enough to discover novel tumor-specific biomolecules, they must be clinically validated. Unfortunately, despite the discovery of dozens of cancer-associated biomolecules, a small number of them have been clinically validated as tumor markers. Moreover, most of these were investigated before the advent of the omics era (\nThe first tumor marker to be identified was the Bence Jones protein, discovered in 1847, which is still widely used today in the diagnosis of multiple myeloma [\nIronically, despite great expectations, omics technologies have so far not yielded the anticipated tumor-specific and sensitive biomarkers suitable for early stage detection in clinical laboratories. However, this does not preclude the possibility that such biomarkers or panels thereof will eventually be identified, and there is hope that omics technologies will ultimately fulfill this promise.\nThe term “-omics” refers to the comprehensive analysis of various molecular components within biological systems [\nIn the omics-based approaches, the process of translating a newly discovered biomarker from initial identification to clinical application involves four main stages: discovery, analytical validation, an assessment of clinical utility, and clinical implementation, along with several intermediate steps [\nThe availability of The Cancer Genome Atlas, Human Protein Atlas, and other large-scale databases enables in silico approaches for screening gene expression and protein profiles, identifying tumor-specific genetic and molecular signatures, and detecting novel biomarker candidates [\nDespite the vast amount of genetic and transcriptomic data that has already been collected, this information cannot be directly translated into protein-level expression. Proteomic studies, leveraging new technologies, have uncovered the early diagnostic potential of various proteins. For instance, many proteins, including osteopontin, midkine, galectin-3, and annexin A2, were initially discovered before the emergence of omics technologies, yet large-scale proteomic analyses later revealed their potential for the early detection of malignancy [\nAlthough examples of such protein biomarkers can be substantially expanded across different cancer types, the overall diagnostic potential of these emerging markers rarely exceeds that of conventional biomarkers currently used in clinical practice. The main reason is that the superiority of novel protein biomarkers is typically demonstrated in small-scale studies with limited patient cohorts. In response to these limitations, a growing body of research has focused on the combined use of established biomarkers and newly identified candidates derived from omics-based analyses, aiming to improve diagnostic performance through complementary biomarker panels. As an example, Gao et al. identified, through proteomics, a novel bile biomarker, clusterin (CLU), to improve the diagnosis of cholangiocarcinoma. The reported sensitivity of CLU was 73.6% and its specificity was 90.1%. Subsequently, a seven-marker diagnostic panel was developed by combining CLU with serum CA 19-9 and five additional biochemical parameters, including indirect bilirubin and gamma-glutamyl transferase. This panel demonstrated improved diagnostic performance, achieving 90.3% sensitivity in an independent validation cohort [\nOn the other hand, individual metabolomes reflect the individual conditions in a highly personalized and dynamic way, as they result from a wide variety of factors, such as genetics, comorbidities, and lifestyle. Tumor markers derived from metabolomic studies are typically organized into comprehensive panels comprising numerous metabolites, due to the inherent complexity and dynamic nature of metabolic pathways, which rarely allow a single metabolite to fully represent tumor-specific alterations. Nevertheless, even within panels, individual metabolites that enhance the potential to indicate tumor development have been identified in certain cancers. As an example, elevated levels of sarcosine have been associated with prostate cancer [\nAnalyses based on a single omics layer (such as genomics, transcriptomics, or proteomics) are often insufficient to reflect the molecular complexity of cancer. While genomic analyses are valuable for revealing an individual’s genetic predisposition, the functional consequences of such variants often remain unclear [\nMany novel biomarkers emerged through multi-omics technologies such as\nInvasive tissue biopsies, commonly used for omics analyses, are not suited for cancer screening or early diagnostics [\nAnother notable example is the detection of\nStudies conducted over many years have accumulated extensive data across multiple omics layers. Multi-omics approaches provide a comprehensive molecular landscape by enabling cross-validation across different omics layers. However, the integration of multi-omics data requires dedicated strategies to manage, harmonize, and effectively interpret diverse omics layers [\nTo date, various omics-based studies supported by artificial intelligence have been carried out for diagnostic purposes. These include the identification of novel miRNA signatures related to renal cell carcinoma [\nRecently, Nagarkar et al. developed a multi-cancer early detection test based on the serum metabolome with the aid of machine learning [\nAs discussed above, since the early 2000s, significant efforts and extensive research have been undertaken to enable early cancer detection through the use of omics technologies. Numerous candidate tumor biomarkers have been rapidly discovered and reported in preclinical studies; however, translating these biomarkers into clinical applications requires large-scale validation efforts that follow a longer timeline. Many biomarkers reported to exhibit high performance were initially identified in small, single-center studies with limited patient populations, and are often subject to reproducibility limitations. For example, a recent study with approximately 12 years of follow-up investigated the association between 1463 plasma proteins and the risk of 19 different cancers, including CRC [\nConsidering cancer’s major global impact on health, monitoring techniques for early cancer diagnosis have consistently attracted significant interest. Although traditional diagnostic methods such as imaging and biopsies are essential in the current state of healthcare technologies for cancer, they have fundamental limitations, including healthcare professional and laboratory resource requirements, the invasiveness of procedures, and high costs. The requirement for patients to visit specialized laboratories for measurements limits accessibility and the feasible testing frequency for screening, early diagnosis, and monitoring—particularly in high-risk individuals and those with rapidly progressing malignancies characterized by short tumor doubling times (\nIn recent years, wearable sensor technologies have been significantly improved and are now actively used in health and disease management [\nWith today’s advanced technology, tumor marker biosensors can perform rapid and sensitive on-site measurements using miniature devices. In the early stages of tumor development, due to the localized settlement of cancer cells, tumor marker concentrations in blood remain low, while levels in biological fluids such as sweat, tears, and ISF are typically even lower [\nMoreover, biosensors enable a rapid sample analysis, i.e., an instantaneous assessment of biomarker levels [\nBiosensor technologies based on the sampling of blood and other body fluids are discussed below.\nSince a great majority of clinically validated tumor biomarkers originate from the blood (\nAFP is routinely measured by immunological assays (\nA recent comprehensive review of Foroozandeh et al. covered analytical features of biosensors for ovarian cancer diagnosis [\nBiosensors developed for CTCs are also becoming popular in early cancer diagnosis [\nBiosensors based on blood sampling are not entirely suitable for continuous or frequent monitoring. However, for many biosensors that have not yet been standardized for clinical use, using blood as a sample enables their performance to be validated by comparison with conventional diagnostic tests [\nAlternatively, biomarker measurements based on easily accessible body fluids are considered more feasible approaches for non-invasive, continuous monitoring.\nEarly cancer detection efforts are increasingly focused on non-invasive technologies that enable continuous monitoring. Wearable or portable sensors that can analyze easily accessible body fluids such as sweat, saliva, urine, tears, and ISF offer suitable platforms for more frequent measurements. However, clinical application of these fluids for early diagnosis requires validated cancer biomarkers and standardized measurement methods [\nISF is the body fluid that surrounds tissue cells and has a composition quite similar to blood plasma [\nSaliva is another easily accessible body fluid enriched in numerous tumor-associated biomarkers. Various biosensors have been developed for the saliva-based measurement of tumor markers, including PSA, CA 125, CA 72-4, CA 19-9, CEA, CYFRA 21-1, p53, TNF-α, IL-1β, and matrix metalloproteinase-9 [\nUrine has been used for many years for the detection of various diseases including cancer, due to its non-invasive collection and the presence of a wide range of biological markers.\nBiosensors designed for urine analysis generally operate by using small (1 cm) microfluidic/disposable chip-structured sensors [\nSweat, as a body fluid with a rich composition and easy accessibility, has shown a rising trend in biomarker analysis. Numerous wearable biosensors have already been developed for the detection of various biomarkers, including proteins, metabolites, and electrolytes [\nTears contain various molecules with the potential to reflect the physiological state of the body [\nExhaled breath contains thousands of distinct organic molecules, and the profile of volatile organic compounds (VOCs) varies between healthy and diseased states [\nRecent biosensors have significantly improved by offering a broad linear range, a high sensitivity, and a low detection limit, thus enabling biomarker detection in early stages [\nFor instance, non-invasive wearable glucose sensors based on ISF sampling are in use for diabetes management [\nBiosensor applications still face technical challenges such as ensuring stability, standardization, and reproducibility, as well as dealing with rapid degradation, cross-reactivity, and non-specific interference. The complexity of biological samples can affect detection performance, and structural similarity between molecules may cause false positives. Reliable performance requires strategies that reduce non-specific measurements [\nNonetheless, elevated levels of tumor markers in non-malignant conditions remain key challenges, leading to diagnostic uncertainty. Advances in wearable biosensor technologies that allow the continuous measurement of tumor markers, along with other developments involving the identification and personalization of cancer-specific tumor markers, are likely to facilitate early stage cancer diagnosis.\nThe interpretation of laboratory data, including tumor markers, relies on a comparison with the reference data, so the latter must be reliable. Despite considerable variance across different individuals having the same tumor, common reference intervals (RIs) are still widely used to interpret tumor marker levels. It should be noted that RIs are derived from population data and reflect population-level characteristics rather than individual-specific values [\nThe concentration of biomolecules, including tumor markers, fluctuates around a set point [\nAn analyte RI has upper and lower limits, thus representing the fluctuation of that analytes around a homeostatic set point (HSP). A prRI is estimated using an individual’s own data. Metabolically, the fluctuation of an analyte corresponds to its CV\nThe variation around the HSP is the Gaussian combination of the CV\nThe prRI can be considered as the prediction interval for the next measurement and can be calculated as shown below [\nThe use of prediction intervals is described in more detail in the literature, e.g., [\nWhen calculating the prRI value, the number of serial measurements is crucial; the higher the n, the more certain and reliable is the value [\nIn the clinical context, RIs are used to distinguish healthy individuals, and corresponds to the specificity of the algorithm used to estimate the RIs. Specificity can be calculated from the following formula:\nAs shown in\nThe HSP may vary among individuals, reflecting the population heterogeneity. Therefore, prRIs for tumor markers reflect individual variation and differ significantly from the fixed popRI values commonly used in routine clinical practice. This example illustrates why the specificity of tumor markers is often suboptimal and why they are not commonly employed for the diagnosis of malignant conditions—the reliance on popRIs limits their diagnostic utility. However, if tumor markers were personalized, they could offer significant potential for the early diagnosis of malignancies with high specificity and sensitivity, as detailed below.\nAlthough RIs are widely used in clinical practice, they are primarily intended to distinguish healthy individuals rather than to diagnose diseases. Therefore, RIs may not be suitable tools for disease diagnosis, which is instead based on decision limits (DL). The estimation of DLs is more complex than the estimation of RIs [\nAlthough theoretically possible, the estimation of DLs for individuals is challenging in practice due to the complexity involved in defining DLs for disease diagnosis. However, this does not imply that DLs cannot be personalized. In fact, they can be individualized through an indirect approach, such as simulation studies utilizing popRIs, population-based decision limits (popDLs), and prRIs, provided that the DLs for tumor markers are well established for specific cancer types [\nThe difference between the upper limit of the popRI and the popDL represents the critical difference, illustrating the minimum concentration gap of tumor markers between healthy individuals and those diagnosed with cancer (\nHere,\nThe specificity of an analyte pertains to its ability to correctly identify healthy individuals and is therefore associated with RIs, whereas sensitivity refers to its ability to correctly identify diseased individuals and is related to the DLs of the analyte used for disease diagnosis, as formulated below.\nAs shown in\nRIs can be used to distinguish healthy individuals based on analyte levels; however, monitoring individuals for disease progression, evaluating treatment effectiveness, and assessing treatment side effects cannot rely solely on RIs. Therefore, a new algorithm is needed for the objective evaluation of individual monitoring in both healthy and diseased conditions. The monitoring of individuals can be performed using serial measurements of analytes during the course of disease. The significance of changes in analyte concentrations can be assessed using the reference change value (RCV), which is calculated as shown below.\nIf the difference between two measurements obtained from different samples taken at the same time on different days, weeks, or months (i.e., the delta value) is lower than the RCV, then this difference can be considered insignificant at a specified probability level, such as 95% [\nAlthough tumor markers are currently used primarily for monitoring malignant diseases, they possess significant potential in the broader management of cancer. More than a century of experience has shown that relying on a single biomarker is often insufficient for the early and accurate diagnosis of malignancies due to limitations in sensitivity and specificity. Therefore, combining multiple tumor markers provides a more robust diagnostic strategy. This insight calls for a new paradigm in the use of tumor markers—one that redefines their role in the early detection, monitoring, and personalized treatment of malignant diseases.\nEmerging technologies such as omics platforms offer powerful avenues for the discovery of novel biomarkers for malignant diseases, while wearable biosensors enable the continuous, real-time monitoring of individuals. Given the biological heterogeneity of tumors, personalizing tumor marker interpretation becomes essential. Furthermore, artificial intelligence can integrate personal health data with wearable biosensor outputs to develop individualized algorithms for the early detection and effective management of malignancies. Together, these innovations promise to transform tumor marker applications and significantly advance personalized oncology.", "topic": "Diagnostic"}
{"pmid": "40449095", "pmcid": "12306066", "title": "Advances in the diagnosis and treatment of congenital scoliosis", "publication_year": "N/A", "abstract": "Congenital scoliosis (CS), a severe form of early-onset scoliosis (EOS), arises from vertebral malformations during embryogenesis, driven by complex genetic and environmental interactions. This review synthesizes recent advances in understanding CS etiology, diagnosis, and treatment. Genetically, CS is linked to mutations in TBX6, GDF3, DSTYK, and COL11A2, alongside copy number variations (CNVs) and epigenetic modifications such as allele-specific methylation in SVIL and TNS3. Maternal hypoxia, toxin exposure, and nutritional deficiencies further contribute to pathogenesis. Diagnosis incorporates advanced imaging techniques—such as X-rays, magnetic resonance imaging (MRI), and computed tomography (CT)—as well as genetic testing, with whole-exome sequencing identifying mutations in 18.6% of cases. Conservative management, including casting and bracing (e.g., alternating cast and brace treatment [ARCBT] and 3D-printed orthoses), effectively delays progression in mild-to-moderate cases. Surgical interventions—such as hemivertebra resection, hybrid techniques (HT), and growth-modulating technologies including magnetic controlled growth rods (MCGR) and the Shilla method—have demonstrated improved outcomes in patients with severe deformities. HT combines posterior osteotomy with dual growing rods, achieving significant Cobb angle correction (81.4° to 40.1°) and spinal growth (1.23 cm/year) with fewer complications. MCGR reduces repeated surgeries but shows variable impacts on quality of life. Emerging approaches, including apical control techniques and robotics, highlight the shift toward personalized care. This review underscores the need for multidisciplinary strategies to optimize outcomes, emphasizing early diagnosis, tailored treatments, and long-term monitoring to address CS complexity.", "full_text": "Congenital scoliosis (CS) is a form of early-onset scoliosis (EOS) caused by skeletal abnormalities during gestational weeks 4 to 6, often leading to additional deformities in other systems [\nTreatment options for CS range from conservative management—such as casting and bracing—for mild-to-moderate cases, to surgical interventions—including in situ fusion, hemivertebra resection, and the use of a vertical expandable prosthetic titanium rib (VEPTR)—for more severe deformities [\nGiven its progressive nature, regular follow-up is essential for monitoring and adjusting treatment plans to improve patient outcomes [\nThis review discusses recent advancements in the etiology, diagnosis, and treatment of CS, aiming to provide clinicians with the latest insights for personalized care.\nWe conducted a narrative literature review in July 2025, adhering to the SANRA (Scale for the Assessment of Narrative Review Articles) guidelines [\nCS is a type of EOS caused by abnormal spinal development during the embryonic period. It is marked by severe deformities and rapid progression, often accompanied by malformations in other organs [\nThe genetic landscape of CS is increasingly complex, involving a variety of mutations, SNPs, and CNVs. Early studies, such as those by Qiu et al., examined genes like MESP2, HES7, and DUSP6, but found no significant mutations, suggesting these genes may not play a major role in sporadic CS within the Chinese Han population [\nOther genes, including LMX1A and FBN1, also play significant roles in spinal development, with mutations linked to CS [\nEpigenetics has also come to the forefront, with studies like Zhang et al. identifying allele-specific methylation in the SVIL gene, suggesting an interaction between genetic and environmental factors [\nRecent studies have continued to broaden our understanding of the genetic basis of CS. Novel variants in the FGFR1 and PTK7 genes have been associated with vertebral malformations and scoliosis [\nDifferent CS types have distinct etiologies. Type I (formation) anomalies are often driven by genetic disruptions in vertebral development. For example, TBX6 mutations or deletions (at 16p11.2) lead primarily to hemivertebrae or butterfly vertebrae [\nIn summary, the genetic factors underlying CS are diverse, involving mutations in TBX6, GDF3, DSTYK, and COL11A2, among others, along with CNVs and epigenetic changes. Ongoing research using advanced sequencing technologies and functional assays continues to shed light on this complex disorder, offering potential for more targeted therapeutic approaches.\nMaternal factors during pregnancy play a significant role in the pathogenesis of CS. Hypoxia is considered a primary factor, with studies in mouse models showing that hypoxic conditions disrupt the normal formation of embryonic vertebral cartilage, leading to spinal curvature [\nTreatment for CS includes conservative and surgical approaches. Conservative treatments, such as casts and braces, are generally considered for milder cases, while severe deformities often require surgical intervention.\nRecent studies on conservative treatment have explored its role in controlling the progression of scoliosis in early-onset cases. Parot et al. observed that chest wall abnormalities and spinal scoliosis could be managed without surgery through braces and regular monitoring, thereby avoiding surgery and highlighting the importance of follow-up care for potential complications [\nKawakami et al. demonstrated that ARCBT significantly reduced the progression of EOS compared to brace-only treatment (BT), providing an alternative approach for early intervention [\nThese findings emphasize that conservative treatments, particularly casting and bracing, can delay surgery and provide personalized care for CS patients. However, further research is necessary to tailor treatment plans based on individual patient needs and ensure long-term success.\nSurgery for CS is indicated when conservative treatment fails, symptoms are severe, or the curve progresses rapidly. Surgical methods include fusion, non-fusion, hybrid techniques, and growth modulation. Surgery is generally performed when rapid curve progression occurs despite nearing skeletal maturity. Preoperative evaluation and communication about risks, such as infection or nerve injury, are critical, as are postoperative rehabilitation strategies to improve spinal stability and quality of life.\nInnovations like robot-assisted surgery and customized graft materials are enhancing surgical outcomes, with ongoing research focusing on more personalized approaches. Interdisciplinary cooperation remains essential for comprehensive CS management [\nHistorically, in situ fusion surgery has been used to treat CS, particularly in young children. However, its use has decreased due to limitations such as restricted lung development and a high rate of reoperations (25.6%, according to Goldberg) [\nHemivertebra resection with short-segment fusion is highly effective for young CS patients (Fig.\nPosterior hemivertebra resection and scoliosis correction (T8–T12) in a 3-year-old girl diagnosed with a congenital T10 hemivertebra.\nGrowth rods, including single and dual systems, allow for spinal correction while enabling continued growth (Fig.\nPosterior spinal correction with Isola growth-friendly instrumentation and bone grafting in a 4-year-old girl diagnosed with congenital scoliosis.\nThe Shilla technique focuses on dynamic realignment of the deformity’s apex to reduce corrective loss. It has been compared to traditional growth rod systems for effectiveness [\nMCGR has transformed EOS treatment, reducing the need for repeated surgeries while maintaining correction [\nThe HT is an advanced surgical method developed to overcome limitations of traditional dual growing rods (TDGR) in treating severe, long-segment congenital early-onset scoliosis (CEOS). Key issues with TDGR, such as insufficient main curve correction, persistent apical deformities, inadequate sagittal plane control, and frequent implant failures due to asymmetric growth forces, are mitigated by HT. Combining posterior osteotomy or vertebrectomy with short fusion and dual growing rods, HT improves deformity correction, especially at the apex, while reducing mechanical complications and preserving spinal growth. Initially proposed by Wang et al., HT demonstrated significant improvements in scoliosis correction (from 81.4° to 40.1°) and spinal growth (T1–S1 length increased by 1.23 cm/year), with a low complication rate over a 53.3-month follow-up [\nThe TDGR technique, combined with apical control techniques (ACTs), has been utilized to improve deformity correction in EOS by addressing apical vertebral rotation and enhancing curve control. Kamaci et al. demonstrated the efficacy of the TDGR in controlling both coronal and sagittal plane deformities while improving apical vertebral rotation [\nCS is a multifactorial disorder rooted in disrupted vertebral development during embryogenesis. Genetic studies implicate mutations in TBX6, GDF3, DSTYK, and COL11A2, alongside CNVs and epigenetic dysregulation, while environmental triggers such as maternal hypoxia and toxin exposure exacerbate risk. Diagnosis leverages advanced imaging and genetic sequencing, with MRI critical for detecting spinal cord anomalies. Conservative therapies, including innovative bracing (e.g., ARCBT, 3D-printed orthoses), effectively manage mild cases, delaying surgical needs. For severe deformities, surgical advancements like HT and MCGR offer superior correction and growth preservation. HT, combining osteotomy with growth rods, achieves 50% Cobb angle reduction and 1.23 cm/year spinal growth, outperforming traditional methods. MCGR minimizes repeat surgeries but requires further quality-of-life assessments. Apical control strategies and robotics enhance precision, reducing complications. Future research must address gene–environment interactions, and long-term outcomes of emerging therapies. A multidisciplinary approach—integrating genetics, imaging, and personalized interventions—is vital to improving prognosis for CS patients. Clinicians should prioritize early diagnosis, tailored treatment algorithms, and lifelong surveillance to mitigate progression and associated comorbidities.", "content_for_embedding": "Congenital scoliosis (CS) is a form of early-onset scoliosis (EOS) caused by skeletal abnormalities during gestational weeks 4 to 6, often leading to additional deformities in other systems [\nTreatment options for CS range from conservative management—such as casting and bracing—for mild-to-moderate cases, to surgical interventions—including in situ fusion, hemivertebra resection, and the use of a vertical expandable prosthetic titanium rib (VEPTR)—for more severe deformities [\nGiven its progressive nature, regular follow-up is essential for monitoring and adjusting treatment plans to improve patient outcomes [\nThis review discusses recent advancements in the etiology, diagnosis, and treatment of CS, aiming to provide clinicians with the latest insights for personalized care.\nWe conducted a narrative literature review in July 2025, adhering to the SANRA (Scale for the Assessment of Narrative Review Articles) guidelines [\nCS is a type of EOS caused by abnormal spinal development during the embryonic period. It is marked by severe deformities and rapid progression, often accompanied by malformations in other organs [\nThe genetic landscape of CS is increasingly complex, involving a variety of mutations, SNPs, and CNVs. Early studies, such as those by Qiu et al., examined genes like MESP2, HES7, and DUSP6, but found no significant mutations, suggesting these genes may not play a major role in sporadic CS within the Chinese Han population [\nOther genes, including LMX1A and FBN1, also play significant roles in spinal development, with mutations linked to CS [\nEpigenetics has also come to the forefront, with studies like Zhang et al. identifying allele-specific methylation in the SVIL gene, suggesting an interaction between genetic and environmental factors [\nRecent studies have continued to broaden our understanding of the genetic basis of CS. Novel variants in the FGFR1 and PTK7 genes have been associated with vertebral malformations and scoliosis [\nDifferent CS types have distinct etiologies. Type I (formation) anomalies are often driven by genetic disruptions in vertebral development. For example, TBX6 mutations or deletions (at 16p11.2) lead primarily to hemivertebrae or butterfly vertebrae [\nIn summary, the genetic factors underlying CS are diverse, involving mutations in TBX6, GDF3, DSTYK, and COL11A2, among others, along with CNVs and epigenetic changes. Ongoing research using advanced sequencing technologies and functional assays continues to shed light on this complex disorder, offering potential for more targeted therapeutic approaches.\nMaternal factors during pregnancy play a significant role in the pathogenesis of CS. Hypoxia is considered a primary factor, with studies in mouse models showing that hypoxic conditions disrupt the normal formation of embryonic vertebral cartilage, leading to spinal curvature [\nTreatment for CS includes conservative and surgical approaches. Conservative treatments, such as casts and braces, are generally considered for milder cases, while severe deformities often require surgical intervention.\nRecent studies on conservative treatment have explored its role in controlling the progression of scoliosis in early-onset cases. Parot et al. observed that chest wall abnormalities and spinal scoliosis could be managed without surgery through braces and regular monitoring, thereby avoiding surgery and highlighting the importance of follow-up care for potential complications [\nKawakami et al. demonstrated that ARCBT significantly reduced the progression of EOS compared to brace-only treatment (BT), providing an alternative approach for early intervention [\nThese findings emphasize that conservative treatments, particularly casting and bracing, can delay surgery and provide personalized care for CS patients. However, further research is necessary to tailor treatment plans based on individual patient needs and ensure long-term success.\nSurgery for CS is indicated when conservative treatment fails, symptoms are severe, or the curve progresses rapidly. Surgical methods include fusion, non-fusion, hybrid techniques, and growth modulation. Surgery is generally performed when rapid curve progression occurs despite nearing skeletal maturity. Preoperative evaluation and communication about risks, such as infection or nerve injury, are critical, as are postoperative rehabilitation strategies to improve spinal stability and quality of life.\nInnovations like robot-assisted surgery and customized graft materials are enhancing surgical outcomes, with ongoing research focusing on more personalized approaches. Interdisciplinary cooperation remains essential for comprehensive CS management [\nHistorically, in situ fusion surgery has been used to treat CS, particularly in young children. However, its use has decreased due to limitations such as restricted lung development and a high rate of reoperations (25.6%, according to Goldberg) [\nHemivertebra resection with short-segment fusion is highly effective for young CS patients (Fig.\nPosterior hemivertebra resection and scoliosis correction (T8–T12) in a 3-year-old girl diagnosed with a congenital T10 hemivertebra.\nGrowth rods, including single and dual systems, allow for spinal correction while enabling continued growth (Fig.\nPosterior spinal correction with Isola growth-friendly instrumentation and bone grafting in a 4-year-old girl diagnosed with congenital scoliosis.\nThe Shilla technique focuses on dynamic realignment of the deformity’s apex to reduce corrective loss. It has been compared to traditional growth rod systems for effectiveness [\nMCGR has transformed EOS treatment, reducing the need for repeated surgeries while maintaining correction [\nThe HT is an advanced surgical method developed to overcome limitations of traditional dual growing rods (TDGR) in treating severe, long-segment congenital early-onset scoliosis (CEOS). Key issues with TDGR, such as insufficient main curve correction, persistent apical deformities, inadequate sagittal plane control, and frequent implant failures due to asymmetric growth forces, are mitigated by HT. Combining posterior osteotomy or vertebrectomy with short fusion and dual growing rods, HT improves deformity correction, especially at the apex, while reducing mechanical complications and preserving spinal growth. Initially proposed by Wang et al., HT demonstrated significant improvements in scoliosis correction (from 81.4° to 40.1°) and spinal growth (T1–S1 length increased by 1.23 cm/year), with a low complication rate over a 53.3-month follow-up [\nThe TDGR technique, combined with apical control techniques (ACTs), has been utilized to improve deformity correction in EOS by addressing apical vertebral rotation and enhancing curve control. Kamaci et al. demonstrated the efficacy of the TDGR in controlling both coronal and sagittal plane deformities while improving apical vertebral rotation [\nCS is a multifactorial disorder rooted in disrupted vertebral development during embryogenesis. Genetic studies implicate mutations in TBX6, GDF3, DSTYK, and COL11A2, alongside CNVs and epigenetic dysregulation, while environmental triggers such as maternal hypoxia and toxin exposure exacerbate risk. Diagnosis leverages advanced imaging and genetic sequencing, with MRI critical for detecting spinal cord anomalies. Conservative therapies, including innovative bracing (e.g., ARCBT, 3D-printed orthoses), effectively manage mild cases, delaying surgical needs. For severe deformities, surgical advancements like HT and MCGR offer superior correction and growth preservation. HT, combining osteotomy with growth rods, achieves 50% Cobb angle reduction and 1.23 cm/year spinal growth, outperforming traditional methods. MCGR minimizes repeat surgeries but requires further quality-of-life assessments. Apical control strategies and robotics enhance precision, reducing complications. Future research must address gene–environment interactions, and long-term outcomes of emerging therapies. A multidisciplinary approach—integrating genetics, imaging, and personalized interventions—is vital to improving prognosis for CS patients. Clinicians should prioritize early diagnosis, tailored treatment algorithms, and lifelong surveillance to mitigate progression and associated comorbidities.", "topic": "Diagnostic"}
{"pmid": "40445098", "pmcid": "12292796", "title": "The Role of IL-6 and TNF-α as Early Biomarkers in the Prediction and Diagnosis of Gestational Diabetes Mellitus", "publication_year": "N/A", "abstract": "Gestational diabetes mellitus (GDM) occurs in approximately 9–25% of pregnancies and, if left undiagnosed or inadequately controlled, can lead to adverse outcomes for both the mother and the fetus, short and long term. GDM is characterized by glucose intolerance with onset or first recognition during pregnancy and is a multifactorial condition with a pathophysiology that remains incompletely understood. It is strongly associated with a chronic low-grade inflammatory state that contributes to insulin resistance, a hallmark of GDM pathogenesis. Among the fundamental pro-inflammatory cytokines implicated in this process, TNF-α and IL-6 play central roles. TNF-α is a cytokine primarily secreted by activated macrophages, as well as by adipocytes in the context of obesity. Many studies have shown that its levels are elevated in pregnant women with GDM compared to normoglycemic pregnant individuals. IL-6 is another pro-inflammatory cytokine secreted by immune cells, adipose tissue, and the placenta. It is found in higher concentrations in the maternal circulation during pregnancies complicated by GDM. Both TNF-α and IL-6 act synergistically to perpetuate a pro-inflammatory intrauterine environment. Their combined effects exacerbate insulin resistance and may impair pancreatic β-cell compensation during pregnancy, facilitating the onset of GDM in genetically or metabolically susceptible individuals. Recent research has identified various maternal serum biomarkers, such as TNF-α and IL-6, that may hold promise for the early detection of GDM. The aim of our study is to evaluate whether TNF-α and IL-6 can be used as diagnostic tools for the early diagnosis of GDM, allowing for timely intervention and reducing the risk of associated maternal and fetal complications.", "full_text": "Gestational diabetes mellitus (GDM) is one of the most common metabolic disorders of pregnancy, affecting approximately 7–14% pregnancies worldwide [\nThe current gold-standard for the diagnosis of GDM is the oral glucose tolerance test (OGTT) that is typically performed between 24–28 weeks of gestation. However, OGTT has several limitations, which include patient inconvenience, fasting requirements, poor reproducibility, and its relatively late administration in pregnancy. Thus, early intervention is not possible, and it may cause irreversible complications. As a result, there is a growing interest in identifying early, reliable biomarkers that reflect the pathophysiological processes leading to GDM and can lead to early diagnosis [\nChronic inflammation is recognized to play a critical role in the pathogenesis of insulin resistance and GDM. Among various inflammatory mediators, interleukin-6 (IL-6) and tumor necrosis factor-alpha (TNF-α) have been extensively studied for their contributions to both systemic insulin resistance and the metabolic alterations that occur during pregnancy. Both cytokines are secreted by adipose tissue, placental trophoblasts, and immune cells, and have been found to be elevated in women who later develop GDM. Their role in disrupting insulin signaling pathways and changing glucose homeostasis suggest their potential as early biomarkers for GDM prediction and diagnosis [\nThis narrative review aims to present the current evidence in the role of IL-6 and TNF-α as biomarkers for early diagnosis of GDM. We will examine their physiological relevance, evidence from observational and prospective studies, potential integration into clinical screening algorithms, and future directions for research.\nGestational diabetes mellitus (GDM) is a complex metabolic condition that arises from the interaction between insulin resistance and insufficient pancreatic β-cell compensation during pregnancy. Although GDM was considered a condition that develops in the late second trimester of pregnancy, current research indicates that metabolic dysfunction may begin even before conception, emphasizing the importance of early physiological changes in its pathogenesis.\nPregnancy is characterized by progressive insulin resistance, as shown in\nEmerging evidence identifies chronic low-grade inflammation as a central mechanism in the pathogenesis of GDM. Pro-inflammatory cytokines, particularly IL-6 and TNF-α, play critical roles in impairing insulin signaling. These cytokines, produced by adipose tissue, placenta, and immune cells, activate intracellular stress pathways such as c-Jun N-terminal kinase (JNK) and inhibitor of kappa B kinase (IKK), leading to serine phosphorylation of insulin receptor substrate-1 (IRS-1) and impaired downstream signaling via the PI3K/Akt pathway. Consequently, glucose transporter 4 (GLUT4) translocation is reduced, resulting in diminished glucose uptake and systemic insulin resistance (\nTNF-α disrupts insulin signaling by promoting serine phosphorylation of IRS proteins and impairing adiponectin signaling. IL-6, in turn, contributes to hepatic glucose production and suppresses insulin sensitivity in peripheral tissues. These inflammatory mediators are elevated in early pregnancy in women who subsequently develop GDM, underscoring their potential utility as early biomarkers for prediction and diagnosis [\nThe placenta exerts a profound influence on maternal metabolic adaptation through secretion of hormones, cytokines, and exosomes. In GDM, alterations in placental function may precede clinical hyperglycemia. Trophoblastic mitochondrial dysfunction and oxidative stress can impair insulin sensitivity and placental nutrient transport. Fetal hyperinsulinemia, induced by maternal hyperglycemia, promotes excessive nutrient uptake and contributes to fetal overgrowth, while also modifying placental signaling loops in a feed-forward manner [\nRecent studies have demonstrated that except for the classical inflammatory cytokines, like TNF-α and IL-6, neurotrophic and gut-derived factors also contribute to the glucose regulation during pregnancy and may play a role in the development of GDM. Brain-derived neurotrophic factor (BDNF) seems to decrease in women with GDM [\nAnother important factor, the duodenal mucosa is a site for incretin hormone secretion, such as GLP-1, but also harbors enteroendocrine cells and immune components that respond to metabolic and inflammatory process. This mucosal dysregulation, including altered microbiota and cytokine expression, may impair gut–pancreas crosstalk, and as a result, GDM. All these findings support the implication of multiple factors in the pathophysiology of GDM that includes immune–neuroendocrine interactions at both systemic and gastrointestinal levels [\nGestational diabetes mellitus (GDM) is increasingly recognized as a systemic condition involving not only insulin resistance and glucose dysregulation but also a complex interplay between inflammatory, neuroendocrine, and metabolic factors. While pro-inflammatory cytokines such as TNF-α and IL-6 have been extensively studied in the context of GDM, a broader perspective reveals significant contributions from anti-inflammatory cytokines, adipokines, and neuropeptides.\nAnti-inflammatory cytokines such as adiponectin, ghrelin, irisin, and vaspin serve to counterbalance the damaging effects of chronic low-grade inflammation in GDM. According to the study by Lis-Kuberka et al. [\nAnsari-Lari et al. highlighted that leptin levels were elevated in women with GDM, whereas TNF-α levels were paradoxically lower [\nCurrent evidence supports a multifactorial pathogenesis of GDM involving pro- and anti-inflammatory imbalance, adipokine dysregulation, impaired gut–brain–pancreas axis, and neuroimmune interactions. These insights justify a revised conceptual model of GDM not as a purely metabolic or inflammatory disorder, but as a neuroimmune metabolic condition with implications for maternal and neonatal outcomes. Future research should aim to integrate these diverse pathways into predictive and therapeutic strategies.\nChronic low-grade inflammation is associated with the pathogenesis of GDM, connecting adipose-derived and placental cytokines to metabolic dysregulation [\nTNF-α and IL-6 are key pro-inflammatory cytokines that are consistently elevated in insulin resistance and GDM. Their involvement in impairing insulin signaling and counteracting insulin’s anti-inflammatory effects positions them as potential mediators of insulin resistance. Under normal conditions, insulin reduces the generation of reactive oxygen species (ROS) by mononuclear cells; however, this protective effect is compromised in the presence of TNF-α and IL-6 [\nTNF-α is a pro-inflammatory cytokine primarily produced by activated monocytes and macrophages, and it plays an important role in inflammatory response [\nIL-6 is a pro-inflammatory cytokine and is secreted by immune cells, endothelial cells, and primarily by monocytes and macrophages within adipose tissue and exerts broad effects on glucose metabolism. IL-6 is involved in a wide range of biological functions, including regulation of acute phase protein responses, modulation of B and T lymphocyte activity, alteration of blood-brain barrier permeability, promotion of synovial inflammation, influence on blood cell formation, and contributions to fetal development. It influences pancreatic islet β-cell function, where it has been shown to enhance insulin secretion under certain conditions [\nIn GDM, there is placental expression of pro-inflammatory cytokines, especially TNF-α and IL-6 [\nRecent studies have shown that proinflammatory cytokines may downregulate the expression or affect signaling of the GLP-1 receptor (GLP-1R) in pancreatic β-cells, thereby limiting the insulinotropic action of GLP-1. This mechanism is particularly important in the case of gestational diabetes mellitus, where mild chronic inflammation is observed. Increased levels of TNF-α, which are frequently found in pregnant women with GDM, have been shown to suppress GLP-1R expression. As a result, this leads to reduced insulin secretion in response to glucose. This phenomenon affects not only insulin sensitivity, but also the ability of β-cells to adequately respond to the increased metabolic demands of pregnancy. This interaction highlights the dual role of inflammation in the pathogenesis of GDM, both through the induction of insulin resistance and through the dysfunction of compensatory mechanisms of insulin secretion [\nTNF-α and IL-6 are expressed in placental tissues and affect trophoblast proliferation, apoptosis, and invasion [\nThere are multiple clinical studies that have examined maternal IL-6 and TNF-α concentrations during pregnancy in relation to GDM development, as shown in\nThe literature about the correlation between TNF-α levels in early gestation and subsequent GDM is somewhat divergent. Many studies indicate that TNF-α is higher (or trends higher) in women who will develop GDM, even in the first or early second trimester, reflecting a preexisting pro-inflammatory state. Hosseini et al. found that elevated circulating TNF-α was significantly associated with increased GDM risk (pooled OR ~1.28, 95%CI 1.01–1.62). They reported that early/mid-pregnancy TNF-α levels were already higher in women who went on to have GDM compared to controls [\nBy the time of GDM diagnosis (24–28 weeks), TNF-α is generally found to be elevated in GDM patients. Wei et al. reported that circulating TNF-α was highly expressed in GDM patients compared to healthy pregnant controls [\nIL-6 and TNF-α can be included in biomarker panels for GDM for various reasons. These cytokines may serve as early indicators of GDM, particularly in high-risk pregnancies, such as those in women with obesity or a family history of diabetes. Elevated concentrations of these markers could help in identifying pregnant women at an increased risk of developing GDM even earlier than the traditional glucose testing. Additionally, the measurement of cytokine levels throughout pregnancy may facilitate the monitoring of insulin resistance and inflammatory processes, which could inform more personalized treatment and management approaches. However, there are several challenges to consider, including the variability in cytokine levels. These levels can fluctuate due to factors such as the stage of pregnancy, individual immune responses, and the presence of comorbid conditions [\nHowever, increased levels of IL-6 and TNF-α are not specific to GDM and they may also increase in inflammatory conditions. As a result, the interpretation of these cytokines should be carefully made and ideally with clinical assessment. Also, further research should be conducted in order to evaluate the levels of these cytokines longitudinally during pregnancy and whether pregnancy alone affects these levels. Also, further maternal characteristics that may affect IL-6 and TNF-α should be taken into consideration in the interpretation of the results.\nIncorporating IL-6 and TNF-α into personalized risk stratification for gestational diabetes offers significant insights into the inflammatory and metabolic mechanisms underlying the condition. Tailored monitoring and lifestyle interventions, such as weight management and physical activity, can be provided to women identified as being at elevated risk based on their TNF-α or IL-6 levels. This approach has the potential to mitigate disease severity or delay its onset. Women with elevated levels of TNF-α or IL-6 can be classified as high-risk and prioritized for more frequent screenings (e.g., oral glucose tolerance test (OGTT), insulin sensitivity assessments), while those with lower levels may require less intensive monitoring. This strategy enhances the efficiency of healthcare resource allocation and optimizes patient care.\nMaternal demographic and metabolic factors, such as age, body mass index (BMI), ethnicity, family history of diabetes, and pre-pregnancy weight, have long been established as traditional risk factors for gestational diabetes mellitus (GDM). The integration of inflammatory cytokines, particularly IL-6 and TNF-α, into this existing framework enables a more comprehensive and individualized approach to risk assessment and management. Advanced maternal age, particularly in women over 35 years, is associated with an elevated risk of GDM [\nBy integrating measurements of IL-6 and TNF-α with maternal demographic and metabolic data, healthcare providers can enhance the accuracy of predicting the risk of GDM and refine both preventive and therapeutic strategies. For women identified as high-risk, personalized interventions, such as modifications to diet, exercise routines, or pharmacological treatments (e.g., metformin or insulin), can be introduced at earlier stages of pregnancy, before the onset of the irreversible damage for the mother and the fetus. As gestation progresses, continuous monitoring of IL-6 and TNF-α levels, in conjunction with glucose measurements, allows clinicians to assess the progression of insulin resistance and inflammation, facilitating timely adjustments in care. This approach, which emphasizes personalized treatment, enables at-risk women to receive interventions that reduce the severity of GDM, minimize the likelihood of complications such as macrosomia, preeclampsia, and cesarean delivery, and promote long-term maternal health, including a reduced future risk of type 2 diabetes.\nDespite the growing evidence supporting the involvement of IL-6 and TNF-α in the pathogenesis of GDM, several limitations must be acknowledged when considering their potential as biomarkers for early diagnosis. First, the existing literature is notable for its considerable heterogeneity in study designs, including differences in patient characteristics and demographics, diagnostic criteria for GDM, and gestational age at the biomarker assessment. This variability limits the ability to draw consistent conclusions or perform meaningful meta-analyses.\nFurthermore, there is still no consensus on gestational age-specific reference ranges or clinically validated cut-off values for IL-6 and TNF-α that can accurately predict GDM. Most studies report relative differences in cytokine concentrations between cases and controls, without defining thresholds that can be implemented in clinical screening algorithms. Additionally, there is variability in assay methods used for cytokine quantification. The sensitivity and specificity of methods such as multiplex platforms and enzyme-linked immunosorbent assay (ELISA) vary, which could lead to discrepancies in the reporting of cytokine levels between studies.\nAnother important limitation is the influence of confounding factors such as maternal body mass index, chronic low-grade inflammation, dietary habits, ethnicity, and stress, all of which can independently modulate circulating cytokine levels. As such, elevated IL-6 or TNF-α concentrations in early pregnancy may not exclusively reflect emerging glycemic dysregulation but rather a combination of overlapping metabolic and immunologic processes. Elevated IL-6 and TNF-α levels are not exclusive to GDM and may also be observed in other conditions, such as infections and autoimmune diseases [\nTo date there is no evidence concerning the variation of IL-6 and TNF-α throughout the pregnancy, as there are no longitudinal studies. However, in our review we included studies that targeted in different trimesters in pregnancy, as shown in\nWhile observational studies have identified significant associations between elevated cytokine levels and subsequent GDM development, there remains a lack of large-scale, prospective validation studies confirming their predictive value in diverse populations. Moreover, IL-6 and TNF-α are infrequently integrated into multivariate risk models alongside traditional clinical and biochemical predictors, making it difficult to assess their additive utility in refining early screening approaches. Additionally, many studies assess these markers at a single time point, limiting our understanding of their longitudinal dynamics and predictive accuracy over the course of gestation.\nThese limitations highlight the need for standardized protocols, better-designed prospective cohorts, and integrated risk models to clarify the clinical relevance of IL-6 and TNF-α in the prediction and diagnosis of GDM.\nThe integration of biomarkers such as IL-6 and TNF-α into GDM risk assessment models holds significant potential for enhancing both diagnosis and treatment strategies. However, the clinical applicability of these biomarkers, especially when combined with traditional maternal demographic and metabolic data, remains an area that requires thorough investigation. Randomized controlled trials are essential to determine whether incorporating IL-6 and TNF-α measurements into clinical practice can lead to better outcomes in managing GDM. These trials are necessary to establish strong evidence regarding the effectiveness of IL-6 and TNF-α panels in informing clinical decision-making. RCTs could examine whether early detection of high-risk pregnancies, based on elevated IL-6 and TNF-α levels, leads to reduced GDM incidence, improved maternal and fetal health outcomes, and a reduction in complications such as macrosomia, preeclampsia, and cesarean sections. Moreover, RCTs can evaluate whether early interventions, guided by the inclusion of these biomarkers in risk assessments, result in measurable improvements in treatment outcomes. The use of IL-6 and TNF-α panels in routine GDM risk assessments may have substantial implications for healthcare costs. RCTs are needed to assess the cost-effectiveness of incorporating these biomarkers into clinical practice, by comparing the costs of these tests and associated interventions with their potential benefits (e.g., reduced long-term maternal health risks, fewer pregnancy complications, and improved post-pregnancy outcomes), to determine whether their widespread use is economically viable. One of the significant potential advantages of early intervention based on IL-6 and TNF-α levels is the potential improvement in long-term maternal health, particularly in reducing the risk of type 2 diabetes. RCTs could assess whether women identified as high-risk for GDM due to elevated levels of these biomarkers experience improved long-term metabolic outcomes, including a decreased incidence of type 2 diabetes or other chronic conditions. Additionally, RCTs must address the ethical considerations of early inflammatory marker testing and the risk of unnecessary treatments or interventions. These trials could help mitigate concerns regarding over-diagnosis or misclassification of women at risk, ensuring that interventions are only provided to those who will benefit. Furthermore, trials conducted across diverse populations are essential to evaluate whether the utility of IL-6 and TNF-α markers is applicable across various ethnic groups and socio-economic backgrounds, which may have differing baseline risks for GDM.\nGestational diabetes mellitus remains a significant obstetric and public health concern due to its association with both immediate pregnancy complications and long-term metabolic consequences for mothers and offspring. The recognition of inflammation as a contributor to insulin resistance and metabolic dysfunction during pregnancy accentuates the need to revisit traditional paradigms of GDM diagnosis and management. Among the various inflammatory mediators, IL-6 and TNF-α have demonstrated consistent associations with early pregnancy glycemic alterations and have shown promise as predictive biomarkers of GDM prior to the onset of hyperglycemia detectable by oral glucose tolerance testing. Their mechanistic involvement in disrupting insulin signaling, via serine phosphorylation of IRS-1, inhibition of GLUT4 translocation, and modulation of adipokine activity, further supports their biological plausibility.\nHeterogeneity in study designs, assay techniques, and population characteristics currently limits the clinical applicability of these biomarkers. Standardization of sampling protocols, identification of gestational age-specific cut-off values, and integration into multivariable predictive models are essential next steps. As our understanding of the immunometabolic pathways in GDM deepens, IL-6 and TNF-α may serve not only as diagnostic adjuncts but also as potential targets for early therapeutic intervention. Future prospective cohort studies and randomized controlled trials are needed to validate their utility in personalized risk stratification, with the ultimate goal of improving maternal and fetal outcomes.", "content_for_embedding": "Gestational diabetes mellitus (GDM) is one of the most common metabolic disorders of pregnancy, affecting approximately 7–14% pregnancies worldwide [\nThe current gold-standard for the diagnosis of GDM is the oral glucose tolerance test (OGTT) that is typically performed between 24–28 weeks of gestation. However, OGTT has several limitations, which include patient inconvenience, fasting requirements, poor reproducibility, and its relatively late administration in pregnancy. Thus, early intervention is not possible, and it may cause irreversible complications. As a result, there is a growing interest in identifying early, reliable biomarkers that reflect the pathophysiological processes leading to GDM and can lead to early diagnosis [\nChronic inflammation is recognized to play a critical role in the pathogenesis of insulin resistance and GDM. Among various inflammatory mediators, interleukin-6 (IL-6) and tumor necrosis factor-alpha (TNF-α) have been extensively studied for their contributions to both systemic insulin resistance and the metabolic alterations that occur during pregnancy. Both cytokines are secreted by adipose tissue, placental trophoblasts, and immune cells, and have been found to be elevated in women who later develop GDM. Their role in disrupting insulin signaling pathways and changing glucose homeostasis suggest their potential as early biomarkers for GDM prediction and diagnosis [\nThis narrative review aims to present the current evidence in the role of IL-6 and TNF-α as biomarkers for early diagnosis of GDM. We will examine their physiological relevance, evidence from observational and prospective studies, potential integration into clinical screening algorithms, and future directions for research.\nGestational diabetes mellitus (GDM) is a complex metabolic condition that arises from the interaction between insulin resistance and insufficient pancreatic β-cell compensation during pregnancy. Although GDM was considered a condition that develops in the late second trimester of pregnancy, current research indicates that metabolic dysfunction may begin even before conception, emphasizing the importance of early physiological changes in its pathogenesis.\nPregnancy is characterized by progressive insulin resistance, as shown in\nEmerging evidence identifies chronic low-grade inflammation as a central mechanism in the pathogenesis of GDM. Pro-inflammatory cytokines, particularly IL-6 and TNF-α, play critical roles in impairing insulin signaling. These cytokines, produced by adipose tissue, placenta, and immune cells, activate intracellular stress pathways such as c-Jun N-terminal kinase (JNK) and inhibitor of kappa B kinase (IKK), leading to serine phosphorylation of insulin receptor substrate-1 (IRS-1) and impaired downstream signaling via the PI3K/Akt pathway. Consequently, glucose transporter 4 (GLUT4) translocation is reduced, resulting in diminished glucose uptake and systemic insulin resistance (\nTNF-α disrupts insulin signaling by promoting serine phosphorylation of IRS proteins and impairing adiponectin signaling. IL-6, in turn, contributes to hepatic glucose production and suppresses insulin sensitivity in peripheral tissues. These inflammatory mediators are elevated in early pregnancy in women who subsequently develop GDM, underscoring their potential utility as early biomarkers for prediction and diagnosis [\nThe placenta exerts a profound influence on maternal metabolic adaptation through secretion of hormones, cytokines, and exosomes. In GDM, alterations in placental function may precede clinical hyperglycemia. Trophoblastic mitochondrial dysfunction and oxidative stress can impair insulin sensitivity and placental nutrient transport. Fetal hyperinsulinemia, induced by maternal hyperglycemia, promotes excessive nutrient uptake and contributes to fetal overgrowth, while also modifying placental signaling loops in a feed-forward manner [\nRecent studies have demonstrated that except for the classical inflammatory cytokines, like TNF-α and IL-6, neurotrophic and gut-derived factors also contribute to the glucose regulation during pregnancy and may play a role in the development of GDM. Brain-derived neurotrophic factor (BDNF) seems to decrease in women with GDM [\nAnother important factor, the duodenal mucosa is a site for incretin hormone secretion, such as GLP-1, but also harbors enteroendocrine cells and immune components that respond to metabolic and inflammatory process. This mucosal dysregulation, including altered microbiota and cytokine expression, may impair gut–pancreas crosstalk, and as a result, GDM. All these findings support the implication of multiple factors in the pathophysiology of GDM that includes immune–neuroendocrine interactions at both systemic and gastrointestinal levels [\nGestational diabetes mellitus (GDM) is increasingly recognized as a systemic condition involving not only insulin resistance and glucose dysregulation but also a complex interplay between inflammatory, neuroendocrine, and metabolic factors. While pro-inflammatory cytokines such as TNF-α and IL-6 have been extensively studied in the context of GDM, a broader perspective reveals significant contributions from anti-inflammatory cytokines, adipokines, and neuropeptides.\nAnti-inflammatory cytokines such as adiponectin, ghrelin, irisin, and vaspin serve to counterbalance the damaging effects of chronic low-grade inflammation in GDM. According to the study by Lis-Kuberka et al. [\nAnsari-Lari et al. highlighted that leptin levels were elevated in women with GDM, whereas TNF-α levels were paradoxically lower [\nCurrent evidence supports a multifactorial pathogenesis of GDM involving pro- and anti-inflammatory imbalance, adipokine dysregulation, impaired gut–brain–pancreas axis, and neuroimmune interactions. These insights justify a revised conceptual model of GDM not as a purely metabolic or inflammatory disorder, but as a neuroimmune metabolic condition with implications for maternal and neonatal outcomes. Future research should aim to integrate these diverse pathways into predictive and therapeutic strategies.\nChronic low-grade inflammation is associated with the pathogenesis of GDM, connecting adipose-derived and placental cytokines to metabolic dysregulation [\nTNF-α and IL-6 are key pro-inflammatory cytokines that are consistently elevated in insulin resistance and GDM. Their involvement in impairing insulin signaling and counteracting insulin’s anti-inflammatory effects positions them as potential mediators of insulin resistance. Under normal conditions, insulin reduces the generation of reactive oxygen species (ROS) by mononuclear cells; however, this protective effect is compromised in the presence of TNF-α and IL-6 [\nTNF-α is a pro-inflammatory cytokine primarily produced by activated monocytes and macrophages, and it plays an important role in inflammatory response [\nIL-6 is a pro-inflammatory cytokine and is secreted by immune cells, endothelial cells, and primarily by monocytes and macrophages within adipose tissue and exerts broad effects on glucose metabolism. IL-6 is involved in a wide range of biological functions, including regulation of acute phase protein responses, modulation of B and T lymphocyte activity, alteration of blood-brain barrier permeability, promotion of synovial inflammation, influence on blood cell formation, and contributions to fetal development. It influences pancreatic islet β-cell function, where it has been shown to enhance insulin secretion under certain conditions [\nIn GDM, there is placental expression of pro-inflammatory cytokines, especially TNF-α and IL-6 [\nRecent studies have shown that proinflammatory cytokines may downregulate the expression or affect signaling of the GLP-1 receptor (GLP-1R) in pancreatic β-cells, thereby limiting the insulinotropic action of GLP-1. This mechanism is particularly important in the case of gestational diabetes mellitus, where mild chronic inflammation is observed. Increased levels of TNF-α, which are frequently found in pregnant women with GDM, have been shown to suppress GLP-1R expression. As a result, this leads to reduced insulin secretion in response to glucose. This phenomenon affects not only insulin sensitivity, but also the ability of β-cells to adequately respond to the increased metabolic demands of pregnancy. This interaction highlights the dual role of inflammation in the pathogenesis of GDM, both through the induction of insulin resistance and through the dysfunction of compensatory mechanisms of insulin secretion [\nTNF-α and IL-6 are expressed in placental tissues and affect trophoblast proliferation, apoptosis, and invasion [\nThere are multiple clinical studies that have examined maternal IL-6 and TNF-α concentrations during pregnancy in relation to GDM development, as shown in\nThe literature about the correlation between TNF-α levels in early gestation and subsequent GDM is somewhat divergent. Many studies indicate that TNF-α is higher (or trends higher) in women who will develop GDM, even in the first or early second trimester, reflecting a preexisting pro-inflammatory state. Hosseini et al. found that elevated circulating TNF-α was significantly associated with increased GDM risk (pooled OR ~1.28, 95%CI 1.01–1.62). They reported that early/mid-pregnancy TNF-α levels were already higher in women who went on to have GDM compared to controls [\nBy the time of GDM diagnosis (24–28 weeks), TNF-α is generally found to be elevated in GDM patients. Wei et al. reported that circulating TNF-α was highly expressed in GDM patients compared to healthy pregnant controls [\nIL-6 and TNF-α can be included in biomarker panels for GDM for various reasons. These cytokines may serve as early indicators of GDM, particularly in high-risk pregnancies, such as those in women with obesity or a family history of diabetes. Elevated concentrations of these markers could help in identifying pregnant women at an increased risk of developing GDM even earlier than the traditional glucose testing. Additionally, the measurement of cytokine levels throughout pregnancy may facilitate the monitoring of insulin resistance and inflammatory processes, which could inform more personalized treatment and management approaches. However, there are several challenges to consider, including the variability in cytokine levels. These levels can fluctuate due to factors such as the stage of pregnancy, individual immune responses, and the presence of comorbid conditions [\nHowever, increased levels of IL-6 and TNF-α are not specific to GDM and they may also increase in inflammatory conditions. As a result, the interpretation of these cytokines should be carefully made and ideally with clinical assessment. Also, further research should be conducted in order to evaluate the levels of these cytokines longitudinally during pregnancy and whether pregnancy alone affects these levels. Also, further maternal characteristics that may affect IL-6 and TNF-α should be taken into consideration in the interpretation of the results.\nIncorporating IL-6 and TNF-α into personalized risk stratification for gestational diabetes offers significant insights into the inflammatory and metabolic mechanisms underlying the condition. Tailored monitoring and lifestyle interventions, such as weight management and physical activity, can be provided to women identified as being at elevated risk based on their TNF-α or IL-6 levels. This approach has the potential to mitigate disease severity or delay its onset. Women with elevated levels of TNF-α or IL-6 can be classified as high-risk and prioritized for more frequent screenings (e.g., oral glucose tolerance test (OGTT), insulin sensitivity assessments), while those with lower levels may require less intensive monitoring. This strategy enhances the efficiency of healthcare resource allocation and optimizes patient care.\nMaternal demographic and metabolic factors, such as age, body mass index (BMI), ethnicity, family history of diabetes, and pre-pregnancy weight, have long been established as traditional risk factors for gestational diabetes mellitus (GDM). The integration of inflammatory cytokines, particularly IL-6 and TNF-α, into this existing framework enables a more comprehensive and individualized approach to risk assessment and management. Advanced maternal age, particularly in women over 35 years, is associated with an elevated risk of GDM [\nBy integrating measurements of IL-6 and TNF-α with maternal demographic and metabolic data, healthcare providers can enhance the accuracy of predicting the risk of GDM and refine both preventive and therapeutic strategies. For women identified as high-risk, personalized interventions, such as modifications to diet, exercise routines, or pharmacological treatments (e.g., metformin or insulin), can be introduced at earlier stages of pregnancy, before the onset of the irreversible damage for the mother and the fetus. As gestation progresses, continuous monitoring of IL-6 and TNF-α levels, in conjunction with glucose measurements, allows clinicians to assess the progression of insulin resistance and inflammation, facilitating timely adjustments in care. This approach, which emphasizes personalized treatment, enables at-risk women to receive interventions that reduce the severity of GDM, minimize the likelihood of complications such as macrosomia, preeclampsia, and cesarean delivery, and promote long-term maternal health, including a reduced future risk of type 2 diabetes.\nDespite the growing evidence supporting the involvement of IL-6 and TNF-α in the pathogenesis of GDM, several limitations must be acknowledged when considering their potential as biomarkers for early diagnosis. First, the existing literature is notable for its considerable heterogeneity in study designs, including differences in patient characteristics and demographics, diagnostic criteria for GDM, and gestational age at the biomarker assessment. This variability limits the ability to draw consistent conclusions or perform meaningful meta-analyses.\nFurthermore, there is still no consensus on gestational age-specific reference ranges or clinically validated cut-off values for IL-6 and TNF-α that can accurately predict GDM. Most studies report relative differences in cytokine concentrations between cases and controls, without defining thresholds that can be implemented in clinical screening algorithms. Additionally, there is variability in assay methods used for cytokine quantification. The sensitivity and specificity of methods such as multiplex platforms and enzyme-linked immunosorbent assay (ELISA) vary, which could lead to discrepancies in the reporting of cytokine levels between studies.\nAnother important limitation is the influence of confounding factors such as maternal body mass index, chronic low-grade inflammation, dietary habits, ethnicity, and stress, all of which can independently modulate circulating cytokine levels. As such, elevated IL-6 or TNF-α concentrations in early pregnancy may not exclusively reflect emerging glycemic dysregulation but rather a combination of overlapping metabolic and immunologic processes. Elevated IL-6 and TNF-α levels are not exclusive to GDM and may also be observed in other conditions, such as infections and autoimmune diseases [\nTo date there is no evidence concerning the variation of IL-6 and TNF-α throughout the pregnancy, as there are no longitudinal studies. However, in our review we included studies that targeted in different trimesters in pregnancy, as shown in\nWhile observational studies have identified significant associations between elevated cytokine levels and subsequent GDM development, there remains a lack of large-scale, prospective validation studies confirming their predictive value in diverse populations. Moreover, IL-6 and TNF-α are infrequently integrated into multivariate risk models alongside traditional clinical and biochemical predictors, making it difficult to assess their additive utility in refining early screening approaches. Additionally, many studies assess these markers at a single time point, limiting our understanding of their longitudinal dynamics and predictive accuracy over the course of gestation.\nThese limitations highlight the need for standardized protocols, better-designed prospective cohorts, and integrated risk models to clarify the clinical relevance of IL-6 and TNF-α in the prediction and diagnosis of GDM.\nThe integration of biomarkers such as IL-6 and TNF-α into GDM risk assessment models holds significant potential for enhancing both diagnosis and treatment strategies. However, the clinical applicability of these biomarkers, especially when combined with traditional maternal demographic and metabolic data, remains an area that requires thorough investigation. Randomized controlled trials are essential to determine whether incorporating IL-6 and TNF-α measurements into clinical practice can lead to better outcomes in managing GDM. These trials are necessary to establish strong evidence regarding the effectiveness of IL-6 and TNF-α panels in informing clinical decision-making. RCTs could examine whether early detection of high-risk pregnancies, based on elevated IL-6 and TNF-α levels, leads to reduced GDM incidence, improved maternal and fetal health outcomes, and a reduction in complications such as macrosomia, preeclampsia, and cesarean sections. Moreover, RCTs can evaluate whether early interventions, guided by the inclusion of these biomarkers in risk assessments, result in measurable improvements in treatment outcomes. The use of IL-6 and TNF-α panels in routine GDM risk assessments may have substantial implications for healthcare costs. RCTs are needed to assess the cost-effectiveness of incorporating these biomarkers into clinical practice, by comparing the costs of these tests and associated interventions with their potential benefits (e.g., reduced long-term maternal health risks, fewer pregnancy complications, and improved post-pregnancy outcomes), to determine whether their widespread use is economically viable. One of the significant potential advantages of early intervention based on IL-6 and TNF-α levels is the potential improvement in long-term maternal health, particularly in reducing the risk of type 2 diabetes. RCTs could assess whether women identified as high-risk for GDM due to elevated levels of these biomarkers experience improved long-term metabolic outcomes, including a decreased incidence of type 2 diabetes or other chronic conditions. Additionally, RCTs must address the ethical considerations of early inflammatory marker testing and the risk of unnecessary treatments or interventions. These trials could help mitigate concerns regarding over-diagnosis or misclassification of women at risk, ensuring that interventions are only provided to those who will benefit. Furthermore, trials conducted across diverse populations are essential to evaluate whether the utility of IL-6 and TNF-α markers is applicable across various ethnic groups and socio-economic backgrounds, which may have differing baseline risks for GDM.\nGestational diabetes mellitus remains a significant obstetric and public health concern due to its association with both immediate pregnancy complications and long-term metabolic consequences for mothers and offspring. The recognition of inflammation as a contributor to insulin resistance and metabolic dysfunction during pregnancy accentuates the need to revisit traditional paradigms of GDM diagnosis and management. Among the various inflammatory mediators, IL-6 and TNF-α have demonstrated consistent associations with early pregnancy glycemic alterations and have shown promise as predictive biomarkers of GDM prior to the onset of hyperglycemia detectable by oral glucose tolerance testing. Their mechanistic involvement in disrupting insulin signaling, via serine phosphorylation of IRS-1, inhibition of GLUT4 translocation, and modulation of adipokine activity, further supports their biological plausibility.\nHeterogeneity in study designs, assay techniques, and population characteristics currently limits the clinical applicability of these biomarkers. Standardization of sampling protocols, identification of gestational age-specific cut-off values, and integration into multivariable predictive models are essential next steps. As our understanding of the immunometabolic pathways in GDM deepens, IL-6 and TNF-α may serve not only as diagnostic adjuncts but also as potential targets for early therapeutic intervention. Future prospective cohort studies and randomized controlled trials are needed to validate their utility in personalized risk stratification, with the ultimate goal of improving maternal and fetal outcomes.", "topic": "Diagnostic"}
{"pmid": "40440122", "pmcid": "12299830", "title": "Minimally Invasive Surgery for the Excision and Repair of Cesarean Scar Defect: A Scoping Review of the Literature", "publication_year": "N/A", "abstract": "", "full_text": "The isthmocele is a pouch-shaped niche in the cesarean scar area on the anterior uterine wall, due to its defect or dehiscence. Most cases occur in women with one previous cesarean section [\nThere are several hypotheses to explain the implications in infertility: an adverse environment for sperm transport and embryo implantation; the scar defect as a physical barrier; psychological problems in case of difficulties in conceive [\nVolume Calculation (Base x Height))/2, as Simple or first degree < 15 mm\nDeficiency Ratio, the ratio between residual myometrium and healthy myometrium x 100, as Large when the thickness of the residual myometrium is <50% of the healthy myometrium or Small when the thickness of the residual myometrium is >50% of the healthy myometrium.\nMeasure of the minimum free myometrium, as Large if the residual myometrium is <2 mm with US, <2.5 mm with SHG, < 3 mm with MRI or Small, if the residual myometrium is >2 mm with US, > 2.5 mm with SHG, >3 mm with MRI.\nShape (triangle, semicircle, rectangle, circular, drop, inclusion cyst) [\nThe diagnostic US image is the simple sagittal uterine plane: it is an easier and more acceptable approach than SHG and/or MRI [\nThe literature is discordant about the best procedure to use for the treatment, but the relief of symptoms is described in most surgically treated patients, with scarce evidence regarding fertility and adequate procedure [\nOur objective is to review the literature about minimally invasive surgical management of isthmocele, with a focus on robot- assisted laparoscopy. Our second objective is to spread the description of video reports, reviewing published articles that could help in training surgeons to learn the procedure.\nThe Cochrane Systematic Review Database, MEDLINE, EMBASE, CINAHL, CENTRAL, and reference lists of well-known research from 2009 to 2025 were all thoroughly searched. For the same period, a gray literature search was also carried out using online databases. MeSH headings, when appropriate, were utilized in all literature searches. To make sure the search was accurate, an author examined it twice. The title and abstract screening included every search result. The words “isthmocele”, “cesarean scar pregnancy”AND “laparoscopy”,”robot”, NOT “laparotomy” OR “pharmacological” were searched on the main online scientific search sources, as indicated in our inclusion flow-chart (\nAfter results from 457 articles were obtained, we excluded duplicates and not strictly scientifically related publications. We considered 56 studies, but finally included 20 articles published or in press in English and French, chosen for the relevance to the topic (\nAs evidenced (\nThe aim of our review was to analyze the experience described in the literature about the minimally invasive robotic surgery for the correction of the isthmocele: the outcomes seem to be encouraging and in favor of a routinary use, when not contraindicated.\nIn fact, as the main results of the analyzed studies (\nWe evaluated the literature on the treatment of isthmocele in pre-Cesarean women treated with minimally invasive surgery: our hypothesis is that this treatment is more effective than other techniques in women desirous of having children.\nUterine scars can be related to hysterotomy after myomectomy and/or hysteroscopic surgery of congenital uterine malformations or cesarean section (CS) [\nThe scar defect may occur for the presence of one or more known risk factors, related to the increased tension in the lower uterine segment and a reduction in scar vascularization. Among the risk factors, those demonstrated are patient-related, as repeated cesarean section, retroverted uterus, high body mass index (BMI), hypertension, surgical factors, CS at cervical dilatation > 5 cm. Data on the incidence of isthmocele are conflictual, varying between 6.9% and 69% (in Italy, 24–84%): it occurs in approximately 60% of women after a primary CS and 100% after 3 CSs [\nMedical care is possible for patients with abnormal genital bleeding, pain, and without a desire for fertility [\nThe main limitations include a dislocated surgical view in cases of hysterotomy, a fixed uterus, or narrow vaginal access (in case of vaginal surgery); the use of general anesthesia; and the expensive costs of laparoscopy and robotic-assisted surgery [\nIn general, these procedures are safe, functional, non-invasive, and may restore anatomy in case of large defects. Surgery for the treatment of symptomatic isthmocele improves bleeding symptoms in more than 80% of women. Minor evidence is described to improve fertility or reduce obstetric complications in asymptomatic patients [\nLimitations are mainly related to the heterogeneity of information and to the sample size described for each included article. The strength of our review is the updated and complete analysis of the topic, with a particular focus on graphical support. To spread the procedure, learning by surgeons and resident medical doctors must take place through revision papers—like our review—and through the dissemination of training videos, considering the previous published research [\nSince surgery was found to alleviate bleeding symptoms in most patients, we found sufficient evidence to justify robotic treatment for symptomatic isthmocele.\nIn cases of patients with sufficient residual myometrial thickness overlaying the isthmocele, hysteroscopic treatment of the condition may be the safest and most successful procedure. When hysteroscopic treatment is inconclusive and individuals have a thinner remaining myometrium above the defect (<2.5 mm), vaginal approach and laparoscopic robotic surgery may be the best options. Vaginal access must be considered in situations such as lower dislocation of the isthmocele, sliding uterus, and absence of pelvic comorbidities. A laparoscopic or robotic-assisted procedure can be used in the case of women with fertility desire or large defects suffering symptoms and the failure of other treatments. Considering this knowledge, it is important to spread the use of the different types of minimally invasive surgery, particularly robotic techniques, to successfully treat isthmocele and improve patients’ quality of life.", "content_for_embedding": "The isthmocele is a pouch-shaped niche in the cesarean scar area on the anterior uterine wall, due to its defect or dehiscence. Most cases occur in women with one previous cesarean section [\nThere are several hypotheses to explain the implications in infertility: an adverse environment for sperm transport and embryo implantation; the scar defect as a physical barrier; psychological problems in case of difficulties in conceive [\nVolume Calculation (Base x Height))/2, as Simple or first degree < 15 mm\nDeficiency Ratio, the ratio between residual myometrium and healthy myometrium x 100, as Large when the thickness of the residual myometrium is <50% of the healthy myometrium or Small when the thickness of the residual myometrium is >50% of the healthy myometrium.\nMeasure of the minimum free myometrium, as Large if the residual myometrium is <2 mm with US, <2.5 mm with SHG, < 3 mm with MRI or Small, if the residual myometrium is >2 mm with US, > 2.5 mm with SHG, >3 mm with MRI.\nShape (triangle, semicircle, rectangle, circular, drop, inclusion cyst) [\nThe diagnostic US image is the simple sagittal uterine plane: it is an easier and more acceptable approach than SHG and/or MRI [\nThe literature is discordant about the best procedure to use for the treatment, but the relief of symptoms is described in most surgically treated patients, with scarce evidence regarding fertility and adequate procedure [\nOur objective is to review the literature about minimally invasive surgical management of isthmocele, with a focus on robot- assisted laparoscopy. Our second objective is to spread the description of video reports, reviewing published articles that could help in training surgeons to learn the procedure.\nThe Cochrane Systematic Review Database, MEDLINE, EMBASE, CINAHL, CENTRAL, and reference lists of well-known research from 2009 to 2025 were all thoroughly searched. For the same period, a gray literature search was also carried out using online databases. MeSH headings, when appropriate, were utilized in all literature searches. To make sure the search was accurate, an author examined it twice. The title and abstract screening included every search result. The words “isthmocele”, “cesarean scar pregnancy”AND “laparoscopy”,”robot”, NOT “laparotomy” OR “pharmacological” were searched on the main online scientific search sources, as indicated in our inclusion flow-chart (\nAfter results from 457 articles were obtained, we excluded duplicates and not strictly scientifically related publications. We considered 56 studies, but finally included 20 articles published or in press in English and French, chosen for the relevance to the topic (\nAs evidenced (\nThe aim of our review was to analyze the experience described in the literature about the minimally invasive robotic surgery for the correction of the isthmocele: the outcomes seem to be encouraging and in favor of a routinary use, when not contraindicated.\nIn fact, as the main results of the analyzed studies (\nWe evaluated the literature on the treatment of isthmocele in pre-Cesarean women treated with minimally invasive surgery: our hypothesis is that this treatment is more effective than other techniques in women desirous of having children.\nUterine scars can be related to hysterotomy after myomectomy and/or hysteroscopic surgery of congenital uterine malformations or cesarean section (CS) [\nThe scar defect may occur for the presence of one or more known risk factors, related to the increased tension in the lower uterine segment and a reduction in scar vascularization. Among the risk factors, those demonstrated are patient-related, as repeated cesarean section, retroverted uterus, high body mass index (BMI), hypertension, surgical factors, CS at cervical dilatation > 5 cm. Data on the incidence of isthmocele are conflictual, varying between 6.9% and 69% (in Italy, 24–84%): it occurs in approximately 60% of women after a primary CS and 100% after 3 CSs [\nMedical care is possible for patients with abnormal genital bleeding, pain, and without a desire for fertility [\nThe main limitations include a dislocated surgical view in cases of hysterotomy, a fixed uterus, or narrow vaginal access (in case of vaginal surgery); the use of general anesthesia; and the expensive costs of laparoscopy and robotic-assisted surgery [\nIn general, these procedures are safe, functional, non-invasive, and may restore anatomy in case of large defects. Surgery for the treatment of symptomatic isthmocele improves bleeding symptoms in more than 80% of women. Minor evidence is described to improve fertility or reduce obstetric complications in asymptomatic patients [\nLimitations are mainly related to the heterogeneity of information and to the sample size described for each included article. The strength of our review is the updated and complete analysis of the topic, with a particular focus on graphical support. To spread the procedure, learning by surgeons and resident medical doctors must take place through revision papers—like our review—and through the dissemination of training videos, considering the previous published research [\nSince surgery was found to alleviate bleeding symptoms in most patients, we found sufficient evidence to justify robotic treatment for symptomatic isthmocele.\nIn cases of patients with sufficient residual myometrial thickness overlaying the isthmocele, hysteroscopic treatment of the condition may be the safest and most successful procedure. When hysteroscopic treatment is inconclusive and individuals have a thinner remaining myometrium above the defect (<2.5 mm), vaginal approach and laparoscopic robotic surgery may be the best options. Vaginal access must be considered in situations such as lower dislocation of the isthmocele, sliding uterus, and absence of pelvic comorbidities. A laparoscopic or robotic-assisted procedure can be used in the case of women with fertility desire or large defects suffering symptoms and the failure of other treatments. Considering this knowledge, it is important to spread the use of the different types of minimally invasive surgery, particularly robotic techniques, to successfully treat isthmocele and improve patients’ quality of life.", "topic": "Diagnostic"}
{"pmid": "40435041", "pmcid": "12300948", "title": "PRV Induces Neurological Inflammatory Injury by Activating Necroptosis of Brain Tissue", "publication_year": "N/A", "abstract": "Pseudorabies virus (PRV) can infect a wide range of animal species, including swine and rodents. Infection in pigs is associated with significant economic losses in the global pork industry and is characterized by acute, often fatal disease, as well as central nervous system (CNS) invasion, which leads to neurological manifestations. Although PRV replication has been extensively characterized in certain murine neuronal cell lines such as Neuro-2a, the mechanisms underlying PRV-induced neuroinflammatory injury and necroptosis remain largely unclear. In this study, Kunming mice and mouse astrocytes (C8-D1A) were infected with PRV-GXLB-2013 at different doses to evaluate neurological injury and inflammatory responses. Given that the NF-κB/MLKL signaling pathway was found to be activated during PRV infection, a selective MLKL inhibitor, necrosulfonamide (NSA), was applied to investigate the role of necroptosis in PRV-induced neuroinflammatory damage. Mice infected with higher viral doses showed increased mortality, severe neurological symptoms, elevated brain inflammation, and pathological changes. In C8-D1A cells, PRV infection significantly upregulated inflammatory cytokines and key components of the NF-κB/MLKL pathway. Importantly, NSA treatment markedly reduced these inflammatory responses, mitochondrial damage, and cellular necrosis. Collectively, these findings suggest that PRV infection triggers neuroinflammatory injury through the activation of necroptosis and the NF-κB/MLKL signaling pathway. This study provides novel mechanistic insights into PRV-induced neurological damage and highlights potential therapeutic targets for intervention.", "full_text": "PRV, also known as Aujeszky’s disease virus, is a highly contagious swine pathogen that spreads rapidly via direct contact or fomite transmission, causing severe respiratory, reproductive, and neurological disorders in pigs, leading to substantial economic losses globally [\nPRV, an alphaherpesvirus with a double-stranded DNA genome, belongs to the Varicellovirus genus within the subfamily Alphaherpesvirinae of the Herpesviridae family. It exhibits pronounced neurotropism similar to other members of the Varicellovirus genus. While PRV is not typically considered a classical zoonotic agent, emerging reports suggest that it may pose a potential risk to immunocompromised individuals under specific circumstances. The virus can invade the host nervous system through synaptic connections and retrograde axonal transport mechanisms [\nNumerous studies have highlighted the relationship that PRV has with different signaling pathways, explaining potential mechanisms of action of the virus. Studies have shown that PRV can activate the NF-κB signaling pathway, and PRV infection induces DNA damage within a short period, leading to ATM activation (ataxia telangiectasia-mutated). Activated ATM further activates IKK kinase (inhibitor of kappa B kinase), which contributes to the phosphorylation and ubiquitination of nuclear factor κB inhibitory factor (IκBα), ultimately leading to IκBα degradation. Subsequently, NF-κB p65 is activated and translocated into the nucleus, where it binds to the target gene’s promoter and regulates the transcription of downstream genes. In addition, PRV inhibits the transcription of IκBα and promotes its proteasome-dependent degradation, thereby blocking the negative feedback regulation of the NF-κB signaling pathway, leading to the continuous activation of the pathway [\nDuring viral infection, certain viruses can activate the necroptotic pathway to facilitate cytokine release, thereby exacerbating tissue damage and amplifying inflammatory responses [\nIn this study, the neuroinflammatory injury induced by PRV-GXLB-2013 infection was investigated in Kunming mice and mouse astrocyte cells (C8-D1A). NSA intervention studies were conducted to investigate the mechanistic basis of PRV infection. The study preliminarily showed that PRV might induce inflammatory injury in the nervous system by activating necroptosis, which provides an important theoretical basis for elucidating the molecular mechanism of inflammatory injury in the nervous system caused by PRV infection.\nThe PRV-GXLB-2013 strain was provided by the Laboratory of Preventive Veterinary Medicine, College of Animal Science and Technology, Guangxi University. The virus was propagated in PK-15 cells cultured in Dulbecco’s Modified Eagle Medium ( DMEM; Gibco, Thermo Fisher Scientific, Shanghai, China) supplemented with 10% fetal bovine serum (FBS, Baidi Science and Technology, Hangzhou, China) at 37 °C under 5% CO\nThe 5-week-old specific pathogen-free (SPF) Kunming mice (20 ± 2 g body weight, equal gender distribution) were obtained from Changsha Tianqin Biotechnology Co., Ltd. (Changsha, China) (Production License: SCXK [Xiang] 2022-0011). Mice were housed in a pathogen-free facility with ad libitum access to food and water. All animal procedures complied with the Institutional Animal Care and Use Committee of Guangxi University (Ethics Approval No.: GXU-2022-210).\nMouse astrocyte-derived C8-D1A cells were generously provided by the Department of Infectious Diseases, College of Animal Science and Technology, Guangxi University. Cells were maintained in DMEM supplemented with 10% FBS and a 1% penicillin–streptomycin–amphotericin B antibiotic cocktail (Baidi Science and Technology, Hangzhou, China) and cultured at 37 °C in 5% CO\nNecrosulfonamide (NSA) was obtained from Selleck Chemicals (Shanghai, China). Anti-pseudorabies virus antibody (ab3534) was acquired from Abcam (Cambridge, UK). Serum nitric oxide (NO), total nitric oxide synthase (TNOS), inducible NOS (iNOS), and constitutive NOS (cNOS) assay kits were purchased from Nanjing Jiancheng Bioengineering Institute (Nanjing, China). MLKL, TNF-α, IL-1β, IL-6, and IL-8 ELISA kits were provided by Enzyme Immunoassay Biotechnology Co. (Yancheng, China). Dimethyl sulfoxide (DMSO), an enhanced CCK-8 proliferation assay kit, SparkZol RNA isolation reagent, SPARKscript II All-in-One RT SuperMix for qPCR (with gDNA Eraser), and 2× SYBR Green qPCR Master Mix (with ROX) were purchased from Sparkjade Biotechnology Co., Ltd. (Qingdao, China).\nFollowing a 12 h fasting period, mice were randomly divided into four groups (n = 16 per group, 1:1 male-to-female ratio): blank control group, 10\nFollowing PRV-GXLB-2013 infection, mice were monitored daily for clinical signs, including mental status, food intake, and locomotor activity. The onset, duration, and progression of neurological symptoms were systematically recorded, along with morbidity and mortality rates. Neurological function was assessed daily for seven days post-infection using a modified Neurological Severity Score (mNSS) system. This comprehensive behavioral assessment evaluates motor function, sensory responses, reflex integrity, and balance capabilities, with total scores ranging from 0 (normal) to 18 (maximal neurological impairment). Higher scores correlate with more severe neurological dysfunction [\nThree randomly selected mice per group received tail vein injections of 2% Evans Blue (EB; 5 mL/kg). Dye extravasation was monitored by observing bluish discoloration of extremities and auricles. Two hours post-injection, mice were anesthetized and subjected to transcardial perfusion with saline. Brains were harvested and wet weights were recorded. Brain tissues were homogenized in formamide (100 mg tissue/mL) and incubated at 45 °C for 24 h. Following centrifugation (1000×\nBrain tissue was taken from three mice per group and dissected into cerebral hemispheres, cerebellum, and brainstem. Following saline rinsing and surface moisture removal with filter paper, tissues were precisely weighed to obtain wet mass (W1). Samples were then dehydrated in a 105 °C drying oven for 48 h and reweighed to determine dry mass (W2). The water content in the brain tissue was calculated using the formula: [(W1 − W2)/W1] × 100%.\nBrain tissues were fixed in 4% paraformaldehyde for 24 h, followed by thorough rinsing in running tap water. Tissues were then dehydrated through a graded ethanol series, cleared in xylene, and embedded in paraffin. Serial sections (5 µm thickness) were cut using a microtome and mounted on slides. After standard deparaffinization with xylene and rehydration through an ethanol gradient, tissue sections were processed for histological analysis. Hematoxylin and eosin (H&E) staining was performed to assess general neuropathological alterations. Additionally, Nissl staining was conducted to evaluate neuronal morphology and integrity.\nImmunohistochemical (IHC) staining was performed to detect viral particles using an anti-PRV monoclonal antibody. Brain tissue paraffin sections were deparaffinized in xylene and rehydrated through a graded ethanol series. Antigen retrieval was conducted by microwave heating (medium power, 10 min) in EDTA buffer. Endogenous peroxidase activity was quenched by a 15 min incubation with 3% hydrogen peroxide. Non-specific binding sites were blocked with rapid containment solution for 30 min at room temperature. Sections were then incubated overnight at 4 °C with rabbit anti-PRV polyclonal antibody (1:100 dilution; Abcam, ab3534, Cambridge, UK), followed by three PBS washes. The secondary antibody, goat anti-rabbit IgG H&L (HRP; Abcam, ab205718, Cambridge, UK), was applied for 20 min at room temperature. After additional PBS washes, color development was performed using DAB substrate until optimal brown staining appeared and then immediately terminated by distilled water rinses. Finally, sections were counterstained with hematoxylin, dehydrated, and mounted for microscopic examination of PRV particle distribution in hippocampal regions.\nPRV genomic DNA was isolated from brain tissue using the SPARKeasy Virus Genomic DNA Extraction Kit (Qingdao, China). Viral DNA copy numbers were quantified by absolute qPCR using extracted DNA as a template on a LightCycler 96 real-time PCR system. The qPCR was performed using the 2× SYBR Green qPCR Master Mix (with ROX) according to the manufacturer’s instructions. The quantification was based on a standard curve generated using serial dilutions of PRV plasmid DNA containing the gE gene, with the following equation: Y = −3.520X + 39.436, where X represents the log\ngE-F: 5′-CGTGTTCTTTGTGGCGGTG-3′\ngE-R: 5′-AGCGTGGCGGTAAAGTTCTC-3′\nBrain tissues were homogenized in ice-cold lysis buffer (1:9\nThe in vitro effect of PRV on C8-D1A cell viability was assessed using CCK-8 assay. Cells were seeded in 96-well plates at 2 × 10\nC8-D1A cells were inoculated into 6-well plates at 1 × 10\nTotal RNA was isolated from brain tissues or C8-D1A cells using the TRIzol reagent. cDNA synthesis was performed with the SPARKscript II All-in-One RT SuperMix (with gDNA Eraser), and the resulting cDNA was stored at −20 °C. Quantitative PCR was conducted using the 2× SYBR Green qPCR Master Mix (with ROX) on a LightCycler 96 real-time PCR system under the following cycling conditions: initial denaturation at 94 °C for 3 min; 40 cycles of 94 °C for 10 sec; and 60 °C for 30 sec. Amplification curves and melt curves were analyzed to determine Ct values. Relative gene expression was calculated using the 2\nMice received intraperitoneal injections of either the NSA inhibitor (20 mg/kg in 100 μL saline) or the vehicle control (100 μL saline) 1 h prior to viral inoculation. On day 7 post-infection, animals were anesthetized and euthanized for brain tissue collection.\nC8-D1A cultures were pretreated with 10 μM NSA (DMSO-solubilized) 30 min prior to infection. Following 12 h incubation, cells were monitored for cytopathic effects (CPE) using phase-contrast microscopy. Both culture supernatants and cellular fractions were harvested for subsequent analysis. Meanwhile, at 12 h post-inoculation, the supernatants were aspirated, and cells were gently washed once with PBS. Cells were then stained with Hoechst 33342 (nuclear dye; blue fluorescence)/propidium iodide (PI; necrosis marker; red fluorescence) working solution (Solarbio, Beijing, China) and incubated at 4 °C for 30 min in the dark. Fluorescence microscopy was performed to visualize cellular staining patterns: viable cells displayed uniform blue nuclear staining, whereas necrotic cells exhibited both intense red cytoplasmic and blue nuclear fluorescence.\nBrain tissue samples and cellular specimens were trimmed into 1 mm\nAll data were analyzed using IBM SPSS Statistics (version 27.0) and were presented as mean ± standard error of the mean (SEM). After verifying normality and homogeneity of variance assumptions, one-way analysis of variance (ANOVA) was performed, followed by Duncan’s post hoc multiple comparisons test. Statistically significant differences (\nAs shown in\nViral DNA extracted from brain tissue was quantified through absolute quantitative PCR analysis in this study. As shown in\nHistopathological analysis revealed distinct morphological alterations in hippocampal neurons across treatment groups (\nHistological examination revealed a distinct neuronal pathology across treatment groups (\nEB extravasation assays were performed to quantitatively assess PRV-GXLB-2013-induced blood–brain barrier (BBB) disruption across varying viral doses.\nPRV infection elicited a robust systemic inflammatory response, characterized by the dose-dependent upregulation of proinflammatory mediators across multiple biological compartments. Quantitative analyses revealed, when compared with the control group, significant elevations in brain tissue nitric oxide synthase (NOS) activity (cNOS, iNOS, and TNOS) and nitric oxide (NO) production (10\nInfection of C8-D1A cells with PRV-GXLB-2013 resulted in a dose- and time-dependent reduction in cell viability, as quantified by CCK-8 assay, when compared with the control group, with highly significant decreases observed at MOI = 0.01 and MOI = 1 across all timepoints (6–48 h;\nAs shown in\nAs shown in\nHistopathological analysis revealed distinct neuronal alterations following PRV-GXLB-2013 infection (10\nThis study evaluated the neuroprotective effects of NSA against PRV-GXLB-2013-induced mitochondrial damage through the ultrastructural analysis of hippocampal neurons using transmission electron microscopy (TEM) (\nElectron microscopy revealed distinct cytopathic effects (CPE) in PRV-GXLB-2013-infected C8-D1A cells as early as 12 h post-infection (\nHoechst 33342/propidium iodide (PI) dual staining was conducted on PRV-GXLB-2013-infected C8-D1A cells to characterize cell death mechanisms further. Quantitative analysis revealed a significant increase in both apoptotic and necrotic cell populations following infection, compared to controls (\nPRV, a member of the Alphaherpesvirinae subfamily, is a neurotropic pathogen that causes fatal neurological disease in neonatal pigs, characterized by locomotor ataxia, paralysis, convulsions, and intense pruritus, with near 100% mortality [\nPRV infection triggered a robust neuroinflammatory response, marked by BBB disruption, cerebral edema, and hemorrhage—hallmark features of viral encephalitis [\nAstrocytes, as the predominant glial cell type in the CNS, play critical roles in maintaining homeostasis and BBB function [\nThe NF-κB signaling pathway plays a central role in regulating neuroinflammatory responses by driving the transcription of cytokines, chemokines, and adhesion molecules [\nFurthermore, our findings suggest that PRV-induced TNF-α release may serve as a key upstream signal for necroptosis induction. TNF-α has been shown to activate RIPK3, which phosphorylates MLKL to execute necroptosis [\nNotably, the pharmacological inhibition of necroptosis using NSA, an MLKL inhibitor, significantly attenuated the expression of inflammatory mediators (TNF-α, IL-1β, IL-6, NF-κB p65, RIP3, and MLKL) and restored IκBα levels, suggesting that necroptosis contributes substantially to PRV-induced neuroinflammation. Ultrastructural analysis via TEM further supported these findings, revealing mitochondrial swelling, cristae disruption, and plasma membrane damage in PRV-infected cells—all of which were alleviated by NSA treatment.\nTaken together, our data indicate that PRV activates the NF-κB signaling pathway, leading to TNF-α production, which subsequently triggers RIP3/MLKL-mediated necroptosis and drives neuroinflammatory pathology.\nPRV-GXLB-2013 infection induces necroptosis in the nervous system, triggering robust neuroinflammation in vivo and in vitro. Nonetheless, the precise molecular mechanisms underlying PRV-induced neuroinflammatory pathogenesis remain to be fully elucidated. These findings establish a critical foundation for developing targeted therapeutic strategies to mitigate PRV-induced neurological damage.", "content_for_embedding": "PRV, also known as Aujeszky’s disease virus, is a highly contagious swine pathogen that spreads rapidly via direct contact or fomite transmission, causing severe respiratory, reproductive, and neurological disorders in pigs, leading to substantial economic losses globally [\nPRV, an alphaherpesvirus with a double-stranded DNA genome, belongs to the Varicellovirus genus within the subfamily Alphaherpesvirinae of the Herpesviridae family. It exhibits pronounced neurotropism similar to other members of the Varicellovirus genus. While PRV is not typically considered a classical zoonotic agent, emerging reports suggest that it may pose a potential risk to immunocompromised individuals under specific circumstances. The virus can invade the host nervous system through synaptic connections and retrograde axonal transport mechanisms [\nNumerous studies have highlighted the relationship that PRV has with different signaling pathways, explaining potential mechanisms of action of the virus. Studies have shown that PRV can activate the NF-κB signaling pathway, and PRV infection induces DNA damage within a short period, leading to ATM activation (ataxia telangiectasia-mutated). Activated ATM further activates IKK kinase (inhibitor of kappa B kinase), which contributes to the phosphorylation and ubiquitination of nuclear factor κB inhibitory factor (IκBα), ultimately leading to IκBα degradation. Subsequently, NF-κB p65 is activated and translocated into the nucleus, where it binds to the target gene’s promoter and regulates the transcription of downstream genes. In addition, PRV inhibits the transcription of IκBα and promotes its proteasome-dependent degradation, thereby blocking the negative feedback regulation of the NF-κB signaling pathway, leading to the continuous activation of the pathway [\nDuring viral infection, certain viruses can activate the necroptotic pathway to facilitate cytokine release, thereby exacerbating tissue damage and amplifying inflammatory responses [\nIn this study, the neuroinflammatory injury induced by PRV-GXLB-2013 infection was investigated in Kunming mice and mouse astrocyte cells (C8-D1A). NSA intervention studies were conducted to investigate the mechanistic basis of PRV infection. The study preliminarily showed that PRV might induce inflammatory injury in the nervous system by activating necroptosis, which provides an important theoretical basis for elucidating the molecular mechanism of inflammatory injury in the nervous system caused by PRV infection.\nThe PRV-GXLB-2013 strain was provided by the Laboratory of Preventive Veterinary Medicine, College of Animal Science and Technology, Guangxi University. The virus was propagated in PK-15 cells cultured in Dulbecco’s Modified Eagle Medium ( DMEM; Gibco, Thermo Fisher Scientific, Shanghai, China) supplemented with 10% fetal bovine serum (FBS, Baidi Science and Technology, Hangzhou, China) at 37 °C under 5% CO\nThe 5-week-old specific pathogen-free (SPF) Kunming mice (20 ± 2 g body weight, equal gender distribution) were obtained from Changsha Tianqin Biotechnology Co., Ltd. (Changsha, China) (Production License: SCXK [Xiang] 2022-0011). Mice were housed in a pathogen-free facility with ad libitum access to food and water. All animal procedures complied with the Institutional Animal Care and Use Committee of Guangxi University (Ethics Approval No.: GXU-2022-210).\nMouse astrocyte-derived C8-D1A cells were generously provided by the Department of Infectious Diseases, College of Animal Science and Technology, Guangxi University. Cells were maintained in DMEM supplemented with 10% FBS and a 1% penicillin–streptomycin–amphotericin B antibiotic cocktail (Baidi Science and Technology, Hangzhou, China) and cultured at 37 °C in 5% CO\nNecrosulfonamide (NSA) was obtained from Selleck Chemicals (Shanghai, China). Anti-pseudorabies virus antibody (ab3534) was acquired from Abcam (Cambridge, UK). Serum nitric oxide (NO), total nitric oxide synthase (TNOS), inducible NOS (iNOS), and constitutive NOS (cNOS) assay kits were purchased from Nanjing Jiancheng Bioengineering Institute (Nanjing, China). MLKL, TNF-α, IL-1β, IL-6, and IL-8 ELISA kits were provided by Enzyme Immunoassay Biotechnology Co. (Yancheng, China). Dimethyl sulfoxide (DMSO), an enhanced CCK-8 proliferation assay kit, SparkZol RNA isolation reagent, SPARKscript II All-in-One RT SuperMix for qPCR (with gDNA Eraser), and 2× SYBR Green qPCR Master Mix (with ROX) were purchased from Sparkjade Biotechnology Co., Ltd. (Qingdao, China).\nFollowing a 12 h fasting period, mice were randomly divided into four groups (n = 16 per group, 1:1 male-to-female ratio): blank control group, 10\nFollowing PRV-GXLB-2013 infection, mice were monitored daily for clinical signs, including mental status, food intake, and locomotor activity. The onset, duration, and progression of neurological symptoms were systematically recorded, along with morbidity and mortality rates. Neurological function was assessed daily for seven days post-infection using a modified Neurological Severity Score (mNSS) system. This comprehensive behavioral assessment evaluates motor function, sensory responses, reflex integrity, and balance capabilities, with total scores ranging from 0 (normal) to 18 (maximal neurological impairment). Higher scores correlate with more severe neurological dysfunction [\nThree randomly selected mice per group received tail vein injections of 2% Evans Blue (EB; 5 mL/kg). Dye extravasation was monitored by observing bluish discoloration of extremities and auricles. Two hours post-injection, mice were anesthetized and subjected to transcardial perfusion with saline. Brains were harvested and wet weights were recorded. Brain tissues were homogenized in formamide (100 mg tissue/mL) and incubated at 45 °C for 24 h. Following centrifugation (1000×\nBrain tissue was taken from three mice per group and dissected into cerebral hemispheres, cerebellum, and brainstem. Following saline rinsing and surface moisture removal with filter paper, tissues were precisely weighed to obtain wet mass (W1). Samples were then dehydrated in a 105 °C drying oven for 48 h and reweighed to determine dry mass (W2). The water content in the brain tissue was calculated using the formula: [(W1 − W2)/W1] × 100%.\nBrain tissues were fixed in 4% paraformaldehyde for 24 h, followed by thorough rinsing in running tap water. Tissues were then dehydrated through a graded ethanol series, cleared in xylene, and embedded in paraffin. Serial sections (5 µm thickness) were cut using a microtome and mounted on slides. After standard deparaffinization with xylene and rehydration through an ethanol gradient, tissue sections were processed for histological analysis. Hematoxylin and eosin (H&E) staining was performed to assess general neuropathological alterations. Additionally, Nissl staining was conducted to evaluate neuronal morphology and integrity.\nImmunohistochemical (IHC) staining was performed to detect viral particles using an anti-PRV monoclonal antibody. Brain tissue paraffin sections were deparaffinized in xylene and rehydrated through a graded ethanol series. Antigen retrieval was conducted by microwave heating (medium power, 10 min) in EDTA buffer. Endogenous peroxidase activity was quenched by a 15 min incubation with 3% hydrogen peroxide. Non-specific binding sites were blocked with rapid containment solution for 30 min at room temperature. Sections were then incubated overnight at 4 °C with rabbit anti-PRV polyclonal antibody (1:100 dilution; Abcam, ab3534, Cambridge, UK), followed by three PBS washes. The secondary antibody, goat anti-rabbit IgG H&L (HRP; Abcam, ab205718, Cambridge, UK), was applied for 20 min at room temperature. After additional PBS washes, color development was performed using DAB substrate until optimal brown staining appeared and then immediately terminated by distilled water rinses. Finally, sections were counterstained with hematoxylin, dehydrated, and mounted for microscopic examination of PRV particle distribution in hippocampal regions.\nPRV genomic DNA was isolated from brain tissue using the SPARKeasy Virus Genomic DNA Extraction Kit (Qingdao, China). Viral DNA copy numbers were quantified by absolute qPCR using extracted DNA as a template on a LightCycler 96 real-time PCR system. The qPCR was performed using the 2× SYBR Green qPCR Master Mix (with ROX) according to the manufacturer’s instructions. The quantification was based on a standard curve generated using serial dilutions of PRV plasmid DNA containing the gE gene, with the following equation: Y = −3.520X + 39.436, where X represents the log\ngE-F: 5′-CGTGTTCTTTGTGGCGGTG-3′\ngE-R: 5′-AGCGTGGCGGTAAAGTTCTC-3′\nBrain tissues were homogenized in ice-cold lysis buffer (1:9\nThe in vitro effect of PRV on C8-D1A cell viability was assessed using CCK-8 assay. Cells were seeded in 96-well plates at 2 × 10\nC8-D1A cells were inoculated into 6-well plates at 1 × 10\nTotal RNA was isolated from brain tissues or C8-D1A cells using the TRIzol reagent. cDNA synthesis was performed with the SPARKscript II All-in-One RT SuperMix (with gDNA Eraser), and the resulting cDNA was stored at −20 °C. Quantitative PCR was conducted using the 2× SYBR Green qPCR Master Mix (with ROX) on a LightCycler 96 real-time PCR system under the following cycling conditions: initial denaturation at 94 °C for 3 min; 40 cycles of 94 °C for 10 sec; and 60 °C for 30 sec. Amplification curves and melt curves were analyzed to determine Ct values. Relative gene expression was calculated using the 2\nMice received intraperitoneal injections of either the NSA inhibitor (20 mg/kg in 100 μL saline) or the vehicle control (100 μL saline) 1 h prior to viral inoculation. On day 7 post-infection, animals were anesthetized and euthanized for brain tissue collection.\nC8-D1A cultures were pretreated with 10 μM NSA (DMSO-solubilized) 30 min prior to infection. Following 12 h incubation, cells were monitored for cytopathic effects (CPE) using phase-contrast microscopy. Both culture supernatants and cellular fractions were harvested for subsequent analysis. Meanwhile, at 12 h post-inoculation, the supernatants were aspirated, and cells were gently washed once with PBS. Cells were then stained with Hoechst 33342 (nuclear dye; blue fluorescence)/propidium iodide (PI; necrosis marker; red fluorescence) working solution (Solarbio, Beijing, China) and incubated at 4 °C for 30 min in the dark. Fluorescence microscopy was performed to visualize cellular staining patterns: viable cells displayed uniform blue nuclear staining, whereas necrotic cells exhibited both intense red cytoplasmic and blue nuclear fluorescence.\nBrain tissue samples and cellular specimens were trimmed into 1 mm\nAll data were analyzed using IBM SPSS Statistics (version 27.0) and were presented as mean ± standard error of the mean (SEM). After verifying normality and homogeneity of variance assumptions, one-way analysis of variance (ANOVA) was performed, followed by Duncan’s post hoc multiple comparisons test. Statistically significant differences (\nAs shown in\nViral DNA extracted from brain tissue was quantified through absolute quantitative PCR analysis in this study. As shown in\nHistopathological analysis revealed distinct morphological alterations in hippocampal neurons across treatment groups (\nHistological examination revealed a distinct neuronal pathology across treatment groups (\nEB extravasation assays were performed to quantitatively assess PRV-GXLB-2013-induced blood–brain barrier (BBB) disruption across varying viral doses.\nPRV infection elicited a robust systemic inflammatory response, characterized by the dose-dependent upregulation of proinflammatory mediators across multiple biological compartments. Quantitative analyses revealed, when compared with the control group, significant elevations in brain tissue nitric oxide synthase (NOS) activity (cNOS, iNOS, and TNOS) and nitric oxide (NO) production (10\nInfection of C8-D1A cells with PRV-GXLB-2013 resulted in a dose- and time-dependent reduction in cell viability, as quantified by CCK-8 assay, when compared with the control group, with highly significant decreases observed at MOI = 0.01 and MOI = 1 across all timepoints (6–48 h;\nAs shown in\nAs shown in\nHistopathological analysis revealed distinct neuronal alterations following PRV-GXLB-2013 infection (10\nThis study evaluated the neuroprotective effects of NSA against PRV-GXLB-2013-induced mitochondrial damage through the ultrastructural analysis of hippocampal neurons using transmission electron microscopy (TEM) (\nElectron microscopy revealed distinct cytopathic effects (CPE) in PRV-GXLB-2013-infected C8-D1A cells as early as 12 h post-infection (\nHoechst 33342/propidium iodide (PI) dual staining was conducted on PRV-GXLB-2013-infected C8-D1A cells to characterize cell death mechanisms further. Quantitative analysis revealed a significant increase in both apoptotic and necrotic cell populations following infection, compared to controls (\nPRV, a member of the Alphaherpesvirinae subfamily, is a neurotropic pathogen that causes fatal neurological disease in neonatal pigs, characterized by locomotor ataxia, paralysis, convulsions, and intense pruritus, with near 100% mortality [\nPRV infection triggered a robust neuroinflammatory response, marked by BBB disruption, cerebral edema, and hemorrhage—hallmark features of viral encephalitis [\nAstrocytes, as the predominant glial cell type in the CNS, play critical roles in maintaining homeostasis and BBB function [\nThe NF-κB signaling pathway plays a central role in regulating neuroinflammatory responses by driving the transcription of cytokines, chemokines, and adhesion molecules [\nFurthermore, our findings suggest that PRV-induced TNF-α release may serve as a key upstream signal for necroptosis induction. TNF-α has been shown to activate RIPK3, which phosphorylates MLKL to execute necroptosis [\nNotably, the pharmacological inhibition of necroptosis using NSA, an MLKL inhibitor, significantly attenuated the expression of inflammatory mediators (TNF-α, IL-1β, IL-6, NF-κB p65, RIP3, and MLKL) and restored IκBα levels, suggesting that necroptosis contributes substantially to PRV-induced neuroinflammation. Ultrastructural analysis via TEM further supported these findings, revealing mitochondrial swelling, cristae disruption, and plasma membrane damage in PRV-infected cells—all of which were alleviated by NSA treatment.\nTaken together, our data indicate that PRV activates the NF-κB signaling pathway, leading to TNF-α production, which subsequently triggers RIP3/MLKL-mediated necroptosis and drives neuroinflammatory pathology.\nPRV-GXLB-2013 infection induces necroptosis in the nervous system, triggering robust neuroinflammation in vivo and in vitro. Nonetheless, the precise molecular mechanisms underlying PRV-induced neuroinflammatory pathogenesis remain to be fully elucidated. These findings establish a critical foundation for developing targeted therapeutic strategies to mitigate PRV-induced neurological damage.", "topic": "Diagnostic"}
{"pmid": "40428812", "pmcid": "12300698", "title": "Gastrointestinal Cancers with Consideration of DPD and UGT1A1 Plasma Levels: Chemotherapy-Related Toxicity", "publication_year": "N/A", "abstract": "Unpredictable, dose-limiting toxicity remains a challenge in cancer treatment. We evaluated dihydropyrimidine dehydrogenase (DPD) and UDP-glucuronosyltransferase 1A1 (UGT1A1) plasma levels in the context of chemotherapy-induced toxicity and disease progression. Seventy gastrointestinal cancer patients (30 FOLFOX; 40 FOLFIRI) were enrolled. DPD and UGT1A1 plasma levels were determined using ELISA. Univariable and bivariable analyses and a general linear model (GLM) framework were used. Post-infusional reductions in white blood cell and granulocyte counts were observed. For FOLFOX, the granulocyte counts decreased by 17% (r = 0.54;", "full_text": "Gastrointestinal (GI) cancers refer to various types of malignancies affecting different parts of the digestive system from the esophagus to the stomach, the pancreas, the liver, the small intestine, the colon, the rectum, and the anus. They represent a major global public health concern, accounting for a significant portion of cancer-related morbidity (26% of all global cancer cases) and mortality (35% of cancer-related deaths) [\nTreating GI cancer is a complex process that requires a multidisciplinary strategy and involves multiple healthcare professionals. Clinicians individualize the therapeutic approach according to the specific cancer type, its stage, and the patient’s overall health status. Despite the significant advances in developing novel anticancer agents targeting specific molecular pathways and genetic mechanisms, conventional chemotherapy remains the most widely employed cornerstone of therapeutic intervention [\nBoth irinotecan and fluorouracil (5-FU) have proven effective as monotherapies or in different combinations in treating solid tumors, including GI malignancies. The FOLFOX regimen (folinic acid, fluorouracil and oxaliplatin) and the FOLFIRI protocol (folinic acid, fluorouracil and irinotecan) are widely recognized for their efficacy as standard chemotherapy regimens. 5-FU is a heterocyclic aromatic organic compound, being a pyrimidine analog composed of a pyrimidine and a furan ring. It blocks the enzyme thymidylate synthase, resulting in an intracellular thymine deficit, the inhibition of DNA synthesis, and the induction of cytotoxic effects. After 5-FU penetrates the cell, it undergoes two competitive processes: catabolic inactivation and anabolic generation of active metabolites. The catabolic pathways in the liver account for the metabolism of 80% to 85% of the injected 5-FU. Within the anabolic pathway, only 1 to 5% of the injected 5-FU is transformed into cytotoxic substances [\nIrinotecan is a bioactive compound and an analog of camptothecin. It is an alkaloid derived from\nThe main challenges in the treatment of cancer are associated with the limitations of the medications currently in use, including a small therapeutic range, dose-limiting toxicity, and the development of resistance. Toxic effects after 5-FU administration are most pronounced in the cells of the gastrointestinal mucosa (toxic diarrhea in 75% of patients), the bone marrow (neutropenia, leukopenia, thrombocytopenia in 69% of patients), and, less frequently, cause cardiac complications [\nAn ultimate goal in modern cancer therapy is to find the balance of “effectiveness–safety–price” combined with a personal approach. Strategies include maximizing multimodal treatment and diagnostic procedures in clinical practice. Among the key challenges in cancer therapy, drug resistance remains a leading cause of treatment failure. When evaluating the expected benefits related to treatment effectiveness and survival rate, attention is drawn to the issue of the safety of the applied therapy and the frequency of side and toxic effects. The leading strategy is to study their prediction, control, and prevention potential [\nThere is a 30% inter-individual variation in irinotecan clearance (CL), whereas SN-38 clearance shows a significantly more considerable variation of 80% [\nFrom this point of view, assessing adverse effects associated with 5-FU and irinotecan administration and exploring their relationship with the level of plasma enzymes, key indicators for chemotherapy-related toxicity and drug metabolism, is important in terms of interindividual variability in pharmacokinetics and drug-induced toxicities. Therefore, this study aims to evaluate dihydropyrimidine dehydrogenase (DPD) and UDP-glucuronosyltransferase 1A1 (UGT1A1) plasma levels in the context of chemotherapy-induced toxicity and estimate their relationships with hematological side effects and disease-specific variables.\nThis study was conducted at the “Medical Oncology” department of SofiaMed University Hospital, Sofia, Bulgaria. Patients with histologically confirmed gastrointestinal malignancies were included. The study focused on cancer patients approved for FOLFOX or FOLFIRI chemotherapy regimens. The FOLFOX and FOLFIRI regimens follow a standard protocol of folinic acid (400 mg/m\nThe eligibility criteria for participation in the study were as follows: being aged over 18, having solid GI tumors with histological verification from a pathologist, and being scheduled for chemotherapy with FOLFOX or FOLFIRI. Exclusion criteria included there being insufficient patient data for the study’s objectives and information regarding another malignancy in the patient’s medical records. Information concerning symptoms, comorbidities, family history, lifestyle habits, and allergies was collected from patients. Examinations included general condition assessment, BMI estimation, blood pressure and pulse measurements, and ECG. Evaluation of patients’ activity level in relation to their disease, i.e., ECOG (Eastern Cooperative Oncology Groups) performance status, was performed. Laboratory testing, imaging studies, and histological examination with TNM staging were conducted as part of the baseline assessment. The participants were informed about the study. Written informed consent was obtained from each patient.\nThe basic features of the analyzed patient cohort were gender, age, disease characteristics associated with initial tumor localization, histological subtype and histological grade, the presence or absence of regional or distant metastases (N and M status), ECOG performance status, and laboratory test values (white blood cell count, lymphocytes count, granulocyte count, platelets, red blood cell count, hematocrit, hemoglobin, creatinine, total bilirubin, aspartate aminotransferase, and alanine aminotransferase). Given the fact that all patients on the FOLFIRI regimen were in stage IV, whereas patients treated with FOLFOX included those in earlier stages, the platelet-to-lymphocyte ratio (PLR) and the lymphocyte-to-monocyte ratio (LMR) were estimated. Both have been frequently cited in the literature as markers of systemic inflammation and hematological alterations influenced by disease stage and have prognostic significance in various malignancies, including GIT cancer [\nAn enzyme-linked immunosorbent assay was used to assess blood plasma levels of dihydropyrimidine dehydrogenase (DPD) in patients treated with the FOLFOX or the FOLFIRI regimen. UDP-glucuronosyltransferase 1A1 (UGT1A1) levels were measured only in patients undergoing FOLFIRI treatment. UGT1A1 testing was not necessary for the FOLFOX regimen since it does not include irinotecan (the drug primarily associated with UGT1A1-related toxicity).\nThe Dihydropyrimidine Dehydrogenase ELISA Kit (Catalog No. EH2958; Wuhan Fine Biotech Co., Ltd. (FineTest), Wuhan, Hubei, China; range: 0.156–10 ng/mL; sensitivity: 0.094 ng/mL), procured in 2019 and 2023, was used to measure patients’ plasma DPD levels. For the determination of the human UGT1A1 enzyme level, the UDP-glucuronosyltransferase 1-1 ELISA Kit (Catalog No. EH1469; Wuhan Fine Biotech Co., Ltd. (FineTest), Wuhan, Hubei, China; range: 0.156–10 ng/mL; sensitivity: 0.094 ng/mL) was used. For each ELISA Kit, standard curves were constructed using manufacturer-supplied standards with known concentrations. Absorbance readings for the standards and patient samples were taken at 450 nm using BioTek ELx800 Absorbance Microplate Reader (BioTek, Winooski, VT, USA). Patients’ enzyme levels were calculated using the respective standard curve equations.\nPatients’ data were collected and organized into a structured database using Excel. Several mathematical and statistical methods were employed when analyzing the obtained experimental data. Quantitative variables were evaluated using variation analysis. Key statistical parameters, i.e., the mean value, median, range, and standard deviation, were determined in order to obtain information concerning data central tendency, and dispersion. Frequency analysis of qualitative variables was performed by estimating the absolute and relative frequencies. Statistical hypothesis testing was performed using the paired Wilcoxon test, Student’s unpaired\nAfter collecting informed consent and comprehensive information covering all key parameters of the studied patient group, we analyzed the clinical and biochemical data and the DPD and UGT1A1 levels obtained from the ELISA experiments performed as described in the Materials and Methods. Following data organization, we applied the statistical tests outlined in\nThe study comprised 70 patients: 38 males (54.29%) and 32 females (45.71%). The mean age was 64 years and 9 months (range from 34 to 83). Most patients were older adults, with a significant proportion of cases in individuals in the age range groups of 60 to 69 (30%, 21 patients) and 70 to 79 (35.71%, 25 patients). Of the 70 patients with gastrointestinal malignancies, esophageal, pancreatic, and hepatic flexure cancers were each present at a proportion of 5.71% (4 patients) of the cohort; rectal and sigmoid colon cancer each represented 21.43% (15 patients) of the cohort; 14.29% (10 patients) had stomach cancer; and 11.43% (8 patients) had colon cancer. In 8.57% (6 patients) of the cases, the initial tumor was in the cecum; in 4.29% (3 patients), it was in the rectosigmoid junction; and we had 1 patient (1.43%) with duodenal cancer. Most patients (75.71%, or 53 patients) were diagnosed with stage IV cancer; 14.29% of patients, or 10 patients, were in stage III; and only 7, or 10.00%, were in stage II. A substantial portion of patients (17.14%, 12 patients) had highly undifferentiated tumors (G3), the majority (70%, 49 patients) had cancers graded G2 (moderately differentiated), and only 12.86%, or 9 patients, had low-grade tumors (G1).\nThe patient cohort was divided into two subgroups based on the type of administered therapy. The first group included 30 patients treated with the FOLFOX chemotherapy regimen. The second group consisted of 40 patients who received the FOLFIRI regimen. The data of the demographic and nosological analysis performed on the recruited patients from both groups are presented in\nThe FOLFOX regimen was associated with alterations in some of the key parameters of the study, i.e., a decrease in the white blood cell count of nearly 11% (r = 0.51;\nSubjects undergoing FOLFIRI-based therapy had hemoglobin levels below the established lower threshold (116 vs. 120). Hemoglobin levels showed no statistically significant variation before or after chemotherapy when comparing FOLFOX- and FOLFIRI-treated patients. In individuals receiving treatment with the FOLFIRI regimen, again, we noted a statistically significant reduction in white blood cell count and granulocyte count, at 37% (r = 0.39;\nBased on data presented in\nThe results from the enzyme-linked immunosorbent assays denote that the enzyme levels and distribution in the studied population were found to be dependent on the type of chemotherapy regimen administered (\nA multiple linear regression analysis was conducted to assess the possibility of the disturbance of the proper relationship between enzyme levels and toxicity outcome. Specifically, the potential influence of age, gender, and disease stage on DPD and UGT1A1 levels was assessed (\nAs the next step, using bivariate analysis and multiple linear regression, we explored the potential relations between the obtained level of the enzymes responsible for the metabolism of 5-FU and irinotecan and the specific baseline for peripheral blood parameters cited as potential indicators of the myelotoxic effects of FOLFIRI regimens and determined according to our previous investigations [\nThe changes in white blood cell (WBC) and granulocyte counts, along with their reductions from baseline levels, are associated with UGT1A1 enzyme levels in individuals receiving the FOLFIRI protocol (\nThe results from the multiple linear regression analysis evaluating the associations between DPD and UGT1A1 levels and hematological outcomes after chemotherapy are presented in\nThe current work presents results from a retrospective single-center study with fixed sample sizes. This has consequently led to relatively limited and moderate patient group sizes (70, with 30 in the FOLFOX group and 40 in the FOLFIRI group). The performed statistical analysis of both groups of patients presented in\nOn day fourteen of the chemotherapeutic infusion, both groups of patients exhibited characteristic side effects, especially those associated with myelotoxicity. This is in accordance with the established clinical practice concerning the nadir period (7–12 days post-infusion, lasting 5–7 days) [\nIdentifying factors associated with responsiveness, resistance, and a predisposition of patients to develop severe adverse reactions has emerged as an increasingly important area of research. Numerous approaches have been investigated in an effort to accurately assess enzyme deficiency or dysfunction before treatment to avoid early and severe toxicity. These include genetic screening for polymorphisms, phenotypic assays to determine enzyme activity, measuring enzyme quantity through ELISA assays, and mathematical models [\nOur results concerning the DPD level in patients assigned for FOLFOX were in accordance with data from other authors who have used alternative methods to study this parameter [\nThe DPD regression model, including three predictors—age, cancer stage and gender—with 70 observations was not statistically significant (F(3, 66) = 1.492,\nDPD deficiency has been related to severe toxic effects after the administration of 5-FU [\nThe results obtained from the bivariate analysis and multivariate regression show that UGT1A1 is the most potent factor in the determination of treatment-related changes in the hematological parameters. In the bivariate analysis, significant differences (\nIn our study, we investigated the relationship between the observed levels of the studied enzymes and the changes in some peripheral blood parameters. In the FOLFIRI group, where the myelotoxic effects of low DPD and low UGT1A1 expression are expected to partially overlap, suggesting that combined deficiencies may exacerbate hematologic toxicity in a synergistic manner, the changes in the studied parameters seem to correlate more strongly with UGT1A1 levels, with no noticeable association with DPD (the high DPD expression likely reduces its influence on toxicity outcomes, thereby explaining the lack of a strong association). These observations should be cautiously interpreted within the limitations of a retrospective, single-center design, a relatively small sample size, and population heterogeneity. Despite the consistent pattern reaching statistical significance identified during data analysis, this study’s statistical power might be insufficient to detect smaller effects reliably, and there is a risk of type II errors. Further investigations in larger, prospective studies are needed to validate the observed associations and help to determine their potential.\nIn conclusion, our study demonstrated that patients on both regimens presented with the typical alterations associated with their application—reductions in white blood cell count, granulocyte count, and platelets for FOLFOX and decreases in white blood cell count, granulocyte count, and neutrophils in FOLFIRI. A lack of post-infusional statistical significance in red blood cells, hemoglobin, and hematocrit was observed. Liver and kidney function remained stable during treatment. The association of DPD levels with cancer progression was observed. In the FOLFIRI group, the changes seem to correlate with UGT1A1 levels. Further investigation and genotyping in the group of patients with low DPD and UGT1A levels is warranted to better understand the correlations between the phenotypes and genotypes related to chemotherapy-related adverse events.", "content_for_embedding": "Gastrointestinal (GI) cancers refer to various types of malignancies affecting different parts of the digestive system from the esophagus to the stomach, the pancreas, the liver, the small intestine, the colon, the rectum, and the anus. They represent a major global public health concern, accounting for a significant portion of cancer-related morbidity (26% of all global cancer cases) and mortality (35% of cancer-related deaths) [\nTreating GI cancer is a complex process that requires a multidisciplinary strategy and involves multiple healthcare professionals. Clinicians individualize the therapeutic approach according to the specific cancer type, its stage, and the patient’s overall health status. Despite the significant advances in developing novel anticancer agents targeting specific molecular pathways and genetic mechanisms, conventional chemotherapy remains the most widely employed cornerstone of therapeutic intervention [\nBoth irinotecan and fluorouracil (5-FU) have proven effective as monotherapies or in different combinations in treating solid tumors, including GI malignancies. The FOLFOX regimen (folinic acid, fluorouracil and oxaliplatin) and the FOLFIRI protocol (folinic acid, fluorouracil and irinotecan) are widely recognized for their efficacy as standard chemotherapy regimens. 5-FU is a heterocyclic aromatic organic compound, being a pyrimidine analog composed of a pyrimidine and a furan ring. It blocks the enzyme thymidylate synthase, resulting in an intracellular thymine deficit, the inhibition of DNA synthesis, and the induction of cytotoxic effects. After 5-FU penetrates the cell, it undergoes two competitive processes: catabolic inactivation and anabolic generation of active metabolites. The catabolic pathways in the liver account for the metabolism of 80% to 85% of the injected 5-FU. Within the anabolic pathway, only 1 to 5% of the injected 5-FU is transformed into cytotoxic substances [\nIrinotecan is a bioactive compound and an analog of camptothecin. It is an alkaloid derived from\nThe main challenges in the treatment of cancer are associated with the limitations of the medications currently in use, including a small therapeutic range, dose-limiting toxicity, and the development of resistance. Toxic effects after 5-FU administration are most pronounced in the cells of the gastrointestinal mucosa (toxic diarrhea in 75% of patients), the bone marrow (neutropenia, leukopenia, thrombocytopenia in 69% of patients), and, less frequently, cause cardiac complications [\nAn ultimate goal in modern cancer therapy is to find the balance of “effectiveness–safety–price” combined with a personal approach. Strategies include maximizing multimodal treatment and diagnostic procedures in clinical practice. Among the key challenges in cancer therapy, drug resistance remains a leading cause of treatment failure. When evaluating the expected benefits related to treatment effectiveness and survival rate, attention is drawn to the issue of the safety of the applied therapy and the frequency of side and toxic effects. The leading strategy is to study their prediction, control, and prevention potential [\nThere is a 30% inter-individual variation in irinotecan clearance (CL), whereas SN-38 clearance shows a significantly more considerable variation of 80% [\nFrom this point of view, assessing adverse effects associated with 5-FU and irinotecan administration and exploring their relationship with the level of plasma enzymes, key indicators for chemotherapy-related toxicity and drug metabolism, is important in terms of interindividual variability in pharmacokinetics and drug-induced toxicities. Therefore, this study aims to evaluate dihydropyrimidine dehydrogenase (DPD) and UDP-glucuronosyltransferase 1A1 (UGT1A1) plasma levels in the context of chemotherapy-induced toxicity and estimate their relationships with hematological side effects and disease-specific variables.\nThis study was conducted at the “Medical Oncology” department of SofiaMed University Hospital, Sofia, Bulgaria. Patients with histologically confirmed gastrointestinal malignancies were included. The study focused on cancer patients approved for FOLFOX or FOLFIRI chemotherapy regimens. The FOLFOX and FOLFIRI regimens follow a standard protocol of folinic acid (400 mg/m\nThe eligibility criteria for participation in the study were as follows: being aged over 18, having solid GI tumors with histological verification from a pathologist, and being scheduled for chemotherapy with FOLFOX or FOLFIRI. Exclusion criteria included there being insufficient patient data for the study’s objectives and information regarding another malignancy in the patient’s medical records. Information concerning symptoms, comorbidities, family history, lifestyle habits, and allergies was collected from patients. Examinations included general condition assessment, BMI estimation, blood pressure and pulse measurements, and ECG. Evaluation of patients’ activity level in relation to their disease, i.e., ECOG (Eastern Cooperative Oncology Groups) performance status, was performed. Laboratory testing, imaging studies, and histological examination with TNM staging were conducted as part of the baseline assessment. The participants were informed about the study. Written informed consent was obtained from each patient.\nThe basic features of the analyzed patient cohort were gender, age, disease characteristics associated with initial tumor localization, histological subtype and histological grade, the presence or absence of regional or distant metastases (N and M status), ECOG performance status, and laboratory test values (white blood cell count, lymphocytes count, granulocyte count, platelets, red blood cell count, hematocrit, hemoglobin, creatinine, total bilirubin, aspartate aminotransferase, and alanine aminotransferase). Given the fact that all patients on the FOLFIRI regimen were in stage IV, whereas patients treated with FOLFOX included those in earlier stages, the platelet-to-lymphocyte ratio (PLR) and the lymphocyte-to-monocyte ratio (LMR) were estimated. Both have been frequently cited in the literature as markers of systemic inflammation and hematological alterations influenced by disease stage and have prognostic significance in various malignancies, including GIT cancer [\nAn enzyme-linked immunosorbent assay was used to assess blood plasma levels of dihydropyrimidine dehydrogenase (DPD) in patients treated with the FOLFOX or the FOLFIRI regimen. UDP-glucuronosyltransferase 1A1 (UGT1A1) levels were measured only in patients undergoing FOLFIRI treatment. UGT1A1 testing was not necessary for the FOLFOX regimen since it does not include irinotecan (the drug primarily associated with UGT1A1-related toxicity).\nThe Dihydropyrimidine Dehydrogenase ELISA Kit (Catalog No. EH2958; Wuhan Fine Biotech Co., Ltd. (FineTest), Wuhan, Hubei, China; range: 0.156–10 ng/mL; sensitivity: 0.094 ng/mL), procured in 2019 and 2023, was used to measure patients’ plasma DPD levels. For the determination of the human UGT1A1 enzyme level, the UDP-glucuronosyltransferase 1-1 ELISA Kit (Catalog No. EH1469; Wuhan Fine Biotech Co., Ltd. (FineTest), Wuhan, Hubei, China; range: 0.156–10 ng/mL; sensitivity: 0.094 ng/mL) was used. For each ELISA Kit, standard curves were constructed using manufacturer-supplied standards with known concentrations. Absorbance readings for the standards and patient samples were taken at 450 nm using BioTek ELx800 Absorbance Microplate Reader (BioTek, Winooski, VT, USA). Patients’ enzyme levels were calculated using the respective standard curve equations.\nPatients’ data were collected and organized into a structured database using Excel. Several mathematical and statistical methods were employed when analyzing the obtained experimental data. Quantitative variables were evaluated using variation analysis. Key statistical parameters, i.e., the mean value, median, range, and standard deviation, were determined in order to obtain information concerning data central tendency, and dispersion. Frequency analysis of qualitative variables was performed by estimating the absolute and relative frequencies. Statistical hypothesis testing was performed using the paired Wilcoxon test, Student’s unpaired\nAfter collecting informed consent and comprehensive information covering all key parameters of the studied patient group, we analyzed the clinical and biochemical data and the DPD and UGT1A1 levels obtained from the ELISA experiments performed as described in the Materials and Methods. Following data organization, we applied the statistical tests outlined in\nThe study comprised 70 patients: 38 males (54.29%) and 32 females (45.71%). The mean age was 64 years and 9 months (range from 34 to 83). Most patients were older adults, with a significant proportion of cases in individuals in the age range groups of 60 to 69 (30%, 21 patients) and 70 to 79 (35.71%, 25 patients). Of the 70 patients with gastrointestinal malignancies, esophageal, pancreatic, and hepatic flexure cancers were each present at a proportion of 5.71% (4 patients) of the cohort; rectal and sigmoid colon cancer each represented 21.43% (15 patients) of the cohort; 14.29% (10 patients) had stomach cancer; and 11.43% (8 patients) had colon cancer. In 8.57% (6 patients) of the cases, the initial tumor was in the cecum; in 4.29% (3 patients), it was in the rectosigmoid junction; and we had 1 patient (1.43%) with duodenal cancer. Most patients (75.71%, or 53 patients) were diagnosed with stage IV cancer; 14.29% of patients, or 10 patients, were in stage III; and only 7, or 10.00%, were in stage II. A substantial portion of patients (17.14%, 12 patients) had highly undifferentiated tumors (G3), the majority (70%, 49 patients) had cancers graded G2 (moderately differentiated), and only 12.86%, or 9 patients, had low-grade tumors (G1).\nThe patient cohort was divided into two subgroups based on the type of administered therapy. The first group included 30 patients treated with the FOLFOX chemotherapy regimen. The second group consisted of 40 patients who received the FOLFIRI regimen. The data of the demographic and nosological analysis performed on the recruited patients from both groups are presented in\nThe FOLFOX regimen was associated with alterations in some of the key parameters of the study, i.e., a decrease in the white blood cell count of nearly 11% (r = 0.51;\nSubjects undergoing FOLFIRI-based therapy had hemoglobin levels below the established lower threshold (116 vs. 120). Hemoglobin levels showed no statistically significant variation before or after chemotherapy when comparing FOLFOX- and FOLFIRI-treated patients. In individuals receiving treatment with the FOLFIRI regimen, again, we noted a statistically significant reduction in white blood cell count and granulocyte count, at 37% (r = 0.39;\nBased on data presented in\nThe results from the enzyme-linked immunosorbent assays denote that the enzyme levels and distribution in the studied population were found to be dependent on the type of chemotherapy regimen administered (\nA multiple linear regression analysis was conducted to assess the possibility of the disturbance of the proper relationship between enzyme levels and toxicity outcome. Specifically, the potential influence of age, gender, and disease stage on DPD and UGT1A1 levels was assessed (\nAs the next step, using bivariate analysis and multiple linear regression, we explored the potential relations between the obtained level of the enzymes responsible for the metabolism of 5-FU and irinotecan and the specific baseline for peripheral blood parameters cited as potential indicators of the myelotoxic effects of FOLFIRI regimens and determined according to our previous investigations [\nThe changes in white blood cell (WBC) and granulocyte counts, along with their reductions from baseline levels, are associated with UGT1A1 enzyme levels in individuals receiving the FOLFIRI protocol (\nThe results from the multiple linear regression analysis evaluating the associations between DPD and UGT1A1 levels and hematological outcomes after chemotherapy are presented in\nThe current work presents results from a retrospective single-center study with fixed sample sizes. This has consequently led to relatively limited and moderate patient group sizes (70, with 30 in the FOLFOX group and 40 in the FOLFIRI group). The performed statistical analysis of both groups of patients presented in\nOn day fourteen of the chemotherapeutic infusion, both groups of patients exhibited characteristic side effects, especially those associated with myelotoxicity. This is in accordance with the established clinical practice concerning the nadir period (7–12 days post-infusion, lasting 5–7 days) [\nIdentifying factors associated with responsiveness, resistance, and a predisposition of patients to develop severe adverse reactions has emerged as an increasingly important area of research. Numerous approaches have been investigated in an effort to accurately assess enzyme deficiency or dysfunction before treatment to avoid early and severe toxicity. These include genetic screening for polymorphisms, phenotypic assays to determine enzyme activity, measuring enzyme quantity through ELISA assays, and mathematical models [\nOur results concerning the DPD level in patients assigned for FOLFOX were in accordance with data from other authors who have used alternative methods to study this parameter [\nThe DPD regression model, including three predictors—age, cancer stage and gender—with 70 observations was not statistically significant (F(3, 66) = 1.492,\nDPD deficiency has been related to severe toxic effects after the administration of 5-FU [\nThe results obtained from the bivariate analysis and multivariate regression show that UGT1A1 is the most potent factor in the determination of treatment-related changes in the hematological parameters. In the bivariate analysis, significant differences (\nIn our study, we investigated the relationship between the observed levels of the studied enzymes and the changes in some peripheral blood parameters. In the FOLFIRI group, where the myelotoxic effects of low DPD and low UGT1A1 expression are expected to partially overlap, suggesting that combined deficiencies may exacerbate hematologic toxicity in a synergistic manner, the changes in the studied parameters seem to correlate more strongly with UGT1A1 levels, with no noticeable association with DPD (the high DPD expression likely reduces its influence on toxicity outcomes, thereby explaining the lack of a strong association). These observations should be cautiously interpreted within the limitations of a retrospective, single-center design, a relatively small sample size, and population heterogeneity. Despite the consistent pattern reaching statistical significance identified during data analysis, this study’s statistical power might be insufficient to detect smaller effects reliably, and there is a risk of type II errors. Further investigations in larger, prospective studies are needed to validate the observed associations and help to determine their potential.\nIn conclusion, our study demonstrated that patients on both regimens presented with the typical alterations associated with their application—reductions in white blood cell count, granulocyte count, and platelets for FOLFOX and decreases in white blood cell count, granulocyte count, and neutrophils in FOLFIRI. A lack of post-infusional statistical significance in red blood cells, hemoglobin, and hematocrit was observed. Liver and kidney function remained stable during treatment. The association of DPD levels with cancer progression was observed. In the FOLFIRI group, the changes seem to correlate with UGT1A1 levels. Further investigation and genotyping in the group of patients with low DPD and UGT1A levels is warranted to better understand the correlations between the phenotypes and genotypes related to chemotherapy-related adverse events.", "topic": "Diagnostic"}
{"pmid": "40421813", "pmcid": "12294577", "title": "Transcriptomic Profiling Reveals Gene Expression Changes in Mouse Liver Tissue During Alveolar Echinococcosis", "publication_year": "N/A", "abstract": "Background/Objectives: Alveolar echinococcosis (AE), caused by", "full_text": "Alveolar echinococcosis (AE), a parasitic disease instigated by the larvae of the tapeworm\nTranscriptomics, as a cutting-edge technology, has found wide-ranging applications in modern biological research. Currently, it is extensively employed in basic research on microorganisms and plants, clinical diagnostics, and drug development [\nIn this study, we successfully developed a mouse model infected with AE to systematically examine the gene expression profiles in liver tissues. We employed RNA-Seq technology at specific time points to comprehensively capture the dynamic changes in gene expression. Following the RNA-Seq analysis, we carried out quantitative real-time polymerase chain reaction (qRT-PCR) as a rigorous validation step for the results from the RNA-Seq experiment. To gain profound insights into the biological functions of differentially expressed genes (DEGs) in the disease development process, we performed Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) enrichment analyses. These sophisticated bioinformatics tools allowed us to map the DEGs to specific biological processes, molecular functions, and signaling pathways, thus shedding light on the underlying biological mechanisms driving the progression of AE. Furthermore, we utilized weighted gene co-expression network analysis (WGCNA) to identify genes that potentially play crucial roles in the infection caused by\nThe\nLong-clawed mole voles exhibiting visibly enlarged abdomens due to\nAt 6, 12, 19, and 25 weeks post-infection with protoscoleces, all experimental and control groups were euthanized via cervical dislocation and subsequently dissected. Liver tissue samples were collected from regions within 1–5 mm of macroscopically visible parasitic lesions, rinsed in a 10% EDTA solution, transferred into cryovials, flash-frozen in liquid nitrogen, and stored at −80 °C for downstream analyses.\nIn parallel, liver tissues were fixed in 4% formaldehyde solution, dehydrated, and embedded in paraffin for sectioning. Following hematoxylin-and-eosin (HE) staining, pathological changes in the liver tissues were assessed under light microscopy.\nLiver samples (≈2 g) were collected from perilesional areas (1–5 mm from macroscopic lesions) and processed for RNA-Seq. The cDNA libraries were sequenced on the Illumina sequencing platform by Metware Biotechnology Co., Ltd. (Wuhan, China). Briefly, total RNA from the liver tissues was extracted using Trizol reagent. The quality of RNA was checked using an Agilent 2100 Bioanalyzer. RNA samples that passed the quality check were used to construct libraries using the NEBNext\nThe DESeq2 software package [\nWith a significance threshold set at q < 0.05, TBtoolsp [\nThe gene co-expression network was constructed using the R version 4.2.2 software WGCNA 1.71 package [\nTissue RNA was isolated using a Total RNA Extraction kit (Beijing Solaibao Biotechnology Co., Ltd., Beijing, China) and transcribed into cDNA utilizing a cDNA reverse transcription kit (Shanghai Yisheng Biotechnology Co., Ltd., Shanghai, China) according to the manufacturers’ protocols. The resultant cDNA was subsequently amplified using a qPCR SYBR Green Kit (Shanghai Yisheng Biotechnology Co., Ltd.) in a thermocycler (Bio-Rad Laboratories, Inc., Hercules, CA, USA). GAPDH was used as the internal reference, and the relative gene expression level was evaluated by the 2\nUpon conducting autopsies, it was determined that at 6, 12, 19, and 25 weeks post-inoculation with the original head segment, the majority of mice exhibited hepatic alveolar echinococcosis, with infection rates of 10/12, 12/12, 12/12, and 12/12, respectively. At six weeks post-infection, the lesions were confined to the vicinity of the hepatic portal vein. By the twelfth week, the individual lesions had spread, resulting in damage to the diaphragmatic peritoneum. By the twenty-fifth week, over half of the mice (7/12) had experienced diaphragmatic metastasis.\nHE staining of tissue sections revealed that the liver tissue structure of mice in the blank control group was normal, with no obvious inflammatory cell infiltration observed in the portal area. Six weeks after\nIn the experimental group’s livers, proliferating hepatocytes near the parasitic lesions were observed (A). Certain areas of coagulative necrosis were also observed (B, C). The arrows in the figures indicate the parasitic lesions in the livers of the infected mice. These lesions are characterized by the typical germinal layer and laminated layer of Echinococcus multilocularis, surrounded by a periparasitic cellular infiltration composed of macrophages, fibroblasts/myofibroblasts, and lymphocytes, spreading gradually from the center outward. The hepatocytes are disorganized, presenting a reticular structure (D).\nA total of 32 samples, 16 from the experimental group and 16 from the control group, with 4 mice per timepoint, were subjected to transcriptome sequencing analysis. A robust dataset of 215.28 Gb of clean data was obtained, with each sample producing an effective data volume of 6 Gb, maintaining Q30 bases at a percentage of 92% or higher, and exhibiting an average GC content of 49%. Notably, the number of matched reads across all libraries exceeded 94%, confirming the high quality of sequencing and gene annotation, such that the data were suitable for subsequent bioinformatic analysis (\nDifferentially expressed genes (DEGs) were identified using stringent criteria, specifically |log2Fold Change| ≥ 1 and FDR < 0.05. Comparative transcriptomic analyses were conducted on liver tissues from mice at varying stages of\nTwelve genes which showed differential expression at a minimum of two of the four experimental timepoints were selected for confirmation using qRT-PCR. The research findings indicate that the expression trends of these selected genes are consistent with those obtained from the RNA-Seq analysis. However, the performance of some genes in the RNA-Seq and qRT-PCR was not entirely identical, for example, that of\nGO enrichment analysis was conducted to investigate the relevant biological processes, cellular components, and molecular functions at various stages of infection progression (\nKEGG enrichment analysis was conducted to discern enriched signaling pathways across different timepoints during the progression of infection (\nWGCNA was conducted on the transcriptome data to identify genes potentially linked to echinococcus infection. A total of 25,117 genes measured in the transcriptome data were analyzed. The co-expression threshold calculated by the software was set at 12 (\nCurrently, transcriptomic research on echinococcosis has advanced significantly, with extensive studies characterizing the hepatic transcriptional profiles and molecular regulatory networks involved in disease progression [\nMicroscopic examination of AE lesions demonstrates peripheral annular fibrous tissue hyperplasia, accompanied by infiltration of diverse immune cells—including lymphocytes, eosinophils, macrophages, and plasma cells—at the lesion margins. This immune-rich periphery constitutes an inflammatory microenvironment that shares histological similarities with hepatocellular carcinoma. AE lesions lack a complete fibrous capsule and instead exhibit invasive growth patterns, facilitated by a unique immune microenvironment that promotes parasite persistence and immune evasion [\nThis study revealed that at 6 weeks post-infection, transcriptional profiling showed minimal differential gene expression and no significantly enriched pathways, suggesting an initial immune-tolerant phase. By 12 weeks, however, immune-related signaling pathways were markedly activated, with early Th1-mediated responses playing a protective role by suppressing parasite proliferation and mitigating granuloma-associated tissue damage [\nKEGG enrichment analysis revealed that, after 12 weeks of\nActivation of the PPAR signaling pathway has been observed in advanced-stage disease. PPARs play crucial roles in adipocyte differentiation and lipid metabolism [\nThrough WGCNA, six core genes, namely,\nIn summary, during the infection of the host by\nOur current research has shed light on the dynamic changes in genes and their associated signaling pathways during the progression of infection by E. multilocularis larvae. Nevertheless, substantial gaps in our knowledge still exist, and reliable experimental validation is urgently needed.", "content_for_embedding": "Alveolar echinococcosis (AE), a parasitic disease instigated by the larvae of the tapeworm\nTranscriptomics, as a cutting-edge technology, has found wide-ranging applications in modern biological research. Currently, it is extensively employed in basic research on microorganisms and plants, clinical diagnostics, and drug development [\nIn this study, we successfully developed a mouse model infected with AE to systematically examine the gene expression profiles in liver tissues. We employed RNA-Seq technology at specific time points to comprehensively capture the dynamic changes in gene expression. Following the RNA-Seq analysis, we carried out quantitative real-time polymerase chain reaction (qRT-PCR) as a rigorous validation step for the results from the RNA-Seq experiment. To gain profound insights into the biological functions of differentially expressed genes (DEGs) in the disease development process, we performed Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) enrichment analyses. These sophisticated bioinformatics tools allowed us to map the DEGs to specific biological processes, molecular functions, and signaling pathways, thus shedding light on the underlying biological mechanisms driving the progression of AE. Furthermore, we utilized weighted gene co-expression network analysis (WGCNA) to identify genes that potentially play crucial roles in the infection caused by\nThe\nLong-clawed mole voles exhibiting visibly enlarged abdomens due to\nAt 6, 12, 19, and 25 weeks post-infection with protoscoleces, all experimental and control groups were euthanized via cervical dislocation and subsequently dissected. Liver tissue samples were collected from regions within 1–5 mm of macroscopically visible parasitic lesions, rinsed in a 10% EDTA solution, transferred into cryovials, flash-frozen in liquid nitrogen, and stored at −80 °C for downstream analyses.\nIn parallel, liver tissues were fixed in 4% formaldehyde solution, dehydrated, and embedded in paraffin for sectioning. Following hematoxylin-and-eosin (HE) staining, pathological changes in the liver tissues were assessed under light microscopy.\nLiver samples (≈2 g) were collected from perilesional areas (1–5 mm from macroscopic lesions) and processed for RNA-Seq. The cDNA libraries were sequenced on the Illumina sequencing platform by Metware Biotechnology Co., Ltd. (Wuhan, China). Briefly, total RNA from the liver tissues was extracted using Trizol reagent. The quality of RNA was checked using an Agilent 2100 Bioanalyzer. RNA samples that passed the quality check were used to construct libraries using the NEBNext\nThe DESeq2 software package [\nWith a significance threshold set at q < 0.05, TBtoolsp [\nThe gene co-expression network was constructed using the R version 4.2.2 software WGCNA 1.71 package [\nTissue RNA was isolated using a Total RNA Extraction kit (Beijing Solaibao Biotechnology Co., Ltd., Beijing, China) and transcribed into cDNA utilizing a cDNA reverse transcription kit (Shanghai Yisheng Biotechnology Co., Ltd., Shanghai, China) according to the manufacturers’ protocols. The resultant cDNA was subsequently amplified using a qPCR SYBR Green Kit (Shanghai Yisheng Biotechnology Co., Ltd.) in a thermocycler (Bio-Rad Laboratories, Inc., Hercules, CA, USA). GAPDH was used as the internal reference, and the relative gene expression level was evaluated by the 2\nUpon conducting autopsies, it was determined that at 6, 12, 19, and 25 weeks post-inoculation with the original head segment, the majority of mice exhibited hepatic alveolar echinococcosis, with infection rates of 10/12, 12/12, 12/12, and 12/12, respectively. At six weeks post-infection, the lesions were confined to the vicinity of the hepatic portal vein. By the twelfth week, the individual lesions had spread, resulting in damage to the diaphragmatic peritoneum. By the twenty-fifth week, over half of the mice (7/12) had experienced diaphragmatic metastasis.\nHE staining of tissue sections revealed that the liver tissue structure of mice in the blank control group was normal, with no obvious inflammatory cell infiltration observed in the portal area. Six weeks after\nIn the experimental group’s livers, proliferating hepatocytes near the parasitic lesions were observed (A). Certain areas of coagulative necrosis were also observed (B, C). The arrows in the figures indicate the parasitic lesions in the livers of the infected mice. These lesions are characterized by the typical germinal layer and laminated layer of Echinococcus multilocularis, surrounded by a periparasitic cellular infiltration composed of macrophages, fibroblasts/myofibroblasts, and lymphocytes, spreading gradually from the center outward. The hepatocytes are disorganized, presenting a reticular structure (D).\nA total of 32 samples, 16 from the experimental group and 16 from the control group, with 4 mice per timepoint, were subjected to transcriptome sequencing analysis. A robust dataset of 215.28 Gb of clean data was obtained, with each sample producing an effective data volume of 6 Gb, maintaining Q30 bases at a percentage of 92% or higher, and exhibiting an average GC content of 49%. Notably, the number of matched reads across all libraries exceeded 94%, confirming the high quality of sequencing and gene annotation, such that the data were suitable for subsequent bioinformatic analysis (\nDifferentially expressed genes (DEGs) were identified using stringent criteria, specifically |log2Fold Change| ≥ 1 and FDR < 0.05. Comparative transcriptomic analyses were conducted on liver tissues from mice at varying stages of\nTwelve genes which showed differential expression at a minimum of two of the four experimental timepoints were selected for confirmation using qRT-PCR. The research findings indicate that the expression trends of these selected genes are consistent with those obtained from the RNA-Seq analysis. However, the performance of some genes in the RNA-Seq and qRT-PCR was not entirely identical, for example, that of\nGO enrichment analysis was conducted to investigate the relevant biological processes, cellular components, and molecular functions at various stages of infection progression (\nKEGG enrichment analysis was conducted to discern enriched signaling pathways across different timepoints during the progression of infection (\nWGCNA was conducted on the transcriptome data to identify genes potentially linked to echinococcus infection. A total of 25,117 genes measured in the transcriptome data were analyzed. The co-expression threshold calculated by the software was set at 12 (\nCurrently, transcriptomic research on echinococcosis has advanced significantly, with extensive studies characterizing the hepatic transcriptional profiles and molecular regulatory networks involved in disease progression [\nMicroscopic examination of AE lesions demonstrates peripheral annular fibrous tissue hyperplasia, accompanied by infiltration of diverse immune cells—including lymphocytes, eosinophils, macrophages, and plasma cells—at the lesion margins. This immune-rich periphery constitutes an inflammatory microenvironment that shares histological similarities with hepatocellular carcinoma. AE lesions lack a complete fibrous capsule and instead exhibit invasive growth patterns, facilitated by a unique immune microenvironment that promotes parasite persistence and immune evasion [\nThis study revealed that at 6 weeks post-infection, transcriptional profiling showed minimal differential gene expression and no significantly enriched pathways, suggesting an initial immune-tolerant phase. By 12 weeks, however, immune-related signaling pathways were markedly activated, with early Th1-mediated responses playing a protective role by suppressing parasite proliferation and mitigating granuloma-associated tissue damage [\nKEGG enrichment analysis revealed that, after 12 weeks of\nActivation of the PPAR signaling pathway has been observed in advanced-stage disease. PPARs play crucial roles in adipocyte differentiation and lipid metabolism [\nThrough WGCNA, six core genes, namely,\nIn summary, during the infection of the host by\nOur current research has shed light on the dynamic changes in genes and their associated signaling pathways during the progression of infection by E. multilocularis larvae. Nevertheless, substantial gaps in our knowledge still exist, and reliable experimental validation is urgently needed.", "topic": "Diagnostic"}
{"pmid": "40417510", "pmcid": "12292877", "title": "Metabolic Reprogramming in Respiratory Viral Infections: A Focus on SARS-CoV-2, Influenza, and Respiratory Syncytial Virus", "publication_year": "N/A", "abstract": "Respiratory infections caused by severe acute respiratory syndrome coronavirus 2, influenza virus, and respiratory syncytial virus pose significant global health challenges, leading to high morbidity and mortality, particularly in vulnerable populations. Despite their distinct virological characteristics, these viruses exploit host cellular metabolism to support replication, modulate immune responses, and promote disease progression. Emerging evidence shows that they induce metabolic reprogramming, shifting cellular energy production toward glycolysis to meet the bioenergetic demands of viral replication. Additionally, alterations in lipid metabolism, including enhanced fatty acid synthesis and disrupted cholesterol homeostasis, facilitate viral entry, replication, and immune evasion. The dysregulation of mitochondrial function and oxidative stress pathways also contributes to disease severity and long-term complications, such as persistent inflammation and immune exhaustion. Understanding these metabolic shifts is crucial for identifying new therapeutic targets and novel biomarkers for early disease detection, prognosis, and patient stratification. This review provides an overview of the metabolic alterations induced by severe acute respiratory syndrome coronavirus 2, influenza virus, and respiratory syncytial virus, highlighting shared and virus-specific mechanisms and potential therapeutic interventions.", "full_text": "Respiratory viral infections remain a significant global health burden, contributing to substantial morbidity and mortality, particularly among vulnerable populations [\nEmerging evidence indicates that viral infections induce profound metabolic reprogramming, shifting cellular energy production, lipid metabolism, and amino acid utilization to favor viral propagation. SARS-CoV-2, influenza virus, and RSV all promote a metabolic switch toward glycolysis (resembling the Warburg effect observed in cancer cells) to meet the bioenergetic and biosynthetic demands of viral replication. Additionally, alterations in lipid metabolism, including increased fatty acid synthesis and disrupted cholesterol homeostasis, play a pivotal role in viral entry, replication, and immune evasion. Furthermore, the dysregulation of mitochondrial function and oxidative stress pathways contributes to disease severity and long-term complications, such as persistent inflammation and immune exhaustion [\nUnderstanding these metabolic alterations is crucial for identifying novel therapeutic targets and optimizing treatment strategies. While current antiviral therapies primarily focus on direct inhibition of viral replication, targeting host metabolic pathways offers a promising complementary approach to limit viral spread and mitigate severe disease outcomes [\nViruses utilize lipid rafts for cell entry, manipulate fatty acid synthesis and β-oxidation to fuel replication, and disrupt cholesterol homeostasis, impairing the innate immune response. Lipid droplets also act as platforms for viral assembly and immune modulation. The interaction between viral infections and mitochondria is essential in lipid metabolism during infectious diseases. In catabolism, mitochondria are the primary site for lipid β-oxidation, where fatty acids are broken down into acetyl-CoA, which enters the Krebs cycle to generate adenosine triphosphate (ATP). In anabolism, mitochondria produce citrate, which is transported to the cytosol and converted into acetyl-CoA for fatty acid synthesis. Thus, mitochondria regulate the balance between lipid degradation and synthesis, adjusting metabolic processes in response to cellular energy demands during infection.\nIn animal cells, phospholipids comprise most of the lipids in cell membranes. However, the plasma membrane also incorporates glycolipids and cholesterol, essential for maintaining membrane fluidity [\nNumerous viruses utilize these lipid rafts as key elements in the fusion process with the host cell. This complex process first requires the virus binding to the cell surface, often via a cell receptor. These interactions induce conformational changes that promote viral entry. Cholesterol, an essential component of rafts, is fundamental in stabilizing these complexes, promoting membrane fluidity, and facilitating fusion with the viral particles [\nThe location of viral receptors within lipid rafts affects the efficiency of the fusion process between the viral particle and the cell membrane. Some receptors are constitutively located in lipid rafts, while others are recruited to rafts after virus binding [\nIn addition to direct fusion with the cell membrane [\nOn the other side, clathrin-independent endocytosis [\nThe central role of lipids in regulating these events has been recognized in the past decade. Although phosphatidylinositol (PI) is the least abundant phospholipid in the cell membrane, its signaling capacity is crucial for endosomal trafficking and maturation [\nThe phosphoinositide 3-kinase (PI3K) pathway is one of the major signaling pathways activated during viral entry. The activation of PI3K and the production of PI triphosphate serve as anchoring platforms for proteins with lipid-binding domains, including Akt, a key regulator of the PI3K pathway [\nDifferent viruses rely on lipid rafts to varying degrees. SARS-CoV-2 primarily enters cells through the binding of spike protein to the angiotensin-converting enzyme 2 (ACE2) receptor, a process facilitated by lipid rafts [\nIn summary, viruses may employ lipid rafts as platforms for viral attachment, fusion, and entry. Many viruses, including SARS-CoV-2, influenza, and RSV, exploit these microdomains to enhance infection efficiency. However, the degree of dependence on lipid rafts varies among viruses. While SARS-CoV-2 primarily utilizes these structures for entry, influenza virus and RSV exhibit greater flexibility, often engaging alternative pathways to facilitate infection. Beyond their role in viral entry, lipid metabolism influences downstream processes critical to viral replication and assembly. In particular, many viruses fine-tune their infection cycle by hijacking phosphoinositide-mediated pathways, ensuring efficient propagation within the host.\nThe relationship between lipid synthesis and glycolysis is schematized in\nViruses exploit fatty acid synthesis to support their replication. SARS-CoV-2 [\nLipid droplets (LDs) are dynamic organelles of a neutral lipid core surrounded by a phospholipid monolayer. They store triacylglycerols and cholesterol esters, which can be mobilized through lipolysis under metabolic stress or increased cellular demand [\nSARS-CoV-2, influenza A, and RSV manipulate LD within host cells through distinct mechanisms to enhance their replication. SARS-CoV-2 promotes their synthesis, as evidenced by increased LD accumulation in monocytes from coronavirus disease (COVID-19) patients compared to uninfected individuals. In vitro studies have shown that SARS-CoV-2 modulates SREBP-1 and DGAT-1 expression, triggering LD formation [\nFatty acid oxidation (β-oxidation) breaks down fatty acids into acetyl-CoA for ATP production in mitochondria and peroxisomes and is regulated by carnitine palmitoyltransferases (CPT) [\nCholesterol is essential to eukaryotic cell membranes, ensuring structural integrity, regulating membrane fluidity, and facilitating key cellular functions such as endocytosis, vesicular transport, and immune response modulation. Cellular cholesterol homeostasis is tightly controlled through endogenous synthesis, receptor-mediated uptake of low-density lipoproteins (LDLs), and high-density lipoprotein (HDL)-dependent efflux, governed by SREBP and liver X receptors [\nHDL particles are considered to be a part of the innate immune system. Under normal conditions, HDLs exhibit anti-inflammatory, antioxidant, and protective properties [\nHowever, during infection and inflammation, the host initiates a cascade of responses known as the acute-phase response, which profoundly disrupts lipid metabolism, particularly HDL function. During the acute-phase response, the levels of key proteins involved in HDL-mediated reverse cholesterol transport decline, including lecithin/cholesterol acyltransferase, cholesterol ester transfer protein, phospholipid transfer protein, apolipoprotein A-I, and paraoxonase 1 [\nIn addition to alterations in HDL composition, infectious diseases induce changes in other lipoproteins. The enhanced secretion of very low-density lipoproteins (VLDLs) is attributed to increased lipolysis in adipose tissue, augmented hepatic fatty acid synthesis, and suppressed fatty acid oxidation. Impaired lipoprotein lipase and apolipoprotein E activity further contribute to reduced VLDL clearance. LDLs are also affected, with their levels varying depending on the type and severity of infection. In some viral infections, LDL concentrations decrease due to increased catabolism or reduced hepatic synthesis, whereas in others, LDL oxidation contributes to foam cell formation, exacerbating inflammation and atherosclerosis. These disruptions in cholesterol homeostasis not only impair lipid transport but may also facilitate immune evasion by pathogens, highlighting the intricate interplay between lipid metabolism and host defense mechanisms [\nRecent studies have indicated that COVID-19 patients have larger and more abundant VLDL particles than healthy individuals, along with elevated VLDL-cholesterol and VLDL–triglyceride concentrations. In contrast, LDL–cholesterol concentrations were lower, with LDL particles being larger and fewer in number. HDL particles exhibited reduced cholesterol content and increased triglycerides, accompanied by a notable decrease in small HDL particles [\nSimilar lipoprotein alterations have been observed in influenza, though the pattern varies. HDL cholesterol levels are often reduced in this disease, while LDL cholesterol levels tend to increase during the acute phase [\nInformation on lipoprotein alterations in RSV infection is scarce. In vitro studies [\nRespiratory virus infections not only alter circulating lipoprotein concentrations but also modify intracellular cholesterol metabolism to enhance viral replication and release. A recent preprint reported that SARS-CoV-2 disrupts host lipid metabolism by inducing lysosomal cholesterol sequestration, a process facilitated by the interaction between the viral protein ORF3a and the host protein VPS39, which impairs cholesterol trafficking and contributes to viral pathogenesis [\nAlterations of respiratory virus infections on the host lipid metabolism are summarized in\nThe metabolic response to viral infections is characterized by alterations in energy demand and mitochondrial function [\nMitochondria play a central role in cellular bioenergetics, integrating energy production with immune signaling. Viral infections frequently disrupt mitochondrial function, leading to altered ATP generation, shifts in metabolic fluxes, and modulation of host defense mechanisms [\nViruses extensively reprogram host cell metabolism to facilitate their replication and persistence. One of the most well-documented metabolic alterations induced by viral infections is the shift towards increased glycolysis, a phenomenon reminiscent of the Warburg effect observed in cancer cells (\nOne of the key mechanisms by which SARS-CoV-2 enhances glycolysis is through the upregulation of enzymes, including hexokinase 2, phosphofructokinase, and lactate dehydrogenase [\nInfluenza virus reprograms host cell metabolism by promoting a shift toward glycolysis, primarily through the activation of HIF-1α, a key regulator of cellular metabolism under hypoxic conditions [\nRSV is another important pathogen known to rewire host cell metabolism towards glycolysis. Like SARS-CoV-2 and influenza, this virus enhances glycolytic flux to sustain viral replication. RSV infection has been shown to activate the insulin receptor-PI3K-Akt axis, upregulate the translation and activity of HIF-1α, increase the expression of GLUT1, GLUT3, and GLUT4, hexokinase 1 and 2, and platelet-type phosphofructokinase, and promote glucose uptake and glycolysis. In addition, mitochondrial damage induced by RSV resulted in the generation of large amounts of reactive oxygen species (ROS) in infected cells, which contributed to stabilizing HIF-1α [\nThe shift towards glycolysis in virally infected cells has profound implications for the host immune response. Activated immune cells, including macrophages, dendritic cells, and T cells, rely on glycolysis for rapid energy production and effector function. However, excessive metabolic reprogramming can harm immune function and disease progression. SARS-CoV-2-infected macrophages exhibit a hyperglycolytic state, leading to increased production of pro-inflammatory cytokines such as interleukin (IL)-6, tumor necrosis factor-α (TNF-α), and IL-1β [\nThe Warburg-like effect in viral infections highlights the intricate relationship between host metabolism and viral pathogenesis. By shifting cellular energy production towards glycolysis while suppressing mitochondrial function, viruses create an environment conducive to their replication. This metabolic reprogramming sustains viral growth and impacts immune function, influencing disease severity and outcomes. Understanding these metabolic alterations provides new insights into antiviral strategies that target host cell metabolism, potentially leading to novel therapeutic interventions for respiratory viral infections.\nMitochondria are essential organelles that serve as the cell’s powerhouse and key regulators of innate immunity. Their ability to generate ATP through OXPHOS is crucial for cellular homeostasis, while their role in immune signaling makes them a primary target for viral manipulation. Numerous viruses have evolved sophisticated mechanisms to disrupt mitochondrial function [\nOne of the major consequences of viral infections on mitochondrial function is the suppression of OXPHOS, which leads to decreased ATP production [\nMitochondria are highly dynamic organelles that continuously undergo fission (division) and fusion (joining) to maintain their function and adapt to cellular demands [\nA crucial component of mitochondrial antiviral defense is the mitochondrial antiviral-signaling protein (MAVS) [\nMitochondria possess quality control mechanisms, such as mitophagy (mitochondrial autophagy), to eliminate damaged mitochondria and maintain cellular homeostasis. Some viruses hijack these pathways to their advantage. For example, the Zika virus activates mitophagy in cultured trophoblasts to degrade mitochondria, suppressing immune responses and prolonging infection [\nMitochondrial dysfunction is a common feature of many viral infections, contributing to metabolic reprogramming, immune evasion, and disease progression. By suppressing OXPHOS, promoting mitochondrial fragmentation, disrupting MAVS signaling, and manipulating mitochondrial quality control, many viruses, including SARS-CoV-2, IV, and RSV, create an environment conducive to favoring their replication and impairing the host defense mechanisms.\nAs discussed in the previous sections, mitochondrial dysfunction and the reprogramming of energy metabolism are hallmarks of viral infections, driving a shift from OXPHOS to glycolysis to support viral replication. Beyond these mitochondrial alterations, viruses also target key cellular metabolic sensors, including AMP-activated protein kinase (AMPK) and mTOR, to further manipulate host cell metabolism in their favor. These pathways are critical in determining whether a cell enters a catabolic or anabolic state, thereby influencing viral replication and immune responses [\nAMPK serves as a central energy sensor that becomes activated under conditions of energy stress, such as viral infection. When ATP levels drop, AMPK is phosphorylated and activated to restore energy homeostasis by promoting catabolic pathways, including fatty acid oxidation and autophagy, while simultaneously inhibiting anabolic processes such as protein and lipid synthesis [\nWhile AMPK functions as a metabolic checkpoint that limits viral replication, mTOR plays an opposing role by promoting anabolic metabolism and cellular growth [\nAnother key metabolic signaling pathway frequently manipulated by viruses is the PI3K-Akt pathway. This pathway is a major upstream activator of mTOR, promoting cell growth and survival by integrating signals from growth factors and nutrients. Activation of PI3K leads to Akt phosphorylation, which activates mTOR complex 1, thereby regulating processes such as protein synthesis and autophagy suppression [\nThe interplay between AMPK, mTOR, and PI3K-Akt highlights the intricate metabolic rewiring during viral infections. While AMPK activation generally acts as a barrier to viral replication by inducing catabolic pathways and inhibiting biosynthesis, mTOR and PI3K-Akt activation facilitate viral propagation by driving anabolic metabolism and cell survival. However, the context-dependent effects of these metabolic regulators must be carefully considered, as their inhibition could also impact immune cell function and host defense mechanisms.\nOverall, viruses have evolved sophisticated strategies to hijack metabolic signaling pathways to optimize their replication and evade immune responses. Understanding the interplay between AMPK, mTOR, and PI3K-Akt in the context of viral infections provides valuable insights into host–virus interactions and potential therapeutic targets to restore metabolic balance and enhance antiviral immunity.\nRespiratory viral infections induce profound disruptions in amino acid and nucleotide metabolism, which are crucial in disease progression and influence viral replication, immune function, and cellular stress responses. Understanding these metabolic shifts provides insight into the host–pathogen interaction and the consequences of viral infections on cellular homeostasis.\nGlutamine is a critical amino acid involved in energy production, nitrogen balance, and the biosynthesis of nucleotides and other amino acids. During viral infections, glutamine metabolism is frequently upregulated to support increased energy demands and nucleotide synthesis required for viral replication. SARS-CoV-2, influenza virus, and RSV infections have been shown to enhance glutaminolysis, contributing to elevated levels of glutamate and downstream metabolites, which provide metabolic intermediates that support viral protein synthesis [\nIn addition to supporting viral replication, glutamine metabolism influences immune cell function. Activated lymphocytes, macrophages, and dendritic cells rely heavily on glutamine for proliferation and cytokine production [\nArginine plays a pivotal role in NO production, which is essential for immune defense [\nArginine metabolism also influences polyamine synthesis, which plays a role in viral RNA stabilization and replication [\nTryptophan metabolism is significantly altered during respiratory viral infections, primarily through activation of the kynurenine pathway by IFN-stimulated enzymes such as indoleamine 2,3-dioxygenase. Elevated serum kynurenine levels have been reported in SARS-CoV-2 infections, correlating with immune suppression and increased inflammatory markers [\nTryptophan metabolism also plays a key role in regulatory T-cell function and immune tolerance. Kynurenine and its downstream metabolites can suppress effector T-cell responses while promoting an anti-inflammatory environment. While beneficial in preventing excessive immune activation, viruses may exploit this mechanism to evade immune detection [\nCysteine availability is crucial for synthesizing glutathione (GSH), a major antioxidant that protects cells from oxidative stress. GSH synthesis is limited by the availability of cysteine, which serves as a rate-limiting substrate in this process [\nIn summary, maintaining adequate cysteine levels is essential for GSH synthesis, which in turn plays a pivotal role in protecting against oxidative stress, regulating inflammation, and ensuring proper immune function during respiratory viral infections.\nRespiratory viruses induce significant alterations in the host’s nucleotide metabolism to ensure sufficient nucleotide availability for viral replication and transcription. They upregulate purine and pyrimidine biosynthesis pathways, facilitating rapid viral genome replication. The increased nucleotide demand imposes metabolic stress on host cells, often leading to nucleotide depletion and cellular dysfunction. In response, host cells enhance nucleotide salvage pathways to compensate. However, the competition between host and viral replication can result in nucleotide shortages, impairing DNA repair mechanisms and immune cell proliferation. This metabolic bottleneck and impaired immune function may contribute to the prolonged recovery observed in severe viral infections [\nSARS-CoV-2, influenza virus, and RSV exploit pyrimidine metabolism, increasing uridine triphosphate and cytidine triphosphate synthesis to support viral genome replication while depleting precursors essential for the host’s adaptive immunity. This metabolic competition can impair T-cell proliferation and antibody production [\nRespiratory viruses trigger increased ROS production through mitochondrial dysfunction, activation of NADPH oxidase (NOX), and inhibition of endogenous antioxidant systems [\nOne proposed way virus-induced oxidative stress can enhance the inflammatory response is by activating inflammasomes, which are multiprotein complexes that initiate an immune response [\nPattern recognition receptors are proteins primarily expressed by cells of the innate immune system that detect molecules characteristic of pathogens. They recognize two main classes of molecular patterns: pathogen-associated molecular patterns, which are derived from microbial pathogens, and damage-associated molecular patterns, which originate from host cell components released during cellular damage or death. Recognition of these patterns leads to the activation of NF-κB and the subsequent production of adhesion molecules and chemokines [\nThe unfolded protein response, activated through inositol-requiring enzyme 1, protein kinase R-like endoplasmic reticulum kinase, and activating transcription factor 6, links oxidative stress with endoplasmic reticulum stress and inflammation [\nWhile inflammation is essential for viral clearance, excessive immune activation can cause severe complications, such as cytokine storms, leading to vascular leakage and multiorgan dysfunction, as seen in severe COVID-19 and influenza cases. Chronic inflammation also depletes antioxidant defenses, increasing cellular vulnerability to oxidative damage.\nThe organism relies on multiple antioxidant systems to defend against oxidative stress. Respiratory virus infections can profoundly disrupt these protective mechanisms. Among the key components involved in maintaining redox homeostasis and regulating inflammatory responses are GSH, superoxide dismutase (SOD), catalase (CAT), and paraoxonase 1 (PON1). Emerging evidence suggests that although respiratory viruses share common pathogenic pathways, they exert distinct and virus-specific effects on the antioxidant systems they impair.\nGSH, the most abundant intracellular non-enzymatic antioxidant, protects cells from oxidative damage by directly scavenging ROS and as a cofactor for glutathione peroxidase. In COVID-19, a marked depletion of GSH has been observed in patients with moderate to severe disease [\nSOD, which catalyzes the dismutation of superoxide radicals into hydrogen peroxide and oxygen, is another critical enzymatic defense. There are three isoforms of SOD: cytosolic (SOD1), mitochondrial (SOD2), and extracellular (SOD3) [\nCAT, responsible for converting hydrogen peroxide into water and oxygen, prevents the accumulation of this toxic intermediate and the subsequent formation of highly reactive hydroxyl radicals. Reduced CAT activity has been reported in SARS-CoV-2, influenza virus, and RSV infections, contributing to redox imbalance and alveolar damage [\nPON1, an esterase associated with HDL, plays a multifaceted antioxidant and anti-inflammatory role. It degrades oxidized lipids, modulates macrophage activation, and helps preserve endothelial function (\nIn comparison, and considering the overall evidence on respiratory viral infections and antioxidant systems, SARS-CoV-2 infection appears to induce a more systemic and persistent oxidative imbalance, likely driven by prolonged viral shedding, endothelial involvement, and dysregulated immune responses. The impact on GSH and PON1 is particularly pronounced, suggesting that these components may be crucial in modulating the severity of COVID-19. Influenza infections, while capable of triggering oxidative stress, often provoke a more localized and transient antioxidant response, with early compensatory increases that may protect against severe tissue damage in immunocompetent hosts. RSV, predominantly affecting infants and older people, leads to intense localized oxidative stress in the lower airways. Depleting GSH and suppressing CAT activity are especially relevant to its pathogenesis. In conclusion, respiratory viruses such as SARS-CoV-2, influenza, and RSV disrupt the host’s antioxidant defense systems through distinct but overlapping mechanisms. The depletion of GSH, reduced activity of SOD and CAT, and suppression of PON1 are key features that contribute to disease severity and tissue damage.\nWhile we have delineated the key metabolic pathways disrupted by respiratory viral infections, the mechanisms through which viruses orchestrate such broad cellular reprogramming remain incompletely understood. Recent studies have highlighted LLPS as a critical organizing principle in the spatial and temporal regulation of cellular processes. In the context of viral infections, LLPS may facilitate the compartmentalization of viral and host factors, enabling efficient hijacking of metabolic machinery and modulation of host responses. The following section examines the emerging role of LLPS in respiratory virus pathogenesis and metabolic reprogramming, offering a mechanistic framework that may partially unify the diverse observations described above.\nLLPS is a biophysical process by which proteins and nucleic acids dynamically condense into membraneless organelles, also known as biomolecular condensates, enabling the compartmentalization of biochemical reactions within the crowded cellular environment [\nSeveral studies showed that some SARS-CoV-2 proteins possess an intrinsic propensity to undergo LLPS [\nThe influenza A virus also exploits LLPS to enhance replication efficiency. The viral nucleoprotein and polymerase components form LLPS-like replication compartments in the nucleus, sometimes referred to as “viral inclusions” [\nIn contrast, RSV has been reported to rely on cytoplasmic LLPS mechanisms. RSV nucleoprotein (N) and phosphoprotein (P) drive the formation of cytoplasmic inclusion bodies that serve as viral replication centers [\nThe formation of viral inclusion bodies may influence cellular metabolism by creating physical barriers to the diffusion of signaling and metabolic proteins, or by altering the localization of enzymes involved in key pathways such as the tricarboxylic acid cycle, lipid metabolism, or nucleotide biosynthesis. Infected cells may also undergo compensatory reprogramming of mitochondrial function or redox balance in response to viral condensates disrupting normal cellular organization.\nViral interference with LLPS may have several metabolic consequences. Enhanced glycolysis and suppressed OXPHOS may result from the mislocalization, conformational change, or inhibition of key metabolic enzymes such as PKM2 and GAPDH, which are known to participate in condensates that regulate glycolytic flux [\nBeyond promoting viral replication, the dysregulation of LLPS has been linked to pathological consequences, including endothelial dysfunction, hyperinflammation, and metabolic syndrome-like manifestations observed in severe cases of COVID-19 and influenza [\nIn the previous sections, we have reviewed how respiratory viruses induce profound alterations in host cell metabolism, reflecting both viral replication strategies and the host immune response. These metabolic disruptions converge on key pathways, including glycolysis, lipid metabolism, mitochondrial function, amino acid turnover, and redox homeostasis. As a result, metabolites and enzymes involved in these pathways represent promising candidates for biomarkers of disease severity, prognosis, and therapeutic response [\nModern science provides powerful analytical tools for exploring the potential of metabolic parameters as disease biomarkers. In addition to traditional techniques such as spectrophotometry and immunoassays, recent decades have witnessed the emergence of advanced approaches, notably multi-omics. Multi-omics refers to the integrative analysis of multiple layers of biological data to comprehensively understand biological systems. This approach reveals complex interactions among genes, proteins, metabolites, and other biomolecules, offering more profound insights into the mechanisms of health, disease progression, and treatment response [\nOmics disciplines can be broadly classified into molecular and phenotypic/clinical categories. Molecular omics encompasses genomics, transcriptomics, proteomics, metabolomics, and epigenomics, each focusing on specific molecular components—DNA, RNA, proteins, metabolites, and epigenetic modifications. Phenotypic or clinical omics includes data derived from clinical observations and diagnostic technologies, such as radiomics, pathomics, and hematological omics. Radiomics extracts quantitative features from medical imaging; pathomics integrates molecular profiles with digital pathology and histological data; and hematological omics involves the detailed molecular and cellular analysis of blood to elucidate the complex biology of hematologic conditions [\nAmong these, metabolomics plays a particularly important role [\nMetabolomics relies on various analytical platforms, each with distinct advantages in terms of sensitivity, specificity, and metabolome coverage. The two most widely employed approaches are mass spectrometry (MS), typically coupled with chromatographic separation techniques such as gas chromatography (GC) or liquid chromatography (LC), and proton nuclear magnetic resonance (\nThe term biomarker is frequently and, at times, indiscriminately used in the biomedical literature. However, the mere presence of a statistically significant difference in the levels of a given parameter between two clinical conditions is not sufficient to classify that parameter as a biomarker. An accurate biomarker is a measurable indicator that distinguishes between two well-defined biological states, such as health versus disease, favorable versus poor prognosis, or responsiveness versus resistance to a specific treatment [\nThis section reviews the most relevant studies identifying candidate metabolites as biomarkers of respiratory viral infections. We also critically evaluate their diagnostic accuracy and practical limitations.\nA comparative lipidomic analysis revealed significant alterations in serum lipid mediators between COVID-19-positive patients and healthy individuals, with elevated levels of O-octanoyl-L-carnitine (CAR 8:0) and lysophosphatidylethanolamine (LPE), and decreased levels of arachidonic acid and oxylipins like 9/13-HODE and 15-HETE [\nLipidomic profiles of lung cells further underscore disease-specific patterns. COVID-19-positive patients exhibited elevated long-chain triglycerides, particularly in immune cells, which could modulate inflammatory signaling. Similar serum triglycerides, VLDL, and polyunsaturated fatty acid elevations have been noted in Ebola and COVID-19 infections [\nOne of the most promising findings was the significant reduction in arachidonic acid in COVID-19 patients, a pattern also observed in cases of influenza A and RSV infections [\nRecently, a novel biosensing platform has been developed using a competitive immunoassay integrated with magnetic microbeads and screen-printed carbon electrodes to quantify arachidonic acid in serum. This system demonstrated high sensitivity, reproducibility, and practicality for clinical settings, with strong concordance with conventional assays [\nLipoprotein alterations detected by\nRecent work by the International COVID-19 Research Network—a global collaboration focused on metabolomics—has contributed significantly to our understanding of how COVID-19 affects human metabolism. Utilizing the B.I. platform, a standardized and automated\nIn a multicenter Spanish cohort,\nAlthough less studied, influenza and RSV infections also induce lipoprotein alterations. Influenza A has been associated with reduced HDL and elevated triglycerides, and lower HDL levels predict worse outcomes [\nThese findings highlight the relevance of lipoprotein profiling in respiratory infections. However, pre-analytical variables, such as sample inactivation, may introduce artifacts [\nComparative studies analyzing the serum metabolomic profiles of healthy individuals, COVID-19-positive patients, and COVID-19-negative patients with infections have revealed pronounced differences in pentose glucuronate interconversion, ascorbate and fructose metabolism, the nucleotide sugar biosynthetic route, as well as nucleotide and amino acid metabolic processes, all of which are related to carbohydrate and energy metabolism [\nDuring viral transcription, the energy requirements and precursor molecules for building viral structural components are primarily supplied by an upregulation of aerobic glycolysis and activation of the pentose phosphate pathway [\nResearchers have also explored whether metabolic profiles differed among COVID-19 patients according to comorbidities and disease severity. Particularly notable were the observations related to the severity of illness. Volcano plot analyses revealed that individuals who required intensive care unit (ICU) admission or who succumbed to the disease exhibited elevated serum levels of lauric acid [\nFurthermore, lower xylitol concentrations were documented in patients requiring intensive care compared to less severe cases. Xylitol, a metabolite derived from the pentose and glucuronate interconversion pathway, has been recognized for its anti-inflammatory, antiglycemic, antiviral, and antibacterial actions in the context of pulmonary infections [\nMoreover, machine learning-based analyses [\nThe biological significance of these observations is not straightforward. Since maltose, mannonic acid, and erythronic acid are predominantly plant-derived compounds and are not endogenously synthesized in large amounts by humans, it has been hypothesized that changes in their serum concentrations may be influenced by alterations in gut microbiota secondary to infection. Indeed, the concept of a gut–lung axis has been proposed, suggesting that respiratory infections can impact the gut microbiota and vice versa, ultimately manifesting in altered circulating metabolite profiles [\nAlthough reprogramming of carbohydrate and energy metabolism is a shared feature among respiratory viral infections, the specific signatures of SARS-CoV-2 differ in essential ways and suggest the presence of unique metabolic biomarkers. Influenza virus, for instance, also enhances glycolysis and pentose phosphate pathway (PPP) activity to support viral replication [\nRSV infection, on the other hand, promotes mitochondrial fragmentation and significantly alters amino acid metabolism, especially glutamine and arginine pathways [\nGSH is the most abundant intracellular antioxidant and a critical regulator of redox homeostasis. GSH depletion and a decreased GSH/GSSG ratio have been consistently reported in viral infections. However, the severity and persistence of these changes appear greater in COVID-19 compared to influenza and RSV. A mechanistic hypothesis [\nSOD and CAT are key enzymatic antioxidants that neutralize superoxide radicals and hydrogen peroxide, respectively. Respiratory virus infections usually elicit a short-lived increase in their activities, followed by suppression or depletion in advanced stages of the disease [\nPON1 activity is reduced during viral infections, but the decrease is especially pronounced in COVID-19 compared to influenza and RSV. Hospitalized COVID-19 patients showed significantly reduced PON1 arylesterase activity [\nAlthough not classical antioxidants, the tryptophan–kynurenine pathway metabolites are modulated by oxidative stress and systemic inflammation. In COVID-19, there is a sustained increase in the kynurenine/tryptophan (Kyn/Trp) ratio, associated with immune activation and disease severity. A metabolomic study reported a high discriminatory performance (AUC = 0.95) for distinguishing COVID-19-positive from COVID-19-negative patients; however, the authors cautioned that these findings should be interpreted carefully due to the limited sample size [\nSummarizing the information presented in this section, redox imbalance emerges as a shared hallmark of respiratory viral infections, yet accumulating evidence points to distinct antioxidant and metabolic signatures for each virus. In COVID-19, key alterations include a marked reduction in GSH and PON1, a consistently elevated kynurenine-to-tryptophan ratio, sustained SOD downregulation, and increased levels of oxidative lipid byproducts such as 4-hydroxynonenal and malondialdehyde. In contrast, influenza virus infection is generally associated with transient oxidative stress, with moderate GSH depletion, variable upregulation of enzymatic antioxidants such as SOD and CAT, and subsequent normalization of redox markers during convalescence. RSV infection shows a different pattern, featuring early mitochondrial oxidative injury, GSH depletion during the acute phase, and increased lipid peroxidation. However, data on enzymatic antioxidant responses in RSV remain limited.\nThese findings suggest that the combined presence of low GSH and PON1 activity, along with elevated kynurenine levels and oxidative lipid metabolites, may constitute a distinctive redox-based biosignature for COVID-19. Importantly, this biosignature not only differentiates COVID-19 from healthy controls, but the results indicate that it may also help to distinguish it from other respiratory viral infections.\nThe metabolic reprogramming induced by respiratory viral infections creates vulnerabilities that can be exploited for therapeutic purposes. Beyond the canonical antiviral approaches, targeting host metabolic pathways altered during infection provides an opportunity to modulate viral replication, control inflammation, and mitigate long-term sequelae. This section identifies promising therapeutic targets emerging from preclinical and clinical studies on SARS-CoV-2, influenza, and RSV, focusing on host metabolic and redox pathways.\nSeveral host factors crucial for viral entry are modulated by cellular metabolic pathways, offering indirect avenues for antiviral intervention. For instance, the expression of the transmembrane protease, serine 2 (TMPRSS2) and ACE2, key entry factors for SARS-CoV-2, can be influenced by metabolic status and hormonal regulation linked to insulin signaling and energy-sensing pathways such as AMPK. Similarly, the fusion machinery of RSV depends on host membrane lipid composition and cholesterol content, both shaped by metabolic activity.\nThese insights have prompted the exploration of drugs that modulate host metabolism to interfere with viral entry. Camostat mesylate, a TMPRSS2 inhibitor, has shown promise in preclinical models by blocking SARS-CoV-2 spike protein priming, thus preventing cell entry [\nAmantadine and rimantadine act on the M2 ion channel protein of influenza A virus, inhibiting viral entry [\nPalivizumab is a monoclonal antibody that specifically targets the protein inducing fusion of RSV to the host epithelial cell membranes (protein F). This compound is used prophylactically to prevent serious lower respiratory tract infections in high-risk children [\nVarious studies have highlighted the reliance of respiratory viruses on host lipid metabolism, including de novo lipogenesis and cholesterol trafficking. FASN inhibitors, such as orlistat, disrupt viral envelope formation and replication in enveloped viruses by interfering with host lipid biosynthesis, and have shown antiviral activity in vitro against SARS-CoV-2, influenza, and RSV [\nStatins, which inhibit HMG-CoA reductase and reduce cholesterol biosynthesis, have demonstrated anti-inflammatory and potential antiviral effects in observational studies of COVID-19, with meta-analyses suggesting a protective effect on mortality [\nOmega-3 fatty acids and their specialized pro-resolving mediators, including resolvins and protectins, have also emerged as modulators of inflammation in viral infections and may counteract the persistent inflammatory response observed in long COVID-19 [\nData on the effect of statins and omega-3 fatty acids on influenza and RSV infections are limited and inconclusive. While some studies suggest statins may reduce influenza prevalence and mortality, others indicate they might increase the risk of common infections. Similarly, omega-3 fatty acids show potential benefits in some cardiovascular studies, but their impact on viral infections is not well-established. Further research is needed to clarify the role of these treatments in preventing or treating viral respiratory illnesses [\nThe enhanced glycolytic flux activation observed in infected cells reflects a shift toward anabolism. Inhibiting key glycolytic enzymes such as hexokinase 2 or 6-phosphofructo-2-kinase/fructose-2,6-biphosphatase 3 (PFKFB3) can reduce viral replication and inflammation. For instance, 2-deoxy-D-glucose has shown efficacy in reducing SARS-CoV-2 replication in vitro and in clinical trials in India, where it shortened oxygen dependency and hospital stay in moderately ill patients [\nOne promising therapeutic avenue is the modulation of mitochondrial dynamics, especially the inhibition of excessive mitochondrial fission, which is associated with inflammation and cell death. Mitochondrial division inhibitor 1 (Mdivi-1), a selective inhibitor of Drp1, prevents mitochondrial fragmentation by blocking Drp1-mediated fission. Studies in experimental animals showed that Mdivi-1 reduces viral-induced mitochondrial fragmentation, restores mitochondrial membrane potential, and attenuates inflammatory cytokine release [\nMoreover, mitochondrial protectants such as melatonin, a potent antioxidant and regulator of mitochondrial homeostasis, have demonstrated anti-inflammatory and antiviral properties in COVID-19 models. Melatonin reduces oxidative stress, supports mitochondrial biogenesis via PGC-1α activation, and modulates immune responses [\nOther pharmacological candidates targeting mitochondrial metabolism include metformin, which supports mitochondrial function via AMPK activation and reduces pro-inflammatory signaling in viral pneumonia [\nPreserving mitochondrial function and preventing mitochondrial fragmentation represent rational strategies to limit inflammation, promote cellular survival, and improve outcomes in respiratory viral infections. Drugs such as Mdivi-1, melatonin, and SS-31 illustrate the potential of this approach, which warrants further investigation in clinical settings. Agents enhancing OXPHOS, such as dichloroacetate, may also counteract the Warburg-like phenotype in infected cells and restore energy balance [\nExperimental evidence from COVID-19, influenza, and RSV models supports the broader applicability of this therapeutic approach. In influenza-infected cells and mice, mitochondrial fission is induced via Drp1 activation, contributing to inflammation and lung injury [\nN-acetylcysteine (NAC), a well-known precursor of cysteine and GSH, has been widely studied among antioxidant therapies. In patients with COVID-19, NAC administration has been associated with improved oxygenation, reduction in inflammatory markers, and lower risk of mechanical ventilation in observational studies [\nMelatonin, an endogenous molecule with antioxidant and anti-inflammatory properties, upregulates enzymatic defenses such as SOD and CAT, and downregulates NF-κB-mediated cytokine production. In preclinical models of viral infections, including RSV and influenza, melatonin treatment has reduced pulmonary inflammation and oxidative stress [\nTempol, a membrane-permeable nitroxide that mimics SOD activity, has shown efficacy in preclinical models by neutralizing superoxide radicals, reducing lipid peroxidation, and attenuating inflammation [\nEbselen, a glutathione peroxidase mimetic, has shown dual action in COVID-19 in an in silico study. This compound possesses direct antiviral activity through the inhibition of the SARS-CoV-2 main protease (Mpro) and has antioxidant effects [\nDespite the growing interest in these antioxidant strategies, the therapeutic modulation of PON1 in viral infections remains largely unexplored. Although reduced PON1 activity has been consistently reported in COVID-19 and associated with disease severity, no pharmacological interventions have been developed to restore PON1 function. Experimental approaches to increase PON1 activity, such as dietary polyphenols, HDL-targeted therapies, or gene modulation, have been proposed in cardiovascular and metabolic diseases [\nThe kynurenine pathway is the principal route of tryptophan catabolism, and its activation plays a central role in immune regulation, oxidative stress, and metabolic control during viral infections. One of its key regulatory enzymes, indoleamine 2,3-dioxygenase 1 (IDO1), is upregulated in response to inflammatory cytokines, particularly IFN-γ, leading to increased conversion of tryptophan into kynurenine and other downstream metabolites. In COVID-19, a persistently elevated Kyn/Trp ratio has been consistently associated with disease severity, lymphopenia, and systemic immune dysregulation [\nGiven its role in immune escape and homeostasis, the kynurenine pathway has emerged as a potential therapeutic target, particularly in diseases marked by chronic inflammation and immune dysfunction. Inhibitors of IDO1, such as epacadostat and navoximod, have been tested extensively in oncology for their ability to reverse immune suppression and restore antitumor immunity [\nIn addition to IDO1 blockade, targeting downstream components of the pathway may offer therapeutic opportunities. For instance, kynurenic acid and quinolinic acid exert neuroactive and pro-oxidant effects, and the possibility exists that they are implicated in the pathophysiology of viral encephalopathy [\nNutritional modulation of the kynurenine pathway is also under investigation. Niacin (vitamin B3), a downstream product of the pathway, may act as a feedback regulator of tryptophan metabolism and has been proposed as an adjunctive therapy to buffer oxidative stress and inflammation [\nDespite these promising avenues, no therapeutic interventions targeting the kynurenine axis have yet been approved or validated in acute viral respiratory infections. Given the strong correlation between the kynurenine pathway and disease severity in COVID-19, this biochemical route represents a compelling target for future translational research.\nMulti-omics approaches provide a comprehensive, systems-level view of disease pathophysiology, enabling the identification of biosignatures that serve as robust diagnostic or prognostic biomarkers and reveal actionable therapeutic targets. Rather than isolated molecular readouts, multi-omics facilitates the construction of dynamic interaction networks that map the cascade of host responses, from gene expression to metabolite accumulation, offering unprecedented precision for therapeutic intervention.\nIn the context of respiratory viral infections, this holistic approach allows for the stratification of patients based on their individual metabolic and immune profiles. For instance, redox status, lipidomic alterations, and amino acid imbalances can guide the personalized use of antioxidant regimens, lipid-modulating agents, amino acid supplementation, or targeted metabolic inhibitors. Notably, integrating metabolic and immune data can help identify patient subgroups more likely to benefit from specific interventions, minimizing ineffective or potentially harmful treatments [\nOne prominent example is the recognition of arginine deficiency in severe COVID-19, derived from metabolomic analyses showing significant depletion of circulating arginine levels. This finding has led to the hypothesis that therapeutic arginine depletion or modulation might influence immune responses and viral replication. Pegylated arginase (PEG-Arg1), which depletes extracellular arginine, has been proposed as a potential therapy to modulate hyperinflammation in COVID-19 [\nFurthermore, machine learning-enhanced metabolomics has demonstrated that combinations of metabolites (e.g., maltose, xylitol, glyceric acid) can differentiate COVID-19 patients from healthy controls and patients without COVID-19 with high accuracy. These panels offer diagnostic utility and may assist in therapeutic stratification, identifying patients with specific metabolic phenotypes that respond better to tailored interventions [\nAnother key application of multi-omics is in the monitoring of therapeutic response. Changes in metabolic or lipidomic profile during treatment can serve as dynamic biomarkers, providing real-time feedback on drug efficacy or therapeutic adjustment [\nUltimately, the multi-omics framework paves the way for a multi-therapeutic approach, combining pharmacological and nutritional strategies adapted to the individual molecular profile. For example, a patient showing GSH depletion, dysregulated kynurenine metabolism, and altered mitochondrial lipid composition could be managed with a tailored regimen combining NAC, AhR modulators, and mitochondrial stabilizers. This personalized, multi-targeted intervention model represents a shift from disease-based to mechanism-based precision medicine, especially relevant for complex viral syndromes like COVID-19 or severe influenza.\nHowever, translating multi-omics findings into clinical practice poses significant challenges, including data standardization, analytical complexity, cost, and interdisciplinary coordination. Nonetheless, ongoing systems biology and computational medicine efforts are progressively overcoming these barriers, bringing personalized multi-therapeutic strategies closer to clinical application [\nRespiratory viral infections such as those caused by SARS-CoV-2, influenza virus, and RSV continue to exert a significant global health burden. Although distinct in structure and host tropism, these viruses share a common feature: the ability to hijack and reprogram host metabolic pathways to facilitate their replication, evade immune responses, and modulate disease progression. This review has detailed how respiratory viruses manipulate lipid metabolism, energy production, amino acid and nucleotide pathways, and oxidative stress responses, often driving the host cell into a pro-viral metabolic state.\nA key advance in recent years has been integrating multi-omics technologies, allowing for a more comprehensive understanding of the host response to infection. These tools facilitate the discovery of biosignatures with diagnostic and prognostic value and highlight actionable metabolic targets. In particular, personalized therapeutic approaches, such as antioxidant regimens tailored to redox imbalance, or amino acid and lipid-based interventions guided by metabolomic signatures, have emerged as promising strategies. Furthermore, targeting virus-induced mitochondrial dysfunction, glycolysis, or pathways like kynurenine metabolism holds translational potential.\nWhile these conceptual and technical advances have been largely propelled by the intense global research efforts on COVID-19, there is a growing recognition that similar efforts are urgently needed for influenza and RSV. Despite the unprecedented depth of metabolic and immunological profiling conducted for SARS-CoV-2, comparable multi-omics datasets and therapeutic trials remain limited for other respiratory viruses. This disparity is especially concerning given recent epidemiological trends. For example, during the 2023–2024 season in the United States, influenza was responsible for approximately 40 million illnesses, 470,000 hospitalizations, and 28,000 deaths, which now rival or exceed those associated with COVID-19 in the same period [\nGiven this context, future research should build upon the methodologies and insights developed during the COVID-19 pandemic to study influenza and RSV with equivalent rigor. Priority areas include expanding the application of multi-omics to uncover metabolic vulnerabilities, conducting randomized clinical trials to validate metabolically guided therapies, and integrating machine learning models for patient stratification and prediction of disease trajectories. Additionally, systems biology approaches that combine omics data with clinical phenotyping will be essential to unravel the complex interplay between viral infection, host metabolism, and immune response.\nIn conclusion, metabolic reprogramming is a central and dynamic aspect of respiratory viral pathogenesis. Leveraging this knowledge deepens our mechanistic understanding and opens new avenues for diagnosis, risk stratification, and therapeutic intervention. Bridging the current research gap between SARS-CoV-2 and other respiratory viruses like influenza and RSV is essential to ensure that all patients benefit from the advances in precision medicine that are now within reach.\nThis review focuses on the metabolic reprogramming of host cells induced by respiratory viral infections, highlighting SARS-CoV-2, influenza virus, and respiratory syncytial virus. While we discuss some interactions between metabolism and immune responses, a comprehensive treatment of immunometabolism—the field studying how metabolic pathways regulate immune cell function and influence infection outcomes—was beyond the scope of this work. Immunometabolic processes have a critical influence on antiviral immunity, inflammation, and disease progression, representing a rapidly evolving area of research. For readers interested in a deeper exploration of immunometabolism in viral infections, we recommend the following recent reviews [\nAdditionally, it is essential to recognize that many metabolic alterations described herein are not exclusive to these respiratory viral infections. Several studies have reported similar metabolic dysregulations, including enhanced glycolysis, mitochondrial dysfunction, and oxidative stress, in bacterial infections such as pneumonia, as well as systemic viral diseases like hepatitis [", "content_for_embedding": "Respiratory viral infections remain a significant global health burden, contributing to substantial morbidity and mortality, particularly among vulnerable populations [\nEmerging evidence indicates that viral infections induce profound metabolic reprogramming, shifting cellular energy production, lipid metabolism, and amino acid utilization to favor viral propagation. SARS-CoV-2, influenza virus, and RSV all promote a metabolic switch toward glycolysis (resembling the Warburg effect observed in cancer cells) to meet the bioenergetic and biosynthetic demands of viral replication. Additionally, alterations in lipid metabolism, including increased fatty acid synthesis and disrupted cholesterol homeostasis, play a pivotal role in viral entry, replication, and immune evasion. Furthermore, the dysregulation of mitochondrial function and oxidative stress pathways contributes to disease severity and long-term complications, such as persistent inflammation and immune exhaustion [\nUnderstanding these metabolic alterations is crucial for identifying novel therapeutic targets and optimizing treatment strategies. While current antiviral therapies primarily focus on direct inhibition of viral replication, targeting host metabolic pathways offers a promising complementary approach to limit viral spread and mitigate severe disease outcomes [\nViruses utilize lipid rafts for cell entry, manipulate fatty acid synthesis and β-oxidation to fuel replication, and disrupt cholesterol homeostasis, impairing the innate immune response. Lipid droplets also act as platforms for viral assembly and immune modulation. The interaction between viral infections and mitochondria is essential in lipid metabolism during infectious diseases. In catabolism, mitochondria are the primary site for lipid β-oxidation, where fatty acids are broken down into acetyl-CoA, which enters the Krebs cycle to generate adenosine triphosphate (ATP). In anabolism, mitochondria produce citrate, which is transported to the cytosol and converted into acetyl-CoA for fatty acid synthesis. Thus, mitochondria regulate the balance between lipid degradation and synthesis, adjusting metabolic processes in response to cellular energy demands during infection.\nIn animal cells, phospholipids comprise most of the lipids in cell membranes. However, the plasma membrane also incorporates glycolipids and cholesterol, essential for maintaining membrane fluidity [\nNumerous viruses utilize these lipid rafts as key elements in the fusion process with the host cell. This complex process first requires the virus binding to the cell surface, often via a cell receptor. These interactions induce conformational changes that promote viral entry. Cholesterol, an essential component of rafts, is fundamental in stabilizing these complexes, promoting membrane fluidity, and facilitating fusion with the viral particles [\nThe location of viral receptors within lipid rafts affects the efficiency of the fusion process between the viral particle and the cell membrane. Some receptors are constitutively located in lipid rafts, while others are recruited to rafts after virus binding [\nIn addition to direct fusion with the cell membrane [\nOn the other side, clathrin-independent endocytosis [\nThe central role of lipids in regulating these events has been recognized in the past decade. Although phosphatidylinositol (PI) is the least abundant phospholipid in the cell membrane, its signaling capacity is crucial for endosomal trafficking and maturation [\nThe phosphoinositide 3-kinase (PI3K) pathway is one of the major signaling pathways activated during viral entry. The activation of PI3K and the production of PI triphosphate serve as anchoring platforms for proteins with lipid-binding domains, including Akt, a key regulator of the PI3K pathway [\nDifferent viruses rely on lipid rafts to varying degrees. SARS-CoV-2 primarily enters cells through the binding of spike protein to the angiotensin-converting enzyme 2 (ACE2) receptor, a process facilitated by lipid rafts [\nIn summary, viruses may employ lipid rafts as platforms for viral attachment, fusion, and entry. Many viruses, including SARS-CoV-2, influenza, and RSV, exploit these microdomains to enhance infection efficiency. However, the degree of dependence on lipid rafts varies among viruses. While SARS-CoV-2 primarily utilizes these structures for entry, influenza virus and RSV exhibit greater flexibility, often engaging alternative pathways to facilitate infection. Beyond their role in viral entry, lipid metabolism influences downstream processes critical to viral replication and assembly. In particular, many viruses fine-tune their infection cycle by hijacking phosphoinositide-mediated pathways, ensuring efficient propagation within the host.\nThe relationship between lipid synthesis and glycolysis is schematized in\nViruses exploit fatty acid synthesis to support their replication. SARS-CoV-2 [\nLipid droplets (LDs) are dynamic organelles of a neutral lipid core surrounded by a phospholipid monolayer. They store triacylglycerols and cholesterol esters, which can be mobilized through lipolysis under metabolic stress or increased cellular demand [\nSARS-CoV-2, influenza A, and RSV manipulate LD within host cells through distinct mechanisms to enhance their replication. SARS-CoV-2 promotes their synthesis, as evidenced by increased LD accumulation in monocytes from coronavirus disease (COVID-19) patients compared to uninfected individuals. In vitro studies have shown that SARS-CoV-2 modulates SREBP-1 and DGAT-1 expression, triggering LD formation [\nFatty acid oxidation (β-oxidation) breaks down fatty acids into acetyl-CoA for ATP production in mitochondria and peroxisomes and is regulated by carnitine palmitoyltransferases (CPT) [\nCholesterol is essential to eukaryotic cell membranes, ensuring structural integrity, regulating membrane fluidity, and facilitating key cellular functions such as endocytosis, vesicular transport, and immune response modulation. Cellular cholesterol homeostasis is tightly controlled through endogenous synthesis, receptor-mediated uptake of low-density lipoproteins (LDLs), and high-density lipoprotein (HDL)-dependent efflux, governed by SREBP and liver X receptors [\nHDL particles are considered to be a part of the innate immune system. Under normal conditions, HDLs exhibit anti-inflammatory, antioxidant, and protective properties [\nHowever, during infection and inflammation, the host initiates a cascade of responses known as the acute-phase response, which profoundly disrupts lipid metabolism, particularly HDL function. During the acute-phase response, the levels of key proteins involved in HDL-mediated reverse cholesterol transport decline, including lecithin/cholesterol acyltransferase, cholesterol ester transfer protein, phospholipid transfer protein, apolipoprotein A-I, and paraoxonase 1 [\nIn addition to alterations in HDL composition, infectious diseases induce changes in other lipoproteins. The enhanced secretion of very low-density lipoproteins (VLDLs) is attributed to increased lipolysis in adipose tissue, augmented hepatic fatty acid synthesis, and suppressed fatty acid oxidation. Impaired lipoprotein lipase and apolipoprotein E activity further contribute to reduced VLDL clearance. LDLs are also affected, with their levels varying depending on the type and severity of infection. In some viral infections, LDL concentrations decrease due to increased catabolism or reduced hepatic synthesis, whereas in others, LDL oxidation contributes to foam cell formation, exacerbating inflammation and atherosclerosis. These disruptions in cholesterol homeostasis not only impair lipid transport but may also facilitate immune evasion by pathogens, highlighting the intricate interplay between lipid metabolism and host defense mechanisms [\nRecent studies have indicated that COVID-19 patients have larger and more abundant VLDL particles than healthy individuals, along with elevated VLDL-cholesterol and VLDL–triglyceride concentrations. In contrast, LDL–cholesterol concentrations were lower, with LDL particles being larger and fewer in number. HDL particles exhibited reduced cholesterol content and increased triglycerides, accompanied by a notable decrease in small HDL particles [\nSimilar lipoprotein alterations have been observed in influenza, though the pattern varies. HDL cholesterol levels are often reduced in this disease, while LDL cholesterol levels tend to increase during the acute phase [\nInformation on lipoprotein alterations in RSV infection is scarce. In vitro studies [\nRespiratory virus infections not only alter circulating lipoprotein concentrations but also modify intracellular cholesterol metabolism to enhance viral replication and release. A recent preprint reported that SARS-CoV-2 disrupts host lipid metabolism by inducing lysosomal cholesterol sequestration, a process facilitated by the interaction between the viral protein ORF3a and the host protein VPS39, which impairs cholesterol trafficking and contributes to viral pathogenesis [\nAlterations of respiratory virus infections on the host lipid metabolism are summarized in\nThe metabolic response to viral infections is characterized by alterations in energy demand and mitochondrial function [\nMitochondria play a central role in cellular bioenergetics, integrating energy production with immune signaling. Viral infections frequently disrupt mitochondrial function, leading to altered ATP generation, shifts in metabolic fluxes, and modulation of host defense mechanisms [\nViruses extensively reprogram host cell metabolism to facilitate their replication and persistence. One of the most well-documented metabolic alterations induced by viral infections is the shift towards increased glycolysis, a phenomenon reminiscent of the Warburg effect observed in cancer cells (\nOne of the key mechanisms by which SARS-CoV-2 enhances glycolysis is through the upregulation of enzymes, including hexokinase 2, phosphofructokinase, and lactate dehydrogenase [\nInfluenza virus reprograms host cell metabolism by promoting a shift toward glycolysis, primarily through the activation of HIF-1α, a key regulator of cellular metabolism under hypoxic conditions [\nRSV is another important pathogen known to rewire host cell metabolism towards glycolysis. Like SARS-CoV-2 and influenza, this virus enhances glycolytic flux to sustain viral replication. RSV infection has been shown to activate the insulin receptor-PI3K-Akt axis, upregulate the translation and activity of HIF-1α, increase the expression of GLUT1, GLUT3, and GLUT4, hexokinase 1 and 2, and platelet-type phosphofructokinase, and promote glucose uptake and glycolysis. In addition, mitochondrial damage induced by RSV resulted in the generation of large amounts of reactive oxygen species (ROS) in infected cells, which contributed to stabilizing HIF-1α [\nThe shift towards glycolysis in virally infected cells has profound implications for the host immune response. Activated immune cells, including macrophages, dendritic cells, and T cells, rely on glycolysis for rapid energy production and effector function. However, excessive metabolic reprogramming can harm immune function and disease progression. SARS-CoV-2-infected macrophages exhibit a hyperglycolytic state, leading to increased production of pro-inflammatory cytokines such as interleukin (IL)-6, tumor necrosis factor-α (TNF-α), and IL-1β [\nThe Warburg-like effect in viral infections highlights the intricate relationship between host metabolism and viral pathogenesis. By shifting cellular energy production towards glycolysis while suppressing mitochondrial function, viruses create an environment conducive to their replication. This metabolic reprogramming sustains viral growth and impacts immune function, influencing disease severity and outcomes. Understanding these metabolic alterations provides new insights into antiviral strategies that target host cell metabolism, potentially leading to novel therapeutic interventions for respiratory viral infections.\nMitochondria are essential organelles that serve as the cell’s powerhouse and key regulators of innate immunity. Their ability to generate ATP through OXPHOS is crucial for cellular homeostasis, while their role in immune signaling makes them a primary target for viral manipulation. Numerous viruses have evolved sophisticated mechanisms to disrupt mitochondrial function [\nOne of the major consequences of viral infections on mitochondrial function is the suppression of OXPHOS, which leads to decreased ATP production [\nMitochondria are highly dynamic organelles that continuously undergo fission (division) and fusion (joining) to maintain their function and adapt to cellular demands [\nA crucial component of mitochondrial antiviral defense is the mitochondrial antiviral-signaling protein (MAVS) [\nMitochondria possess quality control mechanisms, such as mitophagy (mitochondrial autophagy), to eliminate damaged mitochondria and maintain cellular homeostasis. Some viruses hijack these pathways to their advantage. For example, the Zika virus activates mitophagy in cultured trophoblasts to degrade mitochondria, suppressing immune responses and prolonging infection [\nMitochondrial dysfunction is a common feature of many viral infections, contributing to metabolic reprogramming, immune evasion, and disease progression. By suppressing OXPHOS, promoting mitochondrial fragmentation, disrupting MAVS signaling, and manipulating mitochondrial quality control, many viruses, including SARS-CoV-2, IV, and RSV, create an environment conducive to favoring their replication and impairing the host defense mechanisms.\nAs discussed in the previous sections, mitochondrial dysfunction and the reprogramming of energy metabolism are hallmarks of viral infections, driving a shift from OXPHOS to glycolysis to support viral replication. Beyond these mitochondrial alterations, viruses also target key cellular metabolic sensors, including AMP-activated protein kinase (AMPK) and mTOR, to further manipulate host cell metabolism in their favor. These pathways are critical in determining whether a cell enters a catabolic or anabolic state, thereby influencing viral replication and immune responses [\nAMPK serves as a central energy sensor that becomes activated under conditions of energy stress, such as viral infection. When ATP levels drop, AMPK is phosphorylated and activated to restore energy homeostasis by promoting catabolic pathways, including fatty acid oxidation and autophagy, while simultaneously inhibiting anabolic processes such as protein and lipid synthesis [\nWhile AMPK functions as a metabolic checkpoint that limits viral replication, mTOR plays an opposing role by promoting anabolic metabolism and cellular growth [\nAnother key metabolic signaling pathway frequently manipulated by viruses is the PI3K-Akt pathway. This pathway is a major upstream activator of mTOR, promoting cell growth and survival by integrating signals from growth factors and nutrients. Activation of PI3K leads to Akt phosphorylation, which activates mTOR complex 1, thereby regulating processes such as protein synthesis and autophagy suppression [\nThe interplay between AMPK, mTOR, and PI3K-Akt highlights the intricate metabolic rewiring during viral infections. While AMPK activation generally acts as a barrier to viral replication by inducing catabolic pathways and inhibiting biosynthesis, mTOR and PI3K-Akt activation facilitate viral propagation by driving anabolic metabolism and cell survival. However, the context-dependent effects of these metabolic regulators must be carefully considered, as their inhibition could also impact immune cell function and host defense mechanisms.\nOverall, viruses have evolved sophisticated strategies to hijack metabolic signaling pathways to optimize their replication and evade immune responses. Understanding the interplay between AMPK, mTOR, and PI3K-Akt in the context of viral infections provides valuable insights into host–virus interactions and potential therapeutic targets to restore metabolic balance and enhance antiviral immunity.\nRespiratory viral infections induce profound disruptions in amino acid and nucleotide metabolism, which are crucial in disease progression and influence viral replication, immune function, and cellular stress responses. Understanding these metabolic shifts provides insight into the host–pathogen interaction and the consequences of viral infections on cellular homeostasis.\nGlutamine is a critical amino acid involved in energy production, nitrogen balance, and the biosynthesis of nucleotides and other amino acids. During viral infections, glutamine metabolism is frequently upregulated to support increased energy demands and nucleotide synthesis required for viral replication. SARS-CoV-2, influenza virus, and RSV infections have been shown to enhance glutaminolysis, contributing to elevated levels of glutamate and downstream metabolites, which provide metabolic intermediates that support viral protein synthesis [\nIn addition to supporting viral replication, glutamine metabolism influences immune cell function. Activated lymphocytes, macrophages, and dendritic cells rely heavily on glutamine for proliferation and cytokine production [\nArginine plays a pivotal role in NO production, which is essential for immune defense [\nArginine metabolism also influences polyamine synthesis, which plays a role in viral RNA stabilization and replication [\nTryptophan metabolism is significantly altered during respiratory viral infections, primarily through activation of the kynurenine pathway by IFN-stimulated enzymes such as indoleamine 2,3-dioxygenase. Elevated serum kynurenine levels have been reported in SARS-CoV-2 infections, correlating with immune suppression and increased inflammatory markers [\nTryptophan metabolism also plays a key role in regulatory T-cell function and immune tolerance. Kynurenine and its downstream metabolites can suppress effector T-cell responses while promoting an anti-inflammatory environment. While beneficial in preventing excessive immune activation, viruses may exploit this mechanism to evade immune detection [\nCysteine availability is crucial for synthesizing glutathione (GSH), a major antioxidant that protects cells from oxidative stress. GSH synthesis is limited by the availability of cysteine, which serves as a rate-limiting substrate in this process [\nIn summary, maintaining adequate cysteine levels is essential for GSH synthesis, which in turn plays a pivotal role in protecting against oxidative stress, regulating inflammation, and ensuring proper immune function during respiratory viral infections.\nRespiratory viruses induce significant alterations in the host’s nucleotide metabolism to ensure sufficient nucleotide availability for viral replication and transcription. They upregulate purine and pyrimidine biosynthesis pathways, facilitating rapid viral genome replication. The increased nucleotide demand imposes metabolic stress on host cells, often leading to nucleotide depletion and cellular dysfunction. In response, host cells enhance nucleotide salvage pathways to compensate. However, the competition between host and viral replication can result in nucleotide shortages, impairing DNA repair mechanisms and immune cell proliferation. This metabolic bottleneck and impaired immune function may contribute to the prolonged recovery observed in severe viral infections [\nSARS-CoV-2, influenza virus, and RSV exploit pyrimidine metabolism, increasing uridine triphosphate and cytidine triphosphate synthesis to support viral genome replication while depleting precursors essential for the host’s adaptive immunity. This metabolic competition can impair T-cell proliferation and antibody production [\nRespiratory viruses trigger increased ROS production through mitochondrial dysfunction, activation of NADPH oxidase (NOX), and inhibition of endogenous antioxidant systems [\nOne proposed way virus-induced oxidative stress can enhance the inflammatory response is by activating inflammasomes, which are multiprotein complexes that initiate an immune response [\nPattern recognition receptors are proteins primarily expressed by cells of the innate immune system that detect molecules characteristic of pathogens. They recognize two main classes of molecular patterns: pathogen-associated molecular patterns, which are derived from microbial pathogens, and damage-associated molecular patterns, which originate from host cell components released during cellular damage or death. Recognition of these patterns leads to the activation of NF-κB and the subsequent production of adhesion molecules and chemokines [\nThe unfolded protein response, activated through inositol-requiring enzyme 1, protein kinase R-like endoplasmic reticulum kinase, and activating transcription factor 6, links oxidative stress with endoplasmic reticulum stress and inflammation [\nWhile inflammation is essential for viral clearance, excessive immune activation can cause severe complications, such as cytokine storms, leading to vascular leakage and multiorgan dysfunction, as seen in severe COVID-19 and influenza cases. Chronic inflammation also depletes antioxidant defenses, increasing cellular vulnerability to oxidative damage.\nThe organism relies on multiple antioxidant systems to defend against oxidative stress. Respiratory virus infections can profoundly disrupt these protective mechanisms. Among the key components involved in maintaining redox homeostasis and regulating inflammatory responses are GSH, superoxide dismutase (SOD), catalase (CAT), and paraoxonase 1 (PON1). Emerging evidence suggests that although respiratory viruses share common pathogenic pathways, they exert distinct and virus-specific effects on the antioxidant systems they impair.\nGSH, the most abundant intracellular non-enzymatic antioxidant, protects cells from oxidative damage by directly scavenging ROS and as a cofactor for glutathione peroxidase. In COVID-19, a marked depletion of GSH has been observed in patients with moderate to severe disease [\nSOD, which catalyzes the dismutation of superoxide radicals into hydrogen peroxide and oxygen, is another critical enzymatic defense. There are three isoforms of SOD: cytosolic (SOD1), mitochondrial (SOD2), and extracellular (SOD3) [\nCAT, responsible for converting hydrogen peroxide into water and oxygen, prevents the accumulation of this toxic intermediate and the subsequent formation of highly reactive hydroxyl radicals. Reduced CAT activity has been reported in SARS-CoV-2, influenza virus, and RSV infections, contributing to redox imbalance and alveolar damage [\nPON1, an esterase associated with HDL, plays a multifaceted antioxidant and anti-inflammatory role. It degrades oxidized lipids, modulates macrophage activation, and helps preserve endothelial function (\nIn comparison, and considering the overall evidence on respiratory viral infections and antioxidant systems, SARS-CoV-2 infection appears to induce a more systemic and persistent oxidative imbalance, likely driven by prolonged viral shedding, endothelial involvement, and dysregulated immune responses. The impact on GSH and PON1 is particularly pronounced, suggesting that these components may be crucial in modulating the severity of COVID-19. Influenza infections, while capable of triggering oxidative stress, often provoke a more localized and transient antioxidant response, with early compensatory increases that may protect against severe tissue damage in immunocompetent hosts. RSV, predominantly affecting infants and older people, leads to intense localized oxidative stress in the lower airways. Depleting GSH and suppressing CAT activity are especially relevant to its pathogenesis. In conclusion, respiratory viruses such as SARS-CoV-2, influenza, and RSV disrupt the host’s antioxidant defense systems through distinct but overlapping mechanisms. The depletion of GSH, reduced activity of SOD and CAT, and suppression of PON1 are key features that contribute to disease severity and tissue damage.\nWhile we have delineated the key metabolic pathways disrupted by respiratory viral infections, the mechanisms through which viruses orchestrate such broad cellular reprogramming remain incompletely understood. Recent studies have highlighted LLPS as a critical organizing principle in the spatial and temporal regulation of cellular processes. In the context of viral infections, LLPS may facilitate the compartmentalization of viral and host factors, enabling efficient hijacking of metabolic machinery and modulation of host responses. The following section examines the emerging role of LLPS in respiratory virus pathogenesis and metabolic reprogramming, offering a mechanistic framework that may partially unify the diverse observations described above.\nLLPS is a biophysical process by which proteins and nucleic acids dynamically condense into membraneless organelles, also known as biomolecular condensates, enabling the compartmentalization of biochemical reactions within the crowded cellular environment [\nSeveral studies showed that some SARS-CoV-2 proteins possess an intrinsic propensity to undergo LLPS [\nThe influenza A virus also exploits LLPS to enhance replication efficiency. The viral nucleoprotein and polymerase components form LLPS-like replication compartments in the nucleus, sometimes referred to as “viral inclusions” [\nIn contrast, RSV has been reported to rely on cytoplasmic LLPS mechanisms. RSV nucleoprotein (N) and phosphoprotein (P) drive the formation of cytoplasmic inclusion bodies that serve as viral replication centers [\nThe formation of viral inclusion bodies may influence cellular metabolism by creating physical barriers to the diffusion of signaling and metabolic proteins, or by altering the localization of enzymes involved in key pathways such as the tricarboxylic acid cycle, lipid metabolism, or nucleotide biosynthesis. Infected cells may also undergo compensatory reprogramming of mitochondrial function or redox balance in response to viral condensates disrupting normal cellular organization.\nViral interference with LLPS may have several metabolic consequences. Enhanced glycolysis and suppressed OXPHOS may result from the mislocalization, conformational change, or inhibition of key metabolic enzymes such as PKM2 and GAPDH, which are known to participate in condensates that regulate glycolytic flux [\nBeyond promoting viral replication, the dysregulation of LLPS has been linked to pathological consequences, including endothelial dysfunction, hyperinflammation, and metabolic syndrome-like manifestations observed in severe cases of COVID-19 and influenza [\nIn the previous sections, we have reviewed how respiratory viruses induce profound alterations in host cell metabolism, reflecting both viral replication strategies and the host immune response. These metabolic disruptions converge on key pathways, including glycolysis, lipid metabolism, mitochondrial function, amino acid turnover, and redox homeostasis. As a result, metabolites and enzymes involved in these pathways represent promising candidates for biomarkers of disease severity, prognosis, and therapeutic response [\nModern science provides powerful analytical tools for exploring the potential of metabolic parameters as disease biomarkers. In addition to traditional techniques such as spectrophotometry and immunoassays, recent decades have witnessed the emergence of advanced approaches, notably multi-omics. Multi-omics refers to the integrative analysis of multiple layers of biological data to comprehensively understand biological systems. This approach reveals complex interactions among genes, proteins, metabolites, and other biomolecules, offering more profound insights into the mechanisms of health, disease progression, and treatment response [\nOmics disciplines can be broadly classified into molecular and phenotypic/clinical categories. Molecular omics encompasses genomics, transcriptomics, proteomics, metabolomics, and epigenomics, each focusing on specific molecular components—DNA, RNA, proteins, metabolites, and epigenetic modifications. Phenotypic or clinical omics includes data derived from clinical observations and diagnostic technologies, such as radiomics, pathomics, and hematological omics. Radiomics extracts quantitative features from medical imaging; pathomics integrates molecular profiles with digital pathology and histological data; and hematological omics involves the detailed molecular and cellular analysis of blood to elucidate the complex biology of hematologic conditions [\nAmong these, metabolomics plays a particularly important role [\nMetabolomics relies on various analytical platforms, each with distinct advantages in terms of sensitivity, specificity, and metabolome coverage. The two most widely employed approaches are mass spectrometry (MS), typically coupled with chromatographic separation techniques such as gas chromatography (GC) or liquid chromatography (LC), and proton nuclear magnetic resonance (\nThe term biomarker is frequently and, at times, indiscriminately used in the biomedical literature. However, the mere presence of a statistically significant difference in the levels of a given parameter between two clinical conditions is not sufficient to classify that parameter as a biomarker. An accurate biomarker is a measurable indicator that distinguishes between two well-defined biological states, such as health versus disease, favorable versus poor prognosis, or responsiveness versus resistance to a specific treatment [\nThis section reviews the most relevant studies identifying candidate metabolites as biomarkers of respiratory viral infections. We also critically evaluate their diagnostic accuracy and practical limitations.\nA comparative lipidomic analysis revealed significant alterations in serum lipid mediators between COVID-19-positive patients and healthy individuals, with elevated levels of O-octanoyl-L-carnitine (CAR 8:0) and lysophosphatidylethanolamine (LPE), and decreased levels of arachidonic acid and oxylipins like 9/13-HODE and 15-HETE [\nLipidomic profiles of lung cells further underscore disease-specific patterns. COVID-19-positive patients exhibited elevated long-chain triglycerides, particularly in immune cells, which could modulate inflammatory signaling. Similar serum triglycerides, VLDL, and polyunsaturated fatty acid elevations have been noted in Ebola and COVID-19 infections [\nOne of the most promising findings was the significant reduction in arachidonic acid in COVID-19 patients, a pattern also observed in cases of influenza A and RSV infections [\nRecently, a novel biosensing platform has been developed using a competitive immunoassay integrated with magnetic microbeads and screen-printed carbon electrodes to quantify arachidonic acid in serum. This system demonstrated high sensitivity, reproducibility, and practicality for clinical settings, with strong concordance with conventional assays [\nLipoprotein alterations detected by\nRecent work by the International COVID-19 Research Network—a global collaboration focused on metabolomics—has contributed significantly to our understanding of how COVID-19 affects human metabolism. Utilizing the B.I. platform, a standardized and automated\nIn a multicenter Spanish cohort,\nAlthough less studied, influenza and RSV infections also induce lipoprotein alterations. Influenza A has been associated with reduced HDL and elevated triglycerides, and lower HDL levels predict worse outcomes [\nThese findings highlight the relevance of lipoprotein profiling in respiratory infections. However, pre-analytical variables, such as sample inactivation, may introduce artifacts [\nComparative studies analyzing the serum metabolomic profiles of healthy individuals, COVID-19-positive patients, and COVID-19-negative patients with infections have revealed pronounced differences in pentose glucuronate interconversion, ascorbate and fructose metabolism, the nucleotide sugar biosynthetic route, as well as nucleotide and amino acid metabolic processes, all of which are related to carbohydrate and energy metabolism [\nDuring viral transcription, the energy requirements and precursor molecules for building viral structural components are primarily supplied by an upregulation of aerobic glycolysis and activation of the pentose phosphate pathway [\nResearchers have also explored whether metabolic profiles differed among COVID-19 patients according to comorbidities and disease severity. Particularly notable were the observations related to the severity of illness. Volcano plot analyses revealed that individuals who required intensive care unit (ICU) admission or who succumbed to the disease exhibited elevated serum levels of lauric acid [\nFurthermore, lower xylitol concentrations were documented in patients requiring intensive care compared to less severe cases. Xylitol, a metabolite derived from the pentose and glucuronate interconversion pathway, has been recognized for its anti-inflammatory, antiglycemic, antiviral, and antibacterial actions in the context of pulmonary infections [\nMoreover, machine learning-based analyses [\nThe biological significance of these observations is not straightforward. Since maltose, mannonic acid, and erythronic acid are predominantly plant-derived compounds and are not endogenously synthesized in large amounts by humans, it has been hypothesized that changes in their serum concentrations may be influenced by alterations in gut microbiota secondary to infection. Indeed, the concept of a gut–lung axis has been proposed, suggesting that respiratory infections can impact the gut microbiota and vice versa, ultimately manifesting in altered circulating metabolite profiles [\nAlthough reprogramming of carbohydrate and energy metabolism is a shared feature among respiratory viral infections, the specific signatures of SARS-CoV-2 differ in essential ways and suggest the presence of unique metabolic biomarkers. Influenza virus, for instance, also enhances glycolysis and pentose phosphate pathway (PPP) activity to support viral replication [\nRSV infection, on the other hand, promotes mitochondrial fragmentation and significantly alters amino acid metabolism, especially glutamine and arginine pathways [\nGSH is the most abundant intracellular antioxidant and a critical regulator of redox homeostasis. GSH depletion and a decreased GSH/GSSG ratio have been consistently reported in viral infections. However, the severity and persistence of these changes appear greater in COVID-19 compared to influenza and RSV. A mechanistic hypothesis [\nSOD and CAT are key enzymatic antioxidants that neutralize superoxide radicals and hydrogen peroxide, respectively. Respiratory virus infections usually elicit a short-lived increase in their activities, followed by suppression or depletion in advanced stages of the disease [\nPON1 activity is reduced during viral infections, but the decrease is especially pronounced in COVID-19 compared to influenza and RSV. Hospitalized COVID-19 patients showed significantly reduced PON1 arylesterase activity [\nAlthough not classical antioxidants, the tryptophan–kynurenine pathway metabolites are modulated by oxidative stress and systemic inflammation. In COVID-19, there is a sustained increase in the kynurenine/tryptophan (Kyn/Trp) ratio, associated with immune activation and disease severity. A metabolomic study reported a high discriminatory performance (AUC = 0.95) for distinguishing COVID-19-positive from COVID-19-negative patients; however, the authors cautioned that these findings should be interpreted carefully due to the limited sample size [\nSummarizing the information presented in this section, redox imbalance emerges as a shared hallmark of respiratory viral infections, yet accumulating evidence points to distinct antioxidant and metabolic signatures for each virus. In COVID-19, key alterations include a marked reduction in GSH and PON1, a consistently elevated kynurenine-to-tryptophan ratio, sustained SOD downregulation, and increased levels of oxidative lipid byproducts such as 4-hydroxynonenal and malondialdehyde. In contrast, influenza virus infection is generally associated with transient oxidative stress, with moderate GSH depletion, variable upregulation of enzymatic antioxidants such as SOD and CAT, and subsequent normalization of redox markers during convalescence. RSV infection shows a different pattern, featuring early mitochondrial oxidative injury, GSH depletion during the acute phase, and increased lipid peroxidation. However, data on enzymatic antioxidant responses in RSV remain limited.\nThese findings suggest that the combined presence of low GSH and PON1 activity, along with elevated kynurenine levels and oxidative lipid metabolites, may constitute a distinctive redox-based biosignature for COVID-19. Importantly, this biosignature not only differentiates COVID-19 from healthy controls, but the results indicate that it may also help to distinguish it from other respiratory viral infections.\nThe metabolic reprogramming induced by respiratory viral infections creates vulnerabilities that can be exploited for therapeutic purposes. Beyond the canonical antiviral approaches, targeting host metabolic pathways altered during infection provides an opportunity to modulate viral replication, control inflammation, and mitigate long-term sequelae. This section identifies promising therapeutic targets emerging from preclinical and clinical studies on SARS-CoV-2, influenza, and RSV, focusing on host metabolic and redox pathways.\nSeveral host factors crucial for viral entry are modulated by cellular metabolic pathways, offering indirect avenues for antiviral intervention. For instance, the expression of the transmembrane protease, serine 2 (TMPRSS2) and ACE2, key entry factors for SARS-CoV-2, can be influenced by metabolic status and hormonal regulation linked to insulin signaling and energy-sensing pathways such as AMPK. Similarly, the fusion machinery of RSV depends on host membrane lipid composition and cholesterol content, both shaped by metabolic activity.\nThese insights have prompted the exploration of drugs that modulate host metabolism to interfere with viral entry. Camostat mesylate, a TMPRSS2 inhibitor, has shown promise in preclinical models by blocking SARS-CoV-2 spike protein priming, thus preventing cell entry [\nAmantadine and rimantadine act on the M2 ion channel protein of influenza A virus, inhibiting viral entry [\nPalivizumab is a monoclonal antibody that specifically targets the protein inducing fusion of RSV to the host epithelial cell membranes (protein F). This compound is used prophylactically to prevent serious lower respiratory tract infections in high-risk children [\nVarious studies have highlighted the reliance of respiratory viruses on host lipid metabolism, including de novo lipogenesis and cholesterol trafficking. FASN inhibitors, such as orlistat, disrupt viral envelope formation and replication in enveloped viruses by interfering with host lipid biosynthesis, and have shown antiviral activity in vitro against SARS-CoV-2, influenza, and RSV [\nStatins, which inhibit HMG-CoA reductase and reduce cholesterol biosynthesis, have demonstrated anti-inflammatory and potential antiviral effects in observational studies of COVID-19, with meta-analyses suggesting a protective effect on mortality [\nOmega-3 fatty acids and their specialized pro-resolving mediators, including resolvins and protectins, have also emerged as modulators of inflammation in viral infections and may counteract the persistent inflammatory response observed in long COVID-19 [\nData on the effect of statins and omega-3 fatty acids on influenza and RSV infections are limited and inconclusive. While some studies suggest statins may reduce influenza prevalence and mortality, others indicate they might increase the risk of common infections. Similarly, omega-3 fatty acids show potential benefits in some cardiovascular studies, but their impact on viral infections is not well-established. Further research is needed to clarify the role of these treatments in preventing or treating viral respiratory illnesses [\nThe enhanced glycolytic flux activation observed in infected cells reflects a shift toward anabolism. Inhibiting key glycolytic enzymes such as hexokinase 2 or 6-phosphofructo-2-kinase/fructose-2,6-biphosphatase 3 (PFKFB3) can reduce viral replication and inflammation. For instance, 2-deoxy-D-glucose has shown efficacy in reducing SARS-CoV-2 replication in vitro and in clinical trials in India, where it shortened oxygen dependency and hospital stay in moderately ill patients [\nOne promising therapeutic avenue is the modulation of mitochondrial dynamics, especially the inhibition of excessive mitochondrial fission, which is associated with inflammation and cell death. Mitochondrial division inhibitor 1 (Mdivi-1), a selective inhibitor of Drp1, prevents mitochondrial fragmentation by blocking Drp1-mediated fission. Studies in experimental animals showed that Mdivi-1 reduces viral-induced mitochondrial fragmentation, restores mitochondrial membrane potential, and attenuates inflammatory cytokine release [\nMoreover, mitochondrial protectants such as melatonin, a potent antioxidant and regulator of mitochondrial homeostasis, have demonstrated anti-inflammatory and antiviral properties in COVID-19 models. Melatonin reduces oxidative stress, supports mitochondrial biogenesis via PGC-1α activation, and modulates immune responses [\nOther pharmacological candidates targeting mitochondrial metabolism include metformin, which supports mitochondrial function via AMPK activation and reduces pro-inflammatory signaling in viral pneumonia [\nPreserving mitochondrial function and preventing mitochondrial fragmentation represent rational strategies to limit inflammation, promote cellular survival, and improve outcomes in respiratory viral infections. Drugs such as Mdivi-1, melatonin, and SS-31 illustrate the potential of this approach, which warrants further investigation in clinical settings. Agents enhancing OXPHOS, such as dichloroacetate, may also counteract the Warburg-like phenotype in infected cells and restore energy balance [\nExperimental evidence from COVID-19, influenza, and RSV models supports the broader applicability of this therapeutic approach. In influenza-infected cells and mice, mitochondrial fission is induced via Drp1 activation, contributing to inflammation and lung injury [\nN-acetylcysteine (NAC), a well-known precursor of cysteine and GSH, has been widely studied among antioxidant therapies. In patients with COVID-19, NAC administration has been associated with improved oxygenation, reduction in inflammatory markers, and lower risk of mechanical ventilation in observational studies [\nMelatonin, an endogenous molecule with antioxidant and anti-inflammatory properties, upregulates enzymatic defenses such as SOD and CAT, and downregulates NF-κB-mediated cytokine production. In preclinical models of viral infections, including RSV and influenza, melatonin treatment has reduced pulmonary inflammation and oxidative stress [\nTempol, a membrane-permeable nitroxide that mimics SOD activity, has shown efficacy in preclinical models by neutralizing superoxide radicals, reducing lipid peroxidation, and attenuating inflammation [\nEbselen, a glutathione peroxidase mimetic, has shown dual action in COVID-19 in an in silico study. This compound possesses direct antiviral activity through the inhibition of the SARS-CoV-2 main protease (Mpro) and has antioxidant effects [\nDespite the growing interest in these antioxidant strategies, the therapeutic modulation of PON1 in viral infections remains largely unexplored. Although reduced PON1 activity has been consistently reported in COVID-19 and associated with disease severity, no pharmacological interventions have been developed to restore PON1 function. Experimental approaches to increase PON1 activity, such as dietary polyphenols, HDL-targeted therapies, or gene modulation, have been proposed in cardiovascular and metabolic diseases [\nThe kynurenine pathway is the principal route of tryptophan catabolism, and its activation plays a central role in immune regulation, oxidative stress, and metabolic control during viral infections. One of its key regulatory enzymes, indoleamine 2,3-dioxygenase 1 (IDO1), is upregulated in response to inflammatory cytokines, particularly IFN-γ, leading to increased conversion of tryptophan into kynurenine and other downstream metabolites. In COVID-19, a persistently elevated Kyn/Trp ratio has been consistently associated with disease severity, lymphopenia, and systemic immune dysregulation [\nGiven its role in immune escape and homeostasis, the kynurenine pathway has emerged as a potential therapeutic target, particularly in diseases marked by chronic inflammation and immune dysfunction. Inhibitors of IDO1, such as epacadostat and navoximod, have been tested extensively in oncology for their ability to reverse immune suppression and restore antitumor immunity [\nIn addition to IDO1 blockade, targeting downstream components of the pathway may offer therapeutic opportunities. For instance, kynurenic acid and quinolinic acid exert neuroactive and pro-oxidant effects, and the possibility exists that they are implicated in the pathophysiology of viral encephalopathy [\nNutritional modulation of the kynurenine pathway is also under investigation. Niacin (vitamin B3), a downstream product of the pathway, may act as a feedback regulator of tryptophan metabolism and has been proposed as an adjunctive therapy to buffer oxidative stress and inflammation [\nDespite these promising avenues, no therapeutic interventions targeting the kynurenine axis have yet been approved or validated in acute viral respiratory infections. Given the strong correlation between the kynurenine pathway and disease severity in COVID-19, this biochemical route represents a compelling target for future translational research.\nMulti-omics approaches provide a comprehensive, systems-level view of disease pathophysiology, enabling the identification of biosignatures that serve as robust diagnostic or prognostic biomarkers and reveal actionable therapeutic targets. Rather than isolated molecular readouts, multi-omics facilitates the construction of dynamic interaction networks that map the cascade of host responses, from gene expression to metabolite accumulation, offering unprecedented precision for therapeutic intervention.\nIn the context of respiratory viral infections, this holistic approach allows for the stratification of patients based on their individual metabolic and immune profiles. For instance, redox status, lipidomic alterations, and amino acid imbalances can guide the personalized use of antioxidant regimens, lipid-modulating agents, amino acid supplementation, or targeted metabolic inhibitors. Notably, integrating metabolic and immune data can help identify patient subgroups more likely to benefit from specific interventions, minimizing ineffective or potentially harmful treatments [\nOne prominent example is the recognition of arginine deficiency in severe COVID-19, derived from metabolomic analyses showing significant depletion of circulating arginine levels. This finding has led to the hypothesis that therapeutic arginine depletion or modulation might influence immune responses and viral replication. Pegylated arginase (PEG-Arg1), which depletes extracellular arginine, has been proposed as a potential therapy to modulate hyperinflammation in COVID-19 [\nFurthermore, machine learning-enhanced metabolomics has demonstrated that combinations of metabolites (e.g., maltose, xylitol, glyceric acid) can differentiate COVID-19 patients from healthy controls and patients without COVID-19 with high accuracy. These panels offer diagnostic utility and may assist in therapeutic stratification, identifying patients with specific metabolic phenotypes that respond better to tailored interventions [\nAnother key application of multi-omics is in the monitoring of therapeutic response. Changes in metabolic or lipidomic profile during treatment can serve as dynamic biomarkers, providing real-time feedback on drug efficacy or therapeutic adjustment [\nUltimately, the multi-omics framework paves the way for a multi-therapeutic approach, combining pharmacological and nutritional strategies adapted to the individual molecular profile. For example, a patient showing GSH depletion, dysregulated kynurenine metabolism, and altered mitochondrial lipid composition could be managed with a tailored regimen combining NAC, AhR modulators, and mitochondrial stabilizers. This personalized, multi-targeted intervention model represents a shift from disease-based to mechanism-based precision medicine, especially relevant for complex viral syndromes like COVID-19 or severe influenza.\nHowever, translating multi-omics findings into clinical practice poses significant challenges, including data standardization, analytical complexity, cost, and interdisciplinary coordination. Nonetheless, ongoing systems biology and computational medicine efforts are progressively overcoming these barriers, bringing personalized multi-therapeutic strategies closer to clinical application [\nRespiratory viral infections such as those caused by SARS-CoV-2, influenza virus, and RSV continue to exert a significant global health burden. Although distinct in structure and host tropism, these viruses share a common feature: the ability to hijack and reprogram host metabolic pathways to facilitate their replication, evade immune responses, and modulate disease progression. This review has detailed how respiratory viruses manipulate lipid metabolism, energy production, amino acid and nucleotide pathways, and oxidative stress responses, often driving the host cell into a pro-viral metabolic state.\nA key advance in recent years has been integrating multi-omics technologies, allowing for a more comprehensive understanding of the host response to infection. These tools facilitate the discovery of biosignatures with diagnostic and prognostic value and highlight actionable metabolic targets. In particular, personalized therapeutic approaches, such as antioxidant regimens tailored to redox imbalance, or amino acid and lipid-based interventions guided by metabolomic signatures, have emerged as promising strategies. Furthermore, targeting virus-induced mitochondrial dysfunction, glycolysis, or pathways like kynurenine metabolism holds translational potential.\nWhile these conceptual and technical advances have been largely propelled by the intense global research efforts on COVID-19, there is a growing recognition that similar efforts are urgently needed for influenza and RSV. Despite the unprecedented depth of metabolic and immunological profiling conducted for SARS-CoV-2, comparable multi-omics datasets and therapeutic trials remain limited for other respiratory viruses. This disparity is especially concerning given recent epidemiological trends. For example, during the 2023–2024 season in the United States, influenza was responsible for approximately 40 million illnesses, 470,000 hospitalizations, and 28,000 deaths, which now rival or exceed those associated with COVID-19 in the same period [\nGiven this context, future research should build upon the methodologies and insights developed during the COVID-19 pandemic to study influenza and RSV with equivalent rigor. Priority areas include expanding the application of multi-omics to uncover metabolic vulnerabilities, conducting randomized clinical trials to validate metabolically guided therapies, and integrating machine learning models for patient stratification and prediction of disease trajectories. Additionally, systems biology approaches that combine omics data with clinical phenotyping will be essential to unravel the complex interplay between viral infection, host metabolism, and immune response.\nIn conclusion, metabolic reprogramming is a central and dynamic aspect of respiratory viral pathogenesis. Leveraging this knowledge deepens our mechanistic understanding and opens new avenues for diagnosis, risk stratification, and therapeutic intervention. Bridging the current research gap between SARS-CoV-2 and other respiratory viruses like influenza and RSV is essential to ensure that all patients benefit from the advances in precision medicine that are now within reach.\nThis review focuses on the metabolic reprogramming of host cells induced by respiratory viral infections, highlighting SARS-CoV-2, influenza virus, and respiratory syncytial virus. While we discuss some interactions between metabolism and immune responses, a comprehensive treatment of immunometabolism—the field studying how metabolic pathways regulate immune cell function and influence infection outcomes—was beyond the scope of this work. Immunometabolic processes have a critical influence on antiviral immunity, inflammation, and disease progression, representing a rapidly evolving area of research. For readers interested in a deeper exploration of immunometabolism in viral infections, we recommend the following recent reviews [\nAdditionally, it is essential to recognize that many metabolic alterations described herein are not exclusive to these respiratory viral infections. Several studies have reported similar metabolic dysregulations, including enhanced glycolysis, mitochondrial dysfunction, and oxidative stress, in bacterial infections such as pneumonia, as well as systemic viral diseases like hepatitis [", "topic": "Diagnostic"}
